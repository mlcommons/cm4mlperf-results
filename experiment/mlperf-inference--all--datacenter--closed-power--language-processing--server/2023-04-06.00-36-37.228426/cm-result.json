[
  {
    "Accuracy": 90.36306105137962,
    "Accuracy_div_100": 0.90363,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Krai/results/r282_z93_q5e-qaic-v1.6.80-aic100/bert-99/server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Krai",
    "Platform": "r282_z93_q5e-qaic-v1.6.80-aic100",
    "Result": 2848.1,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Gigabyte R282-Z93 (5x QAIC100, EE)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 5,
    "compliance": 1,
    "errors": 0,
    "framework": "Qualcomm Cloud AI SDK v1.6.80",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 7282 16-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "CentOS 7 (Linux kernel: 5.4.1-1.el7.elrepo.x86_64 #1 SMP Fri Nov 29 10:21:13 EST 2019 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "6729d43829d4425b",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Krai/results/r282_z93_q5e-qaic-v1.6.80-aic100/bert-99/server",
    "version": "v2.0",
    "Result_Power": 424.3088685524124,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 90.36306105137962,
    "Accuracy_div_100": 0.90363,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Krai/results/r282_z93_q5e-qaic-v1.6.80-aic100/bert-99/server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Krai",
    "Platform": "r282_z93_q5e-qaic-v1.6.80-aic100",
    "Result": 2848.1,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Gigabyte R282-Z93 (5x QAIC100, EE)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 5,
    "compliance": 1,
    "errors": 0,
    "framework": "Qualcomm Cloud AI SDK v1.6.80",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 7282 16-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "CentOS 7 (Linux kernel: 5.4.1-1.el7.elrepo.x86_64 #1 SMP Fri Nov 29 10:21:13 EST 2019 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "6729d43829d4425b",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Krai/results/r282_z93_q5e-qaic-v1.6.80-aic100/bert-99/server",
    "version": "v2.0",
    "Result_Power": 424.3088685524124,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 90.87603921605954,
    "Accuracy_div_100": 0.90876,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Krai/results/r282_z93_q5e-qaic-v1.6.80-aic100/bert-99.9/server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Krai",
    "Platform": "r282_z93_q5e-qaic-v1.6.80-aic100",
    "Result": 1300.33,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Gigabyte R282-Z93 (5x QAIC100, EE)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 5,
    "compliance": 1,
    "errors": 0,
    "framework": "Qualcomm Cloud AI SDK v1.6.80",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 7282 16-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "CentOS 7 (Linux kernel: 5.4.1-1.el7.elrepo.x86_64 #1 SMP Fri Nov 29 10:21:13 EST 2019 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "ec85cdd7f4d34cc4",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Krai/results/r282_z93_q5e-qaic-v1.6.80-aic100/bert-99.9/server",
    "version": "v2.0",
    "Result_Power": 397.7072333333332,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 90.87603921605954,
    "Accuracy_div_100": 0.90876,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Krai/results/r282_z93_q5e-qaic-v1.6.80-aic100/bert-99.9/server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Krai",
    "Platform": "r282_z93_q5e-qaic-v1.6.80-aic100",
    "Result": 1300.33,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Gigabyte R282-Z93 (5x QAIC100, EE)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 5,
    "compliance": 1,
    "errors": 0,
    "framework": "Qualcomm Cloud AI SDK v1.6.80",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 7282 16-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "CentOS 7 (Linux kernel: 5.4.1-1.el7.elrepo.x86_64 #1 SMP Fri Nov 29 10:21:13 EST 2019 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "ec85cdd7f4d34cc4",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Krai/results/r282_z93_q5e-qaic-v1.6.80-aic100/bert-99.9/server",
    "version": "v2.0",
    "Result_Power": 397.7072333333332,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 90.36306105137962,
    "Accuracy_div_100": 0.90363,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Krai/results/r282_z93_q8_dc-qaic-v1.6.80-aic100/bert-99/server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Krai",
    "Platform": "r282_z93_q8_dc-qaic-v1.6.80-aic100",
    "Result": 5511.75,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Gigabyte R282-Z93 (8x QAIC100)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "Qualcomm Cloud AI SDK v1.6.80",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 7282 16-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026. Powered by Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "CentOS 7 (Linux kernel: 5.4.1-1.el7.elrepo.x86_64 #1 SMP Fri Nov 29 10:21:13 EST 2019 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "c3af1f4548d74be4",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Krai/results/r282_z93_q8_dc-qaic-v1.6.80-aic100/bert-99/server",
    "version": "v2.0",
    "Result_Power": 790.6184999999999,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 90.36306105137962,
    "Accuracy_div_100": 0.90363,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Krai/results/r282_z93_q8_dc-qaic-v1.6.80-aic100/bert-99/server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Krai",
    "Platform": "r282_z93_q8_dc-qaic-v1.6.80-aic100",
    "Result": 5511.75,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Gigabyte R282-Z93 (8x QAIC100)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "Qualcomm Cloud AI SDK v1.6.80",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 7282 16-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026. Powered by Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "CentOS 7 (Linux kernel: 5.4.1-1.el7.elrepo.x86_64 #1 SMP Fri Nov 29 10:21:13 EST 2019 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "c3af1f4548d74be4",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Krai/results/r282_z93_q8_dc-qaic-v1.6.80-aic100/bert-99/server",
    "version": "v2.0",
    "Result_Power": 790.6184999999999,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 90.87603921605954,
    "Accuracy_div_100": 0.90876,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Krai/results/r282_z93_q8_dc-qaic-v1.6.80-aic100/bert-99.9/server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Krai",
    "Platform": "r282_z93_q8_dc-qaic-v1.6.80-aic100",
    "Result": 2667.85,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Gigabyte R282-Z93 (8x QAIC100)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "Qualcomm Cloud AI SDK v1.6.80",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 7282 16-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026. Powered by Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "CentOS 7 (Linux kernel: 5.4.1-1.el7.elrepo.x86_64 #1 SMP Fri Nov 29 10:21:13 EST 2019 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "b478d8f354404a60",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Krai/results/r282_z93_q8_dc-qaic-v1.6.80-aic100/bert-99.9/server",
    "version": "v2.0",
    "Result_Power": 723.8394999999997,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 90.87603921605954,
    "Accuracy_div_100": 0.90876,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Krai/results/r282_z93_q8_dc-qaic-v1.6.80-aic100/bert-99.9/server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Krai",
    "Platform": "r282_z93_q8_dc-qaic-v1.6.80-aic100",
    "Result": 2667.85,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Gigabyte R282-Z93 (8x QAIC100)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "Qualcomm Cloud AI SDK v1.6.80",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 7282 16-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026. Powered by Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "CentOS 7 (Linux kernel: 5.4.1-1.el7.elrepo.x86_64 #1 SMP Fri Nov 29 10:21:13 EST 2019 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "b478d8f354404a60",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Krai/results/r282_z93_q8_dc-qaic-v1.6.80-aic100/bert-99.9/server",
    "version": "v2.0",
    "Result_Power": 723.8394999999997,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 90.37586600946241,
    "Accuracy_div_100": 0.90376,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A100-PCIe-80GBx8_TRT_MaxQ/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "NVIDIA",
    "Platform": "A100-PCIe-80GBx8_TRT_MaxQ",
    "Result": 17291.6,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Gigabyte G482-Z54 (8x A100-PCIe-80GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "a2cf7c4c497042d3",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/A100-PCIe-80GBx8_TRT_MaxQ/bert-99/Server",
    "version": "v2.0",
    "Result_Power": 2137.032666666668,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 90.37586600946241,
    "Accuracy_div_100": 0.90376,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A100-PCIe-80GBx8_TRT_MaxQ/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "NVIDIA",
    "Platform": "A100-PCIe-80GBx8_TRT_MaxQ",
    "Result": 17291.6,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Gigabyte G482-Z54 (8x A100-PCIe-80GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "a2cf7c4c497042d3",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/A100-PCIe-80GBx8_TRT_MaxQ/bert-99/Server",
    "version": "v2.0",
    "Result_Power": 2137.032666666668,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 90.87601624418225,
    "Accuracy_div_100": 0.90876,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A100-PCIe-80GBx8_TRT_MaxQ/bert-99.9/Server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "NVIDIA",
    "Platform": "A100-PCIe-80GBx8_TRT_MaxQ",
    "Result": 7494.89,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Gigabyte G482-Z54 (8x A100-PCIe-80GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "d796373dfc1642f6",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/A100-PCIe-80GBx8_TRT_MaxQ/bert-99.9/Server",
    "version": "v2.0",
    "Result_Power": 2142.023627287856,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 90.87601624418225,
    "Accuracy_div_100": 0.90876,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A100-PCIe-80GBx8_TRT_MaxQ/bert-99.9/Server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "NVIDIA",
    "Platform": "A100-PCIe-80GBx8_TRT_MaxQ",
    "Result": 7494.89,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Gigabyte G482-Z54 (8x A100-PCIe-80GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "d796373dfc1642f6",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/A100-PCIe-80GBx8_TRT_MaxQ/bert-99.9/Server",
    "version": "v2.0",
    "Result_Power": 2142.023627287856,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 90.37586600946241,
    "Accuracy_div_100": 0.90376,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-Station-A100_A100-SXM-80GBx4_TRT_MaxQ/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "NVIDIA",
    "Platform": "DGX-Station-A100_A100-SXM-80GBx4_TRT_MaxQ",
    "Result": 10194.7,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "NVIDIA DGX Station A100 (4x A100-SXM-80GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "18f6349a72e14a27",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/DGX-Station-A100_A100-SXM-80GBx4_TRT_MaxQ/bert-99/Server",
    "version": "v2.0",
    "Result_Power": 1272.1938333333337,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 90.37586600946241,
    "Accuracy_div_100": 0.90376,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-Station-A100_A100-SXM-80GBx4_TRT_MaxQ/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "NVIDIA",
    "Platform": "DGX-Station-A100_A100-SXM-80GBx4_TRT_MaxQ",
    "Result": 10194.7,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "NVIDIA DGX Station A100 (4x A100-SXM-80GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "18f6349a72e14a27",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/DGX-Station-A100_A100-SXM-80GBx4_TRT_MaxQ/bert-99/Server",
    "version": "v2.0",
    "Result_Power": 1272.1938333333337,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 90.87601624418225,
    "Accuracy_div_100": 0.90876,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-Station-A100_A100-SXM-80GBx4_TRT_MaxQ/bert-99.9/Server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "NVIDIA",
    "Platform": "DGX-Station-A100_A100-SXM-80GBx4_TRT_MaxQ",
    "Result": 4297.74,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "NVIDIA DGX Station A100 (4x A100-SXM-80GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "c1266fb6ffe4468b",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/DGX-Station-A100_A100-SXM-80GBx4_TRT_MaxQ/bert-99.9/Server",
    "version": "v2.0",
    "Result_Power": 1270.586333333332,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 90.87601624418225,
    "Accuracy_div_100": 0.90876,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-Station-A100_A100-SXM-80GBx4_TRT_MaxQ/bert-99.9/Server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "NVIDIA",
    "Platform": "DGX-Station-A100_A100-SXM-80GBx4_TRT_MaxQ",
    "Result": 4297.74,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "NVIDIA DGX Station A100 (4x A100-SXM-80GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "c1266fb6ffe4468b",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/DGX-Station-A100_A100-SXM-80GBx4_TRT_MaxQ/bert-99.9/Server",
    "version": "v2.0",
    "Result_Power": 1270.586333333332,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 90.37586600946241,
    "Accuracy_div_100": 0.90376,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT_MaxQ/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "NVIDIA",
    "Platform": "DGX-A100_A100-SXM-80GBx8_TRT_MaxQ",
    "Result": 21491.7,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "NVIDIA DGX A100 (8x A100-SXM-80GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "61f1c51702894475",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT_MaxQ/bert-99/Server",
    "version": "v2.0",
    "Result_Power": 3378.7609555189456,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 90.37586600946241,
    "Accuracy_div_100": 0.90376,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT_MaxQ/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "NVIDIA",
    "Platform": "DGX-A100_A100-SXM-80GBx8_TRT_MaxQ",
    "Result": 21491.7,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "NVIDIA DGX A100 (8x A100-SXM-80GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "61f1c51702894475",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT_MaxQ/bert-99/Server",
    "version": "v2.0",
    "Result_Power": 3378.7609555189456,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 90.87601624418225,
    "Accuracy_div_100": 0.90876,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT_MaxQ/bert-99.9/Server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "NVIDIA",
    "Platform": "DGX-A100_A100-SXM-80GBx8_TRT_MaxQ",
    "Result": 9994.96,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "NVIDIA DGX A100 (8x A100-SXM-80GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "1f6418e1d714420f",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT_MaxQ/bert-99.9/Server",
    "version": "v2.0",
    "Result_Power": 3409.6062706270636,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 90.87601624418225,
    "Accuracy_div_100": 0.90876,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT_MaxQ/bert-99.9/Server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "NVIDIA",
    "Platform": "DGX-A100_A100-SXM-80GBx8_TRT_MaxQ",
    "Result": 9994.96,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "NVIDIA DGX A100 (8x A100-SXM-80GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "1f6418e1d714420f",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT_MaxQ/bert-99.9/Server",
    "version": "v2.0",
    "Result_Power": 3409.6062706270636,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 90.3917923012987,
    "Accuracy_div_100": 0.90392,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A100-SXM-80GB_aarch64x8_TRT_MaxQ/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "NVIDIA",
    "Platform": "A100-SXM-80GB_aarch64x8_TRT_MaxQ",
    "Result": 20991.6,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Gigabyte G492-PD0 (8x A100-SXM-80GB_aarch64, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 80,
    "host_processor_model_name": "Ampere Altra Q80-30",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "c8661c8d976e40e9",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/A100-SXM-80GB_aarch64x8_TRT_MaxQ/bert-99/Server",
    "version": "v2.0",
    "Result_Power": 3242.2280528052843,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 90.3917923012987,
    "Accuracy_div_100": 0.90392,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A100-SXM-80GB_aarch64x8_TRT_MaxQ/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "NVIDIA",
    "Platform": "A100-SXM-80GB_aarch64x8_TRT_MaxQ",
    "Result": 20991.6,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Gigabyte G492-PD0 (8x A100-SXM-80GB_aarch64, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 80,
    "host_processor_model_name": "Ampere Altra Q80-30",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "c8661c8d976e40e9",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/A100-SXM-80GB_aarch64x8_TRT_MaxQ/bert-99/Server",
    "version": "v2.0",
    "Result_Power": 3242.2280528052843,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 90.87601624418225,
    "Accuracy_div_100": 0.90876,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A100-SXM-80GB_aarch64x8_TRT_MaxQ/bert-99.9/Server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "NVIDIA",
    "Platform": "A100-SXM-80GB_aarch64x8_TRT_MaxQ",
    "Result": 8794.88,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Gigabyte G492-PD0 (8x A100-SXM-80GB_aarch64, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 80,
    "host_processor_model_name": "Ampere Altra Q80-30",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "6fa2c95ae26a4af6",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/A100-SXM-80GB_aarch64x8_TRT_MaxQ/bert-99.9/Server",
    "version": "v2.0",
    "Result_Power": 3230.9088039867115,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 90.87601624418225,
    "Accuracy_div_100": 0.90876,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A100-SXM-80GB_aarch64x8_TRT_MaxQ/bert-99.9/Server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "NVIDIA",
    "Platform": "A100-SXM-80GB_aarch64x8_TRT_MaxQ",
    "Result": 8794.88,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Gigabyte G492-PD0 (8x A100-SXM-80GB_aarch64, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 80,
    "host_processor_model_name": "Ampere Altra Q80-30",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "6fa2c95ae26a4af6",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/A100-SXM-80GB_aarch64x8_TRT_MaxQ/bert-99.9/Server",
    "version": "v2.0",
    "Result_Power": 3230.9088039867115,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 90.3917923012987,
    "Accuracy_div_100": 0.90392,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A100-PCIe-80GB_aarch64x4_TRT_MaxQ/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "NVIDIA",
    "Platform": "A100-PCIe-80GB_aarch64x4_TRT_MaxQ",
    "Result": 9994.96,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Gigabyte G242-P31 (4x A100-PCIe-80GB_aarch64, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 80,
    "host_processor_model_name": "Ampere Altra Q80-30",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "1c401aeb655e481b",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/A100-PCIe-80GB_aarch64x4_TRT_MaxQ/bert-99/Server",
    "version": "v2.0",
    "Result_Power": 1250.4544999999998,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 90.3917923012987,
    "Accuracy_div_100": 0.90392,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A100-PCIe-80GB_aarch64x4_TRT_MaxQ/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "NVIDIA",
    "Platform": "A100-PCIe-80GB_aarch64x4_TRT_MaxQ",
    "Result": 9994.96,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Gigabyte G242-P31 (4x A100-PCIe-80GB_aarch64, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 80,
    "host_processor_model_name": "Ampere Altra Q80-30",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "1c401aeb655e481b",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/A100-PCIe-80GB_aarch64x4_TRT_MaxQ/bert-99/Server",
    "version": "v2.0",
    "Result_Power": 1250.4544999999998,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 90.87601624418225,
    "Accuracy_div_100": 0.90876,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A100-PCIe-80GB_aarch64x4_TRT_MaxQ/bert-99.9/Server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "NVIDIA",
    "Platform": "A100-PCIe-80GB_aarch64x4_TRT_MaxQ",
    "Result": 3997.54,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Gigabyte G242-P31 (4x A100-PCIe-80GB_aarch64, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 80,
    "host_processor_model_name": "Ampere Altra Q80-30",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "4df70151b294476a",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/A100-PCIe-80GB_aarch64x4_TRT_MaxQ/bert-99.9/Server",
    "version": "v2.0",
    "Result_Power": 1238.5674999999987,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 90.87601624418225,
    "Accuracy_div_100": 0.90876,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A100-PCIe-80GB_aarch64x4_TRT_MaxQ/bert-99.9/Server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "NVIDIA",
    "Platform": "A100-PCIe-80GB_aarch64x4_TRT_MaxQ",
    "Result": 3997.54,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Gigabyte G242-P31 (4x A100-PCIe-80GB_aarch64, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 80,
    "host_processor_model_name": "Ampere Altra Q80-30",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "4df70151b294476a",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/A100-PCIe-80GB_aarch64x4_TRT_MaxQ/bert-99.9/Server",
    "version": "v2.0",
    "Result_Power": 1238.5674999999987,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 90.36306105137962,
    "Accuracy_div_100": 0.90363,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Qualcomm/results/g292_z43_q18e-qaic-v1.6.80-aic100/bert-99/server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Qualcomm",
    "Platform": "g292_z43_q18e-qaic-v1.6.80-aic100",
    "Result": 10793.5,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Gigabyte G292-Z43 (18x QAIC100, EE)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 18,
    "compliance": 1,
    "errors": 0,
    "framework": "Qualcomm Cloud AI SDK v1.6.80",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7713 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "CentOS 7 (Linux kernel: 5.4.1-1.el7.elrepo.x86_64 #1 SMP Fri Nov 29 10:21:13 EST 2019 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "851ff7e0692b4267",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Qualcomm/results/g292_z43_q18e-qaic-v1.6.80-aic100/bert-99/server",
    "version": "v2.0",
    "Result_Power": 1486.3911813643933,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 90.36306105137962,
    "Accuracy_div_100": 0.90363,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Qualcomm/results/g292_z43_q18e-qaic-v1.6.80-aic100/bert-99/server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Qualcomm",
    "Platform": "g292_z43_q18e-qaic-v1.6.80-aic100",
    "Result": 10793.5,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Gigabyte G292-Z43 (18x QAIC100, EE)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 18,
    "compliance": 1,
    "errors": 0,
    "framework": "Qualcomm Cloud AI SDK v1.6.80",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7713 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "CentOS 7 (Linux kernel: 5.4.1-1.el7.elrepo.x86_64 #1 SMP Fri Nov 29 10:21:13 EST 2019 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "851ff7e0692b4267",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Qualcomm/results/g292_z43_q18e-qaic-v1.6.80-aic100/bert-99/server",
    "version": "v2.0",
    "Result_Power": 1486.3911813643933,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 90.87603921605954,
    "Accuracy_div_100": 0.90876,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Qualcomm/results/g292_z43_q18e-qaic-v1.6.80-aic100/bert-99.9/server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Qualcomm",
    "Platform": "g292_z43_q18e-qaic-v1.6.80-aic100",
    "Result": 4797.61,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Gigabyte G292-Z43 (18x QAIC100, EE)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 18,
    "compliance": 1,
    "errors": 0,
    "framework": "Qualcomm Cloud AI SDK v1.6.80",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7713 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "CentOS 7 (Linux kernel: 5.4.1-1.el7.elrepo.x86_64 #1 SMP Fri Nov 29 10:21:13 EST 2019 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "9d49248a64af41e1",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Qualcomm/results/g292_z43_q18e-qaic-v1.6.80-aic100/bert-99.9/server",
    "version": "v2.0",
    "Result_Power": 1309.1548333333335,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 90.87603921605954,
    "Accuracy_div_100": 0.90876,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Qualcomm/results/g292_z43_q18e-qaic-v1.6.80-aic100/bert-99.9/server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Qualcomm",
    "Platform": "g292_z43_q18e-qaic-v1.6.80-aic100",
    "Result": 4797.61,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Gigabyte G292-Z43 (18x QAIC100, EE)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 18,
    "compliance": 1,
    "errors": 0,
    "framework": "Qualcomm Cloud AI SDK v1.6.80",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7713 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "CentOS 7 (Linux kernel: 5.4.1-1.el7.elrepo.x86_64 #1 SMP Fri Nov 29 10:21:13 EST 2019 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "9d49248a64af41e1",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Qualcomm/results/g292_z43_q18e-qaic-v1.6.80-aic100/bert-99.9/server",
    "version": "v2.0",
    "Result_Power": 1309.1548333333335,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 90.3695341878632,
    "Accuracy_div_100": 0.9037,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Qualcomm/results/r282_z93_q8e-qaic-v1.6.80-aic100/bert-99/server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Qualcomm",
    "Platform": "r282_z93_q8e-qaic-v1.6.80-aic100",
    "Result": 4697.46,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Gigabyte R282-Z93 (8x QAIC100, EE)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "Qualcomm Cloud AI SDK v1.6.80",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 7282 16-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026. Powered by Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "CentOS 7 (Linux kernel: 5.4.1-1.el7.elrepo.x86_64 #1 SMP Fri Nov 29 10:21:13 EST 2019 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "411a616e34a64157",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Qualcomm/results/r282_z93_q8e-qaic-v1.6.80-aic100/bert-99/server",
    "version": "v2.0",
    "Result_Power": 574.9969666666664,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 90.3695341878632,
    "Accuracy_div_100": 0.9037,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Qualcomm/results/r282_z93_q8e-qaic-v1.6.80-aic100/bert-99/server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Qualcomm",
    "Platform": "r282_z93_q8e-qaic-v1.6.80-aic100",
    "Result": 4697.46,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Gigabyte R282-Z93 (8x QAIC100, EE)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "Qualcomm Cloud AI SDK v1.6.80",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 7282 16-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026. Powered by Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "CentOS 7 (Linux kernel: 5.4.1-1.el7.elrepo.x86_64 #1 SMP Fri Nov 29 10:21:13 EST 2019 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "411a616e34a64157",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Qualcomm/results/r282_z93_q8e-qaic-v1.6.80-aic100/bert-99/server",
    "version": "v2.0",
    "Result_Power": 574.9969666666664,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 90.87603921605954,
    "Accuracy_div_100": 0.90876,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Qualcomm/results/r282_z93_q8e-qaic-v1.6.80-aic100/bert-99.9/server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Qualcomm",
    "Platform": "r282_z93_q8e-qaic-v1.6.80-aic100",
    "Result": 2098.48,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Gigabyte R282-Z93 (8x QAIC100, EE)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "Qualcomm Cloud AI SDK v1.6.80",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 7282 16-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026. Powered by Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "CentOS 7 (Linux kernel: 5.4.1-1.el7.elrepo.x86_64 #1 SMP Fri Nov 29 10:21:13 EST 2019 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "c4fa3f0e9eb145df",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Qualcomm/results/r282_z93_q8e-qaic-v1.6.80-aic100/bert-99.9/server",
    "version": "v2.0",
    "Result_Power": 525.5452166666671,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 90.87603921605954,
    "Accuracy_div_100": 0.90876,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Qualcomm/results/r282_z93_q8e-qaic-v1.6.80-aic100/bert-99.9/server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Qualcomm",
    "Platform": "r282_z93_q8e-qaic-v1.6.80-aic100",
    "Result": 2098.48,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Gigabyte R282-Z93 (8x QAIC100, EE)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "Qualcomm Cloud AI SDK v1.6.80",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 7282 16-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026. Powered by Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "CentOS 7 (Linux kernel: 5.4.1-1.el7.elrepo.x86_64 #1 SMP Fri Nov 29 10:21:13 EST 2019 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "c4fa3f0e9eb145df",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Qualcomm/results/r282_z93_q8e-qaic-v1.6.80-aic100/bert-99.9/server",
    "version": "v2.0",
    "Result_Power": 525.5452166666671,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 90.30889581502666,
    "Accuracy_div_100": 0.90309,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XR12_A2x1_TRT_MaxQ/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Dell",
    "Platform": "XR12_A2x1_TRT_MaxQ",
    "Result": 149.993,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge XR12 (1x A2, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A2",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6312U CPU @ 2.40GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "CentOS 8.2",
    "uid": "46f67515b03b42a2",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Dell/results/XR12_A2x1_TRT_MaxQ/bert-99/Server",
    "version": "v2.0",
    "Result_Power": 279.3510308710035,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 90.30889581502666,
    "Accuracy_div_100": 0.90309,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XR12_A2x1_TRT_MaxQ/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Dell",
    "Platform": "XR12_A2x1_TRT_MaxQ",
    "Result": 149.993,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge XR12 (1x A2, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A2",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6312U CPU @ 2.40GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "CentOS 8.2",
    "uid": "46f67515b03b42a2",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Dell/results/XR12_A2x1_TRT_MaxQ/bert-99/Server",
    "version": "v2.0",
    "Result_Power": 279.3510308710035,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 90.8677125012522,
    "Accuracy_div_100": 0.90868,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XR12_A2x1_TRT_MaxQ/bert-99.9/Server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Dell",
    "Platform": "XR12_A2x1_TRT_MaxQ",
    "Result": 59.9971,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge XR12 (1x A2, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A2",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6312U CPU @ 2.40GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "CentOS 8.2",
    "uid": "e3269e8f0f3746ce",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Dell/results/XR12_A2x1_TRT_MaxQ/bert-99.9/Server",
    "version": "v2.0",
    "Result_Power": 222.3039562624252,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 90.8677125012522,
    "Accuracy_div_100": 0.90868,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XR12_A2x1_TRT_MaxQ/bert-99.9/Server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Dell",
    "Platform": "XR12_A2x1_TRT_MaxQ",
    "Result": 59.9971,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge XR12 (1x A2, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A2",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6312U CPU @ 2.40GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "CentOS 8.2",
    "uid": "e3269e8f0f3746ce",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Dell/results/XR12_A2x1_TRT_MaxQ/bert-99.9/Server",
    "version": "v2.0",
    "Result_Power": 222.3039562624252,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 90.37586600946241,
    "Accuracy_div_100": 0.90376,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A100-PCIe-80GBx8_TRT_MaxQ/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "NVIDIA",
    "Platform": "A100-PCIe-80GBx8_TRT_MaxQ",
    "Result": 17287.6,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Gigabyte G482-Z54 (8x A100-PCIe-80GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": true,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "1ce7560c01504be0",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/NVIDIA/results/A100-PCIe-80GBx8_TRT_MaxQ/bert-99/Server",
    "version": "v2.1",
    "Result_Power": 2163.2838333333316,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 90.37586600946241,
    "Accuracy_div_100": 0.90376,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A100-PCIe-80GBx8_TRT_MaxQ/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "NVIDIA",
    "Platform": "A100-PCIe-80GBx8_TRT_MaxQ",
    "Result": 17287.6,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Gigabyte G482-Z54 (8x A100-PCIe-80GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": true,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "1ce7560c01504be0",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/NVIDIA/results/A100-PCIe-80GBx8_TRT_MaxQ/bert-99/Server",
    "version": "v2.1",
    "Result_Power": 2163.2838333333316,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 90.88462035425279,
    "Accuracy_div_100": 0.90885,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A100-PCIe-80GBx8_TRT_MaxQ/bert-99.9/Server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "NVIDIA",
    "Platform": "A100-PCIe-80GBx8_TRT_MaxQ",
    "Result": 7494.11,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Gigabyte G482-Z54 (8x A100-PCIe-80GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": true,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "0370463b2cce464b",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/NVIDIA/results/A100-PCIe-80GBx8_TRT_MaxQ/bert-99.9/Server",
    "version": "v2.1",
    "Result_Power": 2169.4446666666668,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 90.88462035425279,
    "Accuracy_div_100": 0.90885,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A100-PCIe-80GBx8_TRT_MaxQ/bert-99.9/Server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "NVIDIA",
    "Platform": "A100-PCIe-80GBx8_TRT_MaxQ",
    "Result": 7494.11,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Gigabyte G482-Z54 (8x A100-PCIe-80GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": true,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "0370463b2cce464b",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/NVIDIA/results/A100-PCIe-80GBx8_TRT_MaxQ/bert-99.9/Server",
    "version": "v2.1",
    "Result_Power": 2169.4446666666668,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 90.37586600946241,
    "Accuracy_div_100": 0.90376,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT_MaxQ/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "NVIDIA",
    "Platform": "DGX-A100_A100-SXM-80GBx8_TRT_MaxQ",
    "Result": 21487.9,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "NVIDIA DGX A100 (8x A100-SXM-80GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": true,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "8267e63187eb47cf",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT_MaxQ/bert-99/Server",
    "version": "v2.1",
    "Result_Power": 3378.1160066006587,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 90.37586600946241,
    "Accuracy_div_100": 0.90376,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT_MaxQ/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "NVIDIA",
    "Platform": "DGX-A100_A100-SXM-80GBx8_TRT_MaxQ",
    "Result": 21487.9,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "NVIDIA DGX A100 (8x A100-SXM-80GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": true,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "8267e63187eb47cf",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT_MaxQ/bert-99/Server",
    "version": "v2.1",
    "Result_Power": 3378.1160066006587,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 90.88462035425279,
    "Accuracy_div_100": 0.90885,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT_MaxQ/bert-99.9/Server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "NVIDIA",
    "Platform": "DGX-A100_A100-SXM-80GBx8_TRT_MaxQ",
    "Result": 9994.91,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "NVIDIA DGX A100 (8x A100-SXM-80GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": true,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "c4f998959ce84412",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT_MaxQ/bert-99.9/Server",
    "version": "v2.1",
    "Result_Power": 3416.2283828382815,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 90.88462035425279,
    "Accuracy_div_100": 0.90885,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT_MaxQ/bert-99.9/Server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "NVIDIA",
    "Platform": "DGX-A100_A100-SXM-80GBx8_TRT_MaxQ",
    "Result": 9994.91,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "NVIDIA DGX A100 (8x A100-SXM-80GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": true,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "c4f998959ce84412",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT_MaxQ/bert-99.9/Server",
    "version": "v2.1",
    "Result_Power": 3416.2283828382815,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 90.22951222279839,
    "Accuracy_div_100": 0.9023,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Qualcomm/results/r282_z93_q8e-qaic-v1.7.1.12-aic100/bert-99/server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Qualcomm",
    "Platform": "r282_z93_q8e-qaic-v1.7.1.12-aic100",
    "Result": 5296.66,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Gigabyte R282-Z93 (8x QAIC100 Pro, EE)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "Qualcomm Cloud AI SDK v1.7.1",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": true,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 7282 16-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026. Powered by MLCommons Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "CentOS 7 (Linux kernel: 5.4.1-1.el7.elrepo.x86_64 #1 SMP Fri Nov 29 10:21:13 EST 2019 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "ffe6ba46de554afd",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/Qualcomm/results/r282_z93_q8e-qaic-v1.7.1.12-aic100/bert-99/server",
    "version": "v2.1",
    "Result_Power": 595.8976666666665,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 90.22951222279839,
    "Accuracy_div_100": 0.9023,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Qualcomm/results/r282_z93_q8e-qaic-v1.7.1.12-aic100/bert-99/server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Qualcomm",
    "Platform": "r282_z93_q8e-qaic-v1.7.1.12-aic100",
    "Result": 5296.66,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Gigabyte R282-Z93 (8x QAIC100 Pro, EE)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "Qualcomm Cloud AI SDK v1.7.1",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": true,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 7282 16-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026. Powered by MLCommons Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "CentOS 7 (Linux kernel: 5.4.1-1.el7.elrepo.x86_64 #1 SMP Fri Nov 29 10:21:13 EST 2019 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "ffe6ba46de554afd",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/Qualcomm/results/r282_z93_q8e-qaic-v1.7.1.12-aic100/bert-99/server",
    "version": "v2.1",
    "Result_Power": 595.8976666666665,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 90.8666333229796,
    "Accuracy_div_100": 0.90867,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Qualcomm/results/r282_z93_q8e-qaic-v1.7.1.12-aic100/bert-99.9/server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Qualcomm",
    "Platform": "r282_z93_q8e-qaic-v1.7.1.12-aic100",
    "Result": 2096.39,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Gigabyte R282-Z93 (8x QAIC100 Pro, EE)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "Qualcomm Cloud AI SDK v1.7.1",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": true,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 7282 16-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026. Powered by MLCommons Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "CentOS 7 (Linux kernel: 5.4.1-1.el7.elrepo.x86_64 #1 SMP Fri Nov 29 10:21:13 EST 2019 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "2d93963f47294255",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/Qualcomm/results/r282_z93_q8e-qaic-v1.7.1.12-aic100/bert-99.9/server",
    "version": "v2.1",
    "Result_Power": 549.2228333333336,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 90.8666333229796,
    "Accuracy_div_100": 0.90867,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Qualcomm/results/r282_z93_q8e-qaic-v1.7.1.12-aic100/bert-99.9/server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Qualcomm",
    "Platform": "r282_z93_q8e-qaic-v1.7.1.12-aic100",
    "Result": 2096.39,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Gigabyte R282-Z93 (8x QAIC100 Pro, EE)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "Qualcomm Cloud AI SDK v1.7.1",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": true,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 7282 16-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026. Powered by MLCommons Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "CentOS 7 (Linux kernel: 5.4.1-1.el7.elrepo.x86_64 #1 SMP Fri Nov 29 10:21:13 EST 2019 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "2d93963f47294255",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/Qualcomm/results/r282_z93_q8e-qaic-v1.7.1.12-aic100/bert-99.9/server",
    "version": "v2.1",
    "Result_Power": 549.2228333333336,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 90.30659619425937,
    "Accuracy_div_100": 0.90307,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XR12_A2x1_TRT_MaxQ/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Dell",
    "Platform": "XR12_A2x1_TRT_MaxQ",
    "Result": 149.674,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge XR12 (1x A2, MaxQ, TensorRT)",
    "SystemType": "datacenter,edge",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A2",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": true,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6312U CPU @ 2.40GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "CentOS 8.2",
    "uid": "444ee6eb3e714466",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/Dell/results/XR12_A2x1_TRT_MaxQ/bert-99/Server",
    "version": "v2.1",
    "Result_Power": 248.59047304730444,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 90.30659619425937,
    "Accuracy_div_100": 0.90307,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XR12_A2x1_TRT_MaxQ/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Dell",
    "Platform": "XR12_A2x1_TRT_MaxQ",
    "Result": 149.674,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge XR12 (1x A2, MaxQ, TensorRT)",
    "SystemType": "datacenter,edge",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A2",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": true,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6312U CPU @ 2.40GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "CentOS 8.2",
    "uid": "444ee6eb3e714466",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/Dell/results/XR12_A2x1_TRT_MaxQ/bert-99/Server",
    "version": "v2.1",
    "Result_Power": 248.59047304730444,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 90.87854364950057,
    "Accuracy_div_100": 0.90879,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XR12_A2x1_TRT_MaxQ/bert-99.9/Server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Dell",
    "Platform": "XR12_A2x1_TRT_MaxQ",
    "Result": 59.8697,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge XR12 (1x A2, MaxQ, TensorRT)",
    "SystemType": "datacenter,edge",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A2",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": true,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6312U CPU @ 2.40GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "CentOS 8.2",
    "uid": "67bac4972e94457d",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/Dell/results/XR12_A2x1_TRT_MaxQ/bert-99.9/Server",
    "version": "v2.1",
    "Result_Power": 212.1589596649765,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 90.87854364950057,
    "Accuracy_div_100": 0.90879,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XR12_A2x1_TRT_MaxQ/bert-99.9/Server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Dell",
    "Platform": "XR12_A2x1_TRT_MaxQ",
    "Result": 59.8697,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge XR12 (1x A2, MaxQ, TensorRT)",
    "SystemType": "datacenter,edge",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A2",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": true,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6312U CPU @ 2.40GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "CentOS 8.2",
    "uid": "67bac4972e94457d",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/Dell/results/XR12_A2x1_TRT_MaxQ/bert-99.9/Server",
    "version": "v2.1",
    "Result_Power": 212.1589596649765,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 90.22951222279839,
    "Accuracy_div_100": 0.9023,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/r7515_q4_pro-qaic-v1.7.1.12-aic100/bert-99/server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Dell",
    "Platform": "r7515_q4_pro-qaic-v1.7.1.12-aic100",
    "Result": 2550.92,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge R7515 (4x QAIC100 Pro)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "Qualcomm Cloud AI SDK v1.7.1",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": true,
    "host_processor_core_count": 32,
    "host_processor_model_name": "AMD EPYC 7542 32-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Powered by MLCommons Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4 LTS (Linux kernel: 5.4.200-0504200-generic #202206221347 SMP Wed Jun 22 15:28:35 UTC 2022 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "473992cac0e64070",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/Dell/results/r7515_q4_pro-qaic-v1.7.1.12-aic100/bert-99/server",
    "version": "v2.1",
    "Result_Power": 455.2483166666671,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 90.22951222279839,
    "Accuracy_div_100": 0.9023,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/r7515_q4_pro-qaic-v1.7.1.12-aic100/bert-99/server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Dell",
    "Platform": "r7515_q4_pro-qaic-v1.7.1.12-aic100",
    "Result": 2550.92,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge R7515 (4x QAIC100 Pro)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "Qualcomm Cloud AI SDK v1.7.1",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": true,
    "host_processor_core_count": 32,
    "host_processor_model_name": "AMD EPYC 7542 32-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Powered by MLCommons Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4 LTS (Linux kernel: 5.4.200-0504200-generic #202206221347 SMP Wed Jun 22 15:28:35 UTC 2022 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "473992cac0e64070",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/Dell/results/r7515_q4_pro-qaic-v1.7.1.12-aic100/bert-99/server",
    "version": "v2.1",
    "Result_Power": 455.2483166666671,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 90.8666333229796,
    "Accuracy_div_100": 0.90867,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/r7515_q4_pro-qaic-v1.7.1.12-aic100/bert-99.9/server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Dell",
    "Platform": "r7515_q4_pro-qaic-v1.7.1.12-aic100",
    "Result": 1277.56,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge R7515 (4x QAIC100 Pro)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "Qualcomm Cloud AI SDK v1.7.1",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": true,
    "host_processor_core_count": 32,
    "host_processor_model_name": "AMD EPYC 7542 32-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Powered by MLCommons Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4 LTS (Linux kernel: 5.4.200-0504200-generic #202206221347 SMP Wed Jun 22 15:28:35 UTC 2022 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "7c1e8177a303484d",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/Dell/results/r7515_q4_pro-qaic-v1.7.1.12-aic100/bert-99.9/server",
    "version": "v2.1",
    "Result_Power": 434.7384833333337,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 90.8666333229796,
    "Accuracy_div_100": 0.90867,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/r7515_q4_pro-qaic-v1.7.1.12-aic100/bert-99.9/server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Dell",
    "Platform": "r7515_q4_pro-qaic-v1.7.1.12-aic100",
    "Result": 1277.56,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge R7515 (4x QAIC100 Pro)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "Qualcomm Cloud AI SDK v1.7.1",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": true,
    "host_processor_core_count": 32,
    "host_processor_model_name": "AMD EPYC 7542 32-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Powered by MLCommons Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4 LTS (Linux kernel: 5.4.200-0504200-generic #202206221347 SMP Wed Jun 22 15:28:35 UTC 2022 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "7c1e8177a303484d",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/Dell/results/r7515_q4_pro-qaic-v1.7.1.12-aic100/bert-99.9/server",
    "version": "v2.1",
    "Result_Power": 434.7384833333337,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 90.37586600946241,
    "Accuracy_div_100": 0.90376,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE8545_A100_SXM_80GBx4_TRT_MaxQ/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Dell",
    "Platform": "XE8545_A100_SXM_80GBx4_TRT_MaxQ",
    "Result": 10495.2,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge XE8545 (4x A100-SXM-80GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB CTS",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": true,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7763",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "NVIDIA A100-SXM-80GB (TDP: 500W)",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "c777a8b7f92c4d6e",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/Dell/results/XE8545_A100_SXM_80GBx4_TRT_MaxQ/bert-99/Server",
    "version": "v2.1",
    "Result_Power": 1608.9733884297527,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 90.37586600946241,
    "Accuracy_div_100": 0.90376,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE8545_A100_SXM_80GBx4_TRT_MaxQ/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Dell",
    "Platform": "XE8545_A100_SXM_80GBx4_TRT_MaxQ",
    "Result": 10495.2,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge XE8545 (4x A100-SXM-80GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB CTS",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": true,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7763",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "NVIDIA A100-SXM-80GB (TDP: 500W)",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "c777a8b7f92c4d6e",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/Dell/results/XE8545_A100_SXM_80GBx4_TRT_MaxQ/bert-99/Server",
    "version": "v2.1",
    "Result_Power": 1608.9733884297527,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 90.88462035425279,
    "Accuracy_div_100": 0.90885,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE8545_A100_SXM_80GBx4_TRT_MaxQ/bert-99.9/Server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Dell",
    "Platform": "XE8545_A100_SXM_80GBx4_TRT_MaxQ",
    "Result": 5296.66,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge XE8545 (4x A100-SXM-80GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB CTS",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": true,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7763",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "NVIDIA A100-SXM-80GB (TDP: 500W)",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "075a52c966b54638",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/Dell/results/XE8545_A100_SXM_80GBx4_TRT_MaxQ/bert-99.9/Server",
    "version": "v2.1",
    "Result_Power": 1771.6421487603309,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 90.88462035425279,
    "Accuracy_div_100": 0.90885,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE8545_A100_SXM_80GBx4_TRT_MaxQ/bert-99.9/Server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Dell",
    "Platform": "XE8545_A100_SXM_80GBx4_TRT_MaxQ",
    "Result": 5296.66,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge XE8545 (4x A100-SXM-80GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB CTS",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": true,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7763",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "NVIDIA A100-SXM-80GB (TDP: 500W)",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "075a52c966b54638",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/Dell/results/XE8545_A100_SXM_80GBx4_TRT_MaxQ/bert-99.9/Server",
    "version": "v2.1",
    "Result_Power": 1771.6421487603309,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 90.37586600946241,
    "Accuracy_div_100": 0.90376,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/A30x3_R4900G5_TRT_MaxQ/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "H3C",
    "Platform": "A30x3_R4900G5_TRT_MaxQ",
    "Result": 4196.94,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "H3C UniServer R4900 G5(3x A30, TensorRT, MaxQ)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 3,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": true,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8380 CPU @ 2.30GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "7073c6c062b441e2",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/H3C/results/A30x3_R4900G5_TRT_MaxQ/bert-99/Server",
    "version": "v2.1",
    "Result_Power": 911.6485950413223,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 90.37586600946241,
    "Accuracy_div_100": 0.90376,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/A30x3_R4900G5_TRT_MaxQ/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "H3C",
    "Platform": "A30x3_R4900G5_TRT_MaxQ",
    "Result": 4196.94,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "H3C UniServer R4900 G5(3x A30, TensorRT, MaxQ)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 3,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": true,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8380 CPU @ 2.30GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "7073c6c062b441e2",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/H3C/results/A30x3_R4900G5_TRT_MaxQ/bert-99/Server",
    "version": "v2.1",
    "Result_Power": 911.6485950413223,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 90.88462035425279,
    "Accuracy_div_100": 0.90885,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/A30x3_R4900G5_TRT_MaxQ/bert-99.9/Server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "H3C",
    "Platform": "A30x3_R4900G5_TRT_MaxQ",
    "Result": 1796.17,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "H3C UniServer R4900 G5(3x A30, TensorRT, MaxQ)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 3,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": true,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8380 CPU @ 2.30GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "d35102b05bc54372",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/H3C/results/A30x3_R4900G5_TRT_MaxQ/bert-99.9/Server",
    "version": "v2.1",
    "Result_Power": 914.2455298013256,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 90.88462035425279,
    "Accuracy_div_100": 0.90885,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/A30x3_R4900G5_TRT_MaxQ/bert-99.9/Server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "H3C",
    "Platform": "A30x3_R4900G5_TRT_MaxQ",
    "Result": 1796.17,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "H3C UniServer R4900 G5(3x A30, TensorRT, MaxQ)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 3,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": true,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8380 CPU @ 2.30GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "d35102b05bc54372",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/H3C/results/A30x3_R4900G5_TRT_MaxQ/bert-99.9/Server",
    "version": "v2.1",
    "Result_Power": 914.2455298013256,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 90.38590173403216,
    "Accuracy_div_100": 0.90386,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A100-PCIe-80GBx8_TRT_MaxQ/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "NVIDIA",
    "Platform": "A100-PCIe-80GBx8_TRT_MaxQ",
    "Result": 17299.1,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Gigabyte G482-Z54 (8x A100-PCIe-80GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": true,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "29c9654930c44e0b",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/NVIDIA/results/A100-PCIe-80GBx8_TRT_MaxQ/bert-99/Server",
    "version": "v3.0",
    "Result_Power": 2164.980500000001,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 90.38590173403216,
    "Accuracy_div_100": 0.90386,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A100-PCIe-80GBx8_TRT_MaxQ/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "NVIDIA",
    "Platform": "A100-PCIe-80GBx8_TRT_MaxQ",
    "Result": 17299.1,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Gigabyte G482-Z54 (8x A100-PCIe-80GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": true,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "29c9654930c44e0b",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/NVIDIA/results/A100-PCIe-80GBx8_TRT_MaxQ/bert-99/Server",
    "version": "v3.0",
    "Result_Power": 2164.980500000001,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 90.88723524062507,
    "Accuracy_div_100": 0.90887,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A100-PCIe-80GBx8_TRT_MaxQ/bert-99.9/Server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "NVIDIA",
    "Platform": "A100-PCIe-80GBx8_TRT_MaxQ",
    "Result": 7503.01,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Gigabyte G482-Z54 (8x A100-PCIe-80GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": true,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "7ba7be6f15fc48fa",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/NVIDIA/results/A100-PCIe-80GBx8_TRT_MaxQ/bert-99.9/Server",
    "version": "v3.0",
    "Result_Power": 2158.1601666666666,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 90.88723524062507,
    "Accuracy_div_100": 0.90887,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A100-PCIe-80GBx8_TRT_MaxQ/bert-99.9/Server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "NVIDIA",
    "Platform": "A100-PCIe-80GBx8_TRT_MaxQ",
    "Result": 7503.01,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Gigabyte G482-Z54 (8x A100-PCIe-80GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": true,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "7ba7be6f15fc48fa",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/NVIDIA/results/A100-PCIe-80GBx8_TRT_MaxQ/bert-99.9/Server",
    "version": "v3.0",
    "Result_Power": 2158.1601666666666,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 90.34992722790872,
    "Accuracy_div_100": 0.9035,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H100-PCIe-80GBx8_TRT_MaxQ/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "NVIDIA",
    "Platform": "H100-PCIe-80GBx8_TRT_MaxQ",
    "Result": 33003.6,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Gigabyte G482-Z54 (8x H100-PCIe-80GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": true,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "25d5281dd680435f",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/NVIDIA/results/H100-PCIe-80GBx8_TRT_MaxQ/bert-99/Server",
    "version": "v3.0",
    "Result_Power": 3061.4089999999987,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 90.34992722790872,
    "Accuracy_div_100": 0.9035,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H100-PCIe-80GBx8_TRT_MaxQ/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "NVIDIA",
    "Platform": "H100-PCIe-80GBx8_TRT_MaxQ",
    "Result": 33003.6,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Gigabyte G482-Z54 (8x H100-PCIe-80GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": true,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "25d5281dd680435f",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/NVIDIA/results/H100-PCIe-80GBx8_TRT_MaxQ/bert-99/Server",
    "version": "v3.0",
    "Result_Power": 3061.4089999999987,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 90.96423386151577,
    "Accuracy_div_100": 0.90964,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H100-PCIe-80GBx8_TRT_MaxQ/bert-99.9/Server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "NVIDIA",
    "Platform": "H100-PCIe-80GBx8_TRT_MaxQ",
    "Result": 25005,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Gigabyte G482-Z54 (8x H100-PCIe-80GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": true,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "b5bfc9575e4d4be6",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/NVIDIA/results/H100-PCIe-80GBx8_TRT_MaxQ/bert-99.9/Server",
    "version": "v3.0",
    "Result_Power": 2952.6649999999977,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 90.96423386151577,
    "Accuracy_div_100": 0.90964,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H100-PCIe-80GBx8_TRT_MaxQ/bert-99.9/Server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "NVIDIA",
    "Platform": "H100-PCIe-80GBx8_TRT_MaxQ",
    "Result": 25005,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Gigabyte G482-Z54 (8x H100-PCIe-80GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": true,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "b5bfc9575e4d4be6",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/NVIDIA/results/H100-PCIe-80GBx8_TRT_MaxQ/bert-99.9/Server",
    "version": "v3.0",
    "Result_Power": 2952.6649999999977,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 90.2426510242233,
    "Accuracy_div_100": 0.90243,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Qualcomm/results/r282_z93_q8e-qaic-v1.8.3.7-aic100/bert-99/server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Qualcomm",
    "Platform": "r282_z93_q8e-qaic-v1.8.3.7-aic100",
    "Result": 4802.16,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "GIGABYTE R282-Z93 (8x QAIC100 Pro, EE)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.8.3",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": true,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 7282 16-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026.. Powered by Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5 LTS (Linux kernel: 5.4.0-135-generic #152-Ubuntu SMP Wed Nov 23 20:19:22 UTC 2022)",
    "uid": "72d6443e5a1549a0",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Qualcomm/results/r282_z93_q8e-qaic-v1.8.3.7-aic100/bert-99/server",
    "version": "v3.0",
    "Result_Power": 536.7114999999999,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 90.2426510242233,
    "Accuracy_div_100": 0.90243,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Qualcomm/results/r282_z93_q8e-qaic-v1.8.3.7-aic100/bert-99/server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Qualcomm",
    "Platform": "r282_z93_q8e-qaic-v1.8.3.7-aic100",
    "Result": 4802.16,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "GIGABYTE R282-Z93 (8x QAIC100 Pro, EE)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.8.3",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": true,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 7282 16-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026.. Powered by Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5 LTS (Linux kernel: 5.4.0-135-generic #152-Ubuntu SMP Wed Nov 23 20:19:22 UTC 2022)",
    "uid": "72d6443e5a1549a0",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Qualcomm/results/r282_z93_q8e-qaic-v1.8.3.7-aic100/bert-99/server",
    "version": "v3.0",
    "Result_Power": 536.7114999999999,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 90.8666333229796,
    "Accuracy_div_100": 0.90867,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Qualcomm/results/r282_z93_q8e-qaic-v1.8.3.7-aic100/bert-99.9/server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Qualcomm",
    "Platform": "r282_z93_q8e-qaic-v1.8.3.7-aic100",
    "Result": 2700.13,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "GIGABYTE R282-Z93 (8x QAIC100 Pro, EE)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.8.3",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": true,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 7282 16-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026.. Powered by Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5 LTS (Linux kernel: 5.4.0-135-generic #152-Ubuntu SMP Wed Nov 23 20:19:22 UTC 2022)",
    "uid": "13c68954e1b54725",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Qualcomm/results/r282_z93_q8e-qaic-v1.8.3.7-aic100/bert-99.9/server",
    "version": "v3.0",
    "Result_Power": 587.0564999999999,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 90.8666333229796,
    "Accuracy_div_100": 0.90867,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Qualcomm/results/r282_z93_q8e-qaic-v1.8.3.7-aic100/bert-99.9/server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Qualcomm",
    "Platform": "r282_z93_q8e-qaic-v1.8.3.7-aic100",
    "Result": 2700.13,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "GIGABYTE R282-Z93 (8x QAIC100 Pro, EE)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.8.3",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": true,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 7282 16-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026.. Powered by Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5 LTS (Linux kernel: 5.4.0-135-generic #152-Ubuntu SMP Wed Nov 23 20:19:22 UTC 2022)",
    "uid": "13c68954e1b54725",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Qualcomm/results/r282_z93_q8e-qaic-v1.8.3.7-aic100/bert-99.9/server",
    "version": "v3.0",
    "Result_Power": 587.0564999999999,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 90.2426510242233,
    "Accuracy_div_100": 0.90243,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Qualcomm/results/g292_z43_q18e-qaic-v1.8.3.7-aic100/bert-99/server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Qualcomm",
    "Platform": "g292_z43_q18e-qaic-v1.8.3.7-aic100",
    "Result": 11000.3,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "GIGABYTE G292-Z43 (18x QAIC100 Pro, EE)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 18,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.8.3",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": true,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7713 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5 LTS (Linux kernel: 5.4.0-135-generic #152-Ubuntu SMP Wed Nov 23 20:19:22 UTC 2022)",
    "uid": "a5292abdf1514bbe",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Qualcomm/results/g292_z43_q18e-qaic-v1.8.3.7-aic100/bert-99/server",
    "version": "v3.0",
    "Result_Power": 1525.9428333333326,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 90.2426510242233,
    "Accuracy_div_100": 0.90243,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Qualcomm/results/g292_z43_q18e-qaic-v1.8.3.7-aic100/bert-99/server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Qualcomm",
    "Platform": "g292_z43_q18e-qaic-v1.8.3.7-aic100",
    "Result": 11000.3,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "GIGABYTE G292-Z43 (18x QAIC100 Pro, EE)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 18,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.8.3",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": true,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7713 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5 LTS (Linux kernel: 5.4.0-135-generic #152-Ubuntu SMP Wed Nov 23 20:19:22 UTC 2022)",
    "uid": "a5292abdf1514bbe",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Qualcomm/results/g292_z43_q18e-qaic-v1.8.3.7-aic100/bert-99/server",
    "version": "v3.0",
    "Result_Power": 1525.9428333333326,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 90.8666333229796,
    "Accuracy_div_100": 0.90867,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Qualcomm/results/g292_z43_q18e-qaic-v1.8.3.7-aic100/bert-99.9/server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Qualcomm",
    "Platform": "g292_z43_q18e-qaic-v1.8.3.7-aic100",
    "Result": 6202.78,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "GIGABYTE G292-Z43 (18x QAIC100 Pro, EE)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 18,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.8.3",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": true,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7713 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5 LTS (Linux kernel: 5.4.0-135-generic #152-Ubuntu SMP Wed Nov 23 20:19:22 UTC 2022)",
    "uid": "fef6e504f7b346f7",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Qualcomm/results/g292_z43_q18e-qaic-v1.8.3.7-aic100/bert-99.9/server",
    "version": "v3.0",
    "Result_Power": 1649.9018333333336,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 90.8666333229796,
    "Accuracy_div_100": 0.90867,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Qualcomm/results/g292_z43_q18e-qaic-v1.8.3.7-aic100/bert-99.9/server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Qualcomm",
    "Platform": "g292_z43_q18e-qaic-v1.8.3.7-aic100",
    "Result": 6202.78,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "GIGABYTE G292-Z43 (18x QAIC100 Pro, EE)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 18,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.8.3",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": true,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7713 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5 LTS (Linux kernel: 5.4.0-135-generic #152-Ubuntu SMP Wed Nov 23 20:19:22 UTC 2022)",
    "uid": "fef6e504f7b346f7",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Qualcomm/results/g292_z43_q18e-qaic-v1.8.3.7-aic100/bert-99.9/server",
    "version": "v3.0",
    "Result_Power": 1649.9018333333336,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 90.2426510242233,
    "Accuracy_div_100": 0.90243,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Qualcomm/results/g292_z43_q16e-qaic-v1.8.3.7-aic100/bert-99/server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Qualcomm",
    "Platform": "g292_z43_q16e-qaic-v1.8.3.7-aic100",
    "Result": 9752.5,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "GIGABYTE G292-Z43 (16x QAIC100 Pro, EE)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 16,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.8.3",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": true,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7713 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5 LTS (Linux kernel: 5.4.0-135-generic #152-Ubuntu SMP Wed Nov 23 20:19:22 UTC 2022)",
    "uid": "25b657df55e344fe",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Qualcomm/results/g292_z43_q16e-qaic-v1.8.3.7-aic100/bert-99/server",
    "version": "v3.0",
    "Result_Power": 1296.4236666666675,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 90.2426510242233,
    "Accuracy_div_100": 0.90243,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Qualcomm/results/g292_z43_q16e-qaic-v1.8.3.7-aic100/bert-99/server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Qualcomm",
    "Platform": "g292_z43_q16e-qaic-v1.8.3.7-aic100",
    "Result": 9752.5,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "GIGABYTE G292-Z43 (16x QAIC100 Pro, EE)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 16,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.8.3",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": true,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7713 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5 LTS (Linux kernel: 5.4.0-135-generic #152-Ubuntu SMP Wed Nov 23 20:19:22 UTC 2022)",
    "uid": "25b657df55e344fe",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Qualcomm/results/g292_z43_q16e-qaic-v1.8.3.7-aic100/bert-99/server",
    "version": "v3.0",
    "Result_Power": 1296.4236666666675,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 90.8666333229796,
    "Accuracy_div_100": 0.90867,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Qualcomm/results/g292_z43_q16e-qaic-v1.8.3.7-aic100/bert-99.9/server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Qualcomm",
    "Platform": "g292_z43_q16e-qaic-v1.8.3.7-aic100",
    "Result": 5527.06,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "GIGABYTE G292-Z43 (16x QAIC100 Pro, EE)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 16,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.8.3",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": true,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7713 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5 LTS (Linux kernel: 5.4.0-135-generic #152-Ubuntu SMP Wed Nov 23 20:19:22 UTC 2022)",
    "uid": "4b077e31b82541af",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Qualcomm/results/g292_z43_q16e-qaic-v1.8.3.7-aic100/bert-99.9/server",
    "version": "v3.0",
    "Result_Power": 1438.037666666668,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 90.8666333229796,
    "Accuracy_div_100": 0.90867,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Qualcomm/results/g292_z43_q16e-qaic-v1.8.3.7-aic100/bert-99.9/server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Qualcomm",
    "Platform": "g292_z43_q16e-qaic-v1.8.3.7-aic100",
    "Result": 5527.06,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "GIGABYTE G292-Z43 (16x QAIC100 Pro, EE)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 16,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.8.3",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": true,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7713 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5 LTS (Linux kernel: 5.4.0-135-generic #152-Ubuntu SMP Wed Nov 23 20:19:22 UTC 2022)",
    "uid": "4b077e31b82541af",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Qualcomm/results/g292_z43_q16e-qaic-v1.8.3.7-aic100/bert-99.9/server",
    "version": "v3.0",
    "Result_Power": 1438.037666666668,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 90.2426510242233,
    "Accuracy_div_100": 0.90243,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/r7515_q4_pro-qaic-v1.8.3.7-aic100/bert-99/server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Dell",
    "Platform": "r7515_q4_pro-qaic-v1.8.3.7-aic100",
    "Result": 2724.61,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge R7515 (4x QAIC100 Pro)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.8.3",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": true,
    "host_processor_core_count": 32,
    "host_processor_model_name": "AMD EPYC 7542 32-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Powered by the KILT and CK technologies",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5 LTS (Linux kernel: 5.4.200-0504200-generic #202206221347 SMP Wed Jun 22 15:28:35 UTC 2022)",
    "uid": "32c64a676811492c",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Dell/results/r7515_q4_pro-qaic-v1.8.3.7-aic100/bert-99/server",
    "version": "v3.0",
    "Result_Power": 454.27133333333353,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 90.2426510242233,
    "Accuracy_div_100": 0.90243,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/r7515_q4_pro-qaic-v1.8.3.7-aic100/bert-99/server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Dell",
    "Platform": "r7515_q4_pro-qaic-v1.8.3.7-aic100",
    "Result": 2724.61,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge R7515 (4x QAIC100 Pro)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.8.3",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": true,
    "host_processor_core_count": 32,
    "host_processor_model_name": "AMD EPYC 7542 32-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Powered by the KILT and CK technologies",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5 LTS (Linux kernel: 5.4.200-0504200-generic #202206221347 SMP Wed Jun 22 15:28:35 UTC 2022)",
    "uid": "32c64a676811492c",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Dell/results/r7515_q4_pro-qaic-v1.8.3.7-aic100/bert-99/server",
    "version": "v3.0",
    "Result_Power": 454.27133333333353,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 90.8666333229796,
    "Accuracy_div_100": 0.90867,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/r7515_q4_pro-qaic-v1.8.3.7-aic100/bert-99.9/server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Dell",
    "Platform": "r7515_q4_pro-qaic-v1.8.3.7-aic100",
    "Result": 1373.07,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge R7515 (4x QAIC100 Pro)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.8.3",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": true,
    "host_processor_core_count": 32,
    "host_processor_model_name": "AMD EPYC 7542 32-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Powered by the KILT and CK technologies",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5 LTS (Linux kernel: 5.4.200-0504200-generic #202206221347 SMP Wed Jun 22 15:28:35 UTC 2022)",
    "uid": "f33ed5a59cda41c9",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Dell/results/r7515_q4_pro-qaic-v1.8.3.7-aic100/bert-99.9/server",
    "version": "v3.0",
    "Result_Power": 430.79308333333324,
    "Result_Power_Units": "Watts"
  },
  {
    "Accuracy": 90.8666333229796,
    "Accuracy_div_100": 0.90867,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/r7515_q4_pro-qaic-v1.8.3.7-aic100/bert-99.9/server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Dell",
    "Platform": "r7515_q4_pro-qaic-v1.8.3.7-aic100",
    "Result": 1373.07,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge R7515 (4x QAIC100 Pro)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.8.3",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": true,
    "host_processor_core_count": 32,
    "host_processor_model_name": "AMD EPYC 7542 32-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Powered by the KILT and CK technologies",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5 LTS (Linux kernel: 5.4.200-0504200-generic #202206221347 SMP Wed Jun 22 15:28:35 UTC 2022)",
    "uid": "f33ed5a59cda41c9",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Dell/results/r7515_q4_pro-qaic-v1.8.3.7-aic100/bert-99.9/server",
    "version": "v3.0",
    "Result_Power": 430.79308333333324,
    "Result_Power_Units": "Watts"
  }
]
