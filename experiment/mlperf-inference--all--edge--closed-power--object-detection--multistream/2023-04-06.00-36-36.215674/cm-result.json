[
  {
    "Accuracy": 37.375,
    "Accuracy_div_100": 0.37375,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 1.800339428921635,
    "Location": "closed/NVIDIA/results/Orin_NX_TRT_MaxQ/retinanet/MultiStream",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "NVIDIA",
    "Platform": "Orin_NX_TRT_MaxQ",
    "Result": 258.863459,
    "Result_Power": 4443.606506352988,
    "Result_Power_Units": "millijoules",
    "Result_Units": "Latency (ms)",
    "Scenario": "MultiStream",
    "SystemName": "NVIDIA Orin NX 16G (MaxQ, TensorRT)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "NVIDIA Orin NX 16G",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Jetpack 5.1.1, TensorRT 8.5.2, CUDA 11.4",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": true,
    "host_processor_core_count": 8,
    "host_processor_model_name": "8-core ARM Cortex-A78AE CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "NVIDIA Orin Nano Developer kit is used as the carrier board. GPU and both DLAs are used in resnet50 and Retinanet, in Offline scenario; WIFI module is physically removed.",
    "number_of_nodes": 1,
    "operating_system": "Jetson r35.3.1 L4T",
    "uid": "7a03f8aac663491b",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/NVIDIA/results/Orin_NX_TRT_MaxQ/retinanet/MultiStream",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.375,
    "Accuracy_div_100": 0.37375,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 1.800339428921635,
    "Location": "closed/NVIDIA/results/Orin_NX_TRT_MaxQ/retinanet/MultiStream",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "NVIDIA",
    "Platform": "Orin_NX_TRT_MaxQ",
    "Result": 258.863459,
    "Result_Power": 4443.606506352988,
    "Result_Power_Units": "millijoules",
    "Result_Units": "Latency (ms)",
    "Scenario": "MultiStream",
    "SystemName": "NVIDIA Orin NX 16G (MaxQ, TensorRT)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "NVIDIA Orin NX 16G",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Jetpack 5.1.1, TensorRT 8.5.2, CUDA 11.4",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": true,
    "host_processor_core_count": 8,
    "host_processor_model_name": "8-core ARM Cortex-A78AE CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "NVIDIA Orin Nano Developer kit is used as the carrier board. GPU and both DLAs are used in resnet50 and Retinanet, in Offline scenario; WIFI module is physically removed.",
    "number_of_nodes": 1,
    "operating_system": "Jetson r35.3.1 L4T",
    "uid": "7a03f8aac663491b",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/NVIDIA/results/Orin_NX_TRT_MaxQ/retinanet/MultiStream",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.373,
    "Accuracy_div_100": 0.37373,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 2.309023588077562,
    "Location": "closed/NVIDIA/results/Orin_TRT_MaxQ/retinanet/MultiStream",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "NVIDIA",
    "Platform": "Orin_TRT_MaxQ",
    "Result": 146.094127,
    "Result_Power": 3464.6679407292713,
    "Result_Power_Units": "millijoules",
    "Result_Units": "Latency (ms)",
    "Scenario": "MultiStream",
    "SystemName": "NVIDIA Jetson AGX Orin Developer Kit 64G (MaxQ, TensorRT)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "NVIDIA Jetson AGX Orin 64G",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Jetpack 5.1.1, TensorRT 8.5.2, CUDA 11.4",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": true,
    "host_processor_core_count": 12,
    "host_processor_model_name": "12-core ARM Cortex-A78AE CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "GPU and both DLAs are used in resnet50 and Retinanet, in Offline scenario. WIFI module is physically removed.",
    "number_of_nodes": 1,
    "operating_system": "Jetson r35.3.1 L4T",
    "uid": "5f5eb0ca4e54403c",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/NVIDIA/results/Orin_TRT_MaxQ/retinanet/MultiStream",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.373,
    "Accuracy_div_100": 0.37373,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 2.309023588077562,
    "Location": "closed/NVIDIA/results/Orin_TRT_MaxQ/retinanet/MultiStream",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "NVIDIA",
    "Platform": "Orin_TRT_MaxQ",
    "Result": 146.094127,
    "Result_Power": 3464.6679407292713,
    "Result_Power_Units": "millijoules",
    "Result_Units": "Latency (ms)",
    "Scenario": "MultiStream",
    "SystemName": "NVIDIA Jetson AGX Orin Developer Kit 64G (MaxQ, TensorRT)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "NVIDIA Jetson AGX Orin 64G",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Jetpack 5.1.1, TensorRT 8.5.2, CUDA 11.4",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": true,
    "host_processor_core_count": 12,
    "host_processor_model_name": "12-core ARM Cortex-A78AE CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "GPU and both DLAs are used in resnet50 and Retinanet, in Offline scenario. WIFI module is physically removed.",
    "number_of_nodes": 1,
    "operating_system": "Jetson r35.3.1 L4T",
    "uid": "5f5eb0ca4e54403c",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/NVIDIA/results/Orin_TRT_MaxQ/retinanet/MultiStream",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.419,
    "Accuracy_div_100": 0.37419,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 1.4756336722605372,
    "Location": "closed/CTuning/results/orin-nvidia_original-gpu-tensorrt-vdefault-default_config/retinanet/multistream",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "CTuning",
    "Platform": "orin-nvidia_original-gpu-tensorrt-vdefault-default_config",
    "Result": 145.36888,
    "Result_Power": 5421.39973516918,
    "Result_Power_Units": "millijoules",
    "Result_Units": "Latency (ms)",
    "Scenario": "MultiStream",
    "SystemName": "Siliconhighway NVIDIA Jetson AGX Orin (non MaxN image)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "NVIDIA Jetson AGX Orin 32G",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Nvidia inference implementation with CM API, Jetpack 5.1.1 with TensorRT 8.5.2, cuDNN 8.6.0, CUDA 11.4.19",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": true,
    "host_processor_core_count": 4,
    "host_processor_model_name": "ARMv8 Processor rev 1 (v8l)",
    "host_processors_per_node": 3,
    "inferred": 0,
    "notes": "Powered by MLCommons CM automation language and CK playground. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04 (linux-5.10.104-tegra-glibc2.31)",
    "uid": "4b12e482f0bf4aa2",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/CTuning/results/orin-nvidia_original-gpu-tensorrt-vdefault-default_config/retinanet/multistream",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.419,
    "Accuracy_div_100": 0.37419,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 1.4756336722605372,
    "Location": "closed/CTuning/results/orin-nvidia_original-gpu-tensorrt-vdefault-default_config/retinanet/multistream",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "CTuning",
    "Platform": "orin-nvidia_original-gpu-tensorrt-vdefault-default_config",
    "Result": 145.36888,
    "Result_Power": 5421.39973516918,
    "Result_Power_Units": "millijoules",
    "Result_Units": "Latency (ms)",
    "Scenario": "MultiStream",
    "SystemName": "Siliconhighway NVIDIA Jetson AGX Orin (non MaxN image)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "NVIDIA Jetson AGX Orin 32G",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Nvidia inference implementation with CM API, Jetpack 5.1.1 with TensorRT 8.5.2, cuDNN 8.6.0, CUDA 11.4.19",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": true,
    "host_processor_core_count": 4,
    "host_processor_model_name": "ARMv8 Processor rev 1 (v8l)",
    "host_processors_per_node": 3,
    "inferred": 0,
    "notes": "Powered by MLCommons CM automation language and CK playground. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04 (linux-5.10.104-tegra-glibc2.31)",
    "uid": "4b12e482f0bf4aa2",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/CTuning/results/orin-nvidia_original-gpu-tensorrt-vdefault-default_config/retinanet/multistream",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.421,
    "Accuracy_div_100": 0.37421,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 1.0355657327197734,
    "Location": "closed/CTuning/results/amd_zen4_workstation-nvidia_original-gpu-tensorrt-vdefault-default_config/retinanet/multistream",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "CTuning",
    "Platform": "amd_zen4_workstation-nvidia_original-gpu-tensorrt-vdefault-default_config",
    "Result": 13.983442,
    "Result_Power": 7725.245966751992,
    "Result_Power_Units": "millijoules",
    "Result_Units": "Latency (ms)",
    "Scenario": "MultiStream",
    "SystemName": "PCSPECIALIST AMD AM5 PC with Nvidia RTX 4090",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "NVIDIA GeForce RTX 4090 (Ada Lovelace)",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Nvidia inference implementation with CM API, TensorRT v8.6.1.6",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": true,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD Ryzen 9 7950X 16-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Powered by MLCommons CM automation language and CK playground. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-5.19.0-46-generic-glibc2.35)",
    "uid": "6fda59df8f1448b1",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/CTuning/results/amd_zen4_workstation-nvidia_original-gpu-tensorrt-vdefault-default_config/retinanet/multistream",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.421,
    "Accuracy_div_100": 0.37421,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 1.0355657327197734,
    "Location": "closed/CTuning/results/amd_zen4_workstation-nvidia_original-gpu-tensorrt-vdefault-default_config/retinanet/multistream",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "CTuning",
    "Platform": "amd_zen4_workstation-nvidia_original-gpu-tensorrt-vdefault-default_config",
    "Result": 13.983442,
    "Result_Power": 7725.245966751992,
    "Result_Power_Units": "millijoules",
    "Result_Units": "Latency (ms)",
    "Scenario": "MultiStream",
    "SystemName": "PCSPECIALIST AMD AM5 PC with Nvidia RTX 4090",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "NVIDIA GeForce RTX 4090 (Ada Lovelace)",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Nvidia inference implementation with CM API, TensorRT v8.6.1.6",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": true,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD Ryzen 9 7950X 16-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Powered by MLCommons CM automation language and CK playground. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-5.19.0-46-generic-glibc2.35)",
    "uid": "6fda59df8f1448b1",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/CTuning/results/amd_zen4_workstation-nvidia_original-gpu-tensorrt-vdefault-default_config/retinanet/multistream",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.422,
    "Accuracy_div_100": 0.37422,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 1.275168058426635,
    "Location": "closed/CTuning/results/nvidia_orin_64k_default_jetpack-nvidia_original-gpu-tensorrt-vdefault-default_config/retinanet/multistream",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "CTuning",
    "Platform": "nvidia_orin_64k_default_jetpack-nvidia_original-gpu-tensorrt-vdefault-default_config",
    "Result": 101.20712,
    "Result_Power": 6273.682866453535,
    "Result_Power_Units": "millijoules",
    "Result_Units": "Latency (ms)",
    "Scenario": "MultiStream",
    "SystemName": "Siliconhighway NVIDIA Jetson AGX Orin (64K page size)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "NVIDIA Jetson AGX Orin 32G",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Jetpack 5.1.1 with TensorRT 8.5.2, cuDNN 8.6.0, CUDA 11.4.19",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": true,
    "host_processor_core_count": 4,
    "host_processor_model_name": "ARMv8 Processor rev 1 (v8l)",
    "host_processors_per_node": 3,
    "inferred": 0,
    "notes": "Powered by MLCommons CM automation language and CK playground. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04 (linux-5.10.104-tegra-glibc2.31)",
    "uid": "6031cd04d037441c",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/CTuning/results/nvidia_orin_64k_default_jetpack-nvidia_original-gpu-tensorrt-vdefault-default_config/retinanet/multistream",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.422,
    "Accuracy_div_100": 0.37422,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 1.275168058426635,
    "Location": "closed/CTuning/results/nvidia_orin_64k_default_jetpack-nvidia_original-gpu-tensorrt-vdefault-default_config/retinanet/multistream",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "CTuning",
    "Platform": "nvidia_orin_64k_default_jetpack-nvidia_original-gpu-tensorrt-vdefault-default_config",
    "Result": 101.20712,
    "Result_Power": 6273.682866453535,
    "Result_Power_Units": "millijoules",
    "Result_Units": "Latency (ms)",
    "Scenario": "MultiStream",
    "SystemName": "Siliconhighway NVIDIA Jetson AGX Orin (64K page size)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "NVIDIA Jetson AGX Orin 32G",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Jetpack 5.1.1 with TensorRT 8.5.2, cuDNN 8.6.0, CUDA 11.4.19",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": true,
    "host_processor_core_count": 4,
    "host_processor_model_name": "ARMv8 Processor rev 1 (v8l)",
    "host_processors_per_node": 3,
    "inferred": 0,
    "notes": "Powered by MLCommons CM automation language and CK playground. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04 (linux-5.10.104-tegra-glibc2.31)",
    "uid": "6031cd04d037441c",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/CTuning/results/nvidia_orin_64k_default_jetpack-nvidia_original-gpu-tensorrt-vdefault-default_config/retinanet/multistream",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.422,
    "Accuracy_div_100": 0.37422,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 1.2472161435851798,
    "Location": "closed/CTuning/results/nvidia_orin_maxn_pagesize.4k-nvidia_original-gpu-tensorrt-vdefault-default_config/retinanet/multistream",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "CTuning",
    "Platform": "nvidia_orin_maxn_pagesize.4k-nvidia_original-gpu-tensorrt-vdefault-default_config",
    "Result": 104.679329,
    "Result_Power": 6414.285159109338,
    "Result_Power_Units": "millijoules",
    "Result_Units": "Latency (ms)",
    "Scenario": "MultiStream",
    "SystemName": "Siliconhighway NVIDIA Jetson AGX Orin (4K page size)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "NVIDIA Jetson AGX Orin 32G",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Jetpack 5.1.1 with TensorRT 8.5.2, cuDNN 8.6.0, CUDA 11.4.19",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": true,
    "host_processor_core_count": 4,
    "host_processor_model_name": "ARMv8 Processor rev 1 (v8l)",
    "host_processors_per_node": 3,
    "inferred": 0,
    "notes": "Powered by MLCommons CM automation language and CK playground. ",
    "number_of_nodes": 1,
    "operating_system": "Jetson Linux 35.3.1, Ubuntu 20.04 (linux-5.10.104-tegra-glibc2.31)",
    "uid": "33dab43abca645f4",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/CTuning/results/nvidia_orin_maxn_pagesize.4k-nvidia_original-gpu-tensorrt-vdefault-default_config/retinanet/multistream",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.422,
    "Accuracy_div_100": 0.37422,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 1.2472161435851798,
    "Location": "closed/CTuning/results/nvidia_orin_maxn_pagesize.4k-nvidia_original-gpu-tensorrt-vdefault-default_config/retinanet/multistream",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "CTuning",
    "Platform": "nvidia_orin_maxn_pagesize.4k-nvidia_original-gpu-tensorrt-vdefault-default_config",
    "Result": 104.679329,
    "Result_Power": 6414.285159109338,
    "Result_Power_Units": "millijoules",
    "Result_Units": "Latency (ms)",
    "Scenario": "MultiStream",
    "SystemName": "Siliconhighway NVIDIA Jetson AGX Orin (4K page size)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "NVIDIA Jetson AGX Orin 32G",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Jetpack 5.1.1 with TensorRT 8.5.2, cuDNN 8.6.0, CUDA 11.4.19",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": true,
    "host_processor_core_count": 4,
    "host_processor_model_name": "ARMv8 Processor rev 1 (v8l)",
    "host_processors_per_node": 3,
    "inferred": 0,
    "notes": "Powered by MLCommons CM automation language and CK playground. ",
    "number_of_nodes": 1,
    "operating_system": "Jetson Linux 35.3.1, Ubuntu 20.04 (linux-5.10.104-tegra-glibc2.31)",
    "uid": "33dab43abca645f4",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/CTuning/results/nvidia_orin_maxn_pagesize.4k-nvidia_original-gpu-tensorrt-vdefault-default_config/retinanet/multistream",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.21,
    "Accuracy_div_100": 0.3721,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 1.3065130035023325,
    "Location": "closed/Lenovo/results/se450_q4_std/retinanet/multistream",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Lenovo",
    "Platform": "se450_q4_std",
    "Result": 21.35082,
    "Result_Power": 6123.169060357322,
    "Result_Power_Units": "millijoules",
    "Result_Units": "Latency (ms)",
    "Scenario": "MultiStream",
    "SystemName": "Lenovo ThinkEdge SE450 Edge Server (4x QAIC100 Standard)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Standard",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.9.1",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": true,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 5318N CPU @ 2.10 GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Powered by the KRAI X and KILT technologies",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6 LTS (Linux kernel: 5.4.0-139-generic #156-Ubuntu SMP Fri Jan 20 17:27:18 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "dab3bf804d514db2",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Lenovo/results/se450_q4_std/retinanet/multistream",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.21,
    "Accuracy_div_100": 0.3721,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 1.3065130035023325,
    "Location": "closed/Lenovo/results/se450_q4_std/retinanet/multistream",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Lenovo",
    "Platform": "se450_q4_std",
    "Result": 21.35082,
    "Result_Power": 6123.169060357322,
    "Result_Power_Units": "millijoules",
    "Result_Units": "Latency (ms)",
    "Scenario": "MultiStream",
    "SystemName": "Lenovo ThinkEdge SE450 Edge Server (4x QAIC100 Standard)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Standard",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.9.1",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": true,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 5318N CPU @ 2.10 GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Powered by the KRAI X and KILT technologies",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6 LTS (Linux kernel: 5.4.0-139-generic #156-Ubuntu SMP Fri Jan 20 17:27:18 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "dab3bf804d514db2",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Lenovo/results/se450_q4_std/retinanet/multistream",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.244,
    "Accuracy_div_100": 0.37244,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 3.8119458001920283,
    "Location": "closed/Qualcomm/results/gloria_highend/retinanet/multistream",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Qualcomm",
    "Platform": "gloria_highend",
    "Result": 107.403019,
    "Result_Power": 2098.665725938967,
    "Result_Power_Units": "millijoules",
    "Result_Units": "Latency (ms)",
    "Scenario": "MultiStream",
    "SystemName": "Foxconn Gloria (Highend)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 DM.2",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.9.1",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": true,
    "host_processor_core_count": 8,
    "host_processor_model_name": "QUALCOMM Snapdragon 865 (QRB5165)",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "With 20W Accelerator TDP constraints; optional SSD and 5G module not installed",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu Linux 18.04.6 LTS (kernel: 4.19.125-perf #1 SMP PREEMPT Wed Jun 8 17:13:04 UTC 2022)",
    "uid": "c36657d849a04afc",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Qualcomm/results/gloria_highend/retinanet/multistream",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.244,
    "Accuracy_div_100": 0.37244,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 3.8119458001920283,
    "Location": "closed/Qualcomm/results/gloria_highend/retinanet/multistream",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Qualcomm",
    "Platform": "gloria_highend",
    "Result": 107.403019,
    "Result_Power": 2098.665725938967,
    "Result_Power_Units": "millijoules",
    "Result_Units": "Latency (ms)",
    "Scenario": "MultiStream",
    "SystemName": "Foxconn Gloria (Highend)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 DM.2",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.9.1",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": true,
    "host_processor_core_count": 8,
    "host_processor_model_name": "QUALCOMM Snapdragon 865 (QRB5165)",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "With 20W Accelerator TDP constraints; optional SSD and 5G module not installed",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu Linux 18.04.6 LTS (kernel: 4.19.125-perf #1 SMP PREEMPT Wed Jun 8 17:13:04 UTC 2022)",
    "uid": "c36657d849a04afc",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Qualcomm/results/gloria_highend/retinanet/multistream",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.21,
    "Accuracy_div_100": 0.3721,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 1.5126466784169017,
    "Location": "closed/Qualcomm/results/r282_z93_q5e/retinanet/multistream",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Qualcomm",
    "Platform": "r282_z93_q5e",
    "Result": 16.564365,
    "Result_Power": 5288.743309424115,
    "Result_Power_Units": "millijoules",
    "Result_Units": "Latency (ms)",
    "Scenario": "MultiStream",
    "SystemName": "GIGABYTE R282-Z93 (5x QAIC100 Pro, EE)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 5,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.9.1",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": true,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 7282 16-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Powered by the KRAI X and KILT technologies",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6 LTS (Linux kernel: 5.4.0-148-generic #165-Ubuntu SMP Tue Apr 18 08:53:12 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "a9b8cdd0245c4d41",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Qualcomm/results/r282_z93_q5e/retinanet/multistream",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.21,
    "Accuracy_div_100": 0.3721,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 1.5126466784169017,
    "Location": "closed/Qualcomm/results/r282_z93_q5e/retinanet/multistream",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Qualcomm",
    "Platform": "r282_z93_q5e",
    "Result": 16.564365,
    "Result_Power": 5288.743309424115,
    "Result_Power_Units": "millijoules",
    "Result_Units": "Latency (ms)",
    "Scenario": "MultiStream",
    "SystemName": "GIGABYTE R282-Z93 (5x QAIC100 Pro, EE)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 5,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.9.1",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": true,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 7282 16-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Powered by the KRAI X and KILT technologies",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6 LTS (Linux kernel: 5.4.0-148-generic #165-Ubuntu SMP Tue Apr 18 08:53:12 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "a9b8cdd0245c4d41",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Qualcomm/results/r282_z93_q5e/retinanet/multistream",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.465,
    "Accuracy_div_100": 0.37465,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 0.5825712653681054,
    "Location": "closed/Dell/results/XR5610_L4x1_TRT_MaxQ/retinanet/MultiStream",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Dell",
    "Platform": "XR5610_L4x1_TRT_MaxQ",
    "Result": 42.060064,
    "Result_Power": 13732.22552428001,
    "Result_Power_Units": "millijoules",
    "Result_Units": "Latency (ms)",
    "Scenario": "MultiStream",
    "SystemName": "Dell PowerEdge XR5610 (1x L4, MaxQ, TensorRT)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2,",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": true,
    "host_processor_core_count": 20,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 5423N CPU @ 2.10GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "CentOS 8.2",
    "uid": "40fcafe44e8a4881",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Dell/results/XR5610_L4x1_TRT_MaxQ/retinanet/MultiStream",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.465,
    "Accuracy_div_100": 0.37465,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 0.5825712653681054,
    "Location": "closed/Dell/results/XR5610_L4x1_TRT_MaxQ/retinanet/MultiStream",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Dell",
    "Platform": "XR5610_L4x1_TRT_MaxQ",
    "Result": 42.060064,
    "Result_Power": 13732.22552428001,
    "Result_Power_Units": "millijoules",
    "Result_Units": "Latency (ms)",
    "Scenario": "MultiStream",
    "SystemName": "Dell PowerEdge XR5610 (1x L4, MaxQ, TensorRT)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2,",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": true,
    "host_processor_core_count": 20,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 5423N CPU @ 2.10GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "CentOS 8.2",
    "uid": "40fcafe44e8a4881",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Dell/results/XR5610_L4x1_TRT_MaxQ/retinanet/MultiStream",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.21,
    "Accuracy_div_100": 0.3721,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 1.301514413587212,
    "Location": "closed/HPE/results/e920d_q4_std/retinanet/multistream",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "HPE",
    "Platform": "e920d_q4_std",
    "Result": 18.597612,
    "Result_Power": 6146.685673615043,
    "Result_Power_Units": "millijoules",
    "Result_Units": "Latency (ms)",
    "Scenario": "MultiStream",
    "SystemName": "HPE ProLiant e920d (4x QAIC100 Standard)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Standard",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.9.1",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": true,
    "host_processor_core_count": 36,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8351N CPU @ 2.40 GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints; Edgeline EL8000 chassis. Powered by the KRAI X and KILT technologies",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6 LTS (Linux kernel: 5.4.0-139-generic #156-Ubuntu SMP Fri Jan 20 17:27:18 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "7e30b1db746548ab",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/HPE/results/e920d_q4_std/retinanet/multistream",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.21,
    "Accuracy_div_100": 0.3721,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 1.301514413587212,
    "Location": "closed/HPE/results/e920d_q4_std/retinanet/multistream",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "HPE",
    "Platform": "e920d_q4_std",
    "Result": 18.597612,
    "Result_Power": 6146.685673615043,
    "Result_Power_Units": "millijoules",
    "Result_Units": "Latency (ms)",
    "Scenario": "MultiStream",
    "SystemName": "HPE ProLiant e920d (4x QAIC100 Standard)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Standard",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.9.1",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": true,
    "host_processor_core_count": 36,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8351N CPU @ 2.40 GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints; Edgeline EL8000 chassis. Powered by the KRAI X and KILT technologies",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6 LTS (Linux kernel: 5.4.0-139-generic #156-Ubuntu SMP Fri Jan 20 17:27:18 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "7e30b1db746548ab",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/HPE/results/e920d_q4_std/retinanet/multistream",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.48,
    "Accuracy_div_100": 0.3748,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 1.3971188650442166,
    "Location": "closed/NVIDIA/results/Orin_TRT_MaxQ/retinanet/MultiStream",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "NVIDIA",
    "Platform": "Orin_TRT_MaxQ",
    "Result": 177.254471,
    "Result_Power": 5726.069699693599,
    "Result_Power_Units": "millijoules",
    "Result_Units": "Latency (ms)",
    "Scenario": "MultiStream",
    "SystemName": "NVIDIA Orin (MaxQ, TensorRT)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "NVIDIA Orin",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "22.08 Jetson CUDA-X AI Developer Preview, TensorRT 8.5.0, CUDA 11.4",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": true,
    "host_processor_core_count": 12,
    "host_processor_model_name": "12-core Cortex-A78 CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "GPU and both DLAs are used in resnet50, in Offline scenario",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04",
    "uid": "80186d7f47034095",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/NVIDIA/results/Orin_TRT_MaxQ/retinanet/MultiStream",
    "version": "v2.1"
  },
  {
    "Accuracy": 37.239,
    "Accuracy_div_100": 0.37239,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 3.267610297016802,
    "Location": "closed/Krai/results/eb6-qaic-v1.8.3.7-aic100/retinanet/multistream",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Krai",
    "Platform": "eb6-qaic-v1.8.3.7-aic100",
    "Result": 118.765124,
    "Result_Power": 2448.2723681289904,
    "Result_Power_Units": "millijoules",
    "Result_Units": "Latency (ms)",
    "Scenario": "MultiStream",
    "SystemName": "Thundercomm TurboX EB6 Edge AI Box",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 DM.2e",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.8.3",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": true,
    "host_processor_core_count": 8,
    "host_processor_model_name": "QUALCOMM Snapdragon 865 (QRB5165)",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "With 15W Accelerator TDP constraints; optional 5G and SSD modules not installed. Powered by Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu Linux 18.04.6 LTS (kernel: 4.19.125-perf #1 SMP PREEMPT Fri May 6 18:00:47 CST 2022)",
    "uid": "d1b6550879df4c10",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Krai/results/eb6-qaic-v1.8.3.7-aic100/retinanet/multistream",
    "version": "v3.0"
  },
  {
    "Accuracy": 37.239,
    "Accuracy_div_100": 0.37239,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 3.4208097264038653,
    "Location": "closed/Krai/results/rb6-qaic-v1.8.3.7-aic100/retinanet/multistream",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Krai",
    "Platform": "rb6-qaic-v1.8.3.7-aic100",
    "Result": 117.445241,
    "Result_Power": 2338.6275881558663,
    "Result_Power_Units": "millijoules",
    "Result_Units": "Latency (ms)",
    "Scenario": "MultiStream",
    "SystemName": "Thundercomm RB6",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 DM.2e",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.8.3",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": true,
    "host_processor_core_count": 8,
    "host_processor_model_name": "QUALCOMM Snapdragon 865 (QRB5165)",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "With 15W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu Linux 18.04.6 LTS (kernel: rb6 4.19.125-perf #1 SMP PREEMPT Wed Sep 21 23:34:16 UTC 2022)",
    "uid": "123a443adbb743ec",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Krai/results/rb6-qaic-v1.8.3.7-aic100/retinanet/multistream",
    "version": "v3.0"
  },
  {
    "Accuracy": 37.519,
    "Accuracy_div_100": 0.37519,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 1.9872171697614691,
    "Location": "closed/NVIDIA/results/Orin_TRT_MaxQ/retinanet/MultiStream",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "NVIDIA",
    "Platform": "Orin_TRT_MaxQ",
    "Result": 149.980812,
    "Result_Power": 4025.7301123058737,
    "Result_Power_Units": "millijoules",
    "Result_Units": "Latency (ms)",
    "Scenario": "MultiStream",
    "SystemName": "NVIDIA Jetson AGX Orin (MaxQ, TensorRT)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "NVIDIA Jetson AGX Orin",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "23.02 Jetson CUDA-X AI Developer Preview, TensorRT 8.5.2, CUDA 11.4",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": true,
    "host_processor_core_count": 12,
    "host_processor_model_name": "12-core ARM Cortex-A78AE CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "GPU and both DLAs are used in resnet50 and Retinanet, in Offline scenario",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04",
    "uid": "c12de091195845a1",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/NVIDIA/results/Orin_TRT_MaxQ/retinanet/MultiStream",
    "version": "v3.0"
  },
  {
    "Accuracy": 37.239,
    "Accuracy_div_100": 0.37239,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 1.1332124496490104,
    "Location": "closed/Lenovo/results/se350_q1_pro-qaic-v1.8.3.7-aic100/retinanet/multistream",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Lenovo",
    "Platform": "se350_q1_pro-qaic-v1.8.3.7-aic100",
    "Result": 67.521374,
    "Result_Power": 7059.576518487631,
    "Result_Power_Units": "millijoules",
    "Result_Units": "Latency (ms)",
    "Scenario": "MultiStream",
    "SystemName": "Lenovo ThinkSystem SE350 Edge Server (1x QAIC100 Pro)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.8.3",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": true,
    "host_processor_core_count": 12,
    "host_processor_model_name": "Intel(R) Xeon(R) D-2166NT CPU @ 2.00GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Powered by the KILT and CK technologies",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5 LTS (Linux kernel: 5.4.0-139-generic #156-Ubuntu SMP Fri Jan 20 17:27:18 UTC 2023)",
    "uid": "d028a40c857344b6",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Lenovo/results/se350_q1_pro-qaic-v1.8.3.7-aic100/retinanet/multistream",
    "version": "v3.0"
  },
  {
    "Accuracy": 37.239,
    "Accuracy_div_100": 0.37239,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 0.7817664006018954,
    "Location": "closed/Lenovo/results/se450_q4_lite-qaic-v1.8.3.7-aic100/retinanet/multistream",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Lenovo",
    "Platform": "se450_q4_lite-qaic-v1.8.3.7-aic100",
    "Result": 45.230661,
    "Result_Power": 10233.235905048698,
    "Result_Power_Units": "millijoules",
    "Result_Units": "Latency (ms)",
    "Scenario": "MultiStream",
    "SystemName": "Lenovo ThinkEdge SE450 Edge Server (4x QAIC100 Lite)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Lite",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.8.3",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": true,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 5318N CPU @ 2.10GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "With 55W Accelerator TDP constraints. Powered by the KILT and CK technologies",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5 LTS (Linux kernel: 5.4.0-136-generic #153-Ubuntu SMP Thu Nov 24 15:56:58 UTC 2022)",
    "uid": "bb565c7bdc944999",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Lenovo/results/se450_q4_lite-qaic-v1.8.3.7-aic100/retinanet/multistream",
    "version": "v3.0"
  },
  {
    "Accuracy": 37.19,
    "Accuracy_div_100": 0.3719,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 3.809002269915044,
    "Location": "closed/Qualcomm/results/gloria_highend-qaic-v1.8.3.7-aic100/retinanet/multistream",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Qualcomm",
    "Platform": "gloria_highend-qaic-v1.8.3.7-aic100",
    "Result": 109.659154,
    "Result_Power": 2100.2875380744867,
    "Result_Power_Units": "millijoules",
    "Result_Units": "Latency (ms)",
    "Scenario": "MultiStream",
    "SystemName": "Foxconn Gloria (Highend)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 DM.2",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.8.3",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": true,
    "host_processor_core_count": 8,
    "host_processor_model_name": "QUALCOMM Snapdragon 865 (QRB5165)",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "With 20W Accelerator TDP constraints; optional 5G and SSD modules not installed. Powered by Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.6 LTS (kernel: 4.19.125-perf #1 SMP PREEMPT Wed Jun 8 17:13:04 UTC 2022)",
    "uid": "550ce76e0d4d4c00",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Qualcomm/results/gloria_highend-qaic-v1.8.3.7-aic100/retinanet/multistream",
    "version": "v3.0"
  },
  {
    "Accuracy": 37.19,
    "Accuracy_div_100": 0.3719,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 3.4175633834130834,
    "Location": "closed/Qualcomm/results/gloria-qaic-v1.8.3.7-aic100/retinanet/multistream",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Qualcomm",
    "Platform": "gloria-qaic-v1.8.3.7-aic100",
    "Result": 113.128738,
    "Result_Power": 2340.8490501822052,
    "Result_Power_Units": "millijoules",
    "Result_Units": "Latency (ms)",
    "Scenario": "MultiStream",
    "SystemName": "Foxconn Gloria (Entry)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 DM.2e",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.8.3",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": true,
    "host_processor_core_count": 8,
    "host_processor_model_name": "QUALCOMM Snapdragon 865 (QRB5165)",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "With 15W Accelerator TDP constraints; optional 5G and SSD modules not installed. Powered by Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.6 LTS (Linux kernel: 4.19.125-perf #1 SMP PREEMPT Tue Apr 19 06:20:02 UTC 2022)",
    "uid": "586726394e8440b3",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Qualcomm/results/gloria-qaic-v1.8.3.7-aic100/retinanet/multistream",
    "version": "v3.0"
  },
  {
    "Accuracy": 37.177,
    "Accuracy_div_100": 0.37177,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 3.59651168685417,
    "Location": "closed/Qualcomm/results/heimdall-qaic-v1.8.3.7-aic100/retinanet/multistream",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Qualcomm",
    "Platform": "heimdall-qaic-v1.8.3.7-aic100",
    "Result": 116.606921,
    "Result_Power": 2224.3775904416743,
    "Result_Power_Units": "millijoules",
    "Result_Units": "Latency (ms)",
    "Scenario": "MultiStream",
    "SystemName": "Inventec Heimdall",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 DM.2e",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.8.3",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": true,
    "host_processor_core_count": 8,
    "host_processor_model_name": "QUALCOMM Snapdragon 865 (SM8250)",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "With 15W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "CentOS Linux release 8.0.1905 (kernel: 4.19.81-perf #1 SMP PREEMPT Thu Feb 24 03:59:56 UTC 2022 aarch64 aarch64 aarch64 GNU/Linux)",
    "uid": "8e529f592291462f",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Qualcomm/results/heimdall-qaic-v1.8.3.7-aic100/retinanet/multistream",
    "version": "v3.0"
  },
  {
    "Accuracy": 37.239,
    "Accuracy_div_100": 0.37239,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 1.0169645319934322,
    "Location": "closed/Qualcomm/results/r282_z93_q5e-qaic-v1.8.3.7-aic100/retinanet/multistream",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Qualcomm",
    "Platform": "r282_z93_q5e-qaic-v1.8.3.7-aic100",
    "Result": 32.725935,
    "Result_Power": 7866.547699867733,
    "Result_Power_Units": "millijoules",
    "Result_Units": "Latency (ms)",
    "Scenario": "MultiStream",
    "SystemName": "GIGABYTE R282-Z93 (5x QAIC100 Pro, EE)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 5,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.8.3",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": true,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 7282 16-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5 LTS (Linux kernel: 5.4.0-125-generic #141-Ubuntu SMP Wed Aug 10 13:42:03 UTC 2022)",
    "uid": "df51e20fad3246eb",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Qualcomm/results/r282_z93_q5e-qaic-v1.8.3.7-aic100/retinanet/multistream",
    "version": "v3.0"
  },
  {
    "Accuracy": 37.239,
    "Accuracy_div_100": 0.37239,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 0.7835884736661612,
    "Location": "closed/Dell/results/xr4520c_q2_lite-qaic-v1.8.3.7-aic100/retinanet/multistream",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Dell",
    "Platform": "xr4520c_q2_lite-qaic-v1.8.3.7-aic100",
    "Result": 81.800861,
    "Result_Power": 10209.440629684794,
    "Result_Power_Units": "millijoules",
    "Result_Units": "Latency (ms)",
    "Scenario": "MultiStream",
    "SystemName": "Dell PowerEdge XR4520c (2x QAIC100 Lite)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Lite",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.8.3",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": true,
    "host_processor_core_count": 16,
    "host_processor_model_name": "Intel(R) Xeon(R) D-2776NT CPU @ 2.10GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "With 55W Accelerator TDP constraints; Accelerator TDP ranges 35-55W.. Powered by the KILT and CK technologies",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2 LTS (Linux kernel: 5.15.0-60-generic #66-Ubuntu SMP Fri Jan 20 14:29:49 UTC 2023)",
    "uid": "8e6e5eae5190477d",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Dell/results/xr4520c_q2_lite-qaic-v1.8.3.7-aic100/retinanet/multistream",
    "version": "v3.0"
  },
  {
    "Accuracy": 37.55,
    "Accuracy_div_100": 0.3755,
    "Availability": "preview",
    "Division": "closed",
    "Inference_per_Joule": 0.25613032551517395,
    "Location": "closed/Dell/results/XR5610_L4x1_TRT_MaxQ/retinanet/MultiStream",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Dell",
    "Platform": "XR5610_L4x1_TRT_MaxQ",
    "Result": 50.672834,
    "Result_Power": 31234.09921847015,
    "Result_Power_Units": "millijoules",
    "Result_Units": "Latency (ms)",
    "Scenario": "MultiStream",
    "SystemName": "Dell PowerEdge XR5610 (1x L4, MaxQ, TensorRT)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": true,
    "host_processor_core_count": 20,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 5423N CPU @ 2.10GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "CentOS 8.2",
    "uid": "ede74251d1bd4e4c",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Dell/results/XR5610_L4x1_TRT_MaxQ/retinanet/MultiStream",
    "version": "v3.0"
  },
  {
    "Accuracy": 37.537,
    "Accuracy_div_100": 0.37537,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 0.2601655630460783,
    "Location": "closed/Dell/results/XR4520c_MaxQ_A2x1_TRT_MaxQ/retinanet/MultiStream",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Dell",
    "Platform": "XR4520c_MaxQ_A2x1_TRT_MaxQ",
    "Result": 148.406729,
    "Result_Power": 30749.649978014608,
    "Result_Power_Units": "millijoules",
    "Result_Units": "Latency (ms)",
    "Scenario": "MultiStream",
    "SystemName": "Dell PowerEdge XR4520c (1x A2, MaxQ, TensorRT)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "NVIDIA A2",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": true,
    "host_processor_core_count": 16,
    "host_processor_model_name": "Intel(R) Xeon(R) D-2776NT CPU @ 2.10GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "83bab50f0e8f4834",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Dell/results/XR4520c_MaxQ_A2x1_TRT_MaxQ/retinanet/MultiStream",
    "version": "v3.0"
  },
  {
    "Accuracy": 37.575,
    "Accuracy_div_100": 0.37575,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 0.1323912329906618,
    "Location": "closed/cTuning/results/amd_zen4_workstation-reference-gpu-onnxruntime-v1.14.0-default_config/retinanet/multistream",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "cTuning",
    "Platform": "amd_zen4_workstation-reference-gpu-onnxruntime-v1.14.0-default_config",
    "Result": 145.877896,
    "Result_Power": 60426.96196178095,
    "Result_Power_Units": "millijoules",
    "Result_Units": "Latency (ms)",
    "Scenario": "MultiStream",
    "SystemName": "AMD Ryzen Zen4 workstation with Nvidia RTX 4090",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "NVIDIA GeForce RTX 4090 (Ada Lovelace)",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Onnxruntime v1.14.0 with GPU support",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": true,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD Ryzen 9 7950X 16-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 1,
    "notes": "Result donated by GATE Overflow Educational Foundation. Powered by MLCommons Collective Mind framework (CK2). ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-5.19.0-32-generic-glibc2.35)",
    "uid": "8078f3655fa04784",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/cTuning/results/amd_zen4_workstation-reference-gpu-onnxruntime-v1.14.0-default_config/retinanet/multistream",
    "version": "v3.0"
  },
  {
    "Accuracy": 37.239,
    "Accuracy_div_100": 0.37239,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 1.0682968834041657,
    "Location": "closed/HPE/results/e920d_q4_std-qaic-v1.8.3.7-aic100/retinanet/multistream",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "HPE",
    "Platform": "e920d_q4_std-qaic-v1.8.3.7-aic100",
    "Result": 26.084267,
    "Result_Power": 7488.555030234402,
    "Result_Power_Units": "millijoules",
    "Result_Units": "Latency (ms)",
    "Scenario": "MultiStream",
    "SystemName": "HPE ProLiant e920d (4x QAIC100 Standard)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Standard",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.8.3",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": true,
    "host_processor_core_count": 36,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8351N CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5 LTS (Linux kernel: 5.4.0-139-generic #156-Ubuntu SMP Fri Jan 20 17:27:18 UTC 2023)",
    "uid": "9a87b3390a9c42f6",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/HPE/results/e920d_q4_std-qaic-v1.8.3.7-aic100/retinanet/multistream",
    "version": "v3.0"
  }
]
