[
  {
    "Accuracy": 90.28408874066913,
    "Accuracy_div_100": 0.90284,
    "Availability": "available",
    "Division": "network",
    "Location": "network/Krai/results/dl385_q8_std/bert-99/server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Krai",
    "Platform": "dl385_q8_std",
    "Result": 5347.67,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "HPE ProLiant DL385 Gen10 Plus v2 (8x QAIC100 Standard) [NETWORK]",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 Standard",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "AMD EPYC 7543 32-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Powered by the KRAI X and KILT technologies over the network",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6 LTS (Linux kernel 5.15.0-91-generic #101~20.04.1-Ubuntu SMP Thu Nov 16 14:22:28 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "9f3592f5def144d1",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/network/Krai/results/dl385_q8_std/bert-99/server",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.8666333229796,
    "Accuracy_div_100": 0.90867,
    "Availability": "available",
    "Division": "network",
    "Location": "network/Krai/results/dl385_q8_std/bert-99.9/server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Krai",
    "Platform": "dl385_q8_std",
    "Result": 2601.21,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "HPE ProLiant DL385 Gen10 Plus v2 (8x QAIC100 Standard) [NETWORK]",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 Standard",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "AMD EPYC 7543 32-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Powered by the KRAI X and KILT technologies over the network",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6 LTS (Linux kernel 5.15.0-91-generic #101~20.04.1-Ubuntu SMP Thu Nov 16 14:22:28 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "8cd3e2db99e44e7f",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/network/Krai/results/dl385_q8_std/bert-99.9/server",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.28408874066913,
    "Accuracy_div_100": 0.90284,
    "Availability": "available",
    "Division": "network",
    "Location": "network/Qualcomm/results/g292_z43_q16/bert-99/server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Qualcomm",
    "Platform": "g292_z43_q16",
    "Result": 12003.7,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Gigabyte G292-Z43 (16x QAIC100)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 16,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.9.1",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7713 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Powered by the KRAI X and KILT technologies",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6 LTS (Linux kernel: 5.4.0-139-generic #156-Ubuntu SMP Fri Jan 20 17:27:18 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "b6b3d99182b447b4",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/network/Qualcomm/results/g292_z43_q16/bert-99/server",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.8666333229796,
    "Accuracy_div_100": 0.90867,
    "Availability": "available",
    "Division": "network",
    "Location": "network/Qualcomm/results/g292_z43_q16/bert-99.9/server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Qualcomm",
    "Platform": "g292_z43_q16",
    "Result": 6004.71,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Gigabyte G292-Z43 (16x QAIC100)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 16,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.9.1",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7713 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Powered by the KRAI X and KILT technologies",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6 LTS (Linux kernel: 5.4.0-139-generic #156-Ubuntu SMP Fri Jan 20 17:27:18 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "151d4ff1761e4057",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/network/Qualcomm/results/g292_z43_q16/bert-99.9/server",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.28408874066913,
    "Accuracy_div_100": 0.90284,
    "Availability": "available",
    "Division": "network",
    "Location": "network/HPE/results/dl385_q8_std/bert-99/server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "HPE",
    "Platform": "dl385_q8_std",
    "Result": 5504.2,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "HPE ProLiant DL385 Gen10 Plus v2 (8x QAIC100 Standard)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Standard",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.9.1",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "AMD EPYC 7543 32-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Powered by the KRAI X and KILT technologies",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6 LTS (Linux kernel 5.15.0-75-generic #82~20.04.1-Ubuntu SMP Wed Jun 7 19:37:37 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "15f9d6cf2def4f95",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/network/HPE/results/dl385_q8_std/bert-99/server",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.8666333229796,
    "Accuracy_div_100": 0.90867,
    "Availability": "available",
    "Division": "network",
    "Location": "network/HPE/results/dl385_q8_std/bert-99.9/server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "HPE",
    "Platform": "dl385_q8_std",
    "Result": 2703.4,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "HPE ProLiant DL385 Gen10 Plus v2 (8x QAIC100 Standard)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Standard",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.9.1",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "AMD EPYC 7543 32-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Powered by the KRAI X and KILT technologies",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6 LTS (Linux kernel 5.15.0-75-generic #82~20.04.1-Ubuntu SMP Wed Jun 7 19:37:37 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "a961bef48e85455c",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/network/HPE/results/dl385_q8_std/bert-99.9/server",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.37586600946241,
    "Accuracy_div_100": 0.90376,
    "Availability": "available",
    "Division": "network",
    "Location": "network/Alibaba/results/SINIAN_VODLA_EFLO_A100x16_A30x16/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Alibaba",
    "Platform": "SINIAN_VODLA_EFLO_A100x16_A30x16",
    "Result": 61994.8,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Alibaba Cloud Server Sinian Platform (vODLA-EFLO, A100x16_A30x16)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "2 Nodes: NVIDIA A100-SXM-80GBx8, 4 Nodes: NVIDIA A30x4",
    "accelerators_per_node": "(8,4)",
    "compliance": 1,
    "errors": 0,
    "framework": "SINIAN VODLA",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8369B CPU (A100), Intel(R) Xeon(R) Silver 4314 (A30)",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 6,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "f6ae4e0d0dca4196",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/network/Alibaba/results/SINIAN_VODLA_EFLO_A100x16_A30x16/bert-99/Server",
    "version": "v2.1"
  },
  {
    "Accuracy": 90.37586600946241,
    "Accuracy_div_100": 0.90376,
    "Availability": "available",
    "Division": "network",
    "Location": "network/Alibaba/results/SINIAN_VODLA_EFLO_A100x32/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Alibaba",
    "Platform": "SINIAN_VODLA_EFLO_A100x32",
    "Result": 90004.9,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Alibaba Cloud Server Sinian Platform (vODLA-EFLO, A100x32)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "SINIAN VODLA",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8369B CPU",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 4,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "baf858fc3b694a54",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/network/Alibaba/results/SINIAN_VODLA_EFLO_A100x32/bert-99/Server",
    "version": "v2.1"
  },
  {
    "Accuracy": 90.8822753850204,
    "Accuracy_div_100": 0.90882,
    "Availability": "available",
    "Division": "network",
    "Location": "network/Alibaba/results/SINIAN_VODLA_EFLO_A100x32/bert-99.9/Server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Alibaba",
    "Platform": "SINIAN_VODLA_EFLO_A100x32",
    "Result": 47997.8,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Alibaba Cloud Server Sinian Platform (vODLA-EFLO, A100x32)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "SINIAN VODLA",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8369B CPU",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 4,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "fda16f8941ed4b0e",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/network/Alibaba/results/SINIAN_VODLA_EFLO_A100x32/bert-99.9/Server",
    "version": "v2.1"
  },
  {
    "Accuracy": 90.37586600946241,
    "Accuracy_div_100": 0.90376,
    "Availability": "available",
    "Division": "network",
    "Location": "network/Alibaba/results/SINIAN_VODLA_EFLO_A100x16/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Alibaba",
    "Platform": "SINIAN_VODLA_EFLO_A100x16",
    "Result": 48498.1,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Alibaba Cloud Server Sinian Platform (vODLA-EFLO, A100x16)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "SINIAN VODLA",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8369B CPU",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 2,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "7ad63c1229de44d0",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/network/Alibaba/results/SINIAN_VODLA_EFLO_A100x16/bert-99/Server",
    "version": "v2.1"
  },
  {
    "Accuracy": 90.88462035425279,
    "Accuracy_div_100": 0.90885,
    "Availability": "available",
    "Division": "network",
    "Location": "network/Alibaba/results/SINIAN_VODLA_EFLO_A100x16/bert-99.9/Server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Alibaba",
    "Platform": "SINIAN_VODLA_EFLO_A100x16",
    "Result": 24188.6,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Alibaba Cloud Server Sinian Platform (vODLA-EFLO, A100x16)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "SINIAN VODLA",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8369B CPU",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 2,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "5bf69ac7750e4837",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/network/Alibaba/results/SINIAN_VODLA_EFLO_A100x16/bert-99.9/Server",
    "version": "v2.1"
  },
  {
    "Accuracy": 90.37586600946241,
    "Accuracy_div_100": 0.90376,
    "Availability": "available",
    "Division": "network",
    "Location": "network/Alibaba/results/SINIAN_VODLA_EFLO_A100x8_A30x8/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Alibaba",
    "Platform": "SINIAN_VODLA_EFLO_A100x8_A30x8",
    "Result": 30988.8,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Alibaba Cloud Server Sinian Platform (vODLA-EFLO, A100x8_A30x8)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "1 Node: NVIDIA A100-SXM-80GBx8, 2 Nodes: NVIDIA A30x4",
    "accelerators_per_node": "(8,4)",
    "compliance": 1,
    "errors": 0,
    "framework": "SINIAN VODLA",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8369B CPU (A100), Intel(R) Xeon(R) Silver 4314 (A30)",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 3,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "220363af54bf4155",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/network/Alibaba/results/SINIAN_VODLA_EFLO_A100x8_A30x8/bert-99/Server",
    "version": "v2.1"
  },
  {
    "Accuracy": 90.37586600946241,
    "Accuracy_div_100": 0.90376,
    "Availability": "available",
    "Division": "network",
    "Location": "network/Alibaba/results/SINIAN_VODLA_EFLO_A30x16/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Alibaba",
    "Platform": "SINIAN_VODLA_EFLO_A30x16",
    "Result": 22990,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Alibaba Cloud Server Sinian Platform (vODLA-EFLO, A30x16)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "SINIAN VODLA",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Silver 4314",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 4,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "1aec03988c9144f0",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/network/Alibaba/results/SINIAN_VODLA_EFLO_A30x16/bert-99/Server",
    "version": "v2.1"
  },
  {
    "Accuracy": 90.88227538502039,
    "Accuracy_div_100": 0.90882,
    "Availability": "available",
    "Division": "network",
    "Location": "network/Alibaba/results/SINIAN_VODLA_EFLO_A30x16/bert-99.9/Server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Alibaba",
    "Platform": "SINIAN_VODLA_EFLO_A30x16",
    "Result": 10495.2,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Alibaba Cloud Server Sinian Platform (vODLA-EFLO, A30x16)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "SINIAN VODLA",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Silver 4314",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 4,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "741f20b230d2484f",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/network/Alibaba/results/SINIAN_VODLA_EFLO_A30x16/bert-99.9/Server",
    "version": "v2.1"
  },
  {
    "Accuracy": 90.38590173403216,
    "Accuracy_div_100": 0.90386,
    "Availability": "available",
    "Division": "network",
    "Location": "network/NVIDIA/results/SUT_DGX_A100-SXM-80GBx8_CX6x8_TRT/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "NVIDIA",
    "Platform": "SUT_DGX_A100-SXM-80GBx8_CX6x8_TRT",
    "Result": 24404.7,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "NVIDIA DGX A100 (8x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.5.3, CUDA 11.8",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "SUT node with A100 SXM x8 and CX6 x8. MOFED 5.7-1.0.2.0",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "4213ee62001d4f55",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/network/NVIDIA/results/SUT_DGX_A100-SXM-80GBx8_CX6x8_TRT/bert-99/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.88462035425279,
    "Accuracy_div_100": 0.90885,
    "Availability": "available",
    "Division": "network",
    "Location": "network/NVIDIA/results/SUT_DGX_A100-SXM-80GBx8_CX6x8_TRT/bert-99.9/Server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "NVIDIA",
    "Platform": "SUT_DGX_A100-SXM-80GBx8_CX6x8_TRT",
    "Result": 12298.4,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "NVIDIA DGX A100 (8x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.5.3, CUDA 11.8",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "SUT node with A100 SXM x8 and CX6 x8. MOFED 5.7-1.0.2.0",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "ca58327522424ddf",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/network/NVIDIA/results/SUT_DGX_A100-SXM-80GBx8_CX6x8_TRT/bert-99.9/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.2426510242233,
    "Accuracy_div_100": 0.90243,
    "Availability": "available",
    "Division": "network",
    "Location": "network/Qualcomm/results/g292_z43_q18-qaic-v1.8.3.7-aic100/bert-99/server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Qualcomm",
    "Platform": "g292_z43_q18-qaic-v1.8.3.7-aic100",
    "Result": 12248.5,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "GIGABYTE G292-Z43 (18x QAIC100 Pro)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 18,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.8.3",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7713 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5 LTS (Linux kernel: 5.4.0-135-generic #152-Ubuntu SMP Wed Nov 23 20:19:22 UTC 2022)",
    "uid": "745a9cd19eee445c",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/network/Qualcomm/results/g292_z43_q18-qaic-v1.8.3.7-aic100/bert-99/server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.8666333229796,
    "Accuracy_div_100": 0.90867,
    "Availability": "available",
    "Division": "network",
    "Location": "network/Qualcomm/results/g292_z43_q18-qaic-v1.8.3.7-aic100/bert-99.9/server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Qualcomm",
    "Platform": "g292_z43_q18-qaic-v1.8.3.7-aic100",
    "Result": 6752.87,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "GIGABYTE G292-Z43 (18x QAIC100 Pro)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 18,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.8.3",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7713 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5 LTS (Linux kernel: 5.4.0-135-generic #152-Ubuntu SMP Wed Nov 23 20:19:22 UTC 2022)",
    "uid": "75ae9a048bf44655",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/network/Qualcomm/results/g292_z43_q18-qaic-v1.8.3.7-aic100/bert-99.9/server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.2426510242233,
    "Accuracy_div_100": 0.90243,
    "Availability": "available",
    "Division": "network",
    "Location": "network/HPE/results/dl385_q8_std-qaic-v1.8.3.7-aic100/bert-99/server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "HPE",
    "Platform": "dl385_q8_std-qaic-v1.8.3.7-aic100",
    "Result": 5326.99,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "HPE ProLiant DL385 Gen10 Plus v2 (8x QAIC100 Standard)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Standard",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.8.3",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "AMD EPYC 7543 32-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5 LTS (Linux kernel: 5.15.0-60-generic #66~20.04.1-Ubuntu SMP Wed Jan 25 09:41:30 UTC 2023)",
    "uid": "3c226a976b224ef1",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/network/HPE/results/dl385_q8_std-qaic-v1.8.3.7-aic100/bert-99/server",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.8666333229796,
    "Accuracy_div_100": 0.90867,
    "Availability": "available",
    "Division": "network",
    "Location": "network/HPE/results/dl385_q8_std-qaic-v1.8.3.7-aic100/bert-99.9/server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "HPE",
    "Platform": "dl385_q8_std-qaic-v1.8.3.7-aic100",
    "Result": 2573.2,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "HPE ProLiant DL385 Gen10 Plus v2 (8x QAIC100 Standard)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Standard",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.8.3",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "AMD EPYC 7543 32-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5 LTS (Linux kernel: 5.15.0-60-generic #66~20.04.1-Ubuntu SMP Wed Jan 25 09:41:30 UTC 2023)",
    "uid": "4f511da8ed0843a6",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/network/HPE/results/dl385_q8_std-qaic-v1.8.3.7-aic100/bert-99.9/server",
    "version": "v3.0"
  }
]
