[
  {
    "Accuracy": 37.3,
    "Accuracy_div_100": 0.373,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC4000A_E12_4XH100_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "ASUSTeK",
    "Platform": "ESC4000A_E12_4XH100_TRT",
    "Result": 2647.04,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "ASUSTeK ESC4000A-E12 (4xH100-NVL-94GB)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 4,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9654 96-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "uid": "700ed70f9ef446c9",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/ASUSTeK/results/ESC4000A_E12_4XH100_TRT/retinanet/Server",
    "version": "v4.1"
  },
  {
    "Accuracy": 37.299,
    "Accuracy_div_100": 0.37299,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC8000A_E12_H100x8_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "ASUSTeK",
    "Platform": "ESC8000A_E12_H100x8_TRT",
    "Result": 8801.91,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "ESC8000A-E12 (8x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "AMD EPYC 9374F 32-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Data bandwidth for GPU-PCIe: 504 GB/s; PCIe-NIC: 126 GB/s",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "uid": "9f43744b543d4ba8",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/ASUSTeK/results/ESC8000A_E12_H100x8_TRT/retinanet/Server",
    "version": "v4.1"
  },
  {
    "Accuracy": 37.349,
    "Accuracy_div_100": 0.37349,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC_N8_E11_H100x8_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "ASUSTeK",
    "Platform": "ESC_N8_E11_H100x8_TRT",
    "Result": 13763,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "ESC-N8-E11 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "uid": "c2b1fd137c4d43b5",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/ASUSTeK/results/ESC_N8_E11_H100x8_TRT/retinanet/Server",
    "version": "v4.1"
  },
  {
    "Accuracy": 37.357,
    "Accuracy_div_100": 0.37357,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Cisco/results/C240M7-1-node-2S-EMR-PyTorch/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Cisco",
    "Platform": "C240M7-1-node-2S-EMR-PyTorch",
    "Result": 285.454,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "C240M7-1-node-2S-EMR-PyTorch",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 0,
    "errors": 0,
    "framework": "PyTorch",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Cisco UCS C240 M7. N/A",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3 LTS",
    "uid": "dc0d4bfe70d54a86",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Cisco/results/C240M7-1-node-2S-EMR-PyTorch/retinanet/Server",
    "version": "v4.1"
  },
  {
    "Accuracy": 37.304,
    "Accuracy_div_100": 0.37304,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Cisco/results/C240M7_L40Sx2_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Cisco",
    "Platform": "C240M7_L40Sx2_TRT",
    "Result": 1580.59,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Cisco UCS C240 M7 (2x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 2,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel Xeon Gold 6448H",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "uid": "dc55b5ccd9334fd4",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Cisco/results/C240M7_L40Sx2_TRT/retinanet/Server",
    "version": "v4.1"
  },
  {
    "Accuracy": 37.246,
    "Accuracy_div_100": 0.37246,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Cisco/results/C245M8_H100_PCIe_80GBx2_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Cisco",
    "Platform": "C245M8_H100_PCIe_80GBx2_TRT",
    "Result": 2101.87,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Cisco UCS C245 M8 (2x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 2,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9684X 96-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "uid": "7c3b2f177c054968",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Cisco/results/C245M8_H100_PCIe_80GBx2_TRT/retinanet/Server",
    "version": "v4.1"
  },
  {
    "Accuracy": 37.307,
    "Accuracy_div_100": 0.37307,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Cisco/results/C245M8_L40Sx2_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Cisco",
    "Platform": "C245M8_L40Sx2_TRT",
    "Result": 1600.42,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Cisco UCS C245 M8 (2x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 2,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9684X 96-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "uid": "7ba84829923046ef",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Cisco/results/C245M8_L40Sx2_TRT/retinanet/Server",
    "version": "v4.1"
  },
  {
    "Accuracy": 37.347,
    "Accuracy_div_100": 0.37347,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Cisco/results/X210c_L40SX2_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Cisco",
    "Platform": "X210c_L40SX2_TRT",
    "Result": 1600.42,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Cisco UCS X210c M7 (2x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 2,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8562Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "uid": "02cea1d8f2e44e87",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Cisco/results/X210c_L40SX2_TRT/retinanet/Server",
    "version": "v4.1"
  },
  {
    "Accuracy": 37.358,
    "Accuracy_div_100": 0.37358,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/1-node-2S-EMR-PyTorch/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Dell",
    "Platform": "1-node-2S-EMR-PyTorch",
    "Result": 285.452,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge R760",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 0,
    "errors": 0,
    "framework": "PyTorch",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "INT4 for GPT-J, and INT8 for all other models",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 24.04",
    "uid": "37e2c144351d40ec",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Dell/results/1-node-2S-EMR-PyTorch/retinanet/Server",
    "version": "v4.1"
  },
  {
    "Accuracy": 37.307,
    "Accuracy_div_100": 0.37307,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R760xa_H100NVL_PCIe_94GBx4_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Dell",
    "Platform": "R760xa_H100NVL_PCIe_94GBx4_TRT",
    "Result": 4802.53,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge R760xa (4xH100 NVL, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 4,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 120,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8580",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "uid": "aa9acadf8a29499d",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Dell/results/R760xa_H100NVL_PCIe_94GBx4_TRT/retinanet/Server",
    "version": "v4.1"
  },
  {
    "Accuracy": 37.324,
    "Accuracy_div_100": 0.37324,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R760xa_H100_PCIe_80GBx4_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Dell",
    "Platform": "R760xa_H100_PCIe_80GBx4_TRT",
    "Result": 4502.63,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge R760xa (4x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "fce62fe8309047d2",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Dell/results/R760xa_H100_PCIe_80GBx4_TRT/retinanet/Server",
    "version": "v4.1"
  },
  {
    "Accuracy": 37.296,
    "Accuracy_div_100": 0.37296,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R760xa_L40Sx4_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Dell",
    "Platform": "R760xa_L40Sx4_TRT",
    "Result": 3152.43,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge R760xa (4x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 4,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6338 CPU @ 2.00GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.1",
    "uid": "0dcc5bded3ad47f1",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Dell/results/R760xa_L40Sx4_TRT/retinanet/Server",
    "version": "v4.1"
  },
  {
    "Accuracy": 37.274,
    "Accuracy_div_100": 0.37274,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R760_H100_PCIe_80GBx2_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Dell",
    "Platform": "R760_H100_PCIe_80GBx2_TRT",
    "Result": 2201.86,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge R760 (2xH100_PCIe_80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 2,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 120,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8580",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "uid": "d42b6fa7f18749d2",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Dell/results/R760_H100_PCIe_80GBx2_TRT/retinanet/Server",
    "version": "v4.1"
  },
  {
    "Accuracy": 37.325,
    "Accuracy_div_100": 0.37325,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Dell",
    "Platform": "XE8640_H100_SXM_80GBx4_TRT",
    "Result": 6791.24,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge XE8640 (4x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "uid": "9b4d7494b9474d76",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/retinanet/Server",
    "version": "v4.1"
  },
  {
    "Accuracy": 37.31,
    "Accuracy_div_100": 0.3731,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9640_H100_SXM_80GBx4_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Dell",
    "Platform": "XE9640_H100_SXM_80GBx4_TRT",
    "Result": 6738.09,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge XE9640 (4x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "uid": "638bc0fc352a4d34",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Dell/results/XE9640_H100_SXM_80GBx4_TRT/retinanet/Server",
    "version": "v4.1"
  },
  {
    "Accuracy": 37.328,
    "Accuracy_div_100": 0.37328,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9680_H200_SXM_141GBx8_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Dell",
    "Platform": "XE9680_H200_SXM_141GBx8_TRT",
    "Result": 13603.8,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge XE9680 (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 52,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "uid": "007a9c4c721a44a7",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Dell/results/XE9680_H200_SXM_141GBx8_TRT/retinanet/Server",
    "version": "v4.1"
  },
  {
    "Accuracy": 37.333,
    "Accuracy_div_100": 0.37333,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Fujitsu/results/CDI_L40Sx16_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Fujitsu",
    "Platform": "CDI_L40Sx16_TRT",
    "Result": 11948.7,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "PRIMERGY CDI (16x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 16,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6454S",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "uid": "85ab204bdb4a4d1d",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Fujitsu/results/CDI_L40Sx16_TRT/retinanet/Server",
    "version": "v4.1"
  },
  {
    "Accuracy": 37.323,
    "Accuracy_div_100": 0.37323,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Fujitsu/results/GX2560M7_H100_SXM_80GBx4_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Fujitsu",
    "Platform": "GX2560M7_H100_SXM_80GBx4_TRT",
    "Result": 6801.47,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "GX2560M7_H100_SXM_80GBx4 (4x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "aa418139d72446ca",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Fujitsu/results/GX2560M7_H100_SXM_80GBx4_TRT/retinanet/Server",
    "version": "v4.1"
  },
  {
    "Accuracy": 37.316,
    "Accuracy_div_100": 0.37316,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/GigaComputing/results/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "GigaComputing",
    "Platform": "GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT",
    "Result": 14012.2,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "GIGABYTE G593-SD1",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "uid": "ce3f93af7be14fdd",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/GigaComputing/results/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT/retinanet/Server",
    "version": "v4.1"
  },
  {
    "Accuracy": 37.357,
    "Accuracy_div_100": 0.37357,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/1-node-2S-EMR-PyTorch/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "HPE",
    "Platform": "1-node-2S-EMR-PyTorch",
    "Result": 275.531,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "HPE ProLiant DL380 Gen11",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 0,
    "errors": 0,
    "framework": "PyTorch",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "N/A",
    "number_of_nodes": 1,
    "operating_system": "CentOS Stream 8",
    "uid": "4cb2c6c6de99439f",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/HPE/results/1-node-2S-EMR-PyTorch/retinanet/Server",
    "version": "v4.1"
  },
  {
    "Accuracy": 37.291,
    "Accuracy_div_100": 0.37291,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/HPE_Cray_XD670_H100_SXM_80GBx8_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "HPE",
    "Platform": "HPE_Cray_XD670_H100_SXM_80GBx8_TRT",
    "Result": 13763,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "HPE Cray XD670 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "22.04.4 LTS",
    "uid": "ed1c4dc7f2034187",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/HPE/results/HPE_Cray_XD670_H100_SXM_80GBx8_TRT/retinanet/Server",
    "version": "v4.1"
  },
  {
    "Accuracy": 37.296,
    "Accuracy_div_100": 0.37296,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "HPE",
    "Platform": "HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT",
    "Result": 5003,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "HPE ProLiant DL380a Gen11 (4x H100-NVL-94GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 4,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "INTEL(R) XEON(R) GOLD 6530",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "uid": "8db74cdcbc7744bd",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/HPE/results/HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT/retinanet/Server",
    "version": "v4.1"
  },
  {
    "Accuracy": 37.319,
    "Accuracy_div_100": 0.37319,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/HPE_ProLiant_DL380a_L40S_PCIe_48GBx4_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "HPE",
    "Platform": "HPE_ProLiant_DL380a_L40S_PCIe_48GBx4_TRT",
    "Result": 3102.23,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "HPE ProLiant DL380a Gen11 (4x L40S-PCIe-48GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 4,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 60,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8580",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "uid": "56984d7e95af47b5",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/HPE/results/HPE_ProLiant_DL380a_L40S_PCIe_48GBx4_TRT/retinanet/Server",
    "version": "v4.1"
  },
  {
    "Accuracy": 37.357,
    "Accuracy_div_100": 0.37357,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Intel/results/1-node-2S-EMR-PyTorch/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Intel",
    "Platform": "1-node-2S-EMR-PyTorch",
    "Result": 285.455,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "1-node-2S-EMR-PyTorch",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 0,
    "errors": 0,
    "framework": "PyTorch",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54Q-2U. N/A",
    "number_of_nodes": 1,
    "operating_system": "CentOS Stream 9",
    "uid": "c4ea54b9defb4b8e",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Intel/results/1-node-2S-EMR-PyTorch/retinanet/Server",
    "version": "v4.1"
  },
  {
    "Accuracy": 37.358,
    "Accuracy_div_100": 0.37358,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/Intel/results/1-node-2S-GNR-PyTorch/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Intel",
    "Platform": "1-node-2S-GNR-PyTorch",
    "Result": 595.785,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "1-node-2S-GNR-PyTorch",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 0,
    "errors": 0,
    "framework": "PyTorch",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 128,
    "host_processor_model_name": "INTEL(R) XEON(R) 6980P",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Intel AvenueCity. N/A",
    "number_of_nodes": 1,
    "operating_system": "CentOS Stream 9",
    "uid": "dc8038e0de814783",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Intel/results/1-node-2S-GNR-PyTorch/retinanet/Server",
    "version": "v4.1"
  },
  {
    "Accuracy": 37.31,
    "Accuracy_div_100": 0.3731,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/H200_SXM_141GBx8_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Lenovo",
    "Platform": "H200_SXM_141GBx8_TRT",
    "Result": 13164,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "ThinkSystem SR685a V3(8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.5",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "AMD EPYC 9454",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "uid": "fa497850985a434c",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Lenovo/results/H200_SXM_141GBx8_TRT/retinanet/Server",
    "version": "v4.1"
  },
  {
    "Accuracy": 37.317,
    "Accuracy_div_100": 0.37317,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/SR650_V3_3xL40S_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Lenovo",
    "Platform": "SR650_V3_3xL40S_TRT",
    "Result": 2201.83,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "ThinkSystem SR650 V3 (3x NVIDIA L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 3,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.5",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6438N",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "uid": "aade935b143a4272",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Lenovo/results/SR650_V3_3xL40S_TRT/retinanet/Server",
    "version": "v4.1"
  },
  {
    "Accuracy": 37.323,
    "Accuracy_div_100": 0.37323,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/SR675_V3_8xH100_NVL_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Lenovo",
    "Platform": "SR675_V3_8xH100_NVL_TRT",
    "Result": 9001.86,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "ThinkSystem SR675 V3 (8x H100-NVL-94GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.5",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 84,
    "host_processor_model_name": "AMD EPYC 9634 84-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "uid": "eb19ae033d474ecc",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Lenovo/results/SR675_V3_8xH100_NVL_TRT/retinanet/Server",
    "version": "v4.1"
  },
  {
    "Accuracy": 37.325,
    "Accuracy_div_100": 0.37325,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GBx8_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GBx8_TRT",
    "Result": 13604,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "NVIDIA H200 (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "uid": "41dc698a31da4ec6",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/NVIDIA/results/H200-SXM-141GBx8_TRT/retinanet/Server",
    "version": "v4.1"
  },
  {
    "Accuracy": 37.331,
    "Accuracy_div_100": 0.37331,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Oracle/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Oracle",
    "Platform": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "Result": 1731.13,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "NVIDIA GH200-GraceHopper-Superchip (1x GH200-96GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 96GB",
    "accelerators_per_node": 1,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "NVIDIA MGX Reference Platform;",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2",
    "uid": "82da3540977b47ed",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Oracle/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/retinanet/Server",
    "version": "v4.1"
  },
  {
    "Accuracy": 37.357,
    "Accuracy_div_100": 0.37357,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/1-node-2S-EMR-PyTorch/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "1-node-2S-EMR-PyTorch",
    "Result": 280.447,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "1-node-2S-EMR-PyTorch",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": "N/A",
    "compliance": 0,
    "errors": 0,
    "framework": "PyTorch",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54X-1U",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.2",
    "uid": "010b03f72deb42a0",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Quanta_Cloud_Technology/results/1-node-2S-EMR-PyTorch/retinanet/Server",
    "version": "v4.1"
  },
  {
    "Accuracy": 37.298,
    "Accuracy_div_100": 0.37298,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/D54U_3U_H100_PCIe_80GBx4_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "D54U_3U_H100_PCIe_80GBx4_TRT",
    "Result": 4003.24,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "D54U_3U_H100_PCIe_80GBx4_TRT",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0.19, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 52,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54U-3U",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.2",
    "uid": "f63bb30fbcf84b6f",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Quanta_Cloud_Technology/results/D54U_3U_H100_PCIe_80GBx4_TRT/retinanet/Server",
    "version": "v4.1"
  },
  {
    "Accuracy": 37.33,
    "Accuracy_div_100": 0.3733,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/D54U_3U_L40S_PCIe_48GBx4_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "D54U_3U_L40S_PCIe_48GBx4_TRT",
    "Result": 3001.4,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "D54U_3U_L40S_PCIe_48GBx4_TRT",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 4,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0.19, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 44,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8458P",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54U-3U",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.2",
    "uid": "57b16ca1723244d3",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Quanta_Cloud_Technology/results/D54U_3U_L40S_PCIe_48GBx4_TRT/retinanet/Server",
    "version": "v4.1"
  },
  {
    "Accuracy": 37.318,
    "Accuracy_div_100": 0.37318,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "Result": 1731.14,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 96GB",
    "accelerators_per_node": 1,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0.19, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "QuantaGrid S74G-2U",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.3",
    "uid": "03901b9f539f4ffd",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Quanta_Cloud_Technology/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/retinanet/Server",
    "version": "v4.1"
  },
  {
    "Accuracy": 37.303,
    "Accuracy_div_100": 0.37303,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Supermicro",
    "Platform": "AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT",
    "Result": 13803,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "AS-4125GS-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9654",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "uid": "f4e0676894484411",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Supermicro/results/AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT/retinanet/Server",
    "version": "v4.1"
  },
  {
    "Accuracy": 37.29,
    "Accuracy_div_100": 0.3729,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Supermicro",
    "Platform": "AS_8125GS_TNHR_H100_SXM_80GBx8_TRT",
    "Result": 13731.3,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "AS-8125GS-TNHR (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "AMD EPYC 9474F",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "uid": "9813cb9f7669469f",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Supermicro/results/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT/retinanet/Server",
    "version": "v4.1"
  },
  {
    "Accuracy": 37.348,
    "Accuracy_div_100": 0.37348,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Supermicro",
    "Platform": "SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT",
    "Result": 13979.3,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "SYS-421GE-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8570",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "uid": "31f7b9f5dd604ff5",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Supermicro/results/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT/retinanet/Server",
    "version": "v4.1"
  },
  {
    "Accuracy": 37.343,
    "Accuracy_div_100": 0.37343,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Supermicro",
    "Platform": "SYS_821GE_TNHR_H100_SXM_80GBx8_TRT",
    "Result": 13803,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "SYS-821GE-TNHR (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "uid": "c699968246024e30",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/retinanet/Server",
    "version": "v4.1"
  },
  {
    "Accuracy": 37.332,
    "Accuracy_div_100": 0.37332,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Sustainable_Metal_Cloud/results/SMC_H100_SXM_80GBX8_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Sustainable_Metal_Cloud",
    "Platform": "SMC_H100_SXM_80GBX8_TRT",
    "Result": 12884.5,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "SMC H100 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8462Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "uid": "413ffd525c864c7a",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Sustainable_Metal_Cloud/results/SMC_H100_SXM_80GBX8_TRT/retinanet/Server",
    "version": "v4.1"
  },
  {
    "Accuracy": 37.438,
    "Accuracy_div_100": 0.37438,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC8000_E11P_H100x8_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "ASUSTeK",
    "Platform": "ESC8000_E11P_H100x8_TRT",
    "Result": 8394.3,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "ESC8000-E11P (8x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Data bandwidth for GPU-PCIe: 504 GB/s; PCIe-NIC: 126 GB/s",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "7fe69460b1364275",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/ASUSTeK/results/ESC8000_E11P_H100x8_TRT/retinanet/Server",
    "version": "v4.0"
  },
  {
    "Accuracy": 37.387,
    "Accuracy_div_100": 0.37387,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC8000_E11_L40Sx8_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "ASUSTeK",
    "Platform": "ESC8000_E11_L40Sx8_TRT",
    "Result": 5797.6,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "ESC8000-E11 (8x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6442Y",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Data bandwidth for GPU-PCIe: 252 GB/s; PCIe-NIC: 63 GB/s",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "71d6209f4e564bc2",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/ASUSTeK/results/ESC8000_E11_L40Sx8_TRT/retinanet/Server",
    "version": "v4.0"
  },
  {
    "Accuracy": 37.357,
    "Accuracy_div_100": 0.37357,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Cisco/results/1-node-2S-C240M7-EMR-PyTorch-INT8/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Cisco",
    "Platform": "1-node-2S-C240M7-EMR-PyTorch-INT8",
    "Result": 303.843,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "1-node-2S-C240M7-EMR-PyTorch-INT8",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "PyTorch",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "N/A",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "uid": "c5343ccdcf664b4c",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Cisco/results/1-node-2S-C240M7-EMR-PyTorch-INT8/retinanet/Server",
    "version": "v4.0"
  },
  {
    "Accuracy": 37.234,
    "Accuracy_div_100": 0.37234,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/CTuning/results/aws_dl2q.24xlarge-kilt-qaic-glow-vdefault-default_config/retinanet/server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "CTuning",
    "Platform": "aws_dl2q.24xlarge-kilt-qaic-glow-vdefault-default_config",
    "Result": 2199.05,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "AWS_EC2_DL2Q (8x QAIC Standard)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "Qualcomm Cloud AI 100 Standard",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI Platform SDK v1.12.2, Apps SDK v1.14.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8259CL CPU @ 2.50GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.6.2. ",
    "number_of_nodes": 1,
    "operating_system": "Amzn 2 (linux-5.10.209-198.812.amzn2.x86_64-glibc2.26)",
    "uid": "3200c39537794203",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/CTuning/results/aws_dl2q.24xlarge-kilt-qaic-glow-vdefault-default_config/retinanet/server",
    "version": "v4.0"
  },
  {
    "Accuracy": 37.319,
    "Accuracy_div_100": 0.37319,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R750xa_A100_PCIe_80GBx4_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Dell",
    "Platform": "R750xa_A100_PCIe_80GBx4_TRT",
    "Result": 2831.6,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge R750xa (4x A100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6338 CPU @ 2.00GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.1",
    "uid": "5d9f2fb5d3544f9c",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Dell/results/R750xa_A100_PCIe_80GBx4_TRT/retinanet/Server",
    "version": "v4.0"
  },
  {
    "Accuracy": 37.319,
    "Accuracy_div_100": 0.37319,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R760xa_L40Sx4_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Dell",
    "Platform": "R760xa_L40Sx4_TRT",
    "Result": 3062.26,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge R760xa (4x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6338 CPU @ 2.00GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.1",
    "uid": "6774614e62474e7e",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Dell/results/R760xa_L40Sx4_TRT/retinanet/Server",
    "version": "v4.0"
  },
  {
    "Accuracy": 37.37,
    "Accuracy_div_100": 0.3737,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R760_CPU/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Dell",
    "Platform": "R760_CPU",
    "Result": 298.998,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge R760",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "PyTorch",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "INT4 for GPT-J, Mixed for RNN-T and INT8 for all other models",
    "number_of_nodes": 1,
    "operating_system": "CentOS Stream 8",
    "uid": "c943c7622a3f45d4",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Dell/results/R760_CPU/retinanet/Server",
    "version": "v4.0"
  },
  {
    "Accuracy": 37.406,
    "Accuracy_div_100": 0.37406,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R760_L40Sx2_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Dell",
    "Platform": "R760_L40Sx2_TRT",
    "Result": 1523.79,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge R760 (2x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.3",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 120,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8580",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "uid": "b433de3b4a9849d0",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Dell/results/R760_L40Sx2_TRT/retinanet/Server",
    "version": "v4.0"
  },
  {
    "Accuracy": 37.208,
    "Accuracy_div_100": 0.37208,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/Dell/results/r760_q4_ultra/retinanet/server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Dell",
    "Platform": "r760_q4_ultra",
    "Result": 3126.65,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge R760xa (4x QAIC100 Ultra)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 Ultra",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6448Y",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Powered by the KRAI X and KILT technologies",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS (Linux kernel 5.15.0-92-generic #102-Ubuntu SMP Wed Jan 10 09:33:48 UTC 2024 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "9487f8904d774022",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Dell/results/r760_q4_ultra/retinanet/server",
    "version": "v4.0"
  },
  {
    "Accuracy": 37.335,
    "Accuracy_div_100": 0.37335,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R7615_L40Sx2_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Dell",
    "Platform": "R7615_L40Sx2_TRT",
    "Result": 1508.66,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge R7615 (2x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 9354 32-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6 LTS",
    "uid": "c6d6bc14573c440f",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Dell/results/R7615_L40Sx2_TRT/retinanet/Server",
    "version": "v4.0"
  },
  {
    "Accuracy": 37.345,
    "Accuracy_div_100": 0.37345,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/vR760_L40S_48Cx2_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Dell",
    "Platform": "vR760_L40S_48Cx2_TRT",
    "Result": 1473.57,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge R760 (2x L40S, TensorRT, VMware ESXi 8.0.2)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "Virtualized NVIDIA L40S",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 60,
    "host_processor_model_name": "Intel Xeon Platinum 8580",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Broadcom VM Specifications 32vCPU out of 120 and memory of 128 GB out of 1.5TB",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4, VMware ESXi 8.0.2 22380479",
    "uid": "a35a844c8cdb40d1",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Dell/results/vR760_L40S_48Cx2_TRT/retinanet/Server",
    "version": "v4.0"
  },
  {
    "Accuracy": 37.42,
    "Accuracy_div_100": 0.3742,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Dell",
    "Platform": "XE8640_H100_SXM_80GBx4_TRT",
    "Result": 6759.23,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge XE8640 (4x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "uid": "514cc8bd9d694064",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/retinanet/Server",
    "version": "v4.0"
  },
  {
    "Accuracy": 37.425,
    "Accuracy_div_100": 0.37425,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9640_H100_SXM_80GBX4_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Dell",
    "Platform": "XE9640_H100_SXM_80GBX4_TRT",
    "Result": 6733.25,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge XE9640 (4x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "uid": "57aeb93e6c804d64",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Dell/results/XE9640_H100_SXM_80GBX4_TRT/retinanet/Server",
    "version": "v4.0"
  },
  {
    "Accuracy": 37.356,
    "Accuracy_div_100": 0.37356,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9680_H100_SXM_80GBx8_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Dell",
    "Platform": "XE9680_H100_SXM_80GBx8_TRT",
    "Result": 13615.6,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge XE9680 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "uid": "9ce42d982b61457b",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Dell/results/XE9680_H100_SXM_80GBx8_TRT/retinanet/Server",
    "version": "v4.0"
  },
  {
    "Accuracy": 37.409,
    "Accuracy_div_100": 0.37409,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9680_IntelXeon8480_NVIDIA_H100_SXM_80GBx8_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Dell",
    "Platform": "XE9680_IntelXeon8480_NVIDIA_H100_SXM_80GBx8_TRT",
    "Result": 12876.2,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge XE9680 (8x H100-SXM-80GB, TensorRT,VMware ESXi 8.0.2) ",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "Virtualized NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel Xeon Platinum 8480",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Broadcom VM Specifications 32vCPU out of 224 and memory of 128 GB out of 1TB",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4, VMware ESXi 8.0.2 22380479",
    "uid": "a4322a6f986b463e",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Dell/results/XE9680_IntelXeon8480_NVIDIA_H100_SXM_80GBx8_TRT/retinanet/Server",
    "version": "v4.0"
  },
  {
    "Accuracy": 37.312,
    "Accuracy_div_100": 0.37312,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/GigaComputing/results/GIGABYTE-G593-SD1_DGX-H100_H100-SXM-80GBx8_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "GigaComputing",
    "Platform": "GIGABYTE-G593-SD1_DGX-H100_H100-SXM-80GBx8_TRT",
    "Result": 12995.7,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "GIGABYTE G593-SD1",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Data bandwidth for GPU-PCIe: 504 GB/s; PCIe-NIC: 600GB/s",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "uid": "f22539670e9a4e86",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/GigaComputing/results/GIGABYTE-G593-SD1_DGX-H100_H100-SXM-80GBx8_TRT/retinanet/Server",
    "version": "v4.0"
  },
  {
    "Accuracy": 37.362,
    "Accuracy_div_100": 0.37362,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Google/results/H100-SXM-80GBx8_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Google",
    "Platform": "H100-SXM-80GBx8_TRT",
    "Result": 12876.2,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "NVIDIA DGX H100 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 208,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8481C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "0e425fdfc5cc41a4",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Google/results/H100-SXM-80GBx8_TRT/retinanet/Server",
    "version": "v4.0"
  },
  {
    "Accuracy": 37.322,
    "Accuracy_div_100": 0.37322,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/HPE_Cray_XD670_H100_SXM_80GBx8_TRT_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "HPE",
    "Platform": "HPE_Cray_XD670_H100_SXM_80GBx8_TRT_TRT",
    "Result": 13675.6,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "HPE Cray XD670 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.3",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.3",
    "uid": "8cd3790db6164c3b",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/HPE/results/HPE_Cray_XD670_H100_SXM_80GBx8_TRT_TRT/retinanet/Server",
    "version": "v4.0"
  },
  {
    "Accuracy": 37.336,
    "Accuracy_div_100": 0.37336,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/HPE_ProLiant_DL380a_H100_PCIe_80GBx4_TRT_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "HPE",
    "Platform": "HPE_ProLiant_DL380a_H100_PCIe_80GBx4_TRT_TRT",
    "Result": 4299.58,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "HPE ProLiant DL380a Gen11 (4x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "uid": "553144514438431a",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/HPE/results/HPE_ProLiant_DL380a_H100_PCIe_80GBx4_TRT_TRT/retinanet/Server",
    "version": "v4.0"
  },
  {
    "Accuracy": 37.31,
    "Accuracy_div_100": 0.3731,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/HPE_ProLiant_DL380a_L40S_PCIe_48GBx4_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "HPE",
    "Platform": "HPE_ProLiant_DL380a_L40S_PCIe_48GBx4_TRT",
    "Result": 2801.87,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "HPE ProLiant DL380a Gen11 (4x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 60,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8580",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "uid": "d8026ce7bdac4351",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/HPE/results/HPE_ProLiant_DL380a_L40S_PCIe_48GBx4_TRT/retinanet/Server",
    "version": "v4.0"
  },
  {
    "Accuracy": 37.357,
    "Accuracy_div_100": 0.37357,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Intel/results/1-node-2S-EMR-PyTorch/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Intel",
    "Platform": "1-node-2S-EMR-PyTorch",
    "Result": 274.283,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "1-node-2S-EMR-PyTorch",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "PyTorch",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54Q-2U. N/A",
    "number_of_nodes": 1,
    "operating_system": "CentOS Stream 8",
    "uid": "041b2847d76641f9",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Intel/results/1-node-2S-EMR-PyTorch/retinanet/Server",
    "version": "v4.0"
  },
  {
    "Accuracy": 37.324,
    "Accuracy_div_100": 0.37324,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/SE455_L40x2_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Lenovo",
    "Platform": "SE455_L40x2_TRT",
    "Result": 949.028,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Lenovo SE455 (2x NVIDIA L40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L40",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.3",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "AMD EPYC 8124P 16-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "uid": "1f3a8b67cb7a4892",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Lenovo/results/SE455_L40x2_TRT/retinanet/Server",
    "version": "v4.0"
  },
  {
    "Accuracy": 37.208,
    "Accuracy_div_100": 0.37208,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/Lenovo/results/sr670_q4_ultra/retinanet/server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Lenovo",
    "Platform": "sr670_q4_ultra",
    "Result": 3002.09,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Lenovo ThinkSystem SR670 V2 (4x QAIC100 Ultra)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 Ultra",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.14.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 36,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8360Y CPU @ 2.40GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Powered by the KRAI X and KILT technologies",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3 LTS (Linux kernel 5.15.0-94-generic #104-Ubuntu SMP Tue Jan 9 15:25:40 UTC 2024 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "95eaa12701d8451e",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Lenovo/results/sr670_q4_ultra/retinanet/server",
    "version": "v4.0"
  },
  {
    "Accuracy": 37.412,
    "Accuracy_div_100": 0.37412,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx1_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "NVIDIA",
    "Platform": "DGX-H100_H100-SXM-80GBx1_TRT",
    "Result": 1618.74,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "NVIDIA DGX H100 (1x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "57a65e4553644527",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx1_TRT/retinanet/Server",
    "version": "v4.0"
  },
  {
    "Accuracy": 37.429,
    "Accuracy_div_100": 0.37429,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "NVIDIA",
    "Platform": "DGX-H100_H100-SXM-80GBx8_TRT",
    "Result": 12876.2,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "NVIDIA DGX H100 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "6b0f16da5dfd48c5",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT/retinanet/Server",
    "version": "v4.0"
  },
  {
    "Accuracy": 37.337,
    "Accuracy_div_100": 0.37337,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Oracle/results/OCI-H100_H100-SXM-80GBx8_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Oracle",
    "Platform": "OCI-H100_H100-SXM-80GBx8_TRT",
    "Result": 12876.2,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "BM.GPU.H100.8",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0.1, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "uid": "b60e6196efc9408f",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Oracle/results/OCI-H100_H100-SXM-80GBx8_TRT/retinanet/Server",
    "version": "v4.0"
  },
  {
    "Accuracy": 37.208,
    "Accuracy_div_100": 0.37208,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/Qualcomm/results/g293_q16_ultra_pp/retinanet/server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Qualcomm",
    "Platform": "g293_q16_ultra_pp",
    "Result": 13745.9,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "GIGABYTE G293-Z43 (16x QAIC100 Ultra, PP)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 Ultra",
    "accelerators_per_node": 16,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 9554 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Powered by the KRAI X and KILT technologies",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3 LTS (Linux kernel 6.2.0-37-generic #38~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov  2 18:01:13 UTC 2 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "b0630f0e901540fa",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Qualcomm/results/g293_q16_ultra_pp/retinanet/server",
    "version": "v4.0"
  },
  {
    "Accuracy": 37.357,
    "Accuracy_div_100": 0.37357,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/1-node-2S-EMR-PyTorch/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "1-node-2S-EMR-PyTorch",
    "Result": 279.295,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "1-node-2S-EMR-PyTorch-INT8",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": "N/A",
    "compliance": 1,
    "errors": 0,
    "framework": "PyTorch",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54X-1U",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.1",
    "uid": "14133865b4da419f",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Quanta_Cloud_Technology/results/1-node-2S-EMR-PyTorch/retinanet/Server",
    "version": "v4.0"
  },
  {
    "Accuracy": 37.329,
    "Accuracy_div_100": 0.37329,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/D54U_3U_H100_PCIe_80GBx4_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "D54U_3U_H100_PCIe_80GBx4_TRT",
    "Result": 4001.14,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "D54U_3U_H100_PCIe_80GBx4_TRT",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.3",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 52,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54U-3U",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.2",
    "uid": "9495209b28014eb3",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Quanta_Cloud_Technology/results/D54U_3U_H100_PCIe_80GBx4_TRT/retinanet/Server",
    "version": "v4.0"
  },
  {
    "Accuracy": 37.325,
    "Accuracy_div_100": 0.37325,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/D54U_3U_L40S_PCIe_48GBx4_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "D54U_3U_L40S_PCIe_48GBx4_TRT",
    "Result": 3002.09,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "D54U_3U_L40S_PCIe_48GBx4_TRT",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.3",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 52,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54U-3U",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.2",
    "uid": "10245cd6c3704526",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Quanta_Cloud_Technology/results/D54U_3U_L40S_PCIe_48GBx4_TRT/retinanet/Server",
    "version": "v4.0"
  },
  {
    "Accuracy": 37.434,
    "Accuracy_div_100": 0.37434,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS-521GE-TNRT_L40S_PCIe_48GBx8_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Supermicro",
    "Platform": "SYS-521GE-TNRT_L40S_PCIe_48GBx8_TRT",
    "Result": 1999.47,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "SYS-521GE-TNRT (8xL40S-PCIe-48GB)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8462Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "uid": "2fc71be40cbc48f8",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Supermicro/results/SYS-521GE-TNRT_L40S_PCIe_48GBx8_TRT/retinanet/Server",
    "version": "v4.0"
  },
  {
    "Accuracy": 37.339,
    "Accuracy_div_100": 0.37339,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Supermicro",
    "Platform": "SYS_821GE_TNHR_H100_SXM_80GBx8_TRT",
    "Result": 12940.3,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "SYS-821GE-TNHR (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8568Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3 LTS",
    "uid": "48b0ed547cb1415d",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/retinanet/Server",
    "version": "v4.0"
  },
  {
    "Accuracy": 37.357,
    "Accuracy_div_100": 0.37357,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Wiwynn/results/1-node-1S-EMR-PyTorch/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Wiwynn",
    "Platform": "1-node-1S-EMR-PyTorch",
    "Result": 61.2312,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Wiwynn ES200G2 (1-node-1S-EMR-PyTorch)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "PyTorch",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "INTEL(R) XEON(R) GOLD 6538Y+",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Wiwynn ES200G2. N/A",
    "number_of_nodes": 1,
    "operating_system": "Centos 8 (linux-6.6.8-1.el8.elrepo.x86_64-glibc2.28)",
    "uid": "4d38dd863e614c82",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Wiwynn/results/1-node-1S-EMR-PyTorch/retinanet/Server",
    "version": "v4.0"
  },
  {
    "Accuracy": 37.572,
    "Accuracy_div_100": 0.37572,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/IEI/results/NF5468M6_A40x8_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "IEI",
    "Platform": "NF5468M6_A40x8_TRT",
    "Result": 2453,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "NF5468M6 (8x A40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A40",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8380",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5",
    "uid": "ae69de68c3fa44fc",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/IEI/results/NF5468M6_A40x8_TRT/retinanet/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.355,
    "Accuracy_div_100": 0.37355,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Krai/results/7920t-kilt-tensorrt/retinanet/server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Krai",
    "Platform": "7920t-kilt-tensorrt",
    "Result": 420.651,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell Precision 7920 Tower (2x NVIDIA RTX A5000 GPU)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA RTX A5000 GPU",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "KRAI Inference Library Technology (KILT) with TensorRT support",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6240R CPU @ 2.40GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Powered by the KRAI X and KILT technologies",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3 LTS (Linux chai 5.15.0-76-generic #83-Ubuntu SMP Thu Jun 15 19:16:32 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "5cf9486050704780",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Krai/results/7920t-kilt-tensorrt/retinanet/server",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.356,
    "Accuracy_div_100": 0.37356,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Supermicro",
    "Platform": "SYS_821GE_TNHR_H100_SXM_80GBx8_TRT",
    "Result": 13020.7,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "SYS-821GE-TNHR (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2 LTS",
    "uid": "adb9a31ef6b44ef7",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/retinanet/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.434,
    "Accuracy_div_100": 0.37434,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS_521GE_TNRT_H100_PCIe_80GBX8_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Supermicro",
    "Platform": "SYS_521GE_TNRT_H100_PCIe_80GBX8_TRT",
    "Result": 8402.57,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "SYS-521GE-TNRT (8xH100-PCIe-80GB)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8462Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "uid": "f7e79943b2df44cf",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Supermicro/results/SYS_521GE_TNRT_H100_PCIe_80GBX8_TRT/retinanet/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.353,
    "Accuracy_div_100": 0.37353,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Supermicro",
    "Platform": "AS_8125GS_TNHR_H100_SXM_80GBx8_TRT",
    "Result": 12996.7,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "AS-8125GS-TNHR (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 9554",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2 LTS",
    "uid": "cdc726275cb9457e",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Supermicro/results/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT/retinanet/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.406,
    "Accuracy_div_100": 0.37406,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H100-PCIe-80GBx1_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "NVIDIA",
    "Platform": "H100-PCIe-80GBx1_TRT",
    "Result": 1049.36,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Gigabyte G482-Z54 (1x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "6098c41995d44cc8",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/NVIDIA/results/H100-PCIe-80GBx1_TRT/retinanet/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.42,
    "Accuracy_div_100": 0.3742,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/L4x1_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "NVIDIA",
    "Platform": "L4x1_TRT",
    "Result": 199.743,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "ASROCKRACK 1U1G-MILAN (1x L4, TensorRT)",
    "SystemType": "datacenter,edge",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 7313P 16-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "2971ce26390f4922",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/NVIDIA/results/L4x1_TRT/retinanet/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.426,
    "Accuracy_div_100": 0.37426,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "NVIDIA",
    "Platform": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "Result": 1731.49,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "NVIDIA GH200-GraceHopper-Superchip (1x GH200-96GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA GH200-GraceHopper-Superchip",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "NVIDIA MGX Reference Platform",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2",
    "uid": "d5ffb7a653a94a72",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/NVIDIA/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/retinanet/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.42,
    "Accuracy_div_100": 0.3742,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H100-PCIe-80GBx8_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "NVIDIA",
    "Platform": "H100-PCIe-80GBx8_TRT",
    "Result": 8402.57,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Gigabyte G482-Z54 (8x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "0c5b5479cbd94615",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/NVIDIA/results/H100-PCIe-80GBx8_TRT/retinanet/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.439,
    "Accuracy_div_100": 0.37439,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "NVIDIA",
    "Platform": "DGX-H100_H100-SXM-80GBx8_TRT",
    "Result": 12884.6,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "NVIDIA DGX H100 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "2f5bb4f8d2a940c6",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT/retinanet/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.409,
    "Accuracy_div_100": 0.37409,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx1_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "NVIDIA",
    "Platform": "DGX-H100_H100-SXM-80GBx1_TRT",
    "Result": 1621.29,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "NVIDIA DGX H100 (1x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "aaf9f04b80294199",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx1_TRT/retinanet/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.42,
    "Accuracy_div_100": 0.3742,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/CTuning/results/gcp_g2.standard.4-nvidia_original-gpu-tensorrt-vdefault-default_config/retinanet/server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "CTuning",
    "Platform": "gcp_g2.standard.4-nvidia_original-gpu-tensorrt-vdefault-default_config",
    "Result": 144.896,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Google Cloud Platform (g2.standard.4)",
    "SystemType": "datacenter,edge",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Nvidia inference implementation with CM API, TensorRT v8.6.1.6",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 2,
    "host_processor_model_name": "Intel(R) Xeon(R) CPU @ 2.20GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Powered by MLCommons CM automation language and CK playground. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-5.19.0-1030-gcp-glibc2.35)",
    "uid": "139902e3a9f64a7a",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/CTuning/results/gcp_g2.standard.4-nvidia_original-gpu-tensorrt-vdefault-default_config/retinanet/server",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.418,
    "Accuracy_div_100": 0.37418,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC4000A_E12_L4x8_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "ASUSTeK",
    "Platform": "ESC4000A_E12_L4x8_TRT",
    "Result": 1601.45,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "ESC4000A-E12 (8x L4, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9654 96-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "39388c729fa74a56",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/ASUSTeK/results/ESC4000A_E12_L4x8_TRT/retinanet/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.413,
    "Accuracy_div_100": 0.37413,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/H100_PCIe_80GBx8_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "ASUSTeK",
    "Platform": "H100_PCIe_80GBx8_TRT",
    "Result": 8402.57,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "ESC8000A-E12 (8xH100-PCIe-80GB, TensorRT",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9654 96-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "414219551fa0478a",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/ASUSTeK/results/H100_PCIe_80GBx8_TRT/retinanet/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.458,
    "Accuracy_div_100": 0.37458,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Fujitsu/results/PRIMERGY_CDI_V1_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Fujitsu",
    "Platform": "PRIMERGY_CDI_V1_TRT",
    "Result": 2916.47,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "PRIMERGY_CDI_V1 (4x A100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-PCIE-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6430 CPU @ 2.10GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "GPUs are installed in an external PCIe box.",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "323feec56a9c4d34",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Fujitsu/results/PRIMERGY_CDI_V1_TRT/retinanet/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.21,
    "Accuracy_div_100": 0.3721,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/sr665_q5_pro/retinanet/server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Lenovo",
    "Platform": "sr665_q5_pro",
    "Result": 1386.48,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Lenovo ThinkSystem SR665v1 (5x QAIC100 Pro)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 5,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.9.1",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "AMD EPYC 75F3 32-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Powered by the KRAI X and KILT technologies",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2 LTS (Jammy Jellyfish) (Linux kernel: 5.15.0-76-generic #83-Ubuntu SMP Thu Jun 15 19:16:32 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux",
    "uid": "b62dafbf58654e9c",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Lenovo/results/sr665_q5_pro/retinanet/server",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.362,
    "Accuracy_div_100": 0.37362,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/Lenovo_H100_PCIe_80GBx8_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Lenovo",
    "Platform": "Lenovo_H100_PCIe_80GBx8_TRT",
    "Result": 8801.85,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Lenovo ThinkSystem SR675 V3 (8x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 9554 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2",
    "uid": "f025bba3ec6e4b75",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Lenovo/results/Lenovo_H100_PCIe_80GBx8_TRT/retinanet/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.21,
    "Accuracy_div_100": 0.3721,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Qualcomm/results/g292_z43_q16/retinanet/server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Qualcomm",
    "Platform": "g292_z43_q16",
    "Result": 4578.88,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "GIGABYTE G292-Z43 (16x QAIC100 Pro)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 16,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.9.1",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7713 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Powered by the KRAI X and KILT technologies",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6 LTS (Linux kernel 5.4.0-139-generic #156-Ubuntu SMP Fri Jan 20 17:27:18 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "463b9cb48bf34ef4",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Qualcomm/results/g292_z43_q16/retinanet/server",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.452,
    "Accuracy_div_100": 0.37452,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R750xa_A100_PCIe_80GBx4_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Dell",
    "Platform": "R750xa_A100_PCIe_80GBx4_TRT",
    "Result": 2703.4,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge R750xa (4x A100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6338 CPU @ 2.00GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.1",
    "uid": "4583060b992142fe",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Dell/results/R750xa_A100_PCIe_80GBx4_TRT/retinanet/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.427,
    "Accuracy_div_100": 0.37427,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R760xa_H100_PCIe_80GBx2_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Dell",
    "Platform": "R760xa_H100_PCIe_80GBx2_TRT",
    "Result": 2248.32,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge R760xa (2x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "0df3c5f14bc947e9",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Dell/results/R760xa_H100_PCIe_80GBx2_TRT/retinanet/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.419,
    "Accuracy_div_100": 0.37419,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9640_H100_SXM_80GBx4_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Dell",
    "Platform": "XE9640_H100_SXM_80GBx4_TRT",
    "Result": 6656.63,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge XE9640 (4x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "9a26245e62084c70",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Dell/results/XE9640_H100_SXM_80GBx4_TRT/retinanet/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.331,
    "Accuracy_div_100": 0.37331,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R750xa_H100_PCIe_80GBx4_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Dell",
    "Platform": "R750xa_H100_PCIe_80GBx4_TRT",
    "Result": 4280.81,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge R750xa (4x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6338 CPU @ 2.00GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "NVIDIA H100-PCIe-80GB (TDP: 310W)",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "uid": "a064657a23ea4277",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Dell/results/R750xa_H100_PCIe_80GBx4_TRT/retinanet/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.344,
    "Accuracy_div_100": 0.37344,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R760xa_H100_PCIe_80GBx4_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Dell",
    "Platform": "R760xa_H100_PCIe_80GBx4_TRT",
    "Result": 4354.53,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge R760xa (4x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "932058a7a1244c29",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Dell/results/R760xa_H100_PCIe_80GBx4_TRT/retinanet/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.35,
    "Accuracy_div_100": 0.3735,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9680_H100_SXM_80GBx8_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Dell",
    "Platform": "XE9680_H100_SXM_80GBx8_TRT",
    "Result": 12484.8,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge XE9680 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 52,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "c4d26922177b48c6",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Dell/results/XE9680_H100_SXM_80GBx8_TRT/retinanet/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.357,
    "Accuracy_div_100": 0.37357,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/1-node-2S-SPR-PyTorch-INT8/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Dell",
    "Platform": "1-node-2S-SPR-PyTorch-INT8",
    "Result": 199.743,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge Server R760 (1x Intel Xeon Platinum 8480+)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "PyTorch",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 224,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "CentOS Stream 8",
    "uid": "f85229dfaeec43f6",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Dell/results/1-node-2S-SPR-PyTorch-INT8/retinanet/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.419,
    "Accuracy_div_100": 0.37419,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R760xa_L40x4_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Dell",
    "Platform": "R760xa_L40x4_TRT",
    "Result": 1901.51,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge R760xa (4x L40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L40",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8460Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.1",
    "uid": "90054a1d1d094f0a",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Dell/results/R760xa_L40x4_TRT/retinanet/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.397,
    "Accuracy_div_100": 0.37397,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Dell",
    "Platform": "XE8640_H100_SXM_80GBx4_TRT",
    "Result": 6756.77,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge XE8640 (4x NVIDIA H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.1",
    "uid": "6bdf2a3549e6437d",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/retinanet/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.436,
    "Accuracy_div_100": 0.37436,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/xFusion/results/G5500V7_A30x10_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "xFusion",
    "Platform": "G5500V7_A30x10_TRT",
    "Result": 3864.53,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "xFusion FusionServer G5500V7(10x NVIDIA A30, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 10,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6458Q @ 3.1 GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "ede7ad7221b04f27",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/xFusion/results/G5500V7_A30x10_TRT/retinanet/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.369,
    "Accuracy_div_100": 0.37369,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/xFusion/results/G5500V7_L40x8_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "xFusion",
    "Platform": "G5500V7_L40x8_TRT",
    "Result": 4204.8,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "xFusion FusionServer G5500V7(8x NVIDIA L40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L40",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6458Q @ 3.1 GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "0c221e0fc39847e0",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/xFusion/results/G5500V7_L40x8_TRT/retinanet/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.437,
    "Accuracy_div_100": 0.37437,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/xFusion/results/G5500V7_A30x8_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "xFusion",
    "Platform": "G5500V7_A30x8_TRT",
    "Result": 3100.41,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "xFusion FusionServer G5500V7(8x NVIDIA A30, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6458Q @ 3.1 GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "971aa5cf27a4485a",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/xFusion/results/G5500V7_A30x8_TRT/retinanet/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.413,
    "Accuracy_div_100": 0.37413,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/xFusion/results/L4x6_2288H_V7_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "xFusion",
    "Platform": "L4x6_2288H_V7_TRT",
    "Result": 1280.38,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "xFusion FusionServer 2288H V7(6x NVIDIA L4, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 6,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 44,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8458P CPU @ 2.7 GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "191571a612f143b2",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/xFusion/results/L4x6_2288H_V7_TRT/retinanet/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.394,
    "Accuracy_div_100": 0.37394,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/xFusion/results/G5500V7_L40x10_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "xFusion",
    "Platform": "G5500V7_L40x10_TRT",
    "Result": 5264.69,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "xFusion FusionServer G5500V7(10x NVIDIA L40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L40",
    "accelerators_per_node": 10,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6458Q @ 3.1 GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "e0c42305bf7c4c86",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/xFusion/results/G5500V7_L40x10_TRT/retinanet/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.357,
    "Accuracy_div_100": 0.37357,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Intel/results/1-node-2S-SPR-PyTorch-INT8/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Intel",
    "Platform": "1-node-2S-SPR-PyTorch-INT8",
    "Result": 214.581,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "1-node-2S-SPR-PyTorch-INT8",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "PyTorch",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54Q-2U. N/A",
    "number_of_nodes": 1,
    "operating_system": "CentOS Stream 8",
    "uid": "0a3219e2acda4160",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Intel/results/1-node-2S-SPR-PyTorch-INT8/retinanet/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.344,
    "Accuracy_div_100": 0.37344,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Oracle/results/OCI-A100_A100-SXM-80GBx8_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Oracle",
    "Platform": "OCI-A100_A100-SXM-80GBx8_TRT",
    "Result": 5603.34,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "BM.GPU.A100-v2.8",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7J13 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "047d03b63028424d",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Oracle/results/OCI-A100_A100-SXM-80GBx8_TRT/retinanet/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.324,
    "Accuracy_div_100": 0.37324,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Oracle/results/A10x4_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Oracle",
    "Platform": "A10x4_TRT",
    "Result": 855.004,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "BM.GPU.A10.4",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A10-PCI-24GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8358 CPU @ 2.60GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "933f5b289c4e4222",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Oracle/results/A10x4_TRT/retinanet/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.33,
    "Accuracy_div_100": 0.3733,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Oracle/results/OCI-H100_H100-SXM-80GBx8_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Oracle",
    "Platform": "OCI-H100_H100-SXM-80GBx8_TRT",
    "Result": 12884.6,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "BM.GPU.H100.8",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "f937329163474d0d",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Oracle/results/OCI-H100_H100-SXM-80GBx8_TRT/retinanet/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.353,
    "Accuracy_div_100": 0.37353,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/GigaComputing/results/GIGABYTE-G593-SD0_H100-SXM-80GBx8_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "GigaComputing",
    "Platform": "GIGABYTE-G593-SD0_H100-SXM-80GBx8_TRT",
    "Result": 12884.6,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "GIGABYTE G593-SD0",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "3f99d6f5faca4a46",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/GigaComputing/results/GIGABYTE-G593-SD0_H100-SXM-80GBx8_TRT/retinanet/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.326,
    "Accuracy_div_100": 0.37326,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/R5350G6_L40x8_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "H3C",
    "Platform": "R5350G6_L40x8_TRT",
    "Result": 4874.86,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "H3C UniServer R5350 G6 (8x L40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L40",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "AMD EPYC 9754 128-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5",
    "uid": "abb3f3ce83844a10",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/H3C/results/R5350G6_L40x8_TRT/retinanet/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.362,
    "Accuracy_div_100": 0.37362,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/R5300G6_L40x8_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "H3C",
    "Platform": "R5300G6_L40x8_TRT",
    "Result": 4904.6,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "H3C UniServer R5300 G6 (8x L40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L40",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 44,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8458P",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5",
    "uid": "2979f37ec499439b",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/H3C/results/R5300G6_L40x8_TRT/retinanet/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.351,
    "Accuracy_div_100": 0.37351,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/D54Q_2U_H100_PCIe_80GBx2_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "D54Q_2U_H100_PCIe_80GBx2_TRT",
    "Result": 2001.26,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "D54Q_2U (2x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6430 32-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.0",
    "uid": "642782836cdd4eae",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Quanta_Cloud_Technology/results/D54Q_2U_H100_PCIe_80GBx2_TRT/retinanet/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.318,
    "Accuracy_div_100": 0.37318,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/D54U_3U_H100_PCIe_80GBx4_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "D54U_3U_H100_PCIe_80GBx4_TRT",
    "Result": 4004.73,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "D54U-3U (4x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.0",
    "uid": "4a65e17077cb44f1",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Quanta_Cloud_Technology/results/D54U_3U_H100_PCIe_80GBx4_TRT/retinanet/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.357,
    "Accuracy_div_100": 0.37357,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/1-node-2S-SPR-PyTorch-INT8/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "1-node-2S-SPR-PyTorch-INT8",
    "Result": 211.654,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "1-node-2S-SPR-PyTorch-INT8",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": "N/A",
    "compliance": 1,
    "errors": 0,
    "framework": "PyTorch",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+ 56-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54Q-2U",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.1",
    "uid": "0410c6db6b71416a",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Quanta_Cloud_Technology/results/1-node-2S-SPR-PyTorch-INT8/retinanet/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.336,
    "Accuracy_div_100": 0.37336,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/D54Q_2U_L4_PCIe_24GBx4_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "D54Q_2U_L4_PCIe_24GBx4_TRT",
    "Result": 799.336,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "D54Q_2U (4x L4-PCIe-24GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L4-PCIe-24GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6430 32-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.0",
    "uid": "aa0e49738c534faf",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Quanta_Cloud_Technology/results/D54Q_2U_L4_PCIe_24GBx4_TRT/retinanet/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.358,
    "Accuracy_div_100": 0.37358,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/HPE_ProLiant_XL675d_Gen10_Plus_A100_SXM_80GBx8_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "HPE",
    "Platform": "HPE_ProLiant_XL675d_Gen10_Plus_A100_SXM_80GBx8_TRT",
    "Result": 5603.34,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "HPE ProLiant XL675d Gen10 Plus (8x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7763 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "RHEL 9.1",
    "uid": "2f66df7f49c547b9",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/HPE/results/HPE_ProLiant_XL675d_Gen10_Plus_A100_SXM_80GBx8_TRT/retinanet/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.335,
    "Accuracy_div_100": 0.37335,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/HPE_ProLiant_DL320_Gen11_L4x4_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "HPE",
    "Platform": "HPE_ProLiant_DL320_Gen11_L4x4_TRT",
    "Result": 799.336,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "HPE ProLiant DL320 Gen11 (4x L4-PCIe-24GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L4-PCIe-24GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 5412U",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "uid": "39f28d63825a4d13",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/HPE/results/HPE_ProLiant_DL320_Gen11_L4x4_TRT/retinanet/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.21,
    "Accuracy_div_100": 0.3721,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/dl385_q8_std/retinanet/server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "HPE",
    "Platform": "dl385_q8_std",
    "Result": 2229.07,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "HPE ProLiant DL385 Gen10 Plus v2 (8x QAIC100 Standard)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Standard",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.9.1",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "AMD EPYC 7543 32-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Powered by the KRAI X and KILT technologies",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6 LTS (Linux kernel 5.15.0-75-generic #82~20.04.1-Ubuntu SMP Wed Jun 7 19:37:37 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "1f575865a7c14c8d",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/HPE/results/dl385_q8_std/retinanet/server",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.323,
    "Accuracy_div_100": 0.37323,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/HPE_ProLiant_DL380a_Gen11_H100_PCIe_80GBx4_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "HPE",
    "Platform": "HPE_ProLiant_DL380a_Gen11_H100_PCIe_80GBx4_TRT",
    "Result": 4004.73,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "HPE ProLiant DL380a Gen11 (4x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "uid": "566ffb9de1fa4d00",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/HPE/results/HPE_ProLiant_DL380a_Gen11_H100_PCIe_80GBx4_TRT/retinanet/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.357,
    "Accuracy_div_100": 0.37357,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/1-node-2S-SPR-PyTorch-INT8/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "HPE",
    "Platform": "1-node-2S-SPR-PyTorch-INT8",
    "Result": 199.743,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "1-node-2S-SPR-PyTorch-INT8",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "PyTorch",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "HPE ProLiant DL380a Gen11. N/A",
    "number_of_nodes": 1,
    "operating_system": "Red Hat Enterprise Linux 8.8 (Ootpa)",
    "uid": "08c7f6f332fe42a2",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/HPE/results/1-node-2S-SPR-PyTorch-INT8/retinanet/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 37.461,
    "Accuracy_div_100": 0.37461,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/AS-4124GS-TNR_8_A100-PCIe-80GB_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Supermicro",
    "Platform": "AS-4124GS-TNR_8_A100-PCIe-80GB_TRT",
    "Result": 3996.74,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "AS-4124GS-TNR (8xA100-PCIe-80GB)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7713 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "fc9e101093ca4821",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/Supermicro/results/AS-4124GS-TNR_8_A100-PCIe-80GB_TRT/retinanet/Server",
    "version": "v2.1"
  },
  {
    "Accuracy": 37.431,
    "Accuracy_div_100": 0.37431,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-A100_A100-SXM-80GB-MIG_1x1g.10gb_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "NVIDIA",
    "Platform": "DGX-A100_A100-SXM-80GB-MIG_1x1g.10gb_TRT",
    "Result": 44.984,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "NVIDIA DGX A100 (1x A100-SXM-80GB-MIG-1x1g.10gb, TensorRT)",
    "SystemType": "datacenter,edge",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB (1x1g.10gb MIG)",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "4051443f13ce4f1e",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GB-MIG_1x1g.10gb_TRT/retinanet/Server",
    "version": "v2.1"
  },
  {
    "Accuracy": 37.462,
    "Accuracy_div_100": 0.37462,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT_Triton/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "NVIDIA",
    "Platform": "DGX-A100_A100-SXM-80GBx8_TRT_Triton",
    "Result": 3731.81,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "NVIDIA DGX A100 (8x A100-SXM-80GB, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "da60aff035e5435f",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT_Triton/retinanet/Server",
    "version": "v2.1"
  },
  {
    "Accuracy": 37.472,
    "Accuracy_div_100": 0.37472,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "NVIDIA",
    "Platform": "DGX-A100_A100-SXM-80GBx8_TRT",
    "Result": 4096.46,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "NVIDIA DGX A100 (8x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "f7792773d0954d73",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT/retinanet/Server",
    "version": "v2.1"
  },
  {
    "Accuracy": 37.472,
    "Accuracy_div_100": 0.37472,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H100-SXM-80GBx1_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "NVIDIA",
    "Platform": "H100-SXM-80GBx1_TRT",
    "Result": 847.949,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "NVIDIA H100 (1x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.5.0, CUDA 11.8",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 7252 8-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Private git branch used to produce all NVIDIA H100 results. The git hash of the private branch is 35fc4b9a7758edc6063bb3a4ba4bfa94ce7aa9e1",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "6f45496edee4449c",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/NVIDIA/results/H100-SXM-80GBx1_TRT/retinanet/Server",
    "version": "v2.1"
  },
  {
    "Accuracy": 37.463,
    "Accuracy_div_100": 0.37463,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A100-PCIe-80GBx8_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "NVIDIA",
    "Platform": "A100-PCIe-80GBx8_TRT",
    "Result": 3996.74,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Gigabyte G482-Z54 (8x A100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "29f1fa061be54132",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/NVIDIA/results/A100-PCIe-80GBx8_TRT/retinanet/Server",
    "version": "v2.1"
  },
  {
    "Accuracy": 37.48,
    "Accuracy_div_100": 0.3748,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC4000_A2x8_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "ASUSTeK",
    "Platform": "ESC4000_A2x8_TRT",
    "Result": 329.284,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "ASUS ESC4000-E10S (8x A2, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A2",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 8,
    "host_processor_model_name": " Intel(R) Xeon(R) Platinum 8352M 32-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "b231bb0695424281",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/ASUSTeK/results/ESC4000_A2x8_TRT/retinanet/Server",
    "version": "v2.1"
  },
  {
    "Accuracy": 37.463,
    "Accuracy_div_100": 0.37463,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/A100-PCIe-80GBx8_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "ASUSTeK",
    "Platform": "A100-PCIe-80GBx8_TRT",
    "Result": 4196.94,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "ASUS ESC8000A-E11 (8x A100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7763 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "21abd8f6a3f14884",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/ASUSTeK/results/A100-PCIe-80GBx8_TRT/retinanet/Server",
    "version": "v2.1"
  },
  {
    "Accuracy": 37.463,
    "Accuracy_div_100": 0.37463,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Azure/results/ND96amsr_A100_v4_TRT_Triton/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Azure",
    "Platform": "ND96amsr_A100_v4_TRT_Triton",
    "Result": 3996.74,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "ND96amsr_A100_v4 (8x A100-SXM-80GB, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 7V12 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.6 LTS",
    "uid": "98c423b73b954758",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/Azure/results/ND96amsr_A100_v4_TRT_Triton/retinanet/Server",
    "version": "v2.1"
  },
  {
    "Accuracy": 37.463,
    "Accuracy_div_100": 0.37463,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Azure/results/ND96amsr_A100_v4_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Azure",
    "Platform": "ND96amsr_A100_v4_TRT",
    "Result": 4096.46,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "ND96amsr_A100_v4 (8x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 7V12 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.6 LTS",
    "uid": "90844fff5f714e3d",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/Azure/results/ND96amsr_A100_v4_TRT/retinanet/Server",
    "version": "v2.1"
  },
  {
    "Accuracy": 37.462,
    "Accuracy_div_100": 0.37462,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Azure/results/NC96ads_A100_v4_TRT_Triton/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Azure",
    "Platform": "NC96ads_A100_v4_TRT_Triton",
    "Result": 1146.92,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "NC96ads_A100_v4 (4x A100-PCIe-80GB, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 7V13 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.6 LTS",
    "uid": "238da02d591f4d0f",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/Azure/results/NC96ads_A100_v4_TRT_Triton/retinanet/Server",
    "version": "v2.1"
  },
  {
    "Accuracy": 37.462,
    "Accuracy_div_100": 0.37462,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Azure/results/NC96ads_A100_v4_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Azure",
    "Platform": "NC96ads_A100_v4_TRT",
    "Result": 1995.76,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "NC96ads_A100_v4 (4x A100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 7V13 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.6 LTS",
    "uid": "73e315d7f003421e",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/Azure/results/NC96ads_A100_v4_TRT/retinanet/Server",
    "version": "v2.1"
  },
  {
    "Accuracy": 37.471,
    "Accuracy_div_100": 0.37471,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R750xa_A100_PCIE_80GBx4_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Dell",
    "Platform": "R750xa_A100_PCIE_80GBx4_TRT",
    "Result": 2141.36,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge R750xa (4x A100-PCIE-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6338 CPU @ 2.00GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "CentOS 8.2",
    "uid": "e996064662ba4772",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/Dell/results/R750xa_A100_PCIE_80GBx4_TRT/retinanet/Server",
    "version": "v2.1"
  },
  {
    "Accuracy": 37.467,
    "Accuracy_div_100": 0.37467,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE8545_A100_SXM_80GBx4_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Dell",
    "Platform": "XE8545_A100_SXM_80GBx4_TRT",
    "Result": 2296.04,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge XE8545 (4x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB CTS",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7763",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "NVIDIA A100-SXM-80GB (TDP: 500W)",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "c89034a66c044014",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/Dell/results/XE8545_A100_SXM_80GBx4_TRT/retinanet/Server",
    "version": "v2.1"
  },
  {
    "Accuracy": 37.463,
    "Accuracy_div_100": 0.37463,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/GIGABYTE/results/G492-ID0_A100-SXM-80GBx8_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "GIGABYTE",
    "Platform": "G492-ID0_A100-SXM-80GBx8_TRT",
    "Result": 4096.46,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "G492-ID0 (8x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.7",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8380",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.3",
    "uid": "429c5e32cef845ba",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/GIGABYTE/results/G492-ID0_A100-SXM-80GBx8_TRT/retinanet/Server",
    "version": "v2.1"
  },
  {
    "Accuracy": 37.188,
    "Accuracy_div_100": 0.37188,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/Intel/results/1-node-2S-SPR-PyTorch-INT8/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Intel",
    "Platform": "1-node-2S-SPR-PyTorch-INT8",
    "Result": 149.674,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "1-node-2S-SPR-PyTorch-INT8",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "PyTorch",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": "",
    "host_processor_model_name": "Intel(R) Xeon(R) (code named Sapphire Rapids)",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Intel Devlopment Platform (2U Server)",
    "number_of_nodes": 1,
    "operating_system": "CentOS Stream 8",
    "uid": "44dd504847d74a2e",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/Intel/results/1-node-2S-SPR-PyTorch-INT8/retinanet/Server",
    "version": "v2.1"
  },
  {
    "Accuracy": 37.462,
    "Accuracy_div_100": 0.37462,
    "Availability": "rdi",
    "Division": "closed",
    "Location": "closed/Nettrix/results/A100_PCIE_80GBx20_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Nettrix",
    "Platform": "A100_PCIE_80GBx20_TRT",
    "Result": 6993.5,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "X640 G40 (20x A100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 20,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6346 CPU",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04",
    "uid": "a17d87a470e941ff",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/Nettrix/results/A100_PCIE_80GBx20_TRT/retinanet/Server",
    "version": "v2.1"
  },
  {
    "Accuracy": 37.463,
    "Accuracy_div_100": 0.37463,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Nettrix/results/A100_SXM4_80GBx8_Custom_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Nettrix",
    "Platform": "A100_SXM4_80GBx8_Custom_TRT",
    "Result": 4716.36,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "X660G45L (8x A100-SXM4-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-SXM4-80GB CTS",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 38,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8368Q",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "NVIDIA A100-SXM4-80GB (TDP:500W)",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "db31e665451940b2",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/Nettrix/results/A100_SXM4_80GBx8_Custom_TRT/retinanet/Server",
    "version": "v2.1"
  },
  {
    "Accuracy": 37.462,
    "Accuracy_div_100": 0.37462,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/R5300G5_A30x8_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "H3C",
    "Platform": "R5300G5_A30x8_TRT",
    "Result": 2226.6,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "H3C UniServer R5300 G5 (8x A30, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8362 CPU @ 2.80GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "9722a4ae47104f3b",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/H3C/results/R5300G5_A30x8_TRT/retinanet/Server",
    "version": "v2.1"
  },
  {
    "Accuracy": 37.462,
    "Accuracy_div_100": 0.37462,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/R5500G5_Intel_A100_A100-SXM-80GBx8_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "H3C",
    "Platform": "R5500G5_Intel_A100_A100-SXM-80GBx8_TRT",
    "Result": 4657.04,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "H3C UniServer R5500 G5 Intel (8x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8378A",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "a028b24bc26a4561",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/H3C/results/R5500G5_Intel_A100_A100-SXM-80GBx8_TRT/retinanet/Server",
    "version": "v2.1"
  },
  {
    "Accuracy": 37.463,
    "Accuracy_div_100": 0.37463,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/R5500G5_AMD_A100_A100-SXM-80GBx8_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "H3C",
    "Platform": "R5500G5_AMD_A100_A100-SXM-80GBx8_TRT",
    "Result": 4646.98,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "H3C UniServer R5500 G5 AMD (8x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7773X",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "2316e3882a474b10",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/H3C/results/R5500G5_AMD_A100_A100-SXM-80GBx8_TRT/retinanet/Server",
    "version": "v2.1"
  },
  {
    "Accuracy": 37.463,
    "Accuracy_div_100": 0.37463,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/R5300G5_A100_PCIE_80GBX4_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "H3C",
    "Platform": "R5300G5_A100_PCIE_80GBX4_TRT",
    "Result": 1995.76,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "H3C UniServer R5300 G5 (4x A100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.5",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8362 CPU @ 2.80GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "38db88a11bb64a0d",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/H3C/results/R5300G5_A100_PCIE_80GBX4_TRT/retinanet/Server",
    "version": "v2.1"
  },
  {
    "Accuracy": 37.462,
    "Accuracy_div_100": 0.37462,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/R5300G5_A30x8_TRT_Triton/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "H3C",
    "Platform": "R5300G5_A30x8_TRT_Triton",
    "Result": 2226.6,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "H3C UniServer R5300 G5 (8x A30, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8362 CPU @ 2.80GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "164279894bdf4652",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/H3C/results/R5300G5_A30x8_TRT_Triton/retinanet/Server",
    "version": "v2.1"
  },
  {
    "Accuracy": 37.482,
    "Accuracy_div_100": 0.37482,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/A30x2_R4950G5_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "H3C",
    "Platform": "A30x2_R4950G5_TRT",
    "Result": 199.566,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "H3C UniServer R4950 G5(2x A30, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 128,
    "host_processor_model_name": "AMD EPYC 7513 32-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "428c133a15344e68",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/H3C/results/A30x2_R4950G5_TRT/retinanet/Server",
    "version": "v2.1"
  },
  {
    "Accuracy": 37.549,
    "Accuracy_div_100": 0.37549,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS-741GE-TNRT_4_H100-PCIe-80GB_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Supermicro",
    "Platform": "SYS-741GE-TNRT_4_H100-PCIe-80GB_TRT",
    "Result": 3750.02,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "SYS-741GE-TNRT (4xH100-PCIe-80GB)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6448Y",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5",
    "uid": "7152f55d90924dfa",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Supermicro/results/SYS-741GE-TNRT_4_H100-PCIe-80GB_TRT/retinanet/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 37.549,
    "Accuracy_div_100": 0.37549,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS-221HE-FTNR-DATACENTER_2_H100-PCIe-80GB_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Supermicro",
    "Platform": "SYS-221HE-FTNR-DATACENTER_2_H100-PCIe-80GB_TRT",
    "Result": 1858.33,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "SYS-221HE-FTNR (2xH100-PCIe-80GB)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "473d11bc9eb64414",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Supermicro/results/SYS-221HE-FTNR-DATACENTER_2_H100-PCIe-80GB_TRT/retinanet/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 37.549,
    "Accuracy_div_100": 0.37549,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/AS-4125GS-TNRT_8_H100-PCIe-80GB_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Supermicro",
    "Platform": "AS-4125GS-TNRT_8_H100-PCIe-80GB_TRT",
    "Result": 8003.89,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "AS-4125GS-TNRT (8xH100-PCIe-80GB)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 9174F 16-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2",
    "uid": "ca62710d2ac84aa4",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Supermicro/results/AS-4125GS-TNRT_8_H100-PCIe-80GB_TRT/retinanet/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 37.549,
    "Accuracy_div_100": 0.37549,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H100-PCIe-80GBx1_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "NVIDIA",
    "Platform": "H100-PCIe-80GBx1_TRT",
    "Result": 928.738,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Gigabyte G482-Z54 (1x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "f599e451e092480e",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/NVIDIA/results/H100-PCIe-80GBx1_TRT/retinanet/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 37.55,
    "Accuracy_div_100": 0.3755,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A100-PCIe-80GBx8_TRT_Triton/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "NVIDIA",
    "Platform": "A100-PCIe-80GBx8_TRT_Triton",
    "Result": 3298.77,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Gigabyte G482-Z54 (8x A100-PCIe-80GB, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "17697b8cf1cf4ad9",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/NVIDIA/results/A100-PCIe-80GBx8_TRT_Triton/retinanet/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 37.549,
    "Accuracy_div_100": 0.37549,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/L4x1_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "NVIDIA",
    "Platform": "L4x1_TRT",
    "Result": 154.901,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "NVIDIA L4 (1x L4, TensorRT)",
    "SystemType": "datacenter,edge",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 7313P 16-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "f65656a2989d44ca",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/NVIDIA/results/L4x1_TRT/retinanet/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 37.549,
    "Accuracy_div_100": 0.37549,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H100-PCIe-80GBx8_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "NVIDIA",
    "Platform": "H100-PCIe-80GBx8_TRT",
    "Result": 7363.4,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Gigabyte G482-Z54 (8x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "621b81bbe5184970",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/NVIDIA/results/H100-PCIe-80GBx8_TRT/retinanet/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 37.55,
    "Accuracy_div_100": 0.3755,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT_Triton/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "NVIDIA",
    "Platform": "DGX-A100_A100-SXM-80GBx8_TRT_Triton",
    "Result": 3734.75,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "NVIDIA DGX A100 (8x A100-SXM-80GB, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "33c4cfcaabcb401c",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT_Triton/retinanet/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 37.55,
    "Accuracy_div_100": 0.3755,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "NVIDIA",
    "Platform": "DGX-A100_A100-SXM-80GBx8_TRT",
    "Result": 5602.54,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "NVIDIA DGX A100 (8x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "4500cfd3946e4238",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT/retinanet/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 37.549,
    "Accuracy_div_100": 0.37549,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "NVIDIA",
    "Platform": "DGX-H100_H100-SXM-80GBx8_TRT",
    "Result": 11518.8,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "NVIDIA DGX H100 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "97ffb0984f73411d",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT/retinanet/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 37.549,
    "Accuracy_div_100": 0.37549,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx1_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "NVIDIA",
    "Platform": "DGX-H100_H100-SXM-80GBx1_TRT",
    "Result": 1437.71,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "NVIDIA DGX H100 (1x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "05c899d06c0e4dcf",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx1_TRT/retinanet/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 37.55,
    "Accuracy_div_100": 0.3755,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A100-PCIe-80GBx8_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "NVIDIA",
    "Platform": "A100-PCIe-80GBx8_TRT",
    "Result": 4642.02,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Gigabyte G482-Z54 (8x A100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "de3cdbfaf69b44de",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/NVIDIA/results/A100-PCIe-80GBx8_TRT/retinanet/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 37.471,
    "Accuracy_div_100": 0.37471,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC4000A_E12_L4x8_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "ASUSTeK",
    "Platform": "ESC4000A_E12_L4x8_TRT",
    "Result": 1158.41,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "ASUS ESC4000A-E12 (8x L4, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9654 96-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "48c49377fd614b34",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/ASUSTeK/results/ESC4000A_E12_L4x8_TRT/retinanet/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 37.549,
    "Accuracy_div_100": 0.37549,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/H100_PCIe_80GBx8_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "ASUSTeK",
    "Platform": "H100_PCIe_80GBx8_TRT",
    "Result": 7522.88,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "ESC8000-E12 (8xH100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8460Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "19934212ea1a4f02",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/ASUSTeK/results/H100_PCIe_80GBx8_TRT/retinanet/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 37.473,
    "Accuracy_div_100": 0.37473,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Azure/results/NC96ads_A100_v4_TRT_Triton/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Azure",
    "Platform": "NC96ads_A100_v4_TRT_Triton",
    "Result": 2498.24,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "NC96ads_A100_v4 (4x A100-PCIe-80GB, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 7V13 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5 LTS",
    "uid": "4b9eee2ef2964cec",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Azure/results/NC96ads_A100_v4_TRT_Triton/retinanet/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 37.473,
    "Accuracy_div_100": 0.37473,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Azure/results/NC96ads_A100_v4_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Azure",
    "Platform": "NC96ads_A100_v4_TRT",
    "Result": 2498.24,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "NC96ads_A100_v4 (4x A100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 7V13 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5 LTS",
    "uid": "7a9e6d8611b643e6",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Azure/results/NC96ads_A100_v4_TRT/retinanet/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 37.239,
    "Accuracy_div_100": 0.37239,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Qualcomm/results/r282_z93_q8-qaic-v1.8.3.7-aic100/retinanet/server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Qualcomm",
    "Platform": "r282_z93_q8-qaic-v1.8.3.7-aic100",
    "Result": 2023.72,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "GIGABYTE R282-Z93 (8x QAIC100 Pro)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.8.3",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 7282 16-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026.. Powered by Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5 LTS (Linux kernel: 5.4.0-135-generic #152-Ubuntu SMP Wed Nov 23 20:19:22 UTC 2022)",
    "uid": "cdca50dc9e81490c",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Qualcomm/results/r282_z93_q8-qaic-v1.8.3.7-aic100/retinanet/server",
    "version": "v3.0"
  },
  {
    "Accuracy": 37.239,
    "Accuracy_div_100": 0.37239,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Qualcomm/results/g292_z43_q16-qaic-v1.8.3.7-aic100/retinanet/server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Qualcomm",
    "Platform": "g292_z43_q16-qaic-v1.8.3.7-aic100",
    "Result": 4121.65,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "GIGABYTE G292-Z43 (16x QAIC100 Pro)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 16,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.8.3",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7713 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5 LTS (Linux kernel: 5.4.0-135-generic #152-Ubuntu SMP Wed Nov 23 20:19:22 UTC 2022)",
    "uid": "015cc1b6240f4fb3",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Qualcomm/results/g292_z43_q16-qaic-v1.8.3.7-aic100/retinanet/server",
    "version": "v3.0"
  },
  {
    "Accuracy": 37.239,
    "Accuracy_div_100": 0.37239,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Qualcomm/results/g292_z43_q18-qaic-v1.8.3.7-aic100/retinanet/server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Qualcomm",
    "Platform": "g292_z43_q18-qaic-v1.8.3.7-aic100",
    "Result": 4627.04,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "GIGABYTE G292-Z43 (18x QAIC100 Pro)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 18,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.8.3",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7713 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5 LTS (Linux kernel: 5.4.0-135-generic #152-Ubuntu SMP Wed Nov 23 20:19:22 UTC 2022)",
    "uid": "f1b016371e2d47ea",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Qualcomm/results/g292_z43_q18-qaic-v1.8.3.7-aic100/retinanet/server",
    "version": "v3.0"
  },
  {
    "Accuracy": 37.487,
    "Accuracy_div_100": 0.37487,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/vR750xa_H100_PCIe_80Cx2_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Dell",
    "Platform": "vR750xa_H100_PCIe_80Cx2_TRT",
    "Result": 1772.81,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge R750xa, VMware vSphere 8.0.1 (2x H100-80C, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-80C",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8358 CPU @ 2.60GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": " VM Specifications 16 vCPU out of 128 available, 128GB of memory out of available 256GB ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4 on VMware ESXi, 8.0.1",
    "uid": "d76a4ff3b6d84f59",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Dell/results/vR750xa_H100_PCIe_80Cx2_TRT/retinanet/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 37.549,
    "Accuracy_div_100": 0.37549,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XR4520c_A30x1_TRT_DATACENTER/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Dell",
    "Platform": "XR4520c_A30x1_TRT_DATACENTER",
    "Result": 279.822,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge XR4520c (1x A30, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "Intel(R) Xeon(R) D-2776NT CPU @ 2.10GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "69a2d0dc385242af",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Dell/results/XR4520c_A30x1_TRT_DATACENTER/retinanet/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 37.549,
    "Accuracy_div_100": 0.37549,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R750xa_H100_PCIe_80GBx4_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Dell",
    "Platform": "R750xa_H100_PCIe_80GBx4_TRT",
    "Result": 3707.91,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge R750xa (4x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6338 CPU @ 2.00GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "NVIDIA H100-PCIe-80GB (TDP: 310W)",
    "number_of_nodes": 1,
    "operating_system": "CentOS 8.2",
    "uid": "d0f7bad13cd143ce",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Dell/results/R750xa_H100_PCIe_80GBx4_TRT/retinanet/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 37.472,
    "Accuracy_div_100": 0.37472,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/vXE8545_A100_SXM_80GBx4_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Dell",
    "Platform": "vXE8545_A100_SXM_80GBx4_TRT",
    "Result": 2798.93,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge XE8545, VMware vSphere 8.0.1 (4x A100-SXM-80C, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80C",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 128,
    "host_processor_model_name": "AMD EPYC 7543",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "VMware vSphere 8.0.1, Ubuntu 20.04.2",
    "uid": "7b1334c8ef91422d",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Dell/results/vXE8545_A100_SXM_80GBx4_TRT/retinanet/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 37.549,
    "Accuracy_div_100": 0.37549,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R750xa_H100_PCIe_80GBx2_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Dell",
    "Platform": "R750xa_H100_PCIe_80GBx2_TRT",
    "Result": 1852.24,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge R750xa (2x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6338 CPU @ 2.00GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "NVIDIA H100-PCIe-80GB (TDP: 310W)",
    "number_of_nodes": 1,
    "operating_system": "CentOS 8.2",
    "uid": "b965c9a1aa894ca0",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Dell/results/R750xa_H100_PCIe_80GBx2_TRT/retinanet/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 37.55,
    "Accuracy_div_100": 0.3755,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE8545_A100_SXM4_80GBx4_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Dell",
    "Platform": "XE8545_A100_SXM4_80GBx4_TRT",
    "Result": 2848.84,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge XE8545 (4x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB CTS",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7763",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "NVIDIA A100-SXM4-80GB (TDP: 500W)",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "c93868fac10641d7",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Dell/results/XE8545_A100_SXM4_80GBx4_TRT/retinanet/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 37.549,
    "Accuracy_div_100": 0.37549,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9680_H100_SXM_80GBx8_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Dell",
    "Platform": "XE9680_H100_SXM_80GBx8_TRT",
    "Result": 11748.6,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge XE9680 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 52,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "57125a7e37fd4547",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Dell/results/XE9680_H100_SXM_80GBx8_TRT/retinanet/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 37.55,
    "Accuracy_div_100": 0.3755,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R750xa_A100_PCIE_80GBx4_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Dell",
    "Platform": "R750xa_A100_PCIE_80GBx4_TRT",
    "Result": 2142.56,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge R750xa (4x A100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6338 CPU @ 2.00GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "CentOS 8.2",
    "uid": "d03a3b6b6bf94bb9",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Dell/results/R750xa_A100_PCIE_80GBx4_TRT/retinanet/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 37.55,
    "Accuracy_div_100": 0.3755,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9680_A100_SXM4_80GBx8_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Dell",
    "Platform": "XE9680_A100_SXM4_80GBx8_TRT",
    "Result": 5721.66,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge XE9680 (8x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB CTS",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 52,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "NVIDIA A100-SXM4-80GB (TDP: 500W)",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "f3bfb1521e2a4e59",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Dell/results/XE9680_A100_SXM4_80GBx8_TRT/retinanet/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 37.357,
    "Accuracy_div_100": 0.37357,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/1-node-2S-SPR-PyTorch-INT8/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Dell",
    "Platform": "1-node-2S-SPR-PyTorch-INT8",
    "Result": 208.867,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge Server R760 (1x Intel Xeon Platinum 8480+)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "PyTorch",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 224,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "CentOS Stream 8",
    "uid": "062161871adc454c",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Dell/results/1-node-2S-SPR-PyTorch-INT8/retinanet/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 37.55,
    "Accuracy_div_100": 0.3755,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/xFusion/results/G5500V7_A30x10_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "xFusion",
    "Platform": "G5500V7_A30x10_TRT",
    "Result": 3348.97,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "xFusion FusionServer G5500V7(10x NVIDIA A30, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 10,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 44,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8458P CPU @ 2.7 GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "38a28cb0ec3f4cfb",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/xFusion/results/G5500V7_A30x10_TRT/retinanet/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 37.514,
    "Accuracy_div_100": 0.37514,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/xFusion/results/G5500V7_L40x8_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "xFusion",
    "Platform": "G5500V7_L40x8_TRT",
    "Result": 3519.95,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "xFusion FusionServer G5500V7(8x NVIDIA L40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L40",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 44,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8458P CPU @ 2.7 GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "a0621fdba5564536",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/xFusion/results/G5500V7_L40x8_TRT/retinanet/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 37.55,
    "Accuracy_div_100": 0.3755,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/xFusion/results/G5500V7_A30x8_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "xFusion",
    "Platform": "G5500V7_A30x8_TRT",
    "Result": 2598.53,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "xFusion FusionServer G5500V7(8x NVIDIA A30, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 44,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8458P CPU @ 2.7 GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "f80dd3aa92f34a89",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/xFusion/results/G5500V7_A30x8_TRT/retinanet/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 37.494,
    "Accuracy_div_100": 0.37494,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/xFusion/results/L4x6_2288H_V7_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "xFusion",
    "Platform": "L4x6_2288H_V7_TRT",
    "Result": 1048.41,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "xFusion FusionServer 2288H V7(6x NVIDIA L4, TensorRT)",
    "SystemType": "datacenter,edge",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 6,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 44,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8458P CPU @ 2.7 GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "7707fcfe067a4c48",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/xFusion/results/L4x6_2288H_V7_TRT/retinanet/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 37.528,
    "Accuracy_div_100": 0.37528,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/xFusion/results/G5500V7_L40x10_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "xFusion",
    "Platform": "G5500V7_L40x10_TRT",
    "Result": 4201.95,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "xFusion FusionServer G5500V7(10x NVIDIA L40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L40",
    "accelerators_per_node": 10,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 44,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8458P CPU @ 2.7 GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "a61130eafdb34260",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/xFusion/results/G5500V7_L40x10_TRT/retinanet/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 37.549,
    "Accuracy_div_100": 0.37549,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/GIGABYTE/results/GIGABYTE-G493-SB0_H100-PCIe-80GBx8_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "GIGABYTE",
    "Platform": "GIGABYTE-G493-SB0_H100-PCIe-80GBx8_TRT",
    "Result": 7603.42,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "GIGABYTE G493-SB0",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "d0ff205bd06b4283",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/GIGABYTE/results/GIGABYTE-G493-SB0_H100-PCIe-80GBx8_TRT/retinanet/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 37.357,
    "Accuracy_div_100": 0.37357,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Intel/results/1-node-2S-SPR-PyTorch-INT8/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Intel",
    "Platform": "1-node-2S-SPR-PyTorch-INT8",
    "Result": 213.864,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "1-node-2S-SPR-PyTorch-INT8",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "PyTorch",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54Q-2U",
    "number_of_nodes": 2,
    "operating_system": "CentOS Stream 8",
    "uid": "bb321f8308e04fd3",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Intel/results/1-node-2S-SPR-PyTorch-INT8/retinanet/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 37.469,
    "Accuracy_div_100": 0.37469,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Nettrix/results/L40x8_Custom_X640_G40_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Nettrix",
    "Platform": "L40x8_Custom_X640_G40_TRT",
    "Result": 3679.94,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "X640 G40 (8xL40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L40",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8380",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "04d0362fef8a41cd",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/L40x8_Custom_X640_G40_TRT/retinanet/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 37.556,
    "Accuracy_div_100": 0.37556,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Nettrix/results/A40X3_CUSTOM_X620_G50_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Nettrix",
    "Platform": "A40X3_CUSTOM_X620_G50_TRT",
    "Result": 909.648,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "X620 G50 (3x A40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A40",
    "accelerators_per_node": 3,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "3d351bf31f754c43",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/A40X3_CUSTOM_X620_G50_TRT/retinanet/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 37.544,
    "Accuracy_div_100": 0.37544,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/Nettrix/results/A30x8_Custom_X640_G50_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Nettrix",
    "Platform": "A30x8_Custom_X640_G50_TRT",
    "Result": 2598.53,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "X640 G50 (8x A30, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "52620dcb59234ef0",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/A30x8_Custom_X640_G50_TRT/retinanet/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 37.53,
    "Accuracy_div_100": 0.3753,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/Nettrix/results/L4x8_Custom_X640_G40_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Nettrix",
    "Platform": "L4x8_Custom_X640_G40_TRT",
    "Result": 1392.6,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "X640 G40 (8x L4, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 38,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8368",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "0f50ee41fe7d4820",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/L4x8_Custom_X640_G40_TRT/retinanet/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 37.347,
    "Accuracy_div_100": 0.37347,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Nettrix/results/L40x3_Custom_X620_G40_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Nettrix",
    "Platform": "L40x3_Custom_X620_G40_TRT",
    "Result": 1357.12,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "X620 G40 (3xL40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L40",
    "accelerators_per_node": 3,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 28,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6348",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "2e550787233149cb",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/L40x3_Custom_X620_G40_TRT/retinanet/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 37.454,
    "Accuracy_div_100": 0.37454,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Nettrix/results/L40x3_Custom_X620_G50_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Nettrix",
    "Platform": "L40x3_Custom_X620_G50_TRT",
    "Result": 1353.29,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "X620 G50 (3xL40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L40",
    "accelerators_per_node": 3,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6442Y",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "3bae428ec9914943",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/L40x3_Custom_X620_G50_TRT/retinanet/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 37.556,
    "Accuracy_div_100": 0.37556,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Nettrix/results/A40X8_CUSTOM_X640_G40_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Nettrix",
    "Platform": "A40X8_CUSTOM_X640_G40_TRT",
    "Result": 2433.93,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "X640 G40 (8x A40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A40",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 38,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8368",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "250fca54ff454cf6",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/A40X8_CUSTOM_X640_G40_TRT/retinanet/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 37.544,
    "Accuracy_div_100": 0.37544,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Nettrix/results/A30x3_Custom_X620_G40_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Nettrix",
    "Platform": "A30x3_Custom_X620_G40_TRT",
    "Result": 953.781,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "X620 G40 (3x A30, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 3,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 28,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6348 CPU @ 2.60GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "bf89181827a2459e",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/A30x3_Custom_X620_G40_TRT/retinanet/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 37.549,
    "Accuracy_div_100": 0.37549,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/Nettrix/results/L4x4_Custom_X620_G40_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Nettrix",
    "Platform": "L4x4_Custom_X620_G40_TRT",
    "Result": 668.985,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "X620 G40 (4x L4, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 28,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6348",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "c2ed0848724a4853",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/L4x4_Custom_X620_G40_TRT/retinanet/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 37.544,
    "Accuracy_div_100": 0.37544,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Nettrix/results/A30x4_Custom_X620_G50_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Nettrix",
    "Platform": "A30x4_Custom_X620_G50_TRT",
    "Result": 1277.87,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "X620 G50 (4x A30, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 44,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8458P",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "f8ff8b64384e4a7b",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/A30x4_Custom_X620_G50_TRT/retinanet/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 37.456,
    "Accuracy_div_100": 0.37456,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/Nettrix/results/L40x8_Custom_X640_G50_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Nettrix",
    "Platform": "L40x8_Custom_X640_G50_TRT",
    "Result": 3679.94,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "X640 G50 (8xL40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L40",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "68fb777b75a243af",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/L40x8_Custom_X640_G50_TRT/retinanet/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 37.55,
    "Accuracy_div_100": 0.3755,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/Nettrix/results/A40X8_CUSTOM_X640_G50_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Nettrix",
    "Platform": "A40X8_CUSTOM_X640_G50_TRT",
    "Result": 2458.8,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "X640 G50 (8x A40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A40",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "208459ac8b8749b6",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/A40X8_CUSTOM_X640_G50_TRT/retinanet/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 37.544,
    "Accuracy_div_100": 0.37544,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Nettrix/results/A30x8_Custom_X640_G40_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Nettrix",
    "Platform": "A30x8_Custom_X640_G40_TRT",
    "Result": 2598.53,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "X640 G40 (8x A30, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 18,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6354",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "b423a4f364d54c9a",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/A30x8_Custom_X640_G40_TRT/retinanet/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 37.556,
    "Accuracy_div_100": 0.37556,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Nettrix/results/A40X3_CUSTOM_X620_G40_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Nettrix",
    "Platform": "A40X3_CUSTOM_X620_G40_TRT",
    "Result": 894.906,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "X620 G40 (3x A40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A40",
    "accelerators_per_node": 3,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 28,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6348",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "8b706c0ebbd5454d",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/A40X3_CUSTOM_X620_G40_TRT/retinanet/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 37.529,
    "Accuracy_div_100": 0.37529,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/Nettrix/results/L4x8_Custom_X640_G50_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Nettrix",
    "Platform": "L4x8_Custom_X640_G50_TRT",
    "Result": 1407.56,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "X640 G50 (8x L4, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "333bd54b743940bf",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/L4x8_Custom_X640_G50_TRT/retinanet/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 37.548,
    "Accuracy_div_100": 0.37548,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/Nettrix/results/L4x5_Custom_X620_G50_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Nettrix",
    "Platform": "L4x5_Custom_X620_G50_TRT",
    "Result": 873.958,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "X620 G50 (5x L4, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 5,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 6458Q",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "10aa2aee54f64cf0",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/L4x5_Custom_X620_G50_TRT/retinanet/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 37.549,
    "Accuracy_div_100": 0.37549,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Inspur/results/NF5468M6_A40x8_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "Inspur",
    "Platform": "NF5468M6_A40x8_TRT",
    "Result": 2446.83,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "NF5468M6 (8x A40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A40",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8380",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5",
    "uid": "ac8a256bc77b460b",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Inspur/results/NF5468M6_A40x8_TRT/retinanet/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 37.483,
    "Accuracy_div_100": 0.37483,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/R5350G6_A30x10_TRT_Triton/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "H3C",
    "Platform": "R5350G6_A30x10_TRT_Triton",
    "Result": 3198.85,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "H3C UniServer R5350 G6 (10x A30, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 10,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "AMD EPYC 9654 96-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5",
    "uid": "d5a697c06bb445fe",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/H3C/results/R5350G6_A30x10_TRT_Triton/retinanet/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 37.483,
    "Accuracy_div_100": 0.37483,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/R5300G6_A30x4_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "H3C",
    "Platform": "R5300G6_A30x4_TRT",
    "Result": 1338.1,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "H3C UniServer R5300 G6 (4x A30, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 11.7",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 44,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8458P",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5",
    "uid": "a002e9488ee64397",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/H3C/results/R5300G6_A30x4_TRT/retinanet/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 37.483,
    "Accuracy_div_100": 0.37483,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/R5350G6_A30x10_TRT/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "H3C",
    "Platform": "R5350G6_A30x10_TRT",
    "Result": 3348.97,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "H3C UniServer R5350 G6 (10x A30, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 10,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "AMD EPYC 9654 96-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5",
    "uid": "4d4bc45dad0e4722",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/H3C/results/R5350G6_A30x10_TRT/retinanet/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 37.239,
    "Accuracy_div_100": 0.37239,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/dl385_q8_std-qaic-v1.8.3.7-aic100/retinanet/server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "HPE",
    "Platform": "dl385_q8_std-qaic-v1.8.3.7-aic100",
    "Result": 2000.71,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "HPE ProLiant DL385 Gen10 Plus v2 (8x QAIC100 Standard)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Standard",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.8.3",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "AMD EPYC 7543 32-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5 LTS (Linux kernel: 5.15.0-60-generic #66~20.04.1-Ubuntu SMP Wed Jan 25 09:41:30 UTC 2023)",
    "uid": "4aa422d98c01414d",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/HPE/results/dl385_q8_std-qaic-v1.8.3.7-aic100/retinanet/server",
    "version": "v3.0"
  },
  {
    "Accuracy": 37.357,
    "Accuracy_div_100": 0.37357,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/1-node-2S-SPR-PyTorch-INT8/retinanet/Server",
    "MlperfModel": "retinanet",
    "Model": "retinanet",
    "Organization": "HPE",
    "Platform": "1-node-2S-SPR-PyTorch-INT8",
    "Result": 204.87,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "1-node-2S-SPR-PyTorch-INT8",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "PyTorch",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "ProLiant DL380a Gen11",
    "number_of_nodes": 2,
    "operating_system": "Red Hat Enterprise Linux 8.7",
    "uid": "3a2165504d694a91",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/HPE/results/1-node-2S-SPR-PyTorch-INT8/retinanet/Server",
    "version": "v3.0"
  }
]
