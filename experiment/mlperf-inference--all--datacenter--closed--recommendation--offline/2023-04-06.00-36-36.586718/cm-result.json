[
  {
    "Accuracy": 80.165,
    "Accuracy_div_100": 0.80165,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC8000_E11P_H100x8_TRT/dlrm-v2-99/Offline",
    "MlperfModel": "dlrm-v2-99",
    "Model": "dlrm-v2-99",
    "Organization": "ASUSTeK",
    "Platform": "ESC8000_E11P_H100x8_TRT",
    "Result": 336637,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "ESC8000-E11P (8x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Data bandwidth for GPU-PCIe: 504 GB/s; PCIe-NIC: 126 GB/s",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "5d3af99fda1e45e1",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/ASUSTeK/results/ESC8000_E11P_H100x8_TRT/dlrm-v2-99/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 80.232,
    "Accuracy_div_100": 0.80232,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC8000_E11P_H100x8_TRT/dlrm-v2-99.9/Offline",
    "MlperfModel": "dlrm-v2-99.9",
    "Model": "dlrm-v2-99.9",
    "Organization": "ASUSTeK",
    "Platform": "ESC8000_E11P_H100x8_TRT",
    "Result": 201726,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "ESC8000-E11P (8x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Data bandwidth for GPU-PCIe: 504 GB/s; PCIe-NIC: 126 GB/s",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "c360b6e461124f13",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/ASUSTeK/results/ESC8000_E11P_H100x8_TRT/dlrm-v2-99.9/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 80.165,
    "Accuracy_div_100": 0.80165,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC8000_E11_L40Sx8_TRT/dlrm-v2-99/Offline",
    "MlperfModel": "dlrm-v2-99",
    "Model": "dlrm-v2-99",
    "Organization": "ASUSTeK",
    "Platform": "ESC8000_E11_L40Sx8_TRT",
    "Result": 196999,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "ESC8000-E11 (8x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6442Y",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Data bandwidth for GPU-PCIe: 252 GB/s; PCIe-NIC: 63 GB/s",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "4e9884340ebd4fdd",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/ASUSTeK/results/ESC8000_E11_L40Sx8_TRT/dlrm-v2-99/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 80.232,
    "Accuracy_div_100": 0.80232,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC8000_E11_L40Sx8_TRT/dlrm-v2-99.9/Offline",
    "MlperfModel": "dlrm-v2-99.9",
    "Model": "dlrm-v2-99.9",
    "Organization": "ASUSTeK",
    "Platform": "ESC8000_E11_L40Sx8_TRT",
    "Result": 101691,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "ESC8000-E11 (8x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6442Y",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Data bandwidth for GPU-PCIe: 252 GB/s; PCIe-NIC: 63 GB/s",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "5dabc64d50b34bf4",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/ASUSTeK/results/ESC8000_E11_L40Sx8_TRT/dlrm-v2-99.9/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 80.24119408703937,
    "Accuracy_div_100": 0.80241,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R760_CPU/dlrm-v2-99.9/Offline",
    "MlperfModel": "dlrm-v2-99.9",
    "Model": "dlrm-v2-99.9",
    "Organization": "Dell",
    "Platform": "R760_CPU",
    "Result": 9239.74,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge R760",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "PyTorch",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "INT4 for GPT-J, Mixed for RNN-T and INT8 for all other models",
    "number_of_nodes": 1,
    "operating_system": "CentOS Stream 8",
    "uid": "60897a904faa4e82",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Dell/results/R760_CPU/dlrm-v2-99.9/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 80.165,
    "Accuracy_div_100": 0.80165,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/dlrm-v2-99/Offline",
    "MlperfModel": "dlrm-v2-99",
    "Model": "dlrm-v2-99",
    "Organization": "Dell",
    "Platform": "XE8640_H100_SXM_80GBx4_TRT",
    "Result": 278414,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE8640 (4x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "uid": "4d4aeabdc9614c22",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/dlrm-v2-99/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 80.232,
    "Accuracy_div_100": 0.80232,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/dlrm-v2-99.9/Offline",
    "MlperfModel": "dlrm-v2-99.9",
    "Model": "dlrm-v2-99.9",
    "Organization": "Dell",
    "Platform": "XE8640_H100_SXM_80GBx4_TRT",
    "Result": 174149,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE8640 (4x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "uid": "e3630a70fa024e30",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/dlrm-v2-99.9/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 80.165,
    "Accuracy_div_100": 0.80165,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9680_H100_SXM_80GBx8_TRT/dlrm-v2-99/Offline",
    "MlperfModel": "dlrm-v2-99",
    "Model": "dlrm-v2-99",
    "Organization": "Dell",
    "Platform": "XE9680_H100_SXM_80GBx8_TRT",
    "Result": 554313,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE9680 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "uid": "46c339e3bb284c70",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Dell/results/XE9680_H100_SXM_80GBx8_TRT/dlrm-v2-99/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 80.232,
    "Accuracy_div_100": 0.80232,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9680_H100_SXM_80GBx8_TRT/dlrm-v2-99.9/Offline",
    "MlperfModel": "dlrm-v2-99.9",
    "Model": "dlrm-v2-99.9",
    "Organization": "Dell",
    "Platform": "XE9680_H100_SXM_80GBx8_TRT",
    "Result": 347289,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE9680 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "uid": "dbf264e741d34e21",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Dell/results/XE9680_H100_SXM_80GBx8_TRT/dlrm-v2-99.9/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 80.165,
    "Accuracy_div_100": 0.80165,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/GigaComputing/results/GIGABYTE-G593-SD1_DGX-H100_H100-SXM-80GBx8_TRT/dlrm-v2-99/Offline",
    "MlperfModel": "dlrm-v2-99",
    "Model": "dlrm-v2-99",
    "Organization": "GigaComputing",
    "Platform": "GIGABYTE-G593-SD1_DGX-H100_H100-SXM-80GBx8_TRT",
    "Result": 558571,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "GIGABYTE G593-SD1",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Data bandwidth for GPU-PCIe: 504 GB/s; PCIe-NIC: 600GB/s",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "uid": "b70d2914a6fd45e5",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/GigaComputing/results/GIGABYTE-G593-SD1_DGX-H100_H100-SXM-80GBx8_TRT/dlrm-v2-99/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 80.232,
    "Accuracy_div_100": 0.80232,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/GigaComputing/results/GIGABYTE-G593-SD1_DGX-H100_H100-SXM-80GBx8_TRT/dlrm-v2-99.9/Offline",
    "MlperfModel": "dlrm-v2-99.9",
    "Model": "dlrm-v2-99.9",
    "Organization": "GigaComputing",
    "Platform": "GIGABYTE-G593-SD1_DGX-H100_H100-SXM-80GBx8_TRT",
    "Result": 347454,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "GIGABYTE G593-SD1",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Data bandwidth for GPU-PCIe: 504 GB/s; PCIe-NIC: 600GB/s",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "uid": "f374a397a0054f9c",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/GigaComputing/results/GIGABYTE-G593-SD1_DGX-H100_H100-SXM-80GBx8_TRT/dlrm-v2-99.9/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 80.232,
    "Accuracy_div_100": 0.80232,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Google/results/H100-SXM-80GBx8_TRT/dlrm-v2-99.9/Offline",
    "MlperfModel": "dlrm-v2-99.9",
    "Model": "dlrm-v2-99.9",
    "Organization": "Google",
    "Platform": "H100-SXM-80GBx8_TRT",
    "Result": 341111,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX H100 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 208,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8481C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "ef9b9ee29392475e",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Google/results/H100-SXM-80GBx8_TRT/dlrm-v2-99.9/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 80.24119408703937,
    "Accuracy_div_100": 0.80241,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Intel/results/1-node-2S-EMR-PyTorch/dlrm-v2-99.9/Offline",
    "MlperfModel": "dlrm-v2-99.9",
    "Model": "dlrm-v2-99.9",
    "Organization": "Intel",
    "Platform": "1-node-2S-EMR-PyTorch",
    "Result": 9111.08,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "1-node-2S-EMR-PyTorch",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "PyTorch",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54Q-2U. N/A",
    "number_of_nodes": 1,
    "operating_system": "CentOS Stream 8",
    "uid": "6a6f22846d8a4753",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Intel/results/1-node-2S-EMR-PyTorch/dlrm-v2-99.9/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 80.164,
    "Accuracy_div_100": 0.80164,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx1_TRT/dlrm-v2-99/Offline",
    "MlperfModel": "dlrm-v2-99",
    "Model": "dlrm-v2-99",
    "Organization": "NVIDIA",
    "Platform": "DGX-H100_H100-SXM-80GBx1_TRT",
    "Result": 70346.2,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX H100 (1x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "2909a3e0de994d94",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx1_TRT/dlrm-v2-99/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 80.232,
    "Accuracy_div_100": 0.80232,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx1_TRT/dlrm-v2-99.9/Offline",
    "MlperfModel": "dlrm-v2-99.9",
    "Model": "dlrm-v2-99.9",
    "Organization": "NVIDIA",
    "Platform": "DGX-H100_H100-SXM-80GBx1_TRT",
    "Result": 44022.7,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX H100 (1x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "2d1d09384fca45a7",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx1_TRT/dlrm-v2-99.9/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 80.164,
    "Accuracy_div_100": 0.80164,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT/dlrm-v2-99/Offline",
    "MlperfModel": "dlrm-v2-99",
    "Model": "dlrm-v2-99",
    "Organization": "NVIDIA",
    "Platform": "DGX-H100_H100-SXM-80GBx8_TRT",
    "Result": 568422,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX H100 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "4eea6adfa54f4d6d",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT/dlrm-v2-99/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 80.232,
    "Accuracy_div_100": 0.80232,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT/dlrm-v2-99.9/Offline",
    "MlperfModel": "dlrm-v2-99.9",
    "Model": "dlrm-v2-99.9",
    "Organization": "NVIDIA",
    "Platform": "DGX-H100_H100-SXM-80GBx8_TRT",
    "Result": 354151,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX H100 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "0edc7f619352419f",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT/dlrm-v2-99.9/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 80.164,
    "Accuracy_div_100": 0.80164,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/dlrm-v2-99/Offline",
    "MlperfModel": "dlrm-v2-99",
    "Model": "dlrm-v2-99",
    "Organization": "NVIDIA",
    "Platform": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "Result": 80118.5,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA GH200-GraceHopper-Superchip (1x GH200-96GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GH200-GraceHopper-Superchip",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "NVIDIA MGX Reference Platform;",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2",
    "uid": "a1a951e978044eec",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/NVIDIA/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/dlrm-v2-99/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 80.232,
    "Accuracy_div_100": 0.80232,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/dlrm-v2-99.9/Offline",
    "MlperfModel": "dlrm-v2-99.9",
    "Model": "dlrm-v2-99.9",
    "Organization": "NVIDIA",
    "Platform": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "Result": 49651,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA GH200-GraceHopper-Superchip (1x GH200-96GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GH200-GraceHopper-Superchip",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "NVIDIA MGX Reference Platform;",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2",
    "uid": "62e2bf67d48d4300",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/NVIDIA/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/dlrm-v2-99.9/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 80.164,
    "Accuracy_div_100": 0.80164,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GBx8_TRT/dlrm-v2-99/Offline",
    "MlperfModel": "dlrm-v2-99",
    "Model": "dlrm-v2-99",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GBx8_TRT",
    "Result": 572867,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA H200 (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "d33bdf72d6ea40f8",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/NVIDIA/results/H200-SXM-141GBx8_TRT/dlrm-v2-99/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 80.232,
    "Accuracy_div_100": 0.80232,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GBx8_TRT/dlrm-v2-99.9/Offline",
    "MlperfModel": "dlrm-v2-99.9",
    "Model": "dlrm-v2-99.9",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GBx8_TRT",
    "Result": 359104,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA H200 (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "4ec73609816e4802",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/NVIDIA/results/H200-SXM-141GBx8_TRT/dlrm-v2-99.9/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 80.153,
    "Accuracy_div_100": 0.80153,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/L40Sx8_TRT/dlrm-v2-99/Offline",
    "MlperfModel": "dlrm-v2-99",
    "Model": "dlrm-v2-99",
    "Organization": "NVIDIA",
    "Platform": "L40Sx8_TRT",
    "Result": 175953,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "ASROCKRACK 4U8G-ROME2/4E (8x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "f63d5564ef7b4567",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/NVIDIA/results/L40Sx8_TRT/dlrm-v2-99/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 80.235,
    "Accuracy_div_100": 0.80235,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/L40Sx8_TRT/dlrm-v2-99.9/Offline",
    "MlperfModel": "dlrm-v2-99.9",
    "Model": "dlrm-v2-99.9",
    "Organization": "NVIDIA",
    "Platform": "L40Sx8_TRT",
    "Result": 85117.6,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "ASROCKRACK 4U8G-ROME2/4E (8x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "c679ebf69de04b4c",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/NVIDIA/results/L40Sx8_TRT/dlrm-v2-99.9/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 80.165,
    "Accuracy_div_100": 0.80165,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Oracle/results/OCI-H100_H100-SXM-80GBx8_TRT/dlrm-v2-99/Offline",
    "MlperfModel": "dlrm-v2-99",
    "Model": "dlrm-v2-99",
    "Organization": "Oracle",
    "Platform": "OCI-H100_H100-SXM-80GBx8_TRT",
    "Result": 557592,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "BM.GPU.H100.8",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0.1, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "uid": "742c3d5b4b044e55",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Oracle/results/OCI-H100_H100-SXM-80GBx8_TRT/dlrm-v2-99/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 80.232,
    "Accuracy_div_100": 0.80232,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Oracle/results/OCI-H100_H100-SXM-80GBx8_TRT/dlrm-v2-99.9/Offline",
    "MlperfModel": "dlrm-v2-99.9",
    "Model": "dlrm-v2-99.9",
    "Organization": "Oracle",
    "Platform": "OCI-H100_H100-SXM-80GBx8_TRT",
    "Result": 347177,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "BM.GPU.H100.8",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0.1, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "uid": "b16e3796b8a14153",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Oracle/results/OCI-H100_H100-SXM-80GBx8_TRT/dlrm-v2-99.9/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 80.24119408703937,
    "Accuracy_div_100": 0.80241,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/1-node-2S-EMR-PyTorch/dlrm-v2-99.9/Offline",
    "MlperfModel": "dlrm-v2-99.9",
    "Model": "dlrm-v2-99.9",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "1-node-2S-EMR-PyTorch",
    "Result": 9245.77,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "1-node-2S-EMR-PyTorch-INT8",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": "N/A",
    "compliance": 1,
    "errors": 0,
    "framework": "PyTorch",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54X-1U",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.1",
    "uid": "aede05a189964e97",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Quanta_Cloud_Technology/results/1-node-2S-EMR-PyTorch/dlrm-v2-99.9/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 80.232,
    "Accuracy_div_100": 0.80232,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/D54U_3U_H100_PCIe_80GBx4_TRT/dlrm-v2-99.9/Offline",
    "MlperfModel": "dlrm-v2-99.9",
    "Model": "dlrm-v2-99.9",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "D54U_3U_H100_PCIe_80GBx4_TRT",
    "Result": 102225,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "D54U_3U_H100_PCIe_80GBx4_TRT",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.3",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 52,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54U-3U",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.2",
    "uid": "b215f9e6d338403b",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Quanta_Cloud_Technology/results/D54U_3U_H100_PCIe_80GBx4_TRT/dlrm-v2-99.9/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 80.165,
    "Accuracy_div_100": 0.80165,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/D54U_3U_L40S_PCIe_48GBx4_TRT/dlrm-v2-99/Offline",
    "MlperfModel": "dlrm-v2-99",
    "Model": "dlrm-v2-99",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "D54U_3U_L40S_PCIe_48GBx4_TRT",
    "Result": 97314.9,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "D54U_3U_L40S_PCIe_48GBx4_TRT",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.3",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 52,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54U-3U",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.2",
    "uid": "820b62b9bd0a43a2",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Quanta_Cloud_Technology/results/D54U_3U_L40S_PCIe_48GBx4_TRT/dlrm-v2-99/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 80.232,
    "Accuracy_div_100": 0.80232,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/D54U_3U_L40S_PCIe_48GBx4_TRT/dlrm-v2-99.9/Offline",
    "MlperfModel": "dlrm-v2-99.9",
    "Model": "dlrm-v2-99.9",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "D54U_3U_L40S_PCIe_48GBx4_TRT",
    "Result": 51318.5,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "D54U_3U_L40S_PCIe_48GBx4_TRT",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.3",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 52,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54U-3U",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.2",
    "uid": "3bee714b7cb644a5",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Quanta_Cloud_Technology/results/D54U_3U_L40S_PCIe_48GBx4_TRT/dlrm-v2-99.9/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 80.232,
    "Accuracy_div_100": 0.80232,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/dlrm-v2-99.9/Offline",
    "MlperfModel": "dlrm-v2-99.9",
    "Model": "dlrm-v2-99.9",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "Result": 48403.1,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GH200-GraceHopper-Superchip",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "QuantaGrid S74G-2U",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.1",
    "uid": "2dc0aca1d82a4c4f",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Quanta_Cloud_Technology/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/dlrm-v2-99.9/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 80.165,
    "Accuracy_div_100": 0.80165,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/dlrm-v2-99/Offline",
    "MlperfModel": "dlrm-v2-99",
    "Model": "dlrm-v2-99",
    "Organization": "Supermicro",
    "Platform": "SYS_821GE_TNHR_H100_SXM_80GBx8_TRT",
    "Result": 560530,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "SYS-821GE-TNHR (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8568Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3 LTS",
    "uid": "316503a904374c69",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/dlrm-v2-99/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 80.232,
    "Accuracy_div_100": 0.80232,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/dlrm-v2-99.9/Offline",
    "MlperfModel": "dlrm-v2-99.9",
    "Model": "dlrm-v2-99.9",
    "Organization": "Supermicro",
    "Platform": "SYS_821GE_TNHR_H100_SXM_80GBx8_TRT",
    "Result": 350225,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "SYS-821GE-TNHR (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8568Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3 LTS",
    "uid": "76c8d2d1843c458f",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/dlrm-v2-99.9/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 80.312,
    "Accuracy_div_100": 0.80312,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/dlrm-v2-99.9/Offline",
    "MlperfModel": "dlrm-v2-99.9",
    "Model": "dlrm-v2-99.9",
    "Organization": "Supermicro",
    "Platform": "SYS_821GE_TNHR_H100_SXM_80GBx8_TRT",
    "Result": 340658,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "SYS-821GE-TNHR (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2 LTS",
    "uid": "4bea78486a2b4ad3",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/dlrm-v2-99.9/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 80.312,
    "Accuracy_div_100": 0.80312,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/dlrm-v2-99/Offline",
    "MlperfModel": "dlrm-v2-99",
    "Model": "dlrm-v2-99",
    "Organization": "Supermicro",
    "Platform": "SYS_821GE_TNHR_H100_SXM_80GBx8_TRT",
    "Result": 340928,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "SYS-821GE-TNHR (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2 LTS",
    "uid": "af3ec3983dc84329",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/dlrm-v2-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 80.312,
    "Accuracy_div_100": 0.80312,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS_521GE_TNRT_H100_PCIe_80GBX8_TRT/dlrm-v2-99.9/Offline",
    "MlperfModel": "dlrm-v2-99.9",
    "Model": "dlrm-v2-99.9",
    "Organization": "Supermicro",
    "Platform": "SYS_521GE_TNRT_H100_PCIe_80GBX8_TRT",
    "Result": 198707,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "SYS-521GE-TNRT (8xH100-PCIe-80GB)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8462Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "uid": "986f17dada92407f",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Supermicro/results/SYS_521GE_TNRT_H100_PCIe_80GBX8_TRT/dlrm-v2-99.9/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 80.312,
    "Accuracy_div_100": 0.80312,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS_521GE_TNRT_H100_PCIe_80GBX8_TRT/dlrm-v2-99/Offline",
    "MlperfModel": "dlrm-v2-99",
    "Model": "dlrm-v2-99",
    "Organization": "Supermicro",
    "Platform": "SYS_521GE_TNRT_H100_PCIe_80GBX8_TRT",
    "Result": 198707,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "SYS-521GE-TNRT (8xH100-PCIe-80GB)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8462Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "uid": "222feca009dc42d4",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Supermicro/results/SYS_521GE_TNRT_H100_PCIe_80GBX8_TRT/dlrm-v2-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 80.312,
    "Accuracy_div_100": 0.80312,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT/dlrm-v2-99.9/Offline",
    "MlperfModel": "dlrm-v2-99.9",
    "Model": "dlrm-v2-99.9",
    "Organization": "Supermicro",
    "Platform": "AS_8125GS_TNHR_H100_SXM_80GBx8_TRT",
    "Result": 341806,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AS-8125GS-TNHR (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 9554",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2 LTS",
    "uid": "7b6dca7f7bcf4061",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Supermicro/results/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT/dlrm-v2-99.9/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 80.312,
    "Accuracy_div_100": 0.80312,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT/dlrm-v2-99/Offline",
    "MlperfModel": "dlrm-v2-99",
    "Model": "dlrm-v2-99",
    "Organization": "Supermicro",
    "Platform": "AS_8125GS_TNHR_H100_SXM_80GBx8_TRT",
    "Result": 342065,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AS-8125GS-TNHR (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 9554",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2 LTS",
    "uid": "b409e530813049fc",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Supermicro/results/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT/dlrm-v2-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 80.312,
    "Accuracy_div_100": 0.80312,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H100-PCIe-80GBx1_TRT/dlrm-v2-99.9/Offline",
    "MlperfModel": "dlrm-v2-99.9",
    "Model": "dlrm-v2-99.9",
    "Organization": "NVIDIA",
    "Platform": "H100-PCIe-80GBx1_TRT",
    "Result": 25153.4,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G482-Z54 (1x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "5abf1d32ef504582",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/NVIDIA/results/H100-PCIe-80GBx1_TRT/dlrm-v2-99.9/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 80.312,
    "Accuracy_div_100": 0.80312,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H100-PCIe-80GBx1_TRT/dlrm-v2-99/Offline",
    "MlperfModel": "dlrm-v2-99",
    "Model": "dlrm-v2-99",
    "Organization": "NVIDIA",
    "Platform": "H100-PCIe-80GBx1_TRT",
    "Result": 25153.4,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G482-Z54 (1x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "ceb2fe90e6c94ddc",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/NVIDIA/results/H100-PCIe-80GBx1_TRT/dlrm-v2-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 80.27,
    "Accuracy_div_100": 0.8027,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/L4x1_TRT/dlrm-v2-99.9/Offline",
    "MlperfModel": "dlrm-v2-99.9",
    "Model": "dlrm-v2-99.9",
    "Organization": "NVIDIA",
    "Platform": "L4x1_TRT",
    "Result": 3672.79,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "ASROCKRACK 1U1G-MILAN (1x L4, TensorRT)",
    "SystemType": "datacenter,edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 7313P 16-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "91ead41d121a40c3",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/NVIDIA/results/L4x1_TRT/dlrm-v2-99.9/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 80.27,
    "Accuracy_div_100": 0.8027,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/L4x1_TRT/dlrm-v2-99/Offline",
    "MlperfModel": "dlrm-v2-99",
    "Model": "dlrm-v2-99",
    "Organization": "NVIDIA",
    "Platform": "L4x1_TRT",
    "Result": 3672.79,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "ASROCKRACK 1U1G-MILAN (1x L4, TensorRT)",
    "SystemType": "datacenter,edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 7313P 16-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "ced577da0cda40e9",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/NVIDIA/results/L4x1_TRT/dlrm-v2-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 80.312,
    "Accuracy_div_100": 0.80312,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/dlrm-v2-99.9/Offline",
    "MlperfModel": "dlrm-v2-99.9",
    "Model": "dlrm-v2-99.9",
    "Organization": "NVIDIA",
    "Platform": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "Result": 49001.8,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA GH200-GraceHopper-Superchip (1x GH200-96GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GH200-GraceHopper-Superchip",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "NVIDIA MGX Reference Platform",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2",
    "uid": "e87f4e910a4845c2",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/NVIDIA/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/dlrm-v2-99.9/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 80.312,
    "Accuracy_div_100": 0.80312,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/dlrm-v2-99/Offline",
    "MlperfModel": "dlrm-v2-99",
    "Model": "dlrm-v2-99",
    "Organization": "NVIDIA",
    "Platform": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "Result": 49001.8,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA GH200-GraceHopper-Superchip (1x GH200-96GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GH200-GraceHopper-Superchip",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "NVIDIA MGX Reference Platform",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2",
    "uid": "58422de911c04b83",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/NVIDIA/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/dlrm-v2-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 80.312,
    "Accuracy_div_100": 0.80312,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H100-PCIe-80GBx8_TRT/dlrm-v2-99.9/Offline",
    "MlperfModel": "dlrm-v2-99.9",
    "Model": "dlrm-v2-99.9",
    "Organization": "NVIDIA",
    "Platform": "H100-PCIe-80GBx8_TRT",
    "Result": 192829,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G482-Z54 (8x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "7ac19922e25341c4",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/NVIDIA/results/H100-PCIe-80GBx8_TRT/dlrm-v2-99.9/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 80.312,
    "Accuracy_div_100": 0.80312,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H100-PCIe-80GBx8_TRT/dlrm-v2-99/Offline",
    "MlperfModel": "dlrm-v2-99",
    "Model": "dlrm-v2-99",
    "Organization": "NVIDIA",
    "Platform": "H100-PCIe-80GBx8_TRT",
    "Result": 192829,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G482-Z54 (8x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "64375e06f20c4b33",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/NVIDIA/results/H100-PCIe-80GBx8_TRT/dlrm-v2-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 80.312,
    "Accuracy_div_100": 0.80312,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT/dlrm-v2-99.9/Offline",
    "MlperfModel": "dlrm-v2-99.9",
    "Model": "dlrm-v2-99.9",
    "Organization": "NVIDIA",
    "Platform": "DGX-H100_H100-SXM-80GBx8_TRT",
    "Result": 329529,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX H100 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "7478d9323952486b",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT/dlrm-v2-99.9/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 80.312,
    "Accuracy_div_100": 0.80312,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT/dlrm-v2-99/Offline",
    "MlperfModel": "dlrm-v2-99",
    "Model": "dlrm-v2-99",
    "Organization": "NVIDIA",
    "Platform": "DGX-H100_H100-SXM-80GBx8_TRT",
    "Result": 329529,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX H100 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "9ed2f9be0b9f4574",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT/dlrm-v2-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 80.312,
    "Accuracy_div_100": 0.80312,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx1_TRT/dlrm-v2-99.9/Offline",
    "MlperfModel": "dlrm-v2-99.9",
    "Model": "dlrm-v2-99.9",
    "Organization": "NVIDIA",
    "Platform": "DGX-H100_H100-SXM-80GBx1_TRT",
    "Result": 42856.4,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX H100 (1x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "dfa4298653dd46dd",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx1_TRT/dlrm-v2-99.9/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 80.312,
    "Accuracy_div_100": 0.80312,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx1_TRT/dlrm-v2-99/Offline",
    "MlperfModel": "dlrm-v2-99",
    "Model": "dlrm-v2-99",
    "Organization": "NVIDIA",
    "Platform": "DGX-H100_H100-SXM-80GBx1_TRT",
    "Result": 42856.4,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX H100 (1x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "32b6b58f441f4029",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx1_TRT/dlrm-v2-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 80.312,
    "Accuracy_div_100": 0.80312,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/H100_PCIe_80GBx8_TRT/dlrm-v2-99.9/Offline",
    "MlperfModel": "dlrm-v2-99.9",
    "Model": "dlrm-v2-99.9",
    "Organization": "ASUSTeK",
    "Platform": "H100_PCIe_80GBx8_TRT",
    "Result": 199526,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "ESC8000A-E12 (8xH100-PCIe-80GB, TensorRT",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9654 96-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "7c2bd9471d904dd6",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/ASUSTeK/results/H100_PCIe_80GBx8_TRT/dlrm-v2-99.9/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 80.312,
    "Accuracy_div_100": 0.80312,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/H100_PCIe_80GBx8_TRT/dlrm-v2-99/Offline",
    "MlperfModel": "dlrm-v2-99",
    "Model": "dlrm-v2-99",
    "Organization": "ASUSTeK",
    "Platform": "H100_PCIe_80GBx8_TRT",
    "Result": 201716,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "ESC8000A-E12 (8xH100-PCIe-80GB, TensorRT",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9654 96-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "6f08c338f0954472",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/ASUSTeK/results/H100_PCIe_80GBx8_TRT/dlrm-v2-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 80.312,
    "Accuracy_div_100": 0.80312,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R750xa_H100_PCIe_80GBx4_TRT/dlrm-v2-99.9/Offline",
    "MlperfModel": "dlrm-v2-99.9",
    "Model": "dlrm-v2-99.9",
    "Organization": "Dell",
    "Platform": "R750xa_H100_PCIe_80GBx4_TRT",
    "Result": 92569.8,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge R750xa (4x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6338 CPU @ 2.00GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "NVIDIA H100-PCIe-80GB (TDP: 310W)",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "uid": "f720fc22774f4dab",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Dell/results/R750xa_H100_PCIe_80GBx4_TRT/dlrm-v2-99.9/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 80.312,
    "Accuracy_div_100": 0.80312,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R750xa_H100_PCIe_80GBx4_TRT/dlrm-v2-99/Offline",
    "MlperfModel": "dlrm-v2-99",
    "Model": "dlrm-v2-99",
    "Organization": "Dell",
    "Platform": "R750xa_H100_PCIe_80GBx4_TRT",
    "Result": 92569.8,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge R750xa (4x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6338 CPU @ 2.00GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "NVIDIA H100-PCIe-80GB (TDP: 310W)",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "uid": "8cc09125c8f64b23",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Dell/results/R750xa_H100_PCIe_80GBx4_TRT/dlrm-v2-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 80.312,
    "Accuracy_div_100": 0.80312,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9680_A100_SXM_80GBx8_TRT/dlrm-v2-99.9/Offline",
    "MlperfModel": "dlrm-v2-99.9",
    "Model": "dlrm-v2-99.9",
    "Organization": "Dell",
    "Platform": "XE9680_A100_SXM_80GBx8_TRT",
    "Result": 149673,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE9680 (8x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB CTS",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "NVIDIA A100-SXM4-80GB (TDP: 500W)",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "5c427c72378c4369",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Dell/results/XE9680_A100_SXM_80GBx8_TRT/dlrm-v2-99.9/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 80.312,
    "Accuracy_div_100": 0.80312,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9680_A100_SXM_80GBx8_TRT/dlrm-v2-99/Offline",
    "MlperfModel": "dlrm-v2-99",
    "Model": "dlrm-v2-99",
    "Organization": "Dell",
    "Platform": "XE9680_A100_SXM_80GBx8_TRT",
    "Result": 149673,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE9680 (8x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB CTS",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "NVIDIA A100-SXM4-80GB (TDP: 500W)",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "6ad931d33cc34a63",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Dell/results/XE9680_A100_SXM_80GBx8_TRT/dlrm-v2-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 80.312,
    "Accuracy_div_100": 0.80312,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R760xa_H100_PCIe_80GBx4_TRT/dlrm-v2-99.9/Offline",
    "MlperfModel": "dlrm-v2-99.9",
    "Model": "dlrm-v2-99.9",
    "Organization": "Dell",
    "Platform": "R760xa_H100_PCIe_80GBx4_TRT",
    "Result": 99964.8,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge R760xa (4x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "d6651ecca5874ff6",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Dell/results/R760xa_H100_PCIe_80GBx4_TRT/dlrm-v2-99.9/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 80.312,
    "Accuracy_div_100": 0.80312,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R760xa_H100_PCIe_80GBx4_TRT/dlrm-v2-99/Offline",
    "MlperfModel": "dlrm-v2-99",
    "Model": "dlrm-v2-99",
    "Organization": "Dell",
    "Platform": "R760xa_H100_PCIe_80GBx4_TRT",
    "Result": 99964.8,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge R760xa (4x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "4eeef410b94f4658",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Dell/results/R760xa_H100_PCIe_80GBx4_TRT/dlrm-v2-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 80.312,
    "Accuracy_div_100": 0.80312,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9680_H100_SXM_80GBx8_TRT/dlrm-v2-99.9/Offline",
    "MlperfModel": "dlrm-v2-99.9",
    "Model": "dlrm-v2-99.9",
    "Organization": "Dell",
    "Platform": "XE9680_H100_SXM_80GBx8_TRT",
    "Result": 344370,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE9680 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 52,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "689e213e26214fd9",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Dell/results/XE9680_H100_SXM_80GBx8_TRT/dlrm-v2-99.9/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 80.312,
    "Accuracy_div_100": 0.80312,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9680_H100_SXM_80GBx8_TRT/dlrm-v2-99/Offline",
    "MlperfModel": "dlrm-v2-99",
    "Model": "dlrm-v2-99",
    "Organization": "Dell",
    "Platform": "XE9680_H100_SXM_80GBx8_TRT",
    "Result": 344370,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE9680 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 52,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "eb3b433c22dd4832",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Dell/results/XE9680_H100_SXM_80GBx8_TRT/dlrm-v2-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 80.312,
    "Accuracy_div_100": 0.80312,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R750xa_A100_PCIE_80GBx4_TRT/dlrm-v2-99.9/Offline",
    "MlperfModel": "dlrm-v2-99.9",
    "Model": "dlrm-v2-99.9",
    "Organization": "Dell",
    "Platform": "R750xa_A100_PCIE_80GBx4_TRT",
    "Result": 63639.6,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge R750xa (4x A100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter,edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6338 CPU @ 2.00GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.1",
    "uid": "d4644735d8c544c3",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Dell/results/R750xa_A100_PCIE_80GBx4_TRT/dlrm-v2-99.9/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 80.312,
    "Accuracy_div_100": 0.80312,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R750xa_A100_PCIE_80GBx4_TRT/dlrm-v2-99/Offline",
    "MlperfModel": "dlrm-v2-99",
    "Model": "dlrm-v2-99",
    "Organization": "Dell",
    "Platform": "R750xa_A100_PCIE_80GBx4_TRT",
    "Result": 63639.6,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge R750xa (4x A100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter,edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6338 CPU @ 2.00GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.1",
    "uid": "5e01c6f3afd343d9",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Dell/results/R750xa_A100_PCIE_80GBx4_TRT/dlrm-v2-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 80.312,
    "Accuracy_div_100": 0.80312,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/dlrm-v2-99.9/Offline",
    "MlperfModel": "dlrm-v2-99.9",
    "Model": "dlrm-v2-99.9",
    "Organization": "Dell",
    "Platform": "XE8640_H100_SXM_80GBx4_TRT",
    "Result": 174733,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE8640 (4x NVIDIA H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.1",
    "uid": "a5b31aaf78f44aef",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/dlrm-v2-99.9/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 80.312,
    "Accuracy_div_100": 0.80312,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/dlrm-v2-99/Offline",
    "MlperfModel": "dlrm-v2-99",
    "Model": "dlrm-v2-99",
    "Organization": "Dell",
    "Platform": "XE8640_H100_SXM_80GBx4_TRT",
    "Result": 174733,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE8640 (4x NVIDIA H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.1",
    "uid": "0a9cc5c6087c4cf3",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/dlrm-v2-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 80.284,
    "Accuracy_div_100": 0.80284,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/xFusion/results/G5500V7_A30x10_TRT/dlrm-v2-99.9/Offline",
    "MlperfModel": "dlrm-v2-99.9",
    "Model": "dlrm-v2-99.9",
    "Organization": "xFusion",
    "Platform": "G5500V7_A30x10_TRT",
    "Result": 68727.9,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "xFusion FusionServer G5500V7(10x NVIDIA A30, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 10,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6458Q @ 3.1 GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "c2964fa43519485c",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/xFusion/results/G5500V7_A30x10_TRT/dlrm-v2-99.9/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 80.284,
    "Accuracy_div_100": 0.80284,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/xFusion/results/G5500V7_A30x10_TRT/dlrm-v2-99/Offline",
    "MlperfModel": "dlrm-v2-99",
    "Model": "dlrm-v2-99",
    "Organization": "xFusion",
    "Platform": "G5500V7_A30x10_TRT",
    "Result": 68727.9,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "xFusion FusionServer G5500V7(10x NVIDIA A30, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 10,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6458Q @ 3.1 GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "5b9df98e757f4a69",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/xFusion/results/G5500V7_A30x10_TRT/dlrm-v2-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 80.312,
    "Accuracy_div_100": 0.80312,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/xFusion/results/G5500V7_L40x8_TRT/dlrm-v2-99.9/Offline",
    "MlperfModel": "dlrm-v2-99.9",
    "Model": "dlrm-v2-99.9",
    "Organization": "xFusion",
    "Platform": "G5500V7_L40x8_TRT",
    "Result": 67717.7,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "xFusion FusionServer G5500V7(8x NVIDIA L40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6458Q @ 3.1 GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "0b3d87e925ce46f3",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/xFusion/results/G5500V7_L40x8_TRT/dlrm-v2-99.9/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 80.312,
    "Accuracy_div_100": 0.80312,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/xFusion/results/G5500V7_L40x8_TRT/dlrm-v2-99/Offline",
    "MlperfModel": "dlrm-v2-99",
    "Model": "dlrm-v2-99",
    "Organization": "xFusion",
    "Platform": "G5500V7_L40x8_TRT",
    "Result": 67717.7,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "xFusion FusionServer G5500V7(8x NVIDIA L40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6458Q @ 3.1 GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "3134363191aa4e96",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/xFusion/results/G5500V7_L40x8_TRT/dlrm-v2-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 80.284,
    "Accuracy_div_100": 0.80284,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/xFusion/results/G5500V7_A30x8_TRT/dlrm-v2-99.9/Offline",
    "MlperfModel": "dlrm-v2-99.9",
    "Model": "dlrm-v2-99.9",
    "Organization": "xFusion",
    "Platform": "G5500V7_A30x8_TRT",
    "Result": 55253.2,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "xFusion FusionServer G5500V7(8x NVIDIA A30, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6458Q @ 3.1 GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "cc5d292951414e12",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/xFusion/results/G5500V7_A30x8_TRT/dlrm-v2-99.9/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 80.284,
    "Accuracy_div_100": 0.80284,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/xFusion/results/G5500V7_A30x8_TRT/dlrm-v2-99/Offline",
    "MlperfModel": "dlrm-v2-99",
    "Model": "dlrm-v2-99",
    "Organization": "xFusion",
    "Platform": "G5500V7_A30x8_TRT",
    "Result": 55253.2,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "xFusion FusionServer G5500V7(8x NVIDIA A30, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6458Q @ 3.1 GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "f573ad7d31be4757",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/xFusion/results/G5500V7_A30x8_TRT/dlrm-v2-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 80.312,
    "Accuracy_div_100": 0.80312,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/xFusion/results/L4x6_2288H_V7_TRT/dlrm-v2-99.9/Offline",
    "MlperfModel": "dlrm-v2-99.9",
    "Model": "dlrm-v2-99.9",
    "Organization": "xFusion",
    "Platform": "L4x6_2288H_V7_TRT",
    "Result": 8903.54,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "xFusion FusionServer 2288H V7(6x NVIDIA L4, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 6,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 44,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8458P CPU @ 2.7 GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "c60674254a6645c8",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/xFusion/results/L4x6_2288H_V7_TRT/dlrm-v2-99.9/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 80.312,
    "Accuracy_div_100": 0.80312,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/xFusion/results/L4x6_2288H_V7_TRT/dlrm-v2-99/Offline",
    "MlperfModel": "dlrm-v2-99",
    "Model": "dlrm-v2-99",
    "Organization": "xFusion",
    "Platform": "L4x6_2288H_V7_TRT",
    "Result": 8914.83,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "xFusion FusionServer 2288H V7(6x NVIDIA L4, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 6,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 44,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8458P CPU @ 2.7 GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "831779eebeac4290",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/xFusion/results/L4x6_2288H_V7_TRT/dlrm-v2-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 80.312,
    "Accuracy_div_100": 0.80312,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/xFusion/results/G5500V7_L40x10_TRT/dlrm-v2-99.9/Offline",
    "MlperfModel": "dlrm-v2-99.9",
    "Model": "dlrm-v2-99.9",
    "Organization": "xFusion",
    "Platform": "G5500V7_L40x10_TRT",
    "Result": 82179.5,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "xFusion FusionServer G5500V7(10x NVIDIA L40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40",
    "accelerators_per_node": 10,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6458Q @ 3.1 GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "8a7eb1b834fc4ed4",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/xFusion/results/G5500V7_L40x10_TRT/dlrm-v2-99.9/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 80.312,
    "Accuracy_div_100": 0.80312,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/xFusion/results/G5500V7_L40x10_TRT/dlrm-v2-99/Offline",
    "MlperfModel": "dlrm-v2-99",
    "Model": "dlrm-v2-99",
    "Organization": "xFusion",
    "Platform": "G5500V7_L40x10_TRT",
    "Result": 82179.5,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "xFusion FusionServer G5500V7(10x NVIDIA L40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40",
    "accelerators_per_node": 10,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6458Q @ 3.1 GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "c190955234434e1a",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/xFusion/results/G5500V7_L40x10_TRT/dlrm-v2-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 80.20245433226236,
    "Accuracy_div_100": 0.80202,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Intel/results/1-node-2S-SPR-PyTorch-INT8/dlrm-v2-99/Offline",
    "MlperfModel": "dlrm-v2-99",
    "Model": "dlrm-v2-99",
    "Organization": "Intel",
    "Platform": "1-node-2S-SPR-PyTorch-INT8",
    "Result": 5367.77,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "1-node-2S-SPR-PyTorch-INT8",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "PyTorch",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54Q-2U. N/A",
    "number_of_nodes": 1,
    "operating_system": "CentOS Stream 8",
    "uid": "41b60ffaef8147c6",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Intel/results/1-node-2S-SPR-PyTorch-INT8/dlrm-v2-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 80.312,
    "Accuracy_div_100": 0.80312,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Oracle/results/OCI-A100_A100-SXM-80GBx8_TRT/dlrm-v2-99.9/Offline",
    "MlperfModel": "dlrm-v2-99.9",
    "Model": "dlrm-v2-99.9",
    "Organization": "Oracle",
    "Platform": "OCI-A100_A100-SXM-80GBx8_TRT",
    "Result": 138179,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "BM.GPU.A100-v2.8",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7J13 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "42b86414752c49d9",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Oracle/results/OCI-A100_A100-SXM-80GBx8_TRT/dlrm-v2-99.9/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 80.312,
    "Accuracy_div_100": 0.80312,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Oracle/results/OCI-A100_A100-SXM-80GBx8_TRT/dlrm-v2-99/Offline",
    "MlperfModel": "dlrm-v2-99",
    "Model": "dlrm-v2-99",
    "Organization": "Oracle",
    "Platform": "OCI-A100_A100-SXM-80GBx8_TRT",
    "Result": 138331,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "BM.GPU.A100-v2.8",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7J13 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "c8516e177a144e7f",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Oracle/results/OCI-A100_A100-SXM-80GBx8_TRT/dlrm-v2-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 80.312,
    "Accuracy_div_100": 0.80312,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Oracle/results/OCI-H100_H100-SXM-80GBx8_TRT/dlrm-v2-99.9/Offline",
    "MlperfModel": "dlrm-v2-99.9",
    "Model": "dlrm-v2-99.9",
    "Organization": "Oracle",
    "Platform": "OCI-H100_H100-SXM-80GBx8_TRT",
    "Result": 339050,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "BM.GPU.H100.8",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "d6334a851499457a",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Oracle/results/OCI-H100_H100-SXM-80GBx8_TRT/dlrm-v2-99.9/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 80.312,
    "Accuracy_div_100": 0.80312,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Oracle/results/OCI-H100_H100-SXM-80GBx8_TRT/dlrm-v2-99/Offline",
    "MlperfModel": "dlrm-v2-99",
    "Model": "dlrm-v2-99",
    "Organization": "Oracle",
    "Platform": "OCI-H100_H100-SXM-80GBx8_TRT",
    "Result": 339265,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "BM.GPU.H100.8",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "c9ca82c7a88f44bc",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Oracle/results/OCI-H100_H100-SXM-80GBx8_TRT/dlrm-v2-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 80.312,
    "Accuracy_div_100": 0.80312,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/GigaComputing/results/GIGABYTE-G593-SD0_H100-SXM-80GBx8_TRT/dlrm-v2-99.9/Offline",
    "MlperfModel": "dlrm-v2-99.9",
    "Model": "dlrm-v2-99.9",
    "Organization": "GigaComputing",
    "Platform": "GIGABYTE-G593-SD0_H100-SXM-80GBx8_TRT",
    "Result": 340121,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "GIGABYTE G593-SD0",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "f4420d7f78f04bad",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/GigaComputing/results/GIGABYTE-G593-SD0_H100-SXM-80GBx8_TRT/dlrm-v2-99.9/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 80.312,
    "Accuracy_div_100": 0.80312,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/GigaComputing/results/GIGABYTE-G593-SD0_H100-SXM-80GBx8_TRT/dlrm-v2-99/Offline",
    "MlperfModel": "dlrm-v2-99",
    "Model": "dlrm-v2-99",
    "Organization": "GigaComputing",
    "Platform": "GIGABYTE-G593-SD0_H100-SXM-80GBx8_TRT",
    "Result": 340121,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "GIGABYTE G593-SD0",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "69b65186911e4d65",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/GigaComputing/results/GIGABYTE-G593-SD0_H100-SXM-80GBx8_TRT/dlrm-v2-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 80.23444046649396,
    "Accuracy_div_100": 0.80234,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/1-node-2S-SPR-PyTorch-INT8/dlrm-v2-99/Offline",
    "MlperfModel": "dlrm-v2-99",
    "Model": "dlrm-v2-99",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "1-node-2S-SPR-PyTorch-INT8",
    "Result": 4767.43,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "1-node-2S-SPR-PyTorch-INT8",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": "N/A",
    "compliance": 1,
    "errors": 0,
    "framework": "PyTorch",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+ 56-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54Q-2U",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.1",
    "uid": "95135b76bb2645a1",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Quanta_Cloud_Technology/results/1-node-2S-SPR-PyTorch-INT8/dlrm-v2-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A100-PCIe-80GBx8_TRT_Triton/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "NVIDIA",
    "Platform": "A100-PCIe-80GBx8_TRT_Triton",
    "Result": 1725730,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G482-Z54 (8x A100-PCIe-80GB, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "4c94b8e309e44a84",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/A100-PCIe-80GBx8_TRT_Triton/dlrm-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A100-PCIe-80GBx8_TRT_Triton/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "NVIDIA",
    "Platform": "A100-PCIe-80GBx8_TRT_Triton",
    "Result": 1725730,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G482-Z54 (8x A100-PCIe-80GB, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "7a94116cf2024983",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/A100-PCIe-80GBx8_TRT_Triton/dlrm-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A100-PCIe-80GB_aarch64x4_TRT_Triton/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "NVIDIA",
    "Platform": "A100-PCIe-80GB_aarch64x4_TRT_Triton",
    "Result": 1136270,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G242-P31 (4x A100-PCIe-80GB_aarch64, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 80,
    "host_processor_model_name": "Ampere Altra Q80-30",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "9da7eb2f9b7e411e",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/A100-PCIe-80GB_aarch64x4_TRT_Triton/dlrm-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A100-PCIe-80GB_aarch64x4_TRT_Triton/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "NVIDIA",
    "Platform": "A100-PCIe-80GB_aarch64x4_TRT_Triton",
    "Result": 1136270,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G242-P31 (4x A100-PCIe-80GB_aarch64, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 80,
    "host_processor_model_name": "Ampere Altra Q80-30",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "47299360278a41d7",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/A100-PCIe-80GB_aarch64x4_TRT_Triton/dlrm-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A30x8_TRT/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "NVIDIA",
    "Platform": "A30x8_TRT",
    "Result": 1105550,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G482-Z54 (8x A30, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "92b96385758c4046",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/A30x8_TRT/dlrm-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A30x8_TRT/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "NVIDIA",
    "Platform": "A30x8_TRT",
    "Result": 1105550,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G482-Z54 (8x A30, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "e824d51a48f946b5",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/A30x8_TRT/dlrm-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-A100_A100-SXM-80GB-MIG_1x1g.10gb_TRT/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "NVIDIA",
    "Platform": "DGX-A100_A100-SXM-80GB-MIG_1x1g.10gb_TRT",
    "Result": 40424,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX A100 (1x A100-SXM-80GB-MIG-1x1g.10gb, TensorRT)",
    "SystemType": "datacenter,edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB (1x1g.10gb MIG)",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "89d2b34da2f64ec0",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GB-MIG_1x1g.10gb_TRT/dlrm-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-A100_A100-SXM-80GB-MIG_1x1g.10gb_TRT/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "NVIDIA",
    "Platform": "DGX-A100_A100-SXM-80GB-MIG_1x1g.10gb_TRT",
    "Result": 40424,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX A100 (1x A100-SXM-80GB-MIG-1x1g.10gb, TensorRT)",
    "SystemType": "datacenter,edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB (1x1g.10gb MIG)",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "8b90d392dcaa4a04",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GB-MIG_1x1g.10gb_TRT/dlrm-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A100-SXM-80GB_aarch64x8_TRT_Triton/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "NVIDIA",
    "Platform": "A100-SXM-80GB_aarch64x8_TRT_Triton",
    "Result": 2446270,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G492-PD0 (8x A100-SXM-80GB_aarch64, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 80,
    "host_processor_model_name": "Ampere Altra Q80-30",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "bb2b8df9c9874b53",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/A100-SXM-80GB_aarch64x8_TRT_Triton/dlrm-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A100-SXM-80GB_aarch64x8_TRT_Triton/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "NVIDIA",
    "Platform": "A100-SXM-80GB_aarch64x8_TRT_Triton",
    "Result": 2446270,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G492-PD0 (8x A100-SXM-80GB_aarch64, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 80,
    "host_processor_model_name": "Ampere Altra Q80-30",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "edd25003a0034cfb",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/A100-SXM-80GB_aarch64x8_TRT_Triton/dlrm-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A2x2_TRT/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "NVIDIA",
    "Platform": "A2x2_TRT",
    "Result": 44256.7,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Supermicro AS-1114S-WTRT (2x A2, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A2",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 8,
    "host_processor_model_name": "AMD EPYC 7232P 8-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "87ef87304dcc49b9",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/A2x2_TRT/dlrm-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A2x2_TRT/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "NVIDIA",
    "Platform": "A2x2_TRT",
    "Result": 44256.7,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Supermicro AS-1114S-WTRT (2x A2, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A2",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 8,
    "host_processor_model_name": "AMD EPYC 7232P 8-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "571b3eb0877b48f1",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/A2x2_TRT/dlrm-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT_Triton/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "NVIDIA",
    "Platform": "DGX-A100_A100-SXM-80GBx8_TRT_Triton",
    "Result": 2465750,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX A100 (8x A100-SXM-80GB, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "a7df8d14b44c476b",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT_Triton/dlrm-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT_Triton/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "NVIDIA",
    "Platform": "DGX-A100_A100-SXM-80GBx8_TRT_Triton",
    "Result": 2465750,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX A100 (8x A100-SXM-80GB, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "560c0cbc4ab24235",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT_Triton/dlrm-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "NVIDIA",
    "Platform": "DGX-A100_A100-SXM-80GBx8_TRT",
    "Result": 2499040,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX A100 (8x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "ce10afc5e8b54570",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT/dlrm-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "NVIDIA",
    "Platform": "DGX-A100_A100-SXM-80GBx8_TRT",
    "Result": 2499040,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX A100 (8x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "588738074b62459d",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT/dlrm-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A30-MIG_1x1g.6gb_TRT/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "NVIDIA",
    "Platform": "A30-MIG_1x1g.6gb_TRT",
    "Result": 35831.2,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G482-Z54 (1x A30-MIG-1x1g.6gb, TensorRT)",
    "SystemType": "datacenter,edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A30 (1x1g.6gb MIG)",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "3ba63de5f2734b9f",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/A30-MIG_1x1g.6gb_TRT/dlrm-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A30-MIG_1x1g.6gb_TRT/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "NVIDIA",
    "Platform": "A30-MIG_1x1g.6gb_TRT",
    "Result": 35831.2,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G482-Z54 (1x A30-MIG-1x1g.6gb, TensorRT)",
    "SystemType": "datacenter,edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A30 (1x1g.6gb MIG)",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "85a40c95a26c40e7",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/A30-MIG_1x1g.6gb_TRT/dlrm-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A30x8_TRT_Triton/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "NVIDIA",
    "Platform": "A30x8_TRT_Triton",
    "Result": 1113970,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G482-Z54 (8x A30, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "fbb2a6d423634f31",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/A30x8_TRT_Triton/dlrm-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A30x8_TRT_Triton/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "NVIDIA",
    "Platform": "A30x8_TRT_Triton",
    "Result": 1113970,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G482-Z54 (8x A30, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "97a1e85c34424653",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/A30x8_TRT_Triton/dlrm-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-A100_A100-SXM-80GB-MIG_1x1g.10gb_TRT_HeteroMultiUse/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "NVIDIA",
    "Platform": "DGX-A100_A100-SXM-80GB-MIG_1x1g.10gb_TRT_HeteroMultiUse",
    "Result": 37579.6,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX A100 (1x A100-SXM-80GB-MIG-1x1g.10gb, TensorRT, HeteroMultiUse)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB (1x1g.10gb MIG)",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "3efd86ed079245b7",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GB-MIG_1x1g.10gb_TRT_HeteroMultiUse/dlrm-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-A100_A100-SXM-80GB-MIG_1x1g.10gb_TRT_HeteroMultiUse/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "NVIDIA",
    "Platform": "DGX-A100_A100-SXM-80GB-MIG_1x1g.10gb_TRT_HeteroMultiUse",
    "Result": 37579.6,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX A100 (1x A100-SXM-80GB-MIG-1x1g.10gb, TensorRT, HeteroMultiUse)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB (1x1g.10gb MIG)",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "a93253d1ad124086",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GB-MIG_1x1g.10gb_TRT_HeteroMultiUse/dlrm-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A30-MIG_1x1g.6gb_TRT_HeteroMultiUse/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "NVIDIA",
    "Platform": "A30-MIG_1x1g.6gb_TRT_HeteroMultiUse",
    "Result": 33319.4,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G482-Z54 (1x A30-MIG-1x1g.6gb, TensorRT, HeteroMultiUse)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A30 (1x1g.6gb MIG)",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "98e3af04a5ed40c5",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/A30-MIG_1x1g.6gb_TRT_HeteroMultiUse/dlrm-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A30-MIG_1x1g.6gb_TRT_HeteroMultiUse/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "NVIDIA",
    "Platform": "A30-MIG_1x1g.6gb_TRT_HeteroMultiUse",
    "Result": 33319.4,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G482-Z54 (1x A30-MIG-1x1g.6gb, TensorRT, HeteroMultiUse)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A30 (1x1g.6gb MIG)",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "c1c2f58d6fb24c39",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/A30-MIG_1x1g.6gb_TRT_HeteroMultiUse/dlrm-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A100-PCIe-80GBx8_TRT/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "NVIDIA",
    "Platform": "A100-PCIe-80GBx8_TRT",
    "Result": 2313280,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G482-Z54 (8x A100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "8b959f96f3174f96",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/A100-PCIe-80GBx8_TRT/dlrm-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A100-PCIe-80GBx8_TRT/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "NVIDIA",
    "Platform": "A100-PCIe-80GBx8_TRT",
    "Result": 2313280,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G482-Z54 (8x A100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "d701dbb7189844a5",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/A100-PCIe-80GBx8_TRT/dlrm-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A100-SXM-80GB_aarch64x8_TRT/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "NVIDIA",
    "Platform": "A100-SXM-80GB_aarch64x8_TRT",
    "Result": 2477270,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G492-PD0 (8x A100-SXM-80GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 80,
    "host_processor_model_name": "Ampere Altra Q80-30",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "847fb6e823ff4280",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/A100-SXM-80GB_aarch64x8_TRT/dlrm-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A100-SXM-80GB_aarch64x8_TRT/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "NVIDIA",
    "Platform": "A100-SXM-80GB_aarch64x8_TRT",
    "Result": 2477270,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G492-PD0 (8x A100-SXM-80GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 80,
    "host_processor_model_name": "Ampere Altra Q80-30",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "f8f69cfb05e44de6",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/A100-SXM-80GB_aarch64x8_TRT/dlrm-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-Station-A100_A100-SXM-80GBx4_TRT/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "NVIDIA",
    "Platform": "DGX-Station-A100_A100-SXM-80GBx4_TRT",
    "Result": 1065600,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX Station A100 (4x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "8ddd485348954fd3",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/DGX-Station-A100_A100-SXM-80GBx4_TRT/dlrm-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-Station-A100_A100-SXM-80GBx4_TRT/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "NVIDIA",
    "Platform": "DGX-Station-A100_A100-SXM-80GBx4_TRT",
    "Result": 1065600,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX Station A100 (4x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "5391eca0b36e4eae",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/DGX-Station-A100_A100-SXM-80GBx4_TRT/dlrm-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-Station-A100_A100-SXM-80GBx4_TRT_Triton/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "NVIDIA",
    "Platform": "DGX-Station-A100_A100-SXM-80GBx4_TRT_Triton",
    "Result": 1071130,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX Station A100 (4x A100-SXM-80GB, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "40852c19998243ab",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/DGX-Station-A100_A100-SXM-80GBx4_TRT_Triton/dlrm-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-Station-A100_A100-SXM-80GBx4_TRT_Triton/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "NVIDIA",
    "Platform": "DGX-Station-A100_A100-SXM-80GBx4_TRT_Triton",
    "Result": 1071130,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX Station A100 (4x A100-SXM-80GB, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "d895f060bbc14583",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/DGX-Station-A100_A100-SXM-80GBx4_TRT_Triton/dlrm-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.173,
    "Accuracy_div_100": 0.80173,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A100-PCIe-80GB_aarch64x4_TRT/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "NVIDIA",
    "Platform": "A100-PCIe-80GB_aarch64x4_TRT",
    "Result": 1125130,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G242-P31 (4x A100-PCIe-80GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 80,
    "host_processor_model_name": "Ampere Altra Q80-30",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "64240f20e66244e5",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/A100-PCIe-80GB_aarch64x4_TRT/dlrm-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.173,
    "Accuracy_div_100": 0.80173,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A100-PCIe-80GB_aarch64x4_TRT/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "NVIDIA",
    "Platform": "A100-PCIe-80GB_aarch64x4_TRT",
    "Result": 1125130,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G242-P31 (4x A100-PCIe-80GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 80,
    "host_processor_model_name": "Ampere Altra Q80-30",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "08c68c947f494ad3",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/A100-PCIe-80GB_aarch64x4_TRT/dlrm-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 79.987,
    "Accuracy_div_100": 0.79987,
    "Availability": "rdi",
    "Division": "closed",
    "Location": "closed/Neuchips/results/Neuchips-triple-RecAccel/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "Neuchips",
    "Platform": "Neuchips-triple-RecAccel",
    "Result": 4200.67,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "RecAccel",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "Neuchips RecAccel",
    "accelerators_per_node": 3,
    "compliance": 1,
    "errors": 0,
    "framework": "PyTorch",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 18,
    "host_processor_model_name": "Intel Core i9-10980XE",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Terasic DE-10 Pro FPGA Acceleration Board",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 16.04.7 LTS",
    "uid": "79c69bdaeae54c8c",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Neuchips/results/Neuchips-triple-RecAccel/dlrm-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Fujitsu/results/GX2460M1_A30x2_TRT/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "Fujitsu",
    "Platform": "GX2460M1_A30x2_TRT",
    "Result": 270103,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "PRIMERGY GX2460M1 (2x A30, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7302",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2 LTS",
    "uid": "063cc357416f45d3",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Fujitsu/results/GX2460M1_A30x2_TRT/dlrm-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Fujitsu/results/GX2460M1_A30x2_TRT/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "Fujitsu",
    "Platform": "GX2460M1_A30x2_TRT",
    "Result": 270103,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "PRIMERGY GX2460M1 (2x A30, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7302",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2 LTS",
    "uid": "ad5276c381154bee",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Fujitsu/results/GX2460M1_A30x2_TRT/dlrm-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Fujitsu/results/GX2570M6_A100-SXM4-40GBx8_TRT/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "Fujitsu",
    "Platform": "GX2570M6_A100-SXM4-40GBx8_TRT",
    "Result": 2415820,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "PRIMERGY GX2570M6 (8x A100-SXM-40GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM4-40GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 144,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8352V CPU @ 2.10GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.3",
    "uid": "7aadfd402a684d16",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Fujitsu/results/GX2570M6_A100-SXM4-40GBx8_TRT/dlrm-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Fujitsu/results/GX2570M6_A100-SXM4-40GBx8_TRT/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "Fujitsu",
    "Platform": "GX2570M6_A100-SXM4-40GBx8_TRT",
    "Result": 2415820,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "PRIMERGY GX2570M6 (8x A100-SXM-40GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM4-40GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 144,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8352V CPU @ 2.10GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.3",
    "uid": "2dffb3cbe79d4c21",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Fujitsu/results/GX2570M6_A100-SXM4-40GBx8_TRT/dlrm-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE2420_T4x1_TRT/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "Dell",
    "Platform": "XE2420_T4x1_TRT",
    "Result": 30883.6,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE2420 (1x T4, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA T4",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 22,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6238 CPU @ 2.10GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "ECC on",
    "number_of_nodes": 1,
    "operating_system": "CentOS 8.2.2004",
    "uid": "2c41df716c604d61",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Dell/results/XE2420_T4x1_TRT/dlrm-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE2420_T4x1_TRT/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "Dell",
    "Platform": "XE2420_T4x1_TRT",
    "Result": 30883.6,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE2420 (1x T4, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA T4",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 22,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6238 CPU @ 2.10GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "ECC on",
    "number_of_nodes": 1,
    "operating_system": "CentOS 8.2.2004",
    "uid": "edcbceb91ba44a9a",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Dell/results/XE2420_T4x1_TRT/dlrm-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XR12_A2x1_TRT/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "Dell",
    "Platform": "XR12_A2x1_TRT",
    "Result": 22022.8,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XR12 (1x A2, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A2",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6312U CPU @ 2.40GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "CentOS 8.2",
    "uid": "13cfd15efdcf4e1b",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Dell/results/XR12_A2x1_TRT/dlrm-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XR12_A2x1_TRT/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "Dell",
    "Platform": "XR12_A2x1_TRT",
    "Result": 22022.8,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XR12 (1x A2, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A2",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6312U CPU @ 2.40GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "CentOS 8.2",
    "uid": "78c3eb0b00db4c14",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Dell/results/XR12_A2x1_TRT/dlrm-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R750xa_A100_PCIE_80GBx4_TRT/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "Dell",
    "Platform": "R750xa_A100_PCIE_80GBx4_TRT",
    "Result": 1166200,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge R750xa (4x A100-PCIE-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6338 CPU @ 2.00GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "CentOS 8.2",
    "uid": "012f68da8ec448ac",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Dell/results/R750xa_A100_PCIE_80GBx4_TRT/dlrm-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R750xa_A100_PCIE_80GBx4_TRT/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "Dell",
    "Platform": "R750xa_A100_PCIE_80GBx4_TRT",
    "Result": 1166200,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge R750xa (4x A100-PCIE-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6338 CPU @ 2.00GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "CentOS 8.2",
    "uid": "1473967cfde44e04",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Dell/results/R750xa_A100_PCIE_80GBx4_TRT/dlrm-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Inspur/results/NF5688M6_A100-SXM-80GBx8_TRT/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "Inspur",
    "Platform": "NF5688M6_A100-SXM-80GBx8_TRT",
    "Result": 2605670,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NF5688M6 (8x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8358",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "8c9c4062252e4fb7",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Inspur/results/NF5688M6_A100-SXM-80GBx8_TRT/dlrm-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Inspur/results/NF5688M6_A100-SXM-80GBx8_TRT/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "Inspur",
    "Platform": "NF5688M6_A100-SXM-80GBx8_TRT",
    "Result": 2605670,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NF5688M6 (8x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8358",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "0979dbd0dd8d4836",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Inspur/results/NF5688M6_A100-SXM-80GBx8_TRT/dlrm-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Inspur/results/NF5488A5_A100-SXM-80GBx8_TRT/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "Inspur",
    "Platform": "NF5488A5_A100-SXM-80GBx8_TRT",
    "Result": 2645980,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NF5488A5 (8x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "ad9947a2b4d64900",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Inspur/results/NF5488A5_A100-SXM-80GBx8_TRT/dlrm-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Inspur/results/NF5488A5_A100-SXM-80GBx8_TRT/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "Inspur",
    "Platform": "NF5488A5_A100-SXM-80GBx8_TRT",
    "Result": 2645980,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NF5488A5 (8x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "3a850da630ef4b95",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Inspur/results/NF5488A5_A100-SXM-80GBx8_TRT/dlrm-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/A100-PCIe-80GBx8_TRT_Triton/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "H3C",
    "Platform": "A100-PCIe-80GBx8_TRT_Triton",
    "Result": 1428970,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "H3C UniServer R5300 G5 (8x A100-PCIe-80GB, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8380 CPU @ 2.30GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "5174914e45f24325",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/H3C/results/A100-PCIe-80GBx8_TRT_Triton/dlrm-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/A100-PCIe-80GBx8_TRT_Triton/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "H3C",
    "Platform": "A100-PCIe-80GBx8_TRT_Triton",
    "Result": 1428970,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "H3C UniServer R5300 G5 (8x A100-PCIe-80GB, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8380 CPU @ 2.30GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "cff2d258a16e4be8",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/H3C/results/A100-PCIe-80GBx8_TRT_Triton/dlrm-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/R5500G5_A100-SXM-80GBx8_TRT/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "H3C",
    "Platform": "R5500G5_A100-SXM-80GBx8_TRT",
    "Result": 2466690,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "H3C UniServer R5500 G5 (8x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8380 CPU @ 2.30GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "400W_A100-SXM-80GB",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "8a8dbf01020f471d",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/H3C/results/R5500G5_A100-SXM-80GBx8_TRT/dlrm-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/R5500G5_A100-SXM-80GBx8_TRT/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "H3C",
    "Platform": "R5500G5_A100-SXM-80GBx8_TRT",
    "Result": 2466690,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "H3C UniServer R5500 G5 (8x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8380 CPU @ 2.30GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "400W_A100-SXM-80GB",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "fd94b46ca1f64e0e",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/H3C/results/R5500G5_A100-SXM-80GBx8_TRT/dlrm-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/A30x8_Custom_R5300G5_TRT_Triton/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "H3C",
    "Platform": "A30x8_Custom_R5300G5_TRT_Triton",
    "Result": 1112790,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "H3C UniServer R5300 G5 (8x A30, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8380 CPU @ 2.30GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "57ac7d89777f40e6",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/H3C/results/A30x8_Custom_R5300G5_TRT_Triton/dlrm-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/A30x8_Custom_R5300G5_TRT_Triton/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "H3C",
    "Platform": "A30x8_Custom_R5300G5_TRT_Triton",
    "Result": 1112790,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "H3C UniServer R5300 G5 (8x A30, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8380 CPU @ 2.30GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "b78fbae6f9164fcb",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/H3C/results/A30x8_Custom_R5300G5_TRT_Triton/dlrm-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/A30x8_Custom_R5300G5_TRT/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "H3C",
    "Platform": "A30x8_Custom_R5300G5_TRT",
    "Result": 1084020,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "H3C UniServer R5300 G5 (8x A30, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8380 CPU @ 2.30GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "2ca3eff91f7c473e",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/H3C/results/A30x8_Custom_R5300G5_TRT/dlrm-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/A30x8_Custom_R5300G5_TRT/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "H3C",
    "Platform": "A30x8_Custom_R5300G5_TRT",
    "Result": 1084020,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "H3C UniServer R5300 G5 (8x A30, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8380 CPU @ 2.30GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "bffb1260077a40c1",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/H3C/results/A30x8_Custom_R5300G5_TRT/dlrm-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/AS-4124GS-TNR_8_A100-PCIe-80GB_TRT/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "Supermicro",
    "Platform": "AS-4124GS-TNR_8_A100-PCIe-80GB_TRT",
    "Result": 2212520,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AS-4124GS-TNR (8xA100-PCIe-80GB)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7713 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "5dfc8364fe534740",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/Supermicro/results/AS-4124GS-TNR_8_A100-PCIe-80GB_TRT/dlrm-99/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/AS-4124GS-TNR_8_A100-PCIe-80GB_TRT/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "Supermicro",
    "Platform": "AS-4124GS-TNR_8_A100-PCIe-80GB_TRT",
    "Result": 2212520,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AS-4124GS-TNR (8xA100-PCIe-80GB)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7713 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "eaa24b926b2c44a1",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/Supermicro/results/AS-4124GS-TNR_8_A100-PCIe-80GB_TRT/dlrm-99.9/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A100-PCIe-80GBx8_TRT_Triton/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "NVIDIA",
    "Platform": "A100-PCIe-80GBx8_TRT_Triton",
    "Result": 2247540,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G482-Z54 (8x A100-PCIe-80GB, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "bd116c378878439e",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/NVIDIA/results/A100-PCIe-80GBx8_TRT_Triton/dlrm-99/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A100-PCIe-80GBx8_TRT_Triton/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "NVIDIA",
    "Platform": "A100-PCIe-80GBx8_TRT_Triton",
    "Result": 2247540,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G482-Z54 (8x A100-PCIe-80GB, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "8ce49fb2fbd84561",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/NVIDIA/results/A100-PCIe-80GBx8_TRT_Triton/dlrm-99.9/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H100-SXM-80GB-02x1_TRT/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "NVIDIA",
    "Platform": "H100-SXM-80GB-02x1_TRT",
    "Result": 661664,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA H100 (1x H100-SXM-80GB-02, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB-02",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.5.0, CUDA 11.8",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Silver 4314 CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Private git branch used to produce all NVIDIA H100 results. The git hash of the private branch is 35fc4b9a7758edc6063bb3a4ba4bfa94ce7aa9e1",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "29c768c25b3b46d9",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/NVIDIA/results/H100-SXM-80GB-02x1_TRT/dlrm-99/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H100-SXM-80GB-02x1_TRT/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "NVIDIA",
    "Platform": "H100-SXM-80GB-02x1_TRT",
    "Result": 661664,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA H100 (1x H100-SXM-80GB-02, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB-02",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.5.0, CUDA 11.8",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Silver 4314 CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Private git branch used to produce all NVIDIA H100 results. The git hash of the private branch is 35fc4b9a7758edc6063bb3a4ba4bfa94ce7aa9e1",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "90bb554f609f468f",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/NVIDIA/results/H100-SXM-80GB-02x1_TRT/dlrm-99.9/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx1_TRT_DATACENTER/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "NVIDIA",
    "Platform": "DGX-A100_A100-SXM-80GBx1_TRT_DATACENTER",
    "Result": 314992,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX A100 (1x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "e04d3cf15c1a4209",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx1_TRT_DATACENTER/dlrm-99/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx1_TRT_DATACENTER/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "NVIDIA",
    "Platform": "DGX-A100_A100-SXM-80GBx1_TRT_DATACENTER",
    "Result": 314992,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX A100 (1x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "09af6e4122054f2c",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx1_TRT_DATACENTER/dlrm-99.9/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-A100_A100-SXM-80GB-MIG_1x1g.10gb_TRT/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "NVIDIA",
    "Platform": "DGX-A100_A100-SXM-80GB-MIG_1x1g.10gb_TRT",
    "Result": 38995.2,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX A100 (1x A100-SXM-80GB-MIG-1x1g.10gb, TensorRT)",
    "SystemType": "datacenter,edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB (1x1g.10gb MIG)",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "c8a677c531f741df",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GB-MIG_1x1g.10gb_TRT/dlrm-99/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-A100_A100-SXM-80GB-MIG_1x1g.10gb_TRT/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "NVIDIA",
    "Platform": "DGX-A100_A100-SXM-80GB-MIG_1x1g.10gb_TRT",
    "Result": 38995.2,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX A100 (1x A100-SXM-80GB-MIG-1x1g.10gb, TensorRT)",
    "SystemType": "datacenter,edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB (1x1g.10gb MIG)",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "207c47fdd043432c",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GB-MIG_1x1g.10gb_TRT/dlrm-99.9/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-A100_A100-SXM-80GB-MIG_1x1g.10gb_TRT_Triton/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "NVIDIA",
    "Platform": "DGX-A100_A100-SXM-80GB-MIG_1x1g.10gb_TRT_Triton",
    "Result": 38817.4,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX A100 (1x A100-SXM-80GB-MIG-1x1g.10gb, TensorRT, Triton)",
    "SystemType": "datacenter,edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB (1x1g.10gb MIG)",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "409a71338a0642bd",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GB-MIG_1x1g.10gb_TRT_Triton/dlrm-99/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-A100_A100-SXM-80GB-MIG_1x1g.10gb_TRT_Triton/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "NVIDIA",
    "Platform": "DGX-A100_A100-SXM-80GB-MIG_1x1g.10gb_TRT_Triton",
    "Result": 38817.4,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX A100 (1x A100-SXM-80GB-MIG-1x1g.10gb, TensorRT, Triton)",
    "SystemType": "datacenter,edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB (1x1g.10gb MIG)",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "f62e303587db4f95",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GB-MIG_1x1g.10gb_TRT_Triton/dlrm-99.9/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT_Triton/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "NVIDIA",
    "Platform": "DGX-A100_A100-SXM-80GBx8_TRT_Triton",
    "Result": 2414760,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX A100 (8x A100-SXM-80GB, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "00b4ce180eb94a2c",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT_Triton/dlrm-99/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT_Triton/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "NVIDIA",
    "Platform": "DGX-A100_A100-SXM-80GBx8_TRT_Triton",
    "Result": 2414760,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX A100 (8x A100-SXM-80GB, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "d631c3d5edda4dd2",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT_Triton/dlrm-99.9/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "NVIDIA",
    "Platform": "DGX-A100_A100-SXM-80GBx8_TRT",
    "Result": 2443220,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX A100 (8x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "f864e24c14cc4cd5",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT/dlrm-99/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "NVIDIA",
    "Platform": "DGX-A100_A100-SXM-80GBx8_TRT",
    "Result": 2443220,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX A100 (8x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "fe0203a0121e4dab",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT/dlrm-99.9/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H100-SXM-80GBx1_TRT/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "NVIDIA",
    "Platform": "H100-SXM-80GBx1_TRT",
    "Result": 695298,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA H100 (1x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.5.0, CUDA 11.8",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 7252 8-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Private git branch used to produce all NVIDIA H100 results. The git hash of the private branch is 35fc4b9a7758edc6063bb3a4ba4bfa94ce7aa9e1",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "0881294031294e12",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/NVIDIA/results/H100-SXM-80GBx1_TRT/dlrm-99/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H100-SXM-80GBx1_TRT/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "NVIDIA",
    "Platform": "H100-SXM-80GBx1_TRT",
    "Result": 695298,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA H100 (1x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.5.0, CUDA 11.8",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 7252 8-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Private git branch used to produce all NVIDIA H100 results. The git hash of the private branch is 35fc4b9a7758edc6063bb3a4ba4bfa94ce7aa9e1",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "4fee9b80c5f44ca3",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/NVIDIA/results/H100-SXM-80GBx1_TRT/dlrm-99.9/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A100-PCIe-80GBx8_TRT/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "NVIDIA",
    "Platform": "A100-PCIe-80GBx8_TRT",
    "Result": 2291310,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G482-Z54 (8x A100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "d1bcfae6a23f4df8",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/NVIDIA/results/A100-PCIe-80GBx8_TRT/dlrm-99/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A100-PCIe-80GBx8_TRT/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "NVIDIA",
    "Platform": "A100-PCIe-80GBx8_TRT",
    "Result": 2291310,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G482-Z54 (8x A100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "df59b52ca0ba4aa8",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/NVIDIA/results/A100-PCIe-80GBx8_TRT/dlrm-99.9/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC4000_A2x8_TRT/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "ASUSTeK",
    "Platform": "ESC4000_A2x8_TRT",
    "Result": 181691,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "ASUS ESC4000-E10S (8x A2, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A2",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 8,
    "host_processor_model_name": " Intel(R) Xeon(R) Platinum 8352M 32-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "7767e561918d47a6",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/ASUSTeK/results/ESC4000_A2x8_TRT/dlrm-99/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC4000_A2x8_TRT/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "ASUSTeK",
    "Platform": "ESC4000_A2x8_TRT",
    "Result": 181691,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "ASUS ESC4000-E10S (8x A2, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A2",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 8,
    "host_processor_model_name": " Intel(R) Xeon(R) Platinum 8352M 32-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "2886e3c5e44640b1",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/ASUSTeK/results/ESC4000_A2x8_TRT/dlrm-99.9/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/A100-PCIe-80GBx8_TRT/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "ASUSTeK",
    "Platform": "A100-PCIe-80GBx8_TRT",
    "Result": 2334380,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "ASUS ESC8000A-E11 (8x A100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7763 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "ae082efb05894a4f",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/ASUSTeK/results/A100-PCIe-80GBx8_TRT/dlrm-99/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/A100-PCIe-80GBx8_TRT/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "ASUSTeK",
    "Platform": "A100-PCIe-80GBx8_TRT",
    "Result": 2334380,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "ASUS ESC8000A-E11 (8x A100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7763 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "0ecc1aa960964824",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/ASUSTeK/results/A100-PCIe-80GBx8_TRT/dlrm-99.9/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R750xa_A100_PCIE_80GBx4_TRT/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "Dell",
    "Platform": "R750xa_A100_PCIE_80GBx4_TRT",
    "Result": 1146290,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge R750xa (4x A100-PCIE-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6338 CPU @ 2.00GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "CentOS 8.2",
    "uid": "39b728e68a1b4d2f",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/Dell/results/R750xa_A100_PCIE_80GBx4_TRT/dlrm-99/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R750xa_A100_PCIE_80GBx4_TRT/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "Dell",
    "Platform": "R750xa_A100_PCIE_80GBx4_TRT",
    "Result": 1146290,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge R750xa (4x A100-PCIE-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6338 CPU @ 2.00GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "CentOS 8.2",
    "uid": "0e5e166c4f174a94",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/Dell/results/R750xa_A100_PCIE_80GBx4_TRT/dlrm-99.9/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE8545_A100_SXM_80GBx4_TRT/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "Dell",
    "Platform": "XE8545_A100_SXM_80GBx4_TRT",
    "Result": 1287210,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE8545 (4x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB CTS",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7763",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "NVIDIA A100-SXM-80GB (TDP: 500W)",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "0309895724444f40",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/Dell/results/XE8545_A100_SXM_80GBx4_TRT/dlrm-99/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE8545_A100_SXM_80GBx4_TRT/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "Dell",
    "Platform": "XE8545_A100_SXM_80GBx4_TRT",
    "Result": 1287210,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE8545 (4x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB CTS",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7763",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "NVIDIA A100-SXM-80GB (TDP: 500W)",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "694a9361e64c4213",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/Dell/results/XE8545_A100_SXM_80GBx4_TRT/dlrm-99.9/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/GIGABYTE/results/G492-ID0_A100-SXM-80GBx8_TRT/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "GIGABYTE",
    "Platform": "G492-ID0_A100-SXM-80GBx8_TRT",
    "Result": 2461960,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "G492-ID0 (8x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.7",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8380",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.3",
    "uid": "d3caedb7084d41b5",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/GIGABYTE/results/G492-ID0_A100-SXM-80GBx8_TRT/dlrm-99/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/GIGABYTE/results/G492-ID0_A100-SXM-80GBx8_TRT/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "GIGABYTE",
    "Platform": "G492-ID0_A100-SXM-80GBx8_TRT",
    "Result": 2461960,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "G492-ID0 (8x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.7",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8380",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.3",
    "uid": "5b293a6fe0514187",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/GIGABYTE/results/G492-ID0_A100-SXM-80GBx8_TRT/dlrm-99.9/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 80.21603191570468,
    "Accuracy_div_100": 0.80216,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/Intel/results/1-node-2S-SPR-PyTorch-INT8/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "Intel",
    "Platform": "1-node-2S-SPR-PyTorch-INT8",
    "Result": 106444,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "1-node-2S-SPR-PyTorch-INT8",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "PyTorch",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": "",
    "host_processor_model_name": "Intel(R) Xeon(R) (code named Sapphire Rapids)",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Intel Devlopment Platform (2U Server)",
    "number_of_nodes": 1,
    "operating_system": "CentOS Stream 8",
    "uid": "9356ae6a6ef6420c",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/Intel/results/1-node-2S-SPR-PyTorch-INT8/dlrm-99/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 80.21603191570468,
    "Accuracy_div_100": 0.80216,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/Intel/results/1-node-2S-SPR-PyTorch-INT8/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "Intel",
    "Platform": "1-node-2S-SPR-PyTorch-INT8",
    "Result": 106444,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "1-node-2S-SPR-PyTorch-INT8",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "PyTorch",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": "",
    "host_processor_model_name": "Intel(R) Xeon(R) (code named Sapphire Rapids)",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Intel Devlopment Platform (2U Server)",
    "number_of_nodes": 1,
    "operating_system": "CentOS Stream 8",
    "uid": "4e8e3d6bbcd149b9",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/Intel/results/1-node-2S-SPR-PyTorch-INT8/dlrm-99.9/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Nettrix/results/A100_SXM4_80GBx8_Custom_TRT/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "Nettrix",
    "Platform": "A100_SXM4_80GBx8_Custom_TRT",
    "Result": 2553720,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "X660G45L (8x A100-SXM4-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM4-80GB CTS",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 38,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8368Q",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "NVIDIA A100-SXM4-80GB (TDP:500W)",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "c7c42bc411964bda",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/Nettrix/results/A100_SXM4_80GBx8_Custom_TRT/dlrm-99/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Nettrix/results/A100_SXM4_80GBx8_Custom_TRT/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "Nettrix",
    "Platform": "A100_SXM4_80GBx8_Custom_TRT",
    "Result": 2553720,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "X660G45L (8x A100-SXM4-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM4-80GB CTS",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 38,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8368Q",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "NVIDIA A100-SXM4-80GB (TDP:500W)",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "da7d3ccb33fe4d21",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/Nettrix/results/A100_SXM4_80GBx8_Custom_TRT/dlrm-99.9/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/R5300G5_A30x8_TRT/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "H3C",
    "Platform": "R5300G5_A30x8_TRT",
    "Result": 1135530,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "H3C UniServer R5300 G5 (8x A30, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8362 CPU @ 2.80GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "b9ee69e377e74722",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/H3C/results/R5300G5_A30x8_TRT/dlrm-99/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/R5300G5_A30x8_TRT/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "H3C",
    "Platform": "R5300G5_A30x8_TRT",
    "Result": 1135530,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "H3C UniServer R5300 G5 (8x A30, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8362 CPU @ 2.80GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "33b96a3ab1914281",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/H3C/results/R5300G5_A30x8_TRT/dlrm-99.9/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/A30x3_R4900G5_TRT/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "H3C",
    "Platform": "A30x3_R4900G5_TRT",
    "Result": 432724,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "H3C UniServer R4900 G5(3x A30, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 3,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8380 CPU @ 2.30GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "7cb1a242e8624b56",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/H3C/results/A30x3_R4900G5_TRT/dlrm-99/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/A30x3_R4900G5_TRT/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "H3C",
    "Platform": "A30x3_R4900G5_TRT",
    "Result": 432724,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "H3C UniServer R4900 G5(3x A30, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 3,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8380 CPU @ 2.30GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "a2c581d2907b4993",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/H3C/results/A30x3_R4900G5_TRT/dlrm-99.9/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/R5500G5_Intel_A100_A100-SXM-80GBx8_TRT/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "H3C",
    "Platform": "R5500G5_Intel_A100_A100-SXM-80GBx8_TRT",
    "Result": 2434920,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "H3C UniServer R5500 G5 Intel (8x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8378A",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "c442b4fc5f564a2d",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/H3C/results/R5500G5_Intel_A100_A100-SXM-80GBx8_TRT/dlrm-99/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/R5500G5_Intel_A100_A100-SXM-80GBx8_TRT/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "H3C",
    "Platform": "R5500G5_Intel_A100_A100-SXM-80GBx8_TRT",
    "Result": 2434920,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "H3C UniServer R5500 G5 Intel (8x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8378A",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "cc8a23ca518242fd",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/H3C/results/R5500G5_Intel_A100_A100-SXM-80GBx8_TRT/dlrm-99.9/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/A2x2_TRT/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "H3C",
    "Platform": "A2x2_TRT",
    "Result": 43952.6,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "H3C UniServer R4950 G5 (2x A2, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A2",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 2,
    "host_processor_model_name": "AMD EPYC 7413 24-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "aaf17381fc3d469e",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/H3C/results/A2x2_TRT/dlrm-99/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/A2x2_TRT/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "H3C",
    "Platform": "A2x2_TRT",
    "Result": 43952.6,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "H3C UniServer R4950 G5 (2x A2, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A2",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 2,
    "host_processor_model_name": "AMD EPYC 7413 24-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "7e4436dbd02c469f",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/H3C/results/A2x2_TRT/dlrm-99.9/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/A100-PCIe-80GBx3_R4900G5_TRT/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "H3C",
    "Platform": "A100-PCIe-80GBx3_R4900G5_TRT",
    "Result": 834831,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "H3C UniServer R4900 G5(3x A100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 3,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8380 CPU @ 2.30GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "ebaa7ed8ff554799",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/H3C/results/A100-PCIe-80GBx3_R4900G5_TRT/dlrm-99/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/A100-PCIe-80GBx3_R4900G5_TRT/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "H3C",
    "Platform": "A100-PCIe-80GBx3_R4900G5_TRT",
    "Result": 834831,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "H3C UniServer R4900 G5(3x A100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 3,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8380 CPU @ 2.30GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "0be7fdbeb9d54df6",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/H3C/results/A100-PCIe-80GBx3_R4900G5_TRT/dlrm-99.9/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/R5500G5_AMD_A100_A100-SXM-80GBx8_TRT/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "H3C",
    "Platform": "R5500G5_AMD_A100_A100-SXM-80GBx8_TRT",
    "Result": 2482310,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "H3C UniServer R5500 G5 AMD (8x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7773X",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "a07678f3514445f2",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/H3C/results/R5500G5_AMD_A100_A100-SXM-80GBx8_TRT/dlrm-99/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/R5500G5_AMD_A100_A100-SXM-80GBx8_TRT/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "H3C",
    "Platform": "R5500G5_AMD_A100_A100-SXM-80GBx8_TRT",
    "Result": 2482310,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "H3C UniServer R5500 G5 AMD (8x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7773X",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "c2f4d29d06f14098",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/H3C/results/R5500G5_AMD_A100_A100-SXM-80GBx8_TRT/dlrm-99.9/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/R5300G5_A100_SXM_80GBx4_TRT/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "H3C",
    "Platform": "R5300G5_A100_SXM_80GBx4_TRT",
    "Result": 1257110,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "H3C UniServer R5300 G5(4x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8362 CPU @ 2.80GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "b5d5c34d042f4a67",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/H3C/results/R5300G5_A100_SXM_80GBx4_TRT/dlrm-99/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/R5300G5_A100_SXM_80GBx4_TRT/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "H3C",
    "Platform": "R5300G5_A100_SXM_80GBx4_TRT",
    "Result": 1257110,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "H3C UniServer R5300 G5(4x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8362 CPU @ 2.80GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "db0a1a371d2c43f3",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/H3C/results/R5300G5_A100_SXM_80GBx4_TRT/dlrm-99.9/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/R5300G5_A100_PCIE_80GBX4_TRT/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "H3C",
    "Platform": "R5300G5_A100_PCIE_80GBX4_TRT",
    "Result": 1150560,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "H3C UniServer R5300 G5 (4x A100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.5",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8362 CPU @ 2.80GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "cd10bc25c03b4fac",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/H3C/results/R5300G5_A100_PCIE_80GBX4_TRT/dlrm-99/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/R5300G5_A100_PCIE_80GBX4_TRT/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "H3C",
    "Platform": "R5300G5_A100_PCIE_80GBX4_TRT",
    "Result": 1150560,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "H3C UniServer R5300 G5 (4x A100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.5",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8362 CPU @ 2.80GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "0bfd7447023b4a9c",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/H3C/results/R5300G5_A100_PCIE_80GBX4_TRT/dlrm-99.9/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS-741GE-TNRT_4_H100-PCIe-80GB_TRT/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "Supermicro",
    "Platform": "SYS-741GE-TNRT_4_H100-PCIe-80GB_TRT",
    "Result": 1815020,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "SYS-741GE-TNRT (4xH100-PCIe-80GB)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6448Y",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5",
    "uid": "190f40a028bf45ea",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Supermicro/results/SYS-741GE-TNRT_4_H100-PCIe-80GB_TRT/dlrm-99/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS-741GE-TNRT_4_H100-PCIe-80GB_TRT/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "Supermicro",
    "Platform": "SYS-741GE-TNRT_4_H100-PCIe-80GB_TRT",
    "Result": 1815020,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "SYS-741GE-TNRT (4xH100-PCIe-80GB)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6448Y",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5",
    "uid": "ec5818adb1614410",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Supermicro/results/SYS-741GE-TNRT_4_H100-PCIe-80GB_TRT/dlrm-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS-221HE-FTNR-DATACENTER_2_H100-PCIe-80GB_TRT/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "Supermicro",
    "Platform": "SYS-221HE-FTNR-DATACENTER_2_H100-PCIe-80GB_TRT",
    "Result": 908080,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "SYS-221HE-FTNR (2xH100-PCIe-80GB)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "a32218811d86450d",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Supermicro/results/SYS-221HE-FTNR-DATACENTER_2_H100-PCIe-80GB_TRT/dlrm-99/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS-221HE-FTNR-DATACENTER_2_H100-PCIe-80GB_TRT/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "Supermicro",
    "Platform": "SYS-221HE-FTNR-DATACENTER_2_H100-PCIe-80GB_TRT",
    "Result": 908080,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "SYS-221HE-FTNR (2xH100-PCIe-80GB)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "3cbef71c906c4aee",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Supermicro/results/SYS-221HE-FTNR-DATACENTER_2_H100-PCIe-80GB_TRT/dlrm-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/AS-4125GS-TNRT_8_H100-PCIe-80GB_TRT/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "Supermicro",
    "Platform": "AS-4125GS-TNRT_8_H100-PCIe-80GB_TRT",
    "Result": 2149450,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AS-4125GS-TNRT (8xH100-PCIe-80GB)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 9174F 16-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2",
    "uid": "82308c0f175e4ce7",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Supermicro/results/AS-4125GS-TNRT_8_H100-PCIe-80GB_TRT/dlrm-99/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/AS-4125GS-TNRT_8_H100-PCIe-80GB_TRT/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "Supermicro",
    "Platform": "AS-4125GS-TNRT_8_H100-PCIe-80GB_TRT",
    "Result": 2145080,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AS-4125GS-TNRT (8xH100-PCIe-80GB)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 9174F 16-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2",
    "uid": "1c490120e17e4fc5",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Supermicro/results/AS-4125GS-TNRT_8_H100-PCIe-80GB_TRT/dlrm-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H100-PCIe-80GBx1_TRT/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "NVIDIA",
    "Platform": "H100-PCIe-80GBx1_TRT",
    "Result": 480168,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G482-Z54 (1x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "8e54668af38c4c3c",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/NVIDIA/results/H100-PCIe-80GBx1_TRT/dlrm-99/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H100-PCIe-80GBx1_TRT/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "NVIDIA",
    "Platform": "H100-PCIe-80GBx1_TRT",
    "Result": 480168,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G482-Z54 (1x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "7781e20a35d0481d",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/NVIDIA/results/H100-PCIe-80GBx1_TRT/dlrm-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A100-PCIe-80GBx8_TRT_Triton/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "NVIDIA",
    "Platform": "A100-PCIe-80GBx8_TRT_Triton",
    "Result": 2257700,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G482-Z54 (8x A100-PCIe-80GB, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "8ddb4ed8f4634289",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/NVIDIA/results/A100-PCIe-80GBx8_TRT_Triton/dlrm-99/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A100-PCIe-80GBx8_TRT_Triton/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "NVIDIA",
    "Platform": "A100-PCIe-80GBx8_TRT_Triton",
    "Result": 2257700,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G482-Z54 (8x A100-PCIe-80GB, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "f31202f84e134fde",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/NVIDIA/results/A100-PCIe-80GBx8_TRT_Triton/dlrm-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/L4x1_TRT/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "NVIDIA",
    "Platform": "L4x1_TRT",
    "Result": 94602.7,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA L4 (1x L4, TensorRT)",
    "SystemType": "datacenter,edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 7313P 16-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "792f1559b21f4520",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/NVIDIA/results/L4x1_TRT/dlrm-99/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/L4x1_TRT/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "NVIDIA",
    "Platform": "L4x1_TRT",
    "Result": 94602.7,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA L4 (1x L4, TensorRT)",
    "SystemType": "datacenter,edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 7313P 16-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "b53860784041402b",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/NVIDIA/results/L4x1_TRT/dlrm-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H100-PCIe-80GBx8_TRT/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "NVIDIA",
    "Platform": "H100-PCIe-80GBx8_TRT",
    "Result": 3713980,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G482-Z54 (8x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "b6c261b5f66d44d2",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/NVIDIA/results/H100-PCIe-80GBx8_TRT/dlrm-99/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H100-PCIe-80GBx8_TRT/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "NVIDIA",
    "Platform": "H100-PCIe-80GBx8_TRT",
    "Result": 3713980,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G482-Z54 (8x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "281f74064b0b462a",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/NVIDIA/results/H100-PCIe-80GBx8_TRT/dlrm-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT_Triton/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "NVIDIA",
    "Platform": "DGX-A100_A100-SXM-80GBx8_TRT_Triton",
    "Result": 2434520,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX A100 (8x A100-SXM-80GB, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "f0447d68029c47ec",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT_Triton/dlrm-99/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT_Triton/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "NVIDIA",
    "Platform": "DGX-A100_A100-SXM-80GBx8_TRT_Triton",
    "Result": 2434520,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX A100 (8x A100-SXM-80GB, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "efff8cf9e4794b51",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT_Triton/dlrm-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "NVIDIA",
    "Platform": "DGX-A100_A100-SXM-80GBx8_TRT",
    "Result": 2443310,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX A100 (8x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "6b754d7b25e347bc",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT/dlrm-99/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "NVIDIA",
    "Platform": "DGX-A100_A100-SXM-80GBx8_TRT",
    "Result": 2443310,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX A100 (8x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "05174243ddbb4311",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT/dlrm-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "NVIDIA",
    "Platform": "DGX-H100_H100-SXM-80GBx8_TRT",
    "Result": 5366820,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX H100 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "42dfe4be1a7948a4",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT/dlrm-99/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "NVIDIA",
    "Platform": "DGX-H100_H100-SXM-80GBx8_TRT",
    "Result": 5366820,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX H100 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "e7833e42cf484d0b",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT/dlrm-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx1_TRT/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "NVIDIA",
    "Platform": "DGX-H100_H100-SXM-80GBx1_TRT",
    "Result": 745480,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX H100 (1x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "95d17999d0a843d2",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx1_TRT/dlrm-99/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx1_TRT/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "NVIDIA",
    "Platform": "DGX-H100_H100-SXM-80GBx1_TRT",
    "Result": 745480,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX H100 (1x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "e948a88efbf448cb",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx1_TRT/dlrm-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 80.172,
    "Accuracy_div_100": 0.80172,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A100-PCIe-80GBx8_TRT/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "NVIDIA",
    "Platform": "A100-PCIe-80GBx8_TRT",
    "Result": 2262170,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G482-Z54 (8x A100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "32f28ca8e90a457d",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/NVIDIA/results/A100-PCIe-80GBx8_TRT/dlrm-99/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 80.172,
    "Accuracy_div_100": 0.80172,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A100-PCIe-80GBx8_TRT/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "NVIDIA",
    "Platform": "A100-PCIe-80GBx8_TRT",
    "Result": 2262170,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G482-Z54 (8x A100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "aebab58b2a1d4bee",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/NVIDIA/results/A100-PCIe-80GBx8_TRT/dlrm-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 80.186,
    "Accuracy_div_100": 0.80186,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/Neuchips/results/RecAccel-N3000-32GB-PCIEx1/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "Neuchips",
    "Platform": "RecAccel-N3000-32GB-PCIEx1",
    "Result": 107057,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G482-Z54 (1x RecAccel-N3000-32GB-PCIE)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "RecAccel N3000",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "AMD EPYC 7452 32-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.1",
    "uid": "d4d61cd4515f4138",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Neuchips/results/RecAccel-N3000-32GB-PCIEx1/dlrm-99/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 80.186,
    "Accuracy_div_100": 0.80186,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/Neuchips/results/RecAccel-N3000-32GB-PCIEx1/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "Neuchips",
    "Platform": "RecAccel-N3000-32GB-PCIEx1",
    "Result": 107057,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G482-Z54 (1x RecAccel-N3000-32GB-PCIE)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "RecAccel N3000",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "AMD EPYC 7452 32-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.1",
    "uid": "76ef6492c45e4a04",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Neuchips/results/RecAccel-N3000-32GB-PCIEx1/dlrm-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC4000A_E12_L4x8_TRT/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "ASUSTeK",
    "Platform": "ESC4000A_E12_L4x8_TRT",
    "Result": 735596,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "ASUS ESC4000A-E12 (8x L4, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9654 96-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "c600bca75d9d49a0",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/ASUSTeK/results/ESC4000A_E12_L4x8_TRT/dlrm-99/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC4000A_E12_L4x8_TRT/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "ASUSTeK",
    "Platform": "ESC4000A_E12_L4x8_TRT",
    "Result": 735596,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "ASUS ESC4000A-E12 (8x L4, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9654 96-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "7d36622dced44223",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/ASUSTeK/results/ESC4000A_E12_L4x8_TRT/dlrm-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE2420_T4x1_TRT/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "Dell",
    "Platform": "XE2420_T4x1_TRT",
    "Result": 33860.5,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE2420 (1x T4, TensorRT)",
    "SystemType": "datacenter,edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA T4",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 22,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6238 CPU @ 2.10GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "ECC on",
    "number_of_nodes": 1,
    "operating_system": "CentOS 8.2.2004",
    "uid": "bd4fd9abae8f40e8",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Dell/results/XE2420_T4x1_TRT/dlrm-99/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE2420_T4x1_TRT/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "Dell",
    "Platform": "XE2420_T4x1_TRT",
    "Result": 33860.5,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE2420 (1x T4, TensorRT)",
    "SystemType": "datacenter,edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA T4",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 22,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6238 CPU @ 2.10GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "ECC on",
    "number_of_nodes": 1,
    "operating_system": "CentOS 8.2.2004",
    "uid": "710f9a0db5b14c9d",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Dell/results/XE2420_T4x1_TRT/dlrm-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XR4520c_A30x1_TRT_DATACENTER/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "Dell",
    "Platform": "XR4520c_A30x1_TRT_DATACENTER",
    "Result": 147821,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XR4520c (1x A30, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "Intel(R) Xeon(R) D-2776NT CPU @ 2.10GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "a01af648cca9466c",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Dell/results/XR4520c_A30x1_TRT_DATACENTER/dlrm-99/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XR4520c_A30x1_TRT_DATACENTER/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "Dell",
    "Platform": "XR4520c_A30x1_TRT_DATACENTER",
    "Result": 147821,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XR4520c (1x A30, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "Intel(R) Xeon(R) D-2776NT CPU @ 2.10GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "5f52b231678c4236",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Dell/results/XR4520c_A30x1_TRT_DATACENTER/dlrm-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R750xa_H100_PCIe_80GBx4_TRT/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "Dell",
    "Platform": "R750xa_H100_PCIe_80GBx4_TRT",
    "Result": 1710360,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge R750xa (4x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6338 CPU @ 2.00GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "NVIDIA H100-PCIe-80GB (TDP: 310W)",
    "number_of_nodes": 1,
    "operating_system": "CentOS 8.2",
    "uid": "c79038f3220d46ed",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Dell/results/R750xa_H100_PCIe_80GBx4_TRT/dlrm-99/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R750xa_H100_PCIe_80GBx4_TRT/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "Dell",
    "Platform": "R750xa_H100_PCIe_80GBx4_TRT",
    "Result": 1710360,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge R750xa (4x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6338 CPU @ 2.00GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "NVIDIA H100-PCIe-80GB (TDP: 310W)",
    "number_of_nodes": 1,
    "operating_system": "CentOS 8.2",
    "uid": "be164c78e2e74697",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Dell/results/R750xa_H100_PCIe_80GBx4_TRT/dlrm-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9680_A100_SXM4_80GBx8_TRT/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "Dell",
    "Platform": "XE9680_A100_SXM4_80GBx8_TRT",
    "Result": 2574220,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE9680 (8x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB CTS",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 52,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "NVIDIA A100-SXM4-80GB (TDP: 500W)",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "5b5b52b9d53e455d",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Dell/results/XE9680_A100_SXM4_80GBx8_TRT/dlrm-99/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9680_A100_SXM4_80GBx8_TRT/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "Dell",
    "Platform": "XE9680_A100_SXM4_80GBx8_TRT",
    "Result": 2574220,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE9680 (8x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB CTS",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 52,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "NVIDIA A100-SXM4-80GB (TDP: 500W)",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "e84c65ca9475460e",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Dell/results/XE9680_A100_SXM4_80GBx8_TRT/dlrm-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 80.2302,
    "Accuracy_div_100": 0.8023,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/1-node-2S-SPR-PyTorch-INT8/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "Dell",
    "Platform": "1-node-2S-SPR-PyTorch-INT8",
    "Result": 136705,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge Server R760 (1x Intel Xeon Platinum 8480+)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "PyTorch",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 224,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "CentOS Stream 8",
    "uid": "839cb18d4f764864",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Dell/results/1-node-2S-SPR-PyTorch-INT8/dlrm-99/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 80.2302,
    "Accuracy_div_100": 0.8023,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/1-node-2S-SPR-PyTorch-INT8/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "Dell",
    "Platform": "1-node-2S-SPR-PyTorch-INT8",
    "Result": 136705,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge Server R760 (1x Intel Xeon Platinum 8480+)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "PyTorch",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 224,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "CentOS Stream 8",
    "uid": "059467b4f6344c4a",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Dell/results/1-node-2S-SPR-PyTorch-INT8/dlrm-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/xFusion/results/G5500V7_A30x10_TRT/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "xFusion",
    "Platform": "G5500V7_A30x10_TRT",
    "Result": 1409800,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "xFusion FusionServer G5500V7(10x NVIDIA A30, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 10,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 44,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8458P CPU @ 2.7 GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "430eb839d5c94ad2",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/xFusion/results/G5500V7_A30x10_TRT/dlrm-99/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/xFusion/results/G5500V7_A30x10_TRT/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "xFusion",
    "Platform": "G5500V7_A30x10_TRT",
    "Result": 1409800,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "xFusion FusionServer G5500V7(10x NVIDIA A30, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 10,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 44,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8458P CPU @ 2.7 GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "95356ac73ce3454a",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/xFusion/results/G5500V7_A30x10_TRT/dlrm-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/xFusion/results/G5500V7_L40x8_TRT/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "xFusion",
    "Platform": "G5500V7_L40x8_TRT",
    "Result": 1465300,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "xFusion FusionServer G5500V7(8x NVIDIA L40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 44,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8458P CPU @ 2.7 GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "b6a29c065eb04a6e",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/xFusion/results/G5500V7_L40x8_TRT/dlrm-99/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/xFusion/results/G5500V7_L40x8_TRT/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "xFusion",
    "Platform": "G5500V7_L40x8_TRT",
    "Result": 1465300,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "xFusion FusionServer G5500V7(8x NVIDIA L40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 44,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8458P CPU @ 2.7 GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "5dedde40c9bf407a",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/xFusion/results/G5500V7_L40x8_TRT/dlrm-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/xFusion/results/G5500V7_A30x8_TRT/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "xFusion",
    "Platform": "G5500V7_A30x8_TRT",
    "Result": 1144270,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "xFusion FusionServer G5500V7(8x NVIDIA A30, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 44,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8458P CPU @ 2.7 GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "d38591da401b4936",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/xFusion/results/G5500V7_A30x8_TRT/dlrm-99/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/xFusion/results/G5500V7_A30x8_TRT/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "xFusion",
    "Platform": "G5500V7_A30x8_TRT",
    "Result": 1144270,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "xFusion FusionServer G5500V7(8x NVIDIA A30, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 44,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8458P CPU @ 2.7 GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "51a9b19e0089425d",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/xFusion/results/G5500V7_A30x8_TRT/dlrm-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/xFusion/results/L4x6_2288H_V7_TRT/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "xFusion",
    "Platform": "L4x6_2288H_V7_TRT",
    "Result": 388100,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "xFusion FusionServer 2288H V7(6x NVIDIA L4, TensorRT)",
    "SystemType": "datacenter,edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 6,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 44,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8458P CPU @ 2.7 GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "c3e869ddb0cf4764",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/xFusion/results/L4x6_2288H_V7_TRT/dlrm-99/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/xFusion/results/L4x6_2288H_V7_TRT/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "xFusion",
    "Platform": "L4x6_2288H_V7_TRT",
    "Result": 388100,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "xFusion FusionServer 2288H V7(6x NVIDIA L4, TensorRT)",
    "SystemType": "datacenter,edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 6,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 44,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8458P CPU @ 2.7 GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "37917d492f4c4055",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/xFusion/results/L4x6_2288H_V7_TRT/dlrm-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/xFusion/results/G5500V7_L40x10_TRT/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "xFusion",
    "Platform": "G5500V7_L40x10_TRT",
    "Result": 1787220,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "xFusion FusionServer G5500V7(10x NVIDIA L40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40",
    "accelerators_per_node": 10,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 44,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8458P CPU @ 2.7 GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "1ede7c4c63064654",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/xFusion/results/G5500V7_L40x10_TRT/dlrm-99/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/xFusion/results/G5500V7_L40x10_TRT/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "xFusion",
    "Platform": "G5500V7_L40x10_TRT",
    "Result": 1787220,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "xFusion FusionServer G5500V7(10x NVIDIA L40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40",
    "accelerators_per_node": 10,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 44,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8458P CPU @ 2.7 GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "0373f104ff204748",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/xFusion/results/G5500V7_L40x10_TRT/dlrm-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/GIGABYTE/results/GIGABYTE-G493-SB0_H100-PCIe-80GBx8_TRT/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "GIGABYTE",
    "Platform": "GIGABYTE-G493-SB0_H100-PCIe-80GBx8_TRT",
    "Result": 3594680,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "GIGABYTE G493-SB0",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "cd7174b7b1fa46ed",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/GIGABYTE/results/GIGABYTE-G493-SB0_H100-PCIe-80GBx8_TRT/dlrm-99/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/GIGABYTE/results/GIGABYTE-G493-SB0_H100-PCIe-80GBx8_TRT/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "GIGABYTE",
    "Platform": "GIGABYTE-G493-SB0_H100-PCIe-80GBx8_TRT",
    "Result": 3594680,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "GIGABYTE G493-SB0",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "e4781b05693b4921",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/GIGABYTE/results/GIGABYTE-G493-SB0_H100-PCIe-80GBx8_TRT/dlrm-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 80.2267,
    "Accuracy_div_100": 0.80227,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Intel/results/1-node-2S-SPR-PyTorch-INT8/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "Intel",
    "Platform": "1-node-2S-SPR-PyTorch-INT8",
    "Result": 140432,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "1-node-2S-SPR-PyTorch-INT8",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "PyTorch",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54Q-2U",
    "number_of_nodes": 2,
    "operating_system": "CentOS Stream 8",
    "uid": "8b59311c0a154395",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Intel/results/1-node-2S-SPR-PyTorch-INT8/dlrm-99/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 80.2267,
    "Accuracy_div_100": 0.80227,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Intel/results/1-node-2S-SPR-PyTorch-INT8/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "Intel",
    "Platform": "1-node-2S-SPR-PyTorch-INT8",
    "Result": 140432,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "1-node-2S-SPR-PyTorch-INT8",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "PyTorch",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54Q-2U",
    "number_of_nodes": 2,
    "operating_system": "CentOS Stream 8",
    "uid": "fd3cb0ad14554f53",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Intel/results/1-node-2S-SPR-PyTorch-INT8/dlrm-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Nettrix/results/L40x8_Custom_X640_G40_TRT/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "Nettrix",
    "Platform": "L40x8_Custom_X640_G40_TRT",
    "Result": 1291210,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "X640 G40 (8xL40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8380",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "ed73525e3a394cfe",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/L40x8_Custom_X640_G40_TRT/dlrm-99/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Nettrix/results/L40x8_Custom_X640_G40_TRT/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "Nettrix",
    "Platform": "L40x8_Custom_X640_G40_TRT",
    "Result": 1291210,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "X640 G40 (8xL40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8380",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "f9053241ade3483a",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/L40x8_Custom_X640_G40_TRT/dlrm-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Nettrix/results/A40X3_CUSTOM_X620_G50_TRT/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "Nettrix",
    "Platform": "A40X3_CUSTOM_X620_G50_TRT",
    "Result": 477529,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "X620 G50 (3x A40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A40",
    "accelerators_per_node": 3,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "17dd552296a14381",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/A40X3_CUSTOM_X620_G50_TRT/dlrm-99/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Nettrix/results/A40X3_CUSTOM_X620_G50_TRT/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "Nettrix",
    "Platform": "A40X3_CUSTOM_X620_G50_TRT",
    "Result": 476654,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "X620 G50 (3x A40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A40",
    "accelerators_per_node": 3,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "8d391871d3404f44",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/A40X3_CUSTOM_X620_G50_TRT/dlrm-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/Nettrix/results/A30x8_Custom_X640_G50_TRT/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "Nettrix",
    "Platform": "A30x8_Custom_X640_G50_TRT",
    "Result": 1126240,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "X640 G50 (8x A30, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "61305d2801c24644",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/A30x8_Custom_X640_G50_TRT/dlrm-99/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/Nettrix/results/A30x8_Custom_X640_G50_TRT/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "Nettrix",
    "Platform": "A30x8_Custom_X640_G50_TRT",
    "Result": 1126020,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "X640 G50 (8x A30, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "aca3caf123c74f2c",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/A30x8_Custom_X640_G50_TRT/dlrm-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/Nettrix/results/L4x8_Custom_X640_G40_TRT/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "Nettrix",
    "Platform": "L4x8_Custom_X640_G40_TRT",
    "Result": 690224,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "X640 G40 (8x L4, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 38,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8368",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "95424c8e08b24a0e",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/L4x8_Custom_X640_G40_TRT/dlrm-99/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/Nettrix/results/L4x8_Custom_X640_G40_TRT/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "Nettrix",
    "Platform": "L4x8_Custom_X640_G40_TRT",
    "Result": 690224,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "X640 G40 (8x L4, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 38,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8368",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "b36aa59aa0ee4651",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/L4x8_Custom_X640_G40_TRT/dlrm-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Nettrix/results/L40x3_Custom_X620_G40_TRT/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "Nettrix",
    "Platform": "L40x3_Custom_X620_G40_TRT",
    "Result": 638008,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "X620 G40 (3xL40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40",
    "accelerators_per_node": 3,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 28,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6348",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "3791fb2313144dde",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/L40x3_Custom_X620_G40_TRT/dlrm-99/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Nettrix/results/L40x3_Custom_X620_G40_TRT/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "Nettrix",
    "Platform": "L40x3_Custom_X620_G40_TRT",
    "Result": 638008,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "X620 G40 (3xL40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40",
    "accelerators_per_node": 3,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 28,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6348",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "aa0c3919f46740a5",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/L40x3_Custom_X620_G40_TRT/dlrm-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Nettrix/results/L40x3_Custom_X620_G50_TRT/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "Nettrix",
    "Platform": "L40x3_Custom_X620_G50_TRT",
    "Result": 639772,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "X620 G50 (3xL40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40",
    "accelerators_per_node": 3,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6442Y",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "877871a3d214448d",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/L40x3_Custom_X620_G50_TRT/dlrm-99/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Nettrix/results/L40x3_Custom_X620_G50_TRT/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "Nettrix",
    "Platform": "L40x3_Custom_X620_G50_TRT",
    "Result": 639772,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "X620 G50 (3xL40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40",
    "accelerators_per_node": 3,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6442Y",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "11088dbe53d249ca",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/L40x3_Custom_X620_G50_TRT/dlrm-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Nettrix/results/A40X8_CUSTOM_X640_G40_TRT/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "Nettrix",
    "Platform": "A40X8_CUSTOM_X640_G40_TRT",
    "Result": 1065630,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "X640 G40 (8x A40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A40",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 38,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8368",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "6e3e9f05e19b413c",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/A40X8_CUSTOM_X640_G40_TRT/dlrm-99/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Nettrix/results/A40X8_CUSTOM_X640_G40_TRT/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "Nettrix",
    "Platform": "A40X8_CUSTOM_X640_G40_TRT",
    "Result": 1062560,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "X640 G40 (8x A40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A40",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 38,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8368",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "abcaeb7b47404326",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/A40X8_CUSTOM_X640_G40_TRT/dlrm-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Nettrix/results/A30x3_Custom_X620_G40_TRT/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "Nettrix",
    "Platform": "A30x3_Custom_X620_G40_TRT",
    "Result": 431245,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "X620 G40 (3x A30, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 3,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 28,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6348 CPU @ 2.60GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "ee08617154684ee5",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/A30x3_Custom_X620_G40_TRT/dlrm-99/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Nettrix/results/A30x3_Custom_X620_G40_TRT/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "Nettrix",
    "Platform": "A30x3_Custom_X620_G40_TRT",
    "Result": 431030,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "X620 G40 (3x A30, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 3,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 28,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6348 CPU @ 2.60GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "b015bca4ad2a4d5d",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/A30x3_Custom_X620_G40_TRT/dlrm-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/Nettrix/results/L4x4_Custom_X620_G40_TRT/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "Nettrix",
    "Platform": "L4x4_Custom_X620_G40_TRT",
    "Result": 360760,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "X620 G40 (4x L4, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 28,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6348",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "d73886bef2544dd0",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/L4x4_Custom_X620_G40_TRT/dlrm-99/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/Nettrix/results/L4x4_Custom_X620_G40_TRT/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "Nettrix",
    "Platform": "L4x4_Custom_X620_G40_TRT",
    "Result": 361090,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "X620 G40 (4x L4, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 28,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6348",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "53392bc7da7d434f",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/L4x4_Custom_X620_G40_TRT/dlrm-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Nettrix/results/A30x4_Custom_X620_G50_TRT/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "Nettrix",
    "Platform": "A30x4_Custom_X620_G50_TRT",
    "Result": 564392,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "X620 G50 (4x A30, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 44,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8458P",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "fc98e4f528e74a18",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/A30x4_Custom_X620_G50_TRT/dlrm-99/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Nettrix/results/A30x4_Custom_X620_G50_TRT/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "Nettrix",
    "Platform": "A30x4_Custom_X620_G50_TRT",
    "Result": 563121,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "X620 G50 (4x A30, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 44,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8458P",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "158cd26e4a5843e2",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/A30x4_Custom_X620_G50_TRT/dlrm-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/Nettrix/results/L40x8_Custom_X640_G50_TRT/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "Nettrix",
    "Platform": "L40x8_Custom_X640_G50_TRT",
    "Result": 1656840,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "X640 G50 (8xL40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "5dc82a9331ff425d",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/L40x8_Custom_X640_G50_TRT/dlrm-99/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/Nettrix/results/L40x8_Custom_X640_G50_TRT/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "Nettrix",
    "Platform": "L40x8_Custom_X640_G50_TRT",
    "Result": 1656010,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "X640 G50 (8xL40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "3e0cee371c884513",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/L40x8_Custom_X640_G50_TRT/dlrm-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/Nettrix/results/A40X8_CUSTOM_X640_G50_TRT/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "Nettrix",
    "Platform": "A40X8_CUSTOM_X640_G50_TRT",
    "Result": 1229680,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "X640 G50 (8x A40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A40",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "5f2e25f1b16d4868",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/A40X8_CUSTOM_X640_G50_TRT/dlrm-99/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/Nettrix/results/A40X8_CUSTOM_X640_G50_TRT/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "Nettrix",
    "Platform": "A40X8_CUSTOM_X640_G50_TRT",
    "Result": 1229970,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "X640 G50 (8x A40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A40",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "12ea618376654ef1",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/A40X8_CUSTOM_X640_G50_TRT/dlrm-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Nettrix/results/A30x8_Custom_X640_G40_TRT/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "Nettrix",
    "Platform": "A30x8_Custom_X640_G40_TRT",
    "Result": 1097620,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "X640 G40 (8x A30, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 18,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6354",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "b51aac8d5e5341e0",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/A30x8_Custom_X640_G40_TRT/dlrm-99/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Nettrix/results/A30x8_Custom_X640_G40_TRT/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "Nettrix",
    "Platform": "A30x8_Custom_X640_G40_TRT",
    "Result": 1097620,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "X640 G40 (8x A30, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 18,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6354",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "61b6a3effcff4cf9",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/A30x8_Custom_X640_G40_TRT/dlrm-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Nettrix/results/A40X3_CUSTOM_X620_G40_TRT/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "Nettrix",
    "Platform": "A40X3_CUSTOM_X620_G40_TRT",
    "Result": 474179,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "X620 G40 (3x A40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A40",
    "accelerators_per_node": 3,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 28,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6348",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "e70656bcad0a4891",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/A40X3_CUSTOM_X620_G40_TRT/dlrm-99/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Nettrix/results/A40X3_CUSTOM_X620_G40_TRT/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "Nettrix",
    "Platform": "A40X3_CUSTOM_X620_G40_TRT",
    "Result": 474179,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "X620 G40 (3x A40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A40",
    "accelerators_per_node": 3,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 28,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6348",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "824a1b0478f94856",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/A40X3_CUSTOM_X620_G40_TRT/dlrm-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/Nettrix/results/L4x8_Custom_X640_G50_TRT/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "Nettrix",
    "Platform": "L4x8_Custom_X640_G50_TRT",
    "Result": 737430,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "X640 G50 (8x L4, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "84a111ecbea74317",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/L4x8_Custom_X640_G50_TRT/dlrm-99/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/Nettrix/results/L4x8_Custom_X640_G50_TRT/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "Nettrix",
    "Platform": "L4x8_Custom_X640_G50_TRT",
    "Result": 735809,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "X640 G50 (8x L4, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "e5dc679cdbf44b69",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/L4x8_Custom_X640_G50_TRT/dlrm-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/Nettrix/results/L4x5_Custom_X620_G50_TRT/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "Nettrix",
    "Platform": "L4x5_Custom_X620_G50_TRT",
    "Result": 463208,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "X620 G50 (5x L4, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 5,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 6458Q",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "ab074cad6e9d4861",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/L4x5_Custom_X620_G50_TRT/dlrm-99/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/Nettrix/results/L4x5_Custom_X620_G50_TRT/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "Nettrix",
    "Platform": "L4x5_Custom_X620_G50_TRT",
    "Result": 463208,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "X620 G50 (5x L4, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 5,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 6458Q",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "e798eba39af54e75",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/L4x5_Custom_X620_G50_TRT/dlrm-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Inspur/results/NF5468M6_A40x8_TRT/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "Inspur",
    "Platform": "NF5468M6_A40x8_TRT",
    "Result": 1222130,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NF5468M6 (8x A40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A40",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8380",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5",
    "uid": "acdd2e018b964d70",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Inspur/results/NF5468M6_A40x8_TRT/dlrm-99/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Inspur/results/NF5468M6_A40x8_TRT/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "Inspur",
    "Platform": "NF5468M6_A40x8_TRT",
    "Result": 1222130,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NF5468M6 (8x A40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A40",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8380",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5",
    "uid": "ac86b9f927324d78",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Inspur/results/NF5468M6_A40x8_TRT/dlrm-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/R5350G6_A30x10_TRT_Triton/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "H3C",
    "Platform": "R5350G6_A30x10_TRT_Triton",
    "Result": 1456400,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "H3C UniServer R5350 G6 (10x A30, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 10,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "AMD EPYC 9654 96-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5",
    "uid": "56ae5dd78df14107",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/H3C/results/R5350G6_A30x10_TRT_Triton/dlrm-99/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/R5350G6_A30x10_TRT_Triton/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "H3C",
    "Platform": "R5350G6_A30x10_TRT_Triton",
    "Result": 1489220,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "H3C UniServer R5350 G6 (10x A30, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 10,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "AMD EPYC 9654 96-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5",
    "uid": "13da24eecf924157",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/H3C/results/R5350G6_A30x10_TRT_Triton/dlrm-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/R5300G6_A30x4_TRT/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "H3C",
    "Platform": "R5300G6_A30x4_TRT",
    "Result": 591852,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "H3C UniServer R5300 G6 (4x A30, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 11.7",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 44,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8458P",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5",
    "uid": "a3bb06b315264025",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/H3C/results/R5300G6_A30x4_TRT/dlrm-99/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/R5300G6_A30x4_TRT/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "H3C",
    "Platform": "R5300G6_A30x4_TRT",
    "Result": 591852,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "H3C UniServer R5300 G6 (4x A30, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 11.7",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 44,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8458P",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5",
    "uid": "7173636977014f1d",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/H3C/results/R5300G6_A30x4_TRT/dlrm-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/R5350G6_A30x10_TRT/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "H3C",
    "Platform": "R5350G6_A30x10_TRT",
    "Result": 1442510,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "H3C UniServer R5350 G6 (10x A30, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 10,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "AMD EPYC 9654 96-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5",
    "uid": "5e94df26c5744a93",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/H3C/results/R5350G6_A30x10_TRT/dlrm-99/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/R5350G6_A30x10_TRT/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "H3C",
    "Platform": "R5350G6_A30x10_TRT",
    "Result": 1479360,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "H3C UniServer R5350 G6 (10x A30, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 10,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "AMD EPYC 9654 96-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5",
    "uid": "ecd2b63cf9ac4314",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/H3C/results/R5350G6_A30x10_TRT/dlrm-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 80.2269,
    "Accuracy_div_100": 0.80227,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/1-node-2S-SPR-PyTorch-INT8/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "HPE",
    "Platform": "1-node-2S-SPR-PyTorch-INT8",
    "Result": 141689,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "1-node-2S-SPR-PyTorch-INT8",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "PyTorch",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "ProLiant DL380a Gen11",
    "number_of_nodes": 2,
    "operating_system": "Red Hat Enterprise Linux 8.7",
    "uid": "1cf82199e4b14e89",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/HPE/results/1-node-2S-SPR-PyTorch-INT8/dlrm-99/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 80.2269,
    "Accuracy_div_100": 0.80227,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/1-node-2S-SPR-PyTorch-INT8/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "HPE",
    "Platform": "1-node-2S-SPR-PyTorch-INT8",
    "Result": 141689,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "1-node-2S-SPR-PyTorch-INT8",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "PyTorch",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "ProLiant DL380a Gen11",
    "number_of_nodes": 2,
    "operating_system": "Red Hat Enterprise Linux 8.7",
    "uid": "b21a72a60f044ef7",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/HPE/results/1-node-2S-SPR-PyTorch-INT8/dlrm-99.9/Offline",
    "version": "v3.0"
  }
]
