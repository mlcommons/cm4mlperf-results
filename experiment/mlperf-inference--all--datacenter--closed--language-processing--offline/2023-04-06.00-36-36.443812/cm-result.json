[
  {
    "Accuracy": 44.5321,
    "Accuracy_div_100": 0.44532,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/AMD/results/1xMI300X_2xEPYC-9374F/llama2-70b-99/Offline",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "AMD",
    "Platform": "1xMI300X_2xEPYC-9374F",
    "Result": 3062.72,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Supermicro AS-8125GS-TNMR2",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "AMD Instinct MI300X-NPS1-SPX-192GB-750W",
    "accelerators_per_node": 1,
    "compliance": 0,
    "errors": 0,
    "framework": "vLLM 0.4.3+rocm614, PyTorch 2.3.0, ROCm 6.1.2",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "2xAMD EPYC 9374F",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS (Jammy Jellyfish)",
    "uid": "7f08368cdb0a4309",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/AMD/results/1xMI300X_2xEPYC-9374F/llama2-70b-99/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 44.5321,
    "Accuracy_div_100": 0.44532,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/AMD/results/1xMI300X_2xEPYC-9374F/llama2-70b-99.9/Offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "AMD",
    "Platform": "1xMI300X_2xEPYC-9374F",
    "Result": 3062.72,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Supermicro AS-8125GS-TNMR2",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "AMD Instinct MI300X-NPS1-SPX-192GB-750W",
    "accelerators_per_node": 1,
    "compliance": 0,
    "errors": 0,
    "framework": "vLLM 0.4.3+rocm614, PyTorch 2.3.0, ROCm 6.1.2",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "2xAMD EPYC 9374F",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS (Jammy Jellyfish)",
    "uid": "3a3c09f14d514ed1",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/AMD/results/1xMI300X_2xEPYC-9374F/llama2-70b-99.9/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 44.5633,
    "Accuracy_div_100": 0.44563,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/AMD/results/8xMI300X_2xEPYC-9374F/llama2-70b-99/Offline",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "AMD",
    "Platform": "8xMI300X_2xEPYC-9374F",
    "Result": 23514.8,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Supermicro AS-8125GS-TNMR2",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "AMD Instinct MI300X-NPS1-SPX-192GB-750W",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "vLLM 0.4.3+rocm614, PyTorch 2.3.0, ROCm 6.1.2",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "2xAMD EPYC 9374F",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS (Jammy Jellyfish)",
    "uid": "d6ef853ae8da4022",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/AMD/results/8xMI300X_2xEPYC-9374F/llama2-70b-99/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 44.5633,
    "Accuracy_div_100": 0.44563,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/AMD/results/8xMI300X_2xEPYC-9374F/llama2-70b-99.9/Offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "AMD",
    "Platform": "8xMI300X_2xEPYC-9374F",
    "Result": 23514.8,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Supermicro AS-8125GS-TNMR2",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "AMD Instinct MI300X-NPS1-SPX-192GB-750W",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "vLLM 0.4.3+rocm614, PyTorch 2.3.0, ROCm 6.1.2",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "2xAMD EPYC 9374F",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS (Jammy Jellyfish)",
    "uid": "024288cf8ac14fff",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/AMD/results/8xMI300X_2xEPYC-9374F/llama2-70b-99.9/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 44.5633,
    "Accuracy_div_100": 0.44563,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/AMD/results/8xMI300X_2xEPYC-TURIN/llama2-70b-99/Offline",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "AMD",
    "Platform": "8xMI300X_2xEPYC-TURIN",
    "Result": 24109.8,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Supermicro AS-8125GS-TNMR2",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "AMD Instinct MI300X-NPS1-SPX-192GB-750W",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "vLLM 0.4.3+rocm614, PyTorch 2.3.0, ROCm 6.1.2",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": "N/A",
    "host_processor_model_name": "2xAMD EPYC TURIN",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Preview due to using AMD next-generation EPYC CPU",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.6 LTS (Jammy Jellyfish)",
    "uid": "b9732261a0274bd9",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/AMD/results/8xMI300X_2xEPYC-TURIN/llama2-70b-99/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 44.5633,
    "Accuracy_div_100": 0.44563,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/AMD/results/8xMI300X_2xEPYC-TURIN/llama2-70b-99.9/Offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "AMD",
    "Platform": "8xMI300X_2xEPYC-TURIN",
    "Result": 24109.8,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Supermicro AS-8125GS-TNMR2",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "AMD Instinct MI300X-NPS1-SPX-192GB-750W",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "vLLM 0.4.3+rocm614, PyTorch 2.3.0, ROCm 6.1.2",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": "N/A",
    "host_processor_model_name": "2xAMD EPYC TURIN",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Preview due to using AMD next-generation EPYC CPU",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.6 LTS (Jammy Jellyfish)",
    "uid": "1d6594827e9f42ff",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/AMD/results/8xMI300X_2xEPYC-TURIN/llama2-70b-99.9/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 90.35676151551918,
    "Accuracy_div_100": 0.90357,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC4000A_E12_4XH100_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "ASUSTeK",
    "Platform": "ESC4000A_E12_4XH100_TRT",
    "Result": 24173.2,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "ASUSTeK ESC4000A-E12 (4xH100-NVL-94GB)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 4,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9654 96-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "uid": "c7fe88e2add44807",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/ASUSTeK/results/ESC4000A_E12_4XH100_TRT/bert-99/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 90.97056894987658,
    "Accuracy_div_100": 0.90971,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC4000A_E12_4XH100_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "ASUSTeK",
    "Platform": "ESC4000A_E12_4XH100_TRT",
    "Result": 20380,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "ASUSTeK ESC4000A-E12 (4xH100-NVL-94GB)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 4,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9654 96-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "uid": "d3bcfc6d63684d43",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/ASUSTeK/results/ESC4000A_E12_4XH100_TRT/bert-99.9/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 43.1017,
    "Accuracy_div_100": 0.43102,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC4000A_E12_4XH100_TRT/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "ASUSTeK",
    "Platform": "ESC4000A_E12_4XH100_TRT",
    "Result": 6985.51,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "ASUSTeK ESC4000A-E12 (4xH100-NVL-94GB)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 4,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9654 96-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "uid": "d80102a572814cd7",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/ASUSTeK/results/ESC4000A_E12_4XH100_TRT/gptj-99/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 43.1017,
    "Accuracy_div_100": 0.43102,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC4000A_E12_4XH100_TRT/gptj-99.9/Offline",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "ASUSTeK",
    "Platform": "ESC4000A_E12_4XH100_TRT",
    "Result": 6985.51,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "ASUSTeK ESC4000A-E12 (4xH100-NVL-94GB)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 4,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9654 96-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "uid": "a8e6a0bb352c4f35",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/ASUSTeK/results/ESC4000A_E12_4XH100_TRT/gptj-99.9/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 44.5664,
    "Accuracy_div_100": 0.44566,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC4000A_E12_4XH100_TRT/llama2-70b-99/Offline",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "ASUSTeK",
    "Platform": "ESC4000A_E12_4XH100_TRT",
    "Result": 6673.95,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "ASUSTeK ESC4000A-E12 (4xH100-NVL-94GB)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 4,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9654 96-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "uid": "436f6ed18c544b8a",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/ASUSTeK/results/ESC4000A_E12_4XH100_TRT/llama2-70b-99/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 44.5664,
    "Accuracy_div_100": 0.44566,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC4000A_E12_4XH100_TRT/llama2-70b-99.9/Offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "ASUSTeK",
    "Platform": "ESC4000A_E12_4XH100_TRT",
    "Result": 6673.95,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "ASUSTeK ESC4000A-E12 (4xH100-NVL-94GB)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 4,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9654 96-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "uid": "5d01bbf157954910",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/ASUSTeK/results/ESC4000A_E12_4XH100_TRT/llama2-70b-99.9/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 90.35676151551918,
    "Accuracy_div_100": 0.90357,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC8000A_E12_H100x8_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "ASUSTeK",
    "Platform": "ESC8000A_E12_H100x8_TRT",
    "Result": 45409.8,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "ESC8000A-E12 (8x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "AMD EPYC 9374F 32-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Data bandwidth for GPU-PCIe: 504 GB/s; PCIe-NIC: 126 GB/s",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "uid": "3136797c706e460c",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/ASUSTeK/results/ESC8000A_E12_H100x8_TRT/bert-99/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 90.97056894987658,
    "Accuracy_div_100": 0.90971,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC8000A_E12_H100x8_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "ASUSTeK",
    "Platform": "ESC8000A_E12_H100x8_TRT",
    "Result": 38464.2,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "ESC8000A-E12 (8x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "AMD EPYC 9374F 32-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Data bandwidth for GPU-PCIe: 504 GB/s; PCIe-NIC: 126 GB/s",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "uid": "8fe86abe226443bd",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/ASUSTeK/results/ESC8000A_E12_H100x8_TRT/bert-99.9/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 43.1261,
    "Accuracy_div_100": 0.43126,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC8000A_E12_H100x8_TRT/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "ASUSTeK",
    "Platform": "ESC8000A_E12_H100x8_TRT",
    "Result": 13078.5,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "ESC8000A-E12 (8x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "AMD EPYC 9374F 32-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Data bandwidth for GPU-PCIe: 504 GB/s; PCIe-NIC: 126 GB/s",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "uid": "3e852f8a4ec8425c",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/ASUSTeK/results/ESC8000A_E12_H100x8_TRT/gptj-99/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 43.1261,
    "Accuracy_div_100": 0.43126,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC8000A_E12_H100x8_TRT/gptj-99.9/Offline",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "ASUSTeK",
    "Platform": "ESC8000A_E12_H100x8_TRT",
    "Result": 13078.5,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "ESC8000A-E12 (8x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "AMD EPYC 9374F 32-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Data bandwidth for GPU-PCIe: 504 GB/s; PCIe-NIC: 126 GB/s",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "uid": "6835bcf5092c4933",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/ASUSTeK/results/ESC8000A_E12_H100x8_TRT/gptj-99.9/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 44.566,
    "Accuracy_div_100": 0.44566,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC8000A_E12_H100x8_TRT/llama2-70b-99/Offline",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "ASUSTeK",
    "Platform": "ESC8000A_E12_H100x8_TRT",
    "Result": 9281.5,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "ESC8000A-E12 (8x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "AMD EPYC 9374F 32-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Data bandwidth for GPU-PCIe: 504 GB/s; PCIe-NIC: 126 GB/s",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "uid": "667efd88f1694185",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/ASUSTeK/results/ESC8000A_E12_H100x8_TRT/llama2-70b-99/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 44.566,
    "Accuracy_div_100": 0.44566,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC8000A_E12_H100x8_TRT/llama2-70b-99.9/Offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "ASUSTeK",
    "Platform": "ESC8000A_E12_H100x8_TRT",
    "Result": 9281.5,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "ESC8000A-E12 (8x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "AMD EPYC 9374F 32-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Data bandwidth for GPU-PCIe: 504 GB/s; PCIe-NIC: 126 GB/s",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "uid": "af4bccd3d90e4f89",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/ASUSTeK/results/ESC8000A_E12_H100x8_TRT/llama2-70b-99.9/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 90.35676151551918,
    "Accuracy_div_100": 0.90357,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC_N8_E11_H100x8_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "ASUSTeK",
    "Platform": "ESC_N8_E11_H100x8_TRT",
    "Result": 70661.2,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "ESC-N8-E11 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "uid": "ee62a288274c4b6b",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/ASUSTeK/results/ESC_N8_E11_H100x8_TRT/bert-99/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 90.97056894987658,
    "Accuracy_div_100": 0.90971,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC_N8_E11_H100x8_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "ASUSTeK",
    "Platform": "ESC_N8_E11_H100x8_TRT",
    "Result": 62371.4,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "ESC-N8-E11 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "uid": "a13a70b0c12f408d",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/ASUSTeK/results/ESC_N8_E11_H100x8_TRT/bert-99.9/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 43.1017,
    "Accuracy_div_100": 0.43102,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC_N8_E11_H100x8_TRT/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "ASUSTeK",
    "Platform": "ESC_N8_E11_H100x8_TRT",
    "Result": 19877.6,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "ESC-N8-E11 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "uid": "290986b245aa48cb",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/ASUSTeK/results/ESC_N8_E11_H100x8_TRT/gptj-99/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 43.1017,
    "Accuracy_div_100": 0.43102,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC_N8_E11_H100x8_TRT/gptj-99.9/Offline",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "ASUSTeK",
    "Platform": "ESC_N8_E11_H100x8_TRT",
    "Result": 19877.6,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "ESC-N8-E11 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "uid": "73a69ab1f77f431a",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/ASUSTeK/results/ESC_N8_E11_H100x8_TRT/gptj-99.9/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 44.5663,
    "Accuracy_div_100": 0.44566,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC_N8_E11_H100x8_TRT/llama2-70b-99/Offline",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "ASUSTeK",
    "Platform": "ESC_N8_E11_H100x8_TRT",
    "Result": 24323.6,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "ESC-N8-E11 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "uid": "848c818ec7254d47",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/ASUSTeK/results/ESC_N8_E11_H100x8_TRT/llama2-70b-99/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 44.5663,
    "Accuracy_div_100": 0.44566,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC_N8_E11_H100x8_TRT/llama2-70b-99.9/Offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "ASUSTeK",
    "Platform": "ESC_N8_E11_H100x8_TRT",
    "Result": 24323.6,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "ESC-N8-E11 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "uid": "7e5f17bde8fe4578",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/ASUSTeK/results/ESC_N8_E11_H100x8_TRT/llama2-70b-99.9/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 90.53885196505269,
    "Accuracy_div_100": 0.90539,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Cisco/results/C240M7-1-node-2S-EMR-PyTorch/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Cisco",
    "Platform": "C240M7-1-node-2S-EMR-PyTorch",
    "Result": 1678.45,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "C240M7-1-node-2S-EMR-PyTorch",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 0,
    "errors": 0,
    "framework": "PyTorch",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Cisco UCS C240 M7. N/A",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3 LTS",
    "uid": "a3282b23fe034f3e",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Cisco/results/C240M7-1-node-2S-EMR-PyTorch/bert-99/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 42.9978,
    "Accuracy_div_100": 0.42998,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Cisco/results/C240M7-1-node-2S-EMR-PyTorch/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Cisco",
    "Platform": "C240M7-1-node-2S-EMR-PyTorch",
    "Result": 252.597,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "C240M7-1-node-2S-EMR-PyTorch",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 0,
    "errors": 0,
    "framework": "PyTorch",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Cisco UCS C240 M7. N/A",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3 LTS",
    "uid": "b92e266dcd9a4b90",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Cisco/results/C240M7-1-node-2S-EMR-PyTorch/gptj-99/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 90.23535730698143,
    "Accuracy_div_100": 0.90235,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Cisco/results/C240M7_L40Sx2_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Cisco",
    "Platform": "C240M7_L40Sx2_TRT",
    "Result": 6684.77,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Cisco UCS C240 M7 (2x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 2,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel Xeon Gold 6448H",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "uid": "abac0be435e14351",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Cisco/results/C240M7_L40Sx2_TRT/bert-99/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 43.0843,
    "Accuracy_div_100": 0.43084,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Cisco/results/C240M7_L40Sx2_TRT/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Cisco",
    "Platform": "C240M7_L40Sx2_TRT",
    "Result": 1747.67,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Cisco UCS C240 M7 (2x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 2,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel Xeon Gold 6448H",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "uid": "6da3c1550aa24e91",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Cisco/results/C240M7_L40Sx2_TRT/gptj-99/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 90.35676151551918,
    "Accuracy_div_100": 0.90357,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Cisco/results/C245M8_H100_PCIe_80GBx2_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Cisco",
    "Platform": "C245M8_H100_PCIe_80GBx2_TRT",
    "Result": 11576,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Cisco UCS C245 M8 (2x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 2,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9684X 96-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "uid": "6247708fe5f04891",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Cisco/results/C245M8_H100_PCIe_80GBx2_TRT/bert-99/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 43.0362,
    "Accuracy_div_100": 0.43036,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Cisco/results/C245M8_H100_PCIe_80GBx2_TRT/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Cisco",
    "Platform": "C245M8_H100_PCIe_80GBx2_TRT",
    "Result": 3268.94,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Cisco UCS C245 M8 (2x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 2,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9684X 96-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "uid": "131fd31bde3a4705",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Cisco/results/C245M8_H100_PCIe_80GBx2_TRT/gptj-99/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 90.23535730698143,
    "Accuracy_div_100": 0.90235,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Cisco/results/C245M8_L40Sx2_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Cisco",
    "Platform": "C245M8_L40Sx2_TRT",
    "Result": 6844.6,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Cisco UCS C245 M8 (2x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 2,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9684X 96-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "uid": "1c4e642c31d54563",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Cisco/results/C245M8_L40Sx2_TRT/bert-99/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 43.0605,
    "Accuracy_div_100": 0.4306,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Cisco/results/C245M8_L40Sx2_TRT/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Cisco",
    "Platform": "C245M8_L40Sx2_TRT",
    "Result": 1729.6,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Cisco UCS C245 M8 (2x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 2,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9684X 96-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "uid": "871ae70a459b4a3d",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Cisco/results/C245M8_L40Sx2_TRT/gptj-99/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 90.23535730698143,
    "Accuracy_div_100": 0.90235,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Cisco/results/X210c_L40SX2_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Cisco",
    "Platform": "X210c_L40SX2_TRT",
    "Result": 6590.32,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Cisco UCS X210c M7 (2x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 2,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8562Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "uid": "a27180c1173b484d",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Cisco/results/X210c_L40SX2_TRT/bert-99/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 43.0605,
    "Accuracy_div_100": 0.4306,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Cisco/results/X210c_L40SX2_TRT/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Cisco",
    "Platform": "X210c_L40SX2_TRT",
    "Result": 1746.46,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Cisco UCS X210c M7 (2x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 2,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8562Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "uid": "122273b1f8eb442d",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Cisco/results/X210c_L40SX2_TRT/gptj-99/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 43.0605,
    "Accuracy_div_100": 0.4306,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Cisco/results/X210c_L40SX2_TRT/gptj-99.9/Offline",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "Cisco",
    "Platform": "X210c_L40SX2_TRT",
    "Result": 1746.46,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Cisco UCS X210c M7 (2x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 2,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8562Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "uid": "d703bd7b1d7b4ea2",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Cisco/results/X210c_L40SX2_TRT/gptj-99.9/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 43.0544,
    "Accuracy_div_100": 0.43054,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Cisco/results/X210M7-1-node-2S-EMR-PyTorch/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Cisco",
    "Platform": "X210M7-1-node-2S-EMR-PyTorch",
    "Result": 206.119,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "X210M7-1-node-2S-EMR-PyTorch",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 0,
    "errors": 0,
    "framework": "PyTorch",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Cisco UCS X210 M7. N/A",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3 LTS",
    "uid": "97686ab4355940db",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Cisco/results/X210M7-1-node-2S-EMR-PyTorch/gptj-99/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 90.53885196505269,
    "Accuracy_div_100": 0.90539,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/1-node-2S-EMR-PyTorch/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Dell",
    "Platform": "1-node-2S-EMR-PyTorch",
    "Result": 1685.75,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge R760",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 0,
    "errors": 0,
    "framework": "PyTorch",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "INT4 for GPT-J, and INT8 for all other models",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 24.04",
    "uid": "e87149413ebd4fa0",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Dell/results/1-node-2S-EMR-PyTorch/bert-99/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 43.0227,
    "Accuracy_div_100": 0.43023,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/1-node-2S-EMR-PyTorch/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Dell",
    "Platform": "1-node-2S-EMR-PyTorch",
    "Result": 248.601,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge R760",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 0,
    "errors": 0,
    "framework": "PyTorch",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "INT4 for GPT-J, and INT8 for all other models",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 24.04",
    "uid": "3f788cfa6bc34a21",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Dell/results/1-node-2S-EMR-PyTorch/gptj-99/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 90.35676151551918,
    "Accuracy_div_100": 0.90357,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R760xa_H100NVL_PCIe_94GBx4_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Dell",
    "Platform": "R760xa_H100NVL_PCIe_94GBx4_TRT",
    "Result": 24851.2,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge R760xa (4xH100 NVL, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 4,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 120,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8580",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "uid": "cb50a077fa934639",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Dell/results/R760xa_H100NVL_PCIe_94GBx4_TRT/bert-99/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 90.97056894987658,
    "Accuracy_div_100": 0.90971,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R760xa_H100NVL_PCIe_94GBx4_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Dell",
    "Platform": "R760xa_H100NVL_PCIe_94GBx4_TRT",
    "Result": 20729.6,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge R760xa (4xH100 NVL, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 4,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 120,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8580",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "uid": "01cbc8052223426f",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Dell/results/R760xa_H100NVL_PCIe_94GBx4_TRT/bert-99.9/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 43.0343,
    "Accuracy_div_100": 0.43034,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R760xa_H100NVL_PCIe_94GBx4_TRT/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Dell",
    "Platform": "R760xa_H100NVL_PCIe_94GBx4_TRT",
    "Result": 7191.41,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge R760xa (4xH100 NVL, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 4,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 120,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8580",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "uid": "0b3e6bea3ce7437f",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Dell/results/R760xa_H100NVL_PCIe_94GBx4_TRT/gptj-99/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 90.35676151551918,
    "Accuracy_div_100": 0.90357,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R760xa_H100_PCIe_80GBx4_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Dell",
    "Platform": "R760xa_H100_PCIe_80GBx4_TRT",
    "Result": 23238.4,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge R760xa (4x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "a6e76244565348e3",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Dell/results/R760xa_H100_PCIe_80GBx4_TRT/bert-99/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 90.23535730698143,
    "Accuracy_div_100": 0.90235,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R760xa_L40Sx4_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Dell",
    "Platform": "R760xa_L40Sx4_TRT",
    "Result": 13903.8,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge R760xa (4x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 4,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6338 CPU @ 2.00GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.1",
    "uid": "e8cee3ba85b04c95",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Dell/results/R760xa_L40Sx4_TRT/bert-99/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 90.35676151551918,
    "Accuracy_div_100": 0.90357,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R760_H100_PCIe_80GBx2_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Dell",
    "Platform": "R760_H100_PCIe_80GBx2_TRT",
    "Result": 11758.6,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge R760 (2xH100_PCIe_80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 2,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 120,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8580",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "uid": "fbd5882aa06b4c63",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Dell/results/R760_H100_PCIe_80GBx2_TRT/bert-99/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 90.97056894987658,
    "Accuracy_div_100": 0.90971,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R760_H100_PCIe_80GBx2_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Dell",
    "Platform": "R760_H100_PCIe_80GBx2_TRT",
    "Result": 10138.8,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge R760 (2xH100_PCIe_80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 2,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 120,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8580",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "uid": "9cdd5f90d6d54f80",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Dell/results/R760_H100_PCIe_80GBx2_TRT/bert-99.9/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 43.1259,
    "Accuracy_div_100": 0.43126,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R760_H100_PCIe_80GBx2_TRT/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Dell",
    "Platform": "R760_H100_PCIe_80GBx2_TRT",
    "Result": 3317.08,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge R760 (2xH100_PCIe_80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 2,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 120,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8580",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "uid": "870b3af61f8d417a",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Dell/results/R760_H100_PCIe_80GBx2_TRT/gptj-99/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 43.1259,
    "Accuracy_div_100": 0.43126,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R760_H100_PCIe_80GBx2_TRT/gptj-99.9/Offline",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "Dell",
    "Platform": "R760_H100_PCIe_80GBx2_TRT",
    "Result": 3317.08,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge R760 (2xH100_PCIe_80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 2,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 120,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8580",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "uid": "36dee4009b424e3a",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Dell/results/R760_H100_PCIe_80GBx2_TRT/gptj-99.9/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 90.35676151551918,
    "Accuracy_div_100": 0.90357,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Dell",
    "Platform": "XE8640_H100_SXM_80GBx4_TRT",
    "Result": 35524.8,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE8640 (4x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "uid": "7df62a28ada94e3a",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/bert-99/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 90.97056894987658,
    "Accuracy_div_100": 0.90971,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Dell",
    "Platform": "XE8640_H100_SXM_80GBx4_TRT",
    "Result": 31392.5,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE8640 (4x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "uid": "ac15b08029874a37",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/bert-99.9/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 43.1017,
    "Accuracy_div_100": 0.43102,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Dell",
    "Platform": "XE8640_H100_SXM_80GBx4_TRT",
    "Result": 9966.79,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE8640 (4x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "uid": "5e539d72cb6a46cf",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/gptj-99/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 43.1017,
    "Accuracy_div_100": 0.43102,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/gptj-99.9/Offline",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "Dell",
    "Platform": "XE8640_H100_SXM_80GBx4_TRT",
    "Result": 9966.79,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE8640 (4x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "uid": "9a53fb24962148b8",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/gptj-99.9/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 44.5354,
    "Accuracy_div_100": 0.44535,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/llama2-70b-99/Offline",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "Dell",
    "Platform": "XE8640_H100_SXM_80GBx4_TRT",
    "Result": 10699.6,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE8640 (4x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "uid": "637e18faa4794a23",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/llama2-70b-99/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 44.5354,
    "Accuracy_div_100": 0.44535,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/llama2-70b-99.9/Offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "Dell",
    "Platform": "XE8640_H100_SXM_80GBx4_TRT",
    "Result": 10699.6,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE8640 (4x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "uid": "0ac89c6fea7f454a",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/llama2-70b-99.9/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 90.35676151551918,
    "Accuracy_div_100": 0.90357,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9640_H100_SXM_80GBx4_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Dell",
    "Platform": "XE9640_H100_SXM_80GBx4_TRT",
    "Result": 36051.2,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE9640 (4x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "uid": "d0e49e407597450f",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Dell/results/XE9640_H100_SXM_80GBx4_TRT/bert-99/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 90.97056894987658,
    "Accuracy_div_100": 0.90971,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9640_H100_SXM_80GBx4_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Dell",
    "Platform": "XE9640_H100_SXM_80GBx4_TRT",
    "Result": 31412.4,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE9640 (4x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "uid": "19c4b0dfdd5c4b8d",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Dell/results/XE9640_H100_SXM_80GBx4_TRT/bert-99.9/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 44.6147,
    "Accuracy_div_100": 0.44615,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9640_H100_SXM_80GBx4_TRT/llama2-70b-99/Offline",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "Dell",
    "Platform": "XE9640_H100_SXM_80GBx4_TRT",
    "Result": 10594.1,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE9640 (4x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "uid": "60ff801b290748b7",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Dell/results/XE9640_H100_SXM_80GBx4_TRT/llama2-70b-99/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 44.6147,
    "Accuracy_div_100": 0.44615,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9640_H100_SXM_80GBx4_TRT/llama2-70b-99.9/Offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "Dell",
    "Platform": "XE9640_H100_SXM_80GBx4_TRT",
    "Result": 10594.1,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE9640 (4x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "uid": "93b36dc251c74776",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Dell/results/XE9640_H100_SXM_80GBx4_TRT/llama2-70b-99.9/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 90.35676151551918,
    "Accuracy_div_100": 0.90357,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9680_H100_SXM_80GBx8_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Dell",
    "Platform": "XE9680_H100_SXM_80GBx8_TRT",
    "Result": 70594,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE9680 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "uid": "fe160975df8b43a1",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Dell/results/XE9680_H100_SXM_80GBx8_TRT/bert-99/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 90.97056894987658,
    "Accuracy_div_100": 0.90971,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9680_H100_SXM_80GBx8_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Dell",
    "Platform": "XE9680_H100_SXM_80GBx8_TRT",
    "Result": 61736.4,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE9680 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "uid": "63443d341faf4234",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Dell/results/XE9680_H100_SXM_80GBx8_TRT/bert-99.9/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 44.6153,
    "Accuracy_div_100": 0.44615,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9680_H100_SXM_80GBx8_TRT/llama2-70b-99/Offline",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "Dell",
    "Platform": "XE9680_H100_SXM_80GBx8_TRT",
    "Result": 24086.7,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE9680 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "uid": "6474abada9c840d0",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Dell/results/XE9680_H100_SXM_80GBx8_TRT/llama2-70b-99/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 44.6153,
    "Accuracy_div_100": 0.44615,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9680_H100_SXM_80GBx8_TRT/llama2-70b-99.9/Offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "Dell",
    "Platform": "XE9680_H100_SXM_80GBx8_TRT",
    "Result": 24086.7,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE9680 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "uid": "0cce4d7cd96348af",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Dell/results/XE9680_H100_SXM_80GBx8_TRT/llama2-70b-99.9/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 90.35676151551918,
    "Accuracy_div_100": 0.90357,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9680_H200_SXM_141GBx8_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Dell",
    "Platform": "XE9680_H200_SXM_141GBx8_TRT",
    "Result": 73791,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE9680 (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 52,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "uid": "d848ab7dbdec4029",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Dell/results/XE9680_H200_SXM_141GBx8_TRT/bert-99/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 90.97056894987658,
    "Accuracy_div_100": 0.90971,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9680_H200_SXM_141GBx8_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Dell",
    "Platform": "XE9680_H200_SXM_141GBx8_TRT",
    "Result": 65322.6,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE9680 (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 52,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "uid": "dcd04d3f794a4f38",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Dell/results/XE9680_H200_SXM_141GBx8_TRT/bert-99.9/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 43.1017,
    "Accuracy_div_100": 0.43102,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9680_H200_SXM_141GBx8_TRT/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Dell",
    "Platform": "XE9680_H200_SXM_141GBx8_TRT",
    "Result": 20238.4,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE9680 (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 52,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "uid": "0e65f74031584fdd",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Dell/results/XE9680_H200_SXM_141GBx8_TRT/gptj-99/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 43.1017,
    "Accuracy_div_100": 0.43102,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9680_H200_SXM_141GBx8_TRT/gptj-99.9/Offline",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "Dell",
    "Platform": "XE9680_H200_SXM_141GBx8_TRT",
    "Result": 20238.4,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE9680 (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 52,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "uid": "400e927e49304e23",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Dell/results/XE9680_H200_SXM_141GBx8_TRT/gptj-99.9/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 44.5883,
    "Accuracy_div_100": 0.44588,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9680_H200_SXM_141GBx8_TRT/llama2-70b-99/Offline",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "Dell",
    "Platform": "XE9680_H200_SXM_141GBx8_TRT",
    "Result": 32124.3,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE9680 (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 52,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "uid": "fb71df497e894d4b",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Dell/results/XE9680_H200_SXM_141GBx8_TRT/llama2-70b-99/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 44.5883,
    "Accuracy_div_100": 0.44588,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9680_H200_SXM_141GBx8_TRT/llama2-70b-99.9/Offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "Dell",
    "Platform": "XE9680_H200_SXM_141GBx8_TRT",
    "Result": 32124.3,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE9680 (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 52,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "uid": "30a7737587894a47",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Dell/results/XE9680_H200_SXM_141GBx8_TRT/llama2-70b-99.9/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 44.5205,
    "Accuracy_div_100": 0.4452,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9680_MI300X_192GBx8/llama2-70b-99/Offline",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "Dell",
    "Platform": "XE9680_MI300X_192GBx8",
    "Result": 22677.6,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE9680 (8x MI300X_192GB, vLLM)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "AMD MI300X-NPS1-SPX-192GB-750W",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "vLLM 0.4.3+rocm614, PyTorch 2.3.0, ROCm 6.1.0",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8460Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "uid": "18a1391eb47145c8",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Dell/results/XE9680_MI300X_192GBx8/llama2-70b-99/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 44.5205,
    "Accuracy_div_100": 0.4452,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9680_MI300X_192GBx8/llama2-70b-99.9/Offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "Dell",
    "Platform": "XE9680_MI300X_192GBx8",
    "Result": 22677.6,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE9680 (8x MI300X_192GB, vLLM)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "AMD MI300X-NPS1-SPX-192GB-750W",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "vLLM 0.4.3+rocm614, PyTorch 2.3.0, ROCm 6.1.0",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8460Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "uid": "a2d7a66fbe214b25",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Dell/results/XE9680_MI300X_192GBx8/llama2-70b-99.9/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 43.1387,
    "Accuracy_div_100": 0.43139,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Fujitsu/results/CDI_L40Sx8_TRT/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Fujitsu",
    "Platform": "CDI_L40Sx8_TRT",
    "Result": 6911.78,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "PRIMERGY CDI (8x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6454S",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "uid": "9520dc88af964726",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Fujitsu/results/CDI_L40Sx8_TRT/gptj-99/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 43.1387,
    "Accuracy_div_100": 0.43139,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Fujitsu/results/CDI_L40Sx8_TRT/gptj-99.9/Offline",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "Fujitsu",
    "Platform": "CDI_L40Sx8_TRT",
    "Result": 6911.78,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "PRIMERGY CDI (8x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6454S",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "uid": "caee91d6e2064116",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Fujitsu/results/CDI_L40Sx8_TRT/gptj-99.9/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 44.5205,
    "Accuracy_div_100": 0.4452,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Fujitsu/results/CDI_L40Sx8_TRT/llama2-70b-99/Offline",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "Fujitsu",
    "Platform": "CDI_L40Sx8_TRT",
    "Result": 3717.74,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "PRIMERGY CDI (8x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6454S",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "uid": "56b6feff43b14eae",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Fujitsu/results/CDI_L40Sx8_TRT/llama2-70b-99/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 44.5205,
    "Accuracy_div_100": 0.4452,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Fujitsu/results/CDI_L40Sx8_TRT/llama2-70b-99.9/Offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "Fujitsu",
    "Platform": "CDI_L40Sx8_TRT",
    "Result": 3717.74,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "PRIMERGY CDI (8x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6454S",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "uid": "470719dc86294dcb",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Fujitsu/results/CDI_L40Sx8_TRT/llama2-70b-99.9/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 90.35676151551918,
    "Accuracy_div_100": 0.90357,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Fujitsu/results/GX2560M7_H100_SXM_80GBx4_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Fujitsu",
    "Platform": "GX2560M7_H100_SXM_80GBx4_TRT",
    "Result": 36110.8,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "GX2560M7_H100_SXM_80GBx4 (4x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "e02efc3c074340f5",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Fujitsu/results/GX2560M7_H100_SXM_80GBx4_TRT/bert-99/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 90.97056894987658,
    "Accuracy_div_100": 0.90971,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Fujitsu/results/GX2560M7_H100_SXM_80GBx4_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Fujitsu",
    "Platform": "GX2560M7_H100_SXM_80GBx4_TRT",
    "Result": 31575.2,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "GX2560M7_H100_SXM_80GBx4 (4x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "de5ccbff71474094",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Fujitsu/results/GX2560M7_H100_SXM_80GBx4_TRT/bert-99.9/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 43.1017,
    "Accuracy_div_100": 0.43102,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Fujitsu/results/GX2560M7_H100_SXM_80GBx4_TRT/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Fujitsu",
    "Platform": "GX2560M7_H100_SXM_80GBx4_TRT",
    "Result": 9960.74,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "GX2560M7_H100_SXM_80GBx4 (4x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "390b5b94f0db4289",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Fujitsu/results/GX2560M7_H100_SXM_80GBx4_TRT/gptj-99/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 43.1017,
    "Accuracy_div_100": 0.43102,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Fujitsu/results/GX2560M7_H100_SXM_80GBx4_TRT/gptj-99.9/Offline",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "Fujitsu",
    "Platform": "GX2560M7_H100_SXM_80GBx4_TRT",
    "Result": 9960.74,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "GX2560M7_H100_SXM_80GBx4 (4x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "83df34d3421945c0",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Fujitsu/results/GX2560M7_H100_SXM_80GBx4_TRT/gptj-99.9/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 44.6147,
    "Accuracy_div_100": 0.44615,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Fujitsu/results/GX2560M7_H100_SXM_80GBx4_TRT/llama2-70b-99/Offline",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "Fujitsu",
    "Platform": "GX2560M7_H100_SXM_80GBx4_TRT",
    "Result": 10133.3,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "GX2560M7_H100_SXM_80GBx4 (4x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "186cf96f0059403d",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Fujitsu/results/GX2560M7_H100_SXM_80GBx4_TRT/llama2-70b-99/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 44.6147,
    "Accuracy_div_100": 0.44615,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Fujitsu/results/GX2560M7_H100_SXM_80GBx4_TRT/llama2-70b-99.9/Offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "Fujitsu",
    "Platform": "GX2560M7_H100_SXM_80GBx4_TRT",
    "Result": 10133.3,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "GX2560M7_H100_SXM_80GBx4 (4x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "98b9ad01ce6f4f72",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Fujitsu/results/GX2560M7_H100_SXM_80GBx4_TRT/llama2-70b-99.9/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 90.35676151551918,
    "Accuracy_div_100": 0.90357,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/GigaComputing/results/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "GigaComputing",
    "Platform": "GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT",
    "Result": 73765.6,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "GIGABYTE G593-SD1",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "uid": "07e96d8dee77497c",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/GigaComputing/results/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT/bert-99/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 90.97056894987658,
    "Accuracy_div_100": 0.90971,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/GigaComputing/results/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "GigaComputing",
    "Platform": "GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT",
    "Result": 64368.8,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "GIGABYTE G593-SD1",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "uid": "1836296becf64e7e",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/GigaComputing/results/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT/bert-99.9/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 43.1017,
    "Accuracy_div_100": 0.43102,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/GigaComputing/results/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "GigaComputing",
    "Platform": "GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT",
    "Result": 20041.3,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "GIGABYTE G593-SD1",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "uid": "c362be288c254e9f",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/GigaComputing/results/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT/gptj-99/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 43.1017,
    "Accuracy_div_100": 0.43102,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/GigaComputing/results/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT/gptj-99.9/Offline",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "GigaComputing",
    "Platform": "GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT",
    "Result": 20041.3,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "GIGABYTE G593-SD1",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "uid": "57a55989f4a94eff",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/GigaComputing/results/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT/gptj-99.9/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 44.5884,
    "Accuracy_div_100": 0.44588,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/GigaComputing/results/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT/llama2-70b-99/Offline",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "GigaComputing",
    "Platform": "GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT",
    "Result": 31263.8,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "GIGABYTE G593-SD1",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "uid": "7fdd31d687154887",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/GigaComputing/results/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT/llama2-70b-99/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 44.5884,
    "Accuracy_div_100": 0.44588,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/GigaComputing/results/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT/llama2-70b-99.9/Offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "GigaComputing",
    "Platform": "GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT",
    "Result": 31263.8,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "GIGABYTE G593-SD1",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "uid": "e90b4d6301be4dd2",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/GigaComputing/results/GIGABYTE_G593_SD1_H200_SXM_141GBx8_TRT/llama2-70b-99.9/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 44.6156,
    "Accuracy_div_100": 0.44616,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Google/results/DGX-H100_H100-SXM-80GBx8_TRT/llama2-70b-99/Offline",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "Google",
    "Platform": "DGX-H100_H100-SXM-80GBx8_TRT",
    "Result": 24133.7,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX H100 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8481C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "uid": "535e4ba98df34018",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Google/results/DGX-H100_H100-SXM-80GBx8_TRT/llama2-70b-99/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 44.6156,
    "Accuracy_div_100": 0.44616,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Google/results/DGX-H100_H100-SXM-80GBx8_TRT/llama2-70b-99.9/Offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "Google",
    "Platform": "DGX-H100_H100-SXM-80GBx8_TRT",
    "Result": 24133.7,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX H100 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8481C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "uid": "a229e3c166b14619",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Google/results/DGX-H100_H100-SXM-80GBx8_TRT/llama2-70b-99.9/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 90.53885196505269,
    "Accuracy_div_100": 0.90539,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/1-node-2S-EMR-PyTorch/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "HPE",
    "Platform": "1-node-2S-EMR-PyTorch",
    "Result": 1608.87,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "HPE ProLiant DL380 Gen11",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 0,
    "errors": 0,
    "framework": "PyTorch",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "N/A",
    "number_of_nodes": 1,
    "operating_system": "CentOS Stream 8",
    "uid": "3b8abd80c6704d13",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/HPE/results/1-node-2S-EMR-PyTorch/bert-99/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 43.0958,
    "Accuracy_div_100": 0.43096,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/1-node-2S-EMR-PyTorch/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "HPE",
    "Platform": "1-node-2S-EMR-PyTorch",
    "Result": 251.298,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "HPE ProLiant DL380 Gen11",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 0,
    "errors": 0,
    "framework": "PyTorch",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "N/A",
    "number_of_nodes": 1,
    "operating_system": "CentOS Stream 8",
    "uid": "cb04256ed3fe4e81",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/HPE/results/1-node-2S-EMR-PyTorch/gptj-99/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 43.1017,
    "Accuracy_div_100": 0.43102,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/HPE/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "HPE",
    "Platform": "GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT",
    "Result": 2632.76,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "HPE ProLiant Compute DL384 Gen12 (1x GH200-144GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 144GB",
    "accelerators_per_node": 1,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "NVIDIA GH200 144GB HBM3e",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2",
    "uid": "1cad957d54764783",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/HPE/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/gptj-99/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 43.1017,
    "Accuracy_div_100": 0.43102,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/HPE/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/gptj-99.9/Offline",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "HPE",
    "Platform": "GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT",
    "Result": 2632.76,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "HPE ProLiant Compute DL384 Gen12 (1x GH200-144GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 144GB",
    "accelerators_per_node": 1,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "NVIDIA GH200 144GB HBM3e",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2",
    "uid": "34d764fbb13341de",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/HPE/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/gptj-99.9/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 44.5631,
    "Accuracy_div_100": 0.44563,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/HPE/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/llama2-70b-99/Offline",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "HPE",
    "Platform": "GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT",
    "Result": 4084.3,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "HPE ProLiant Compute DL384 Gen12 (1x GH200-144GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 144GB",
    "accelerators_per_node": 1,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "NVIDIA GH200 144GB HBM3e",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2",
    "uid": "a17b69d283424565",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/HPE/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/llama2-70b-99/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 44.5631,
    "Accuracy_div_100": 0.44563,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/HPE/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/llama2-70b-99.9/Offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "HPE",
    "Platform": "GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT",
    "Result": 4084.3,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "HPE ProLiant Compute DL384 Gen12 (1x GH200-144GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 144GB",
    "accelerators_per_node": 1,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "NVIDIA GH200 144GB HBM3e",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2",
    "uid": "3adb02cda2c24f6d",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/HPE/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/llama2-70b-99.9/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 90.35676151551918,
    "Accuracy_div_100": 0.90357,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/HPE_Cray_XD670_H100_SXM_80GBx8_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "HPE",
    "Platform": "HPE_Cray_XD670_H100_SXM_80GBx8_TRT",
    "Result": 71560.3,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "HPE Cray XD670 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "22.04.4 LTS",
    "uid": "f87c3cf04b3943ab",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/HPE/results/HPE_Cray_XD670_H100_SXM_80GBx8_TRT/bert-99/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 90.97056894987658,
    "Accuracy_div_100": 0.90971,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/HPE_Cray_XD670_H100_SXM_80GBx8_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "HPE",
    "Platform": "HPE_Cray_XD670_H100_SXM_80GBx8_TRT",
    "Result": 62207.3,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "HPE Cray XD670 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "22.04.4 LTS",
    "uid": "0a7326529d1a4c2d",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/HPE/results/HPE_Cray_XD670_H100_SXM_80GBx8_TRT/bert-99.9/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 43.0343,
    "Accuracy_div_100": 0.43034,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/HPE_Cray_XD670_H100_SXM_80GBx8_TRT/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "HPE",
    "Platform": "HPE_Cray_XD670_H100_SXM_80GBx8_TRT",
    "Result": 19751.9,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "HPE Cray XD670 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "22.04.4 LTS",
    "uid": "c98fc936909a45ff",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/HPE/results/HPE_Cray_XD670_H100_SXM_80GBx8_TRT/gptj-99/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 44.535,
    "Accuracy_div_100": 0.44535,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/HPE_Cray_XD670_H100_SXM_80GBx8_TRT/llama2-70b-99/Offline",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "HPE",
    "Platform": "HPE_Cray_XD670_H100_SXM_80GBx8_TRT",
    "Result": 24528.3,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "HPE Cray XD670 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "22.04.4 LTS",
    "uid": "36b0fe9365c74120",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/HPE/results/HPE_Cray_XD670_H100_SXM_80GBx8_TRT/llama2-70b-99/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 44.535,
    "Accuracy_div_100": 0.44535,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/HPE_Cray_XD670_H100_SXM_80GBx8_TRT/llama2-70b-99.9/Offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "HPE",
    "Platform": "HPE_Cray_XD670_H100_SXM_80GBx8_TRT",
    "Result": 24424.7,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "HPE Cray XD670 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "22.04.4 LTS",
    "uid": "a19cd237a68d46b5",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/HPE/results/HPE_Cray_XD670_H100_SXM_80GBx8_TRT/llama2-70b-99.9/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 90.35676151551918,
    "Accuracy_div_100": 0.90357,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "HPE",
    "Platform": "HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT",
    "Result": 23937.5,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "HPE ProLiant DL380a Gen11 (4x H100-NVL-94GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 4,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "INTEL(R) XEON(R) GOLD 6530",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "uid": "d36f343b88da447d",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/HPE/results/HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT/bert-99/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 90.97056894987658,
    "Accuracy_div_100": 0.90971,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "HPE",
    "Platform": "HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT",
    "Result": 20087.7,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "HPE ProLiant DL380a Gen11 (4x H100-NVL-94GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 4,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "INTEL(R) XEON(R) GOLD 6530",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "uid": "d6749f7db05f4880",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/HPE/results/HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT/bert-99.9/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 44.6113,
    "Accuracy_div_100": 0.44611,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT/llama2-70b-99/Offline",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "HPE",
    "Platform": "HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT",
    "Result": 8858.78,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "HPE ProLiant DL380a Gen11 (4x H100-NVL-94GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 4,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "INTEL(R) XEON(R) GOLD 6530",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "uid": "b8e14550b65343be",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/HPE/results/HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT/llama2-70b-99/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 44.6113,
    "Accuracy_div_100": 0.44611,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT/llama2-70b-99.9/Offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "HPE",
    "Platform": "HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT",
    "Result": 8858.78,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "HPE ProLiant DL380a Gen11 (4x H100-NVL-94GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 4,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "INTEL(R) XEON(R) GOLD 6530",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "uid": "9bef3ae4a259457b",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/HPE/results/HPE_ProLiant_DL380a_H100_NVL_94GBx4_TRT/llama2-70b-99.9/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 90.15707103092267,
    "Accuracy_div_100": 0.90157,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/HPE_ProLiant_DL380a_L40S_PCIe_48GBx4_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "HPE",
    "Platform": "HPE_ProLiant_DL380a_L40S_PCIe_48GBx4_TRT",
    "Result": 12981.8,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "HPE ProLiant DL380a Gen11 (4x L40S-PCIe-48GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 4,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 60,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8580",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "uid": "7f94913ed4644a20",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/HPE/results/HPE_ProLiant_DL380a_L40S_PCIe_48GBx4_TRT/bert-99/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 90.53885196505269,
    "Accuracy_div_100": 0.90539,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Intel/results/1-node-2S-EMR-PyTorch/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Intel",
    "Platform": "1-node-2S-EMR-PyTorch",
    "Result": 1666.82,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "1-node-2S-EMR-PyTorch",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 0,
    "errors": 0,
    "framework": "PyTorch",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54Q-2U. N/A",
    "number_of_nodes": 1,
    "operating_system": "CentOS Stream 9",
    "uid": "cad954ba47d6421c",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Intel/results/1-node-2S-EMR-PyTorch/bert-99/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 43.0704,
    "Accuracy_div_100": 0.4307,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Intel/results/1-node-2S-EMR-PyTorch/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Intel",
    "Platform": "1-node-2S-EMR-PyTorch",
    "Result": 254.724,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "1-node-2S-EMR-PyTorch",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 0,
    "errors": 0,
    "framework": "PyTorch",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54Q-2U. N/A",
    "number_of_nodes": 1,
    "operating_system": "CentOS Stream 9",
    "uid": "c1bdd114e1a64741",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Intel/results/1-node-2S-EMR-PyTorch/gptj-99/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 90.53885196505269,
    "Accuracy_div_100": 0.90539,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/Intel/results/1-node-2S-GNR-PyTorch/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Intel",
    "Platform": "1-node-2S-GNR-PyTorch",
    "Result": 3024.03,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "1-node-2S-GNR-PyTorch",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 0,
    "errors": 0,
    "framework": "PyTorch",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 128,
    "host_processor_model_name": "INTEL(R) XEON(R) 6980P",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Intel AvenueCity. N/A",
    "number_of_nodes": 1,
    "operating_system": "CentOS Stream 9",
    "uid": "230dad79d77d46d5",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Intel/results/1-node-2S-GNR-PyTorch/bert-99/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 43.082,
    "Accuracy_div_100": 0.43082,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/Intel/results/1-node-2S-GNR-PyTorch/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Intel",
    "Platform": "1-node-2S-GNR-PyTorch",
    "Result": 498.316,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "1-node-2S-GNR-PyTorch",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 0,
    "errors": 0,
    "framework": "PyTorch",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 128,
    "host_processor_model_name": "INTEL(R) XEON(R) 6980P",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Intel AvenueCity. N/A",
    "number_of_nodes": 1,
    "operating_system": "CentOS Stream 9",
    "uid": "dd025e2b3143404b",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Intel/results/1-node-2S-GNR-PyTorch/gptj-99/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 44.6047,
    "Accuracy_div_100": 0.44605,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/JuniperNetworks/results/DGX-H100_H100-SXM-80GBx16_TRT/llama2-70b-99/Offline",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "JuniperNetworks",
    "Platform": "DGX-H100_H100-SXM-80GBx16_TRT",
    "Result": 41672.4,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "2x8xH100-SXM-80GB",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 112,
    "host_processor_model_name": "AMD EPYC 7763 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 2,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "88e9f40f49294d7d",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/JuniperNetworks/results/DGX-H100_H100-SXM-80GBx16_TRT/llama2-70b-99/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 44.6047,
    "Accuracy_div_100": 0.44605,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/JuniperNetworks/results/DGX-H100_H100-SXM-80GBx16_TRT/llama2-70b-99.9/Offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "JuniperNetworks",
    "Platform": "DGX-H100_H100-SXM-80GBx16_TRT",
    "Result": 41672.4,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "2x8xH100-SXM-80GB",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 112,
    "host_processor_model_name": "AMD EPYC 7763 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 2,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "1224fd66a1e94f48",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/JuniperNetworks/results/DGX-H100_H100-SXM-80GBx16_TRT/llama2-70b-99.9/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 44.6048,
    "Accuracy_div_100": 0.44605,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/JuniperNetworks/results/DGX-H100_H100-SXM-80GBx32_TRT/llama2-70b-99/Offline",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "JuniperNetworks",
    "Platform": "DGX-H100_H100-SXM-80GBx32_TRT",
    "Result": 82749.6,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "4x8xH100-SXM-80GB",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 112,
    "host_processor_model_name": "AMD EPYC 7763 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 4,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "12018ed3242344a4",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/JuniperNetworks/results/DGX-H100_H100-SXM-80GBx32_TRT/llama2-70b-99/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 44.6048,
    "Accuracy_div_100": 0.44605,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/JuniperNetworks/results/DGX-H100_H100-SXM-80GBx32_TRT/llama2-70b-99.9/Offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "JuniperNetworks",
    "Platform": "DGX-H100_H100-SXM-80GBx32_TRT",
    "Result": 82749.6,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "4x8xH100-SXM-80GB",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 112,
    "host_processor_model_name": "AMD EPYC 7763 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 4,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "fc87921e661e464c",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/JuniperNetworks/results/DGX-H100_H100-SXM-80GBx32_TRT/llama2-70b-99.9/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 90.35676151551918,
    "Accuracy_div_100": 0.90357,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/H200_SXM_141GBx8_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Lenovo",
    "Platform": "H200_SXM_141GBx8_TRT",
    "Result": 70319.1,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "ThinkSystem SR685a V3(8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.5",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "AMD EPYC 9454",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "uid": "b28b0dbc388f4213",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Lenovo/results/H200_SXM_141GBx8_TRT/bert-99/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 90.97056894987658,
    "Accuracy_div_100": 0.90971,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/H200_SXM_141GBx8_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Lenovo",
    "Platform": "H200_SXM_141GBx8_TRT",
    "Result": 62102.5,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "ThinkSystem SR685a V3(8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.5",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "AMD EPYC 9454",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "uid": "77d702199b49427d",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Lenovo/results/H200_SXM_141GBx8_TRT/bert-99.9/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 43.0773,
    "Accuracy_div_100": 0.43077,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/H200_SXM_141GBx8_TRT/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Lenovo",
    "Platform": "H200_SXM_141GBx8_TRT",
    "Result": 19859.2,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "ThinkSystem SR685a V3(8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.5",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "AMD EPYC 9454",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "uid": "2e255cf997904b35",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Lenovo/results/H200_SXM_141GBx8_TRT/gptj-99/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 44.6249,
    "Accuracy_div_100": 0.44625,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/H200_SXM_141GBx8_TRT/llama2-70b-99/Offline",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "Lenovo",
    "Platform": "H200_SXM_141GBx8_TRT",
    "Result": 31917,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "ThinkSystem SR685a V3(8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.5",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "AMD EPYC 9454",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "uid": "1fdf1cd9836b426d",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Lenovo/results/H200_SXM_141GBx8_TRT/llama2-70b-99/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 44.6249,
    "Accuracy_div_100": 0.44625,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/H200_SXM_141GBx8_TRT/llama2-70b-99.9/Offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "Lenovo",
    "Platform": "H200_SXM_141GBx8_TRT",
    "Result": 31917,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "ThinkSystem SR685a V3(8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.5",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "AMD EPYC 9454",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "uid": "d8ae8b9c02a94537",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Lenovo/results/H200_SXM_141GBx8_TRT/llama2-70b-99.9/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 90.35676151551918,
    "Accuracy_div_100": 0.90357,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/Lenovo_8xH200_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Lenovo",
    "Platform": "Lenovo_8xH200_TRT",
    "Result": 70369.8,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "ThinkSystem SR680a V3 (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8568Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "uid": "c8941942cfe04a32",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Lenovo/results/Lenovo_8xH200_TRT/bert-99/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 90.97056894987658,
    "Accuracy_div_100": 0.90971,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/Lenovo_8xH200_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Lenovo",
    "Platform": "Lenovo_8xH200_TRT",
    "Result": 64983.6,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "ThinkSystem SR680a V3 (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8568Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "uid": "8bc26d3cc9fc4eca",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Lenovo/results/Lenovo_8xH200_TRT/bert-99.9/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 43.102,
    "Accuracy_div_100": 0.43102,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/Lenovo_8xH200_TRT/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Lenovo",
    "Platform": "Lenovo_8xH200_TRT",
    "Result": 20552.1,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "ThinkSystem SR680a V3 (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8568Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "uid": "9115e6d0fa9d4419",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Lenovo/results/Lenovo_8xH200_TRT/gptj-99/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 43.102,
    "Accuracy_div_100": 0.43102,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/Lenovo_8xH200_TRT/gptj-99.9/Offline",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "Lenovo",
    "Platform": "Lenovo_8xH200_TRT",
    "Result": 20552.1,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "ThinkSystem SR680a V3 (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8568Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "uid": "52a434e21dc6462c",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Lenovo/results/Lenovo_8xH200_TRT/gptj-99.9/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 44.5884,
    "Accuracy_div_100": 0.44588,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/Lenovo_8xH200_TRT/llama2-70b-99/Offline",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "Lenovo",
    "Platform": "Lenovo_8xH200_TRT",
    "Result": 31973.7,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "ThinkSystem SR680a V3 (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8568Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "uid": "ce17da9acbeb40dc",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Lenovo/results/Lenovo_8xH200_TRT/llama2-70b-99/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 44.5884,
    "Accuracy_div_100": 0.44588,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/Lenovo_8xH200_TRT/llama2-70b-99.9/Offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "Lenovo",
    "Platform": "Lenovo_8xH200_TRT",
    "Result": 31973.7,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "ThinkSystem SR680a V3 (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8568Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "uid": "8332fe44f7874265",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Lenovo/results/Lenovo_8xH200_TRT/llama2-70b-99.9/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 90.23535730698143,
    "Accuracy_div_100": 0.90235,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/SR650_V3_3xL40S_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Lenovo",
    "Platform": "SR650_V3_3xL40S_TRT",
    "Result": 9480.82,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "ThinkSystem SR650 V3 (3x NVIDIA L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 3,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.5",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6438N",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "uid": "844a31f0c265417e",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Lenovo/results/SR650_V3_3xL40S_TRT/bert-99/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 43.0516,
    "Accuracy_div_100": 0.43052,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/SR650_V3_3xL40S_TRT/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Lenovo",
    "Platform": "SR650_V3_3xL40S_TRT",
    "Result": 2593.65,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "ThinkSystem SR650 V3 (3x NVIDIA L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 3,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.5",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6438N",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "uid": "cceecc59861d445b",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Lenovo/results/SR650_V3_3xL40S_TRT/gptj-99/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 90.35676151551918,
    "Accuracy_div_100": 0.90357,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/SR675_V3_8xH100_NVL_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Lenovo",
    "Platform": "SR675_V3_8xH100_NVL_TRT",
    "Result": 47655.3,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "ThinkSystem SR675 V3 (8x H100-NVL-94GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.5",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 84,
    "host_processor_model_name": "AMD EPYC 9634 84-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "uid": "c9a4039403504f65",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Lenovo/results/SR675_V3_8xH100_NVL_TRT/bert-99/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 43.0394,
    "Accuracy_div_100": 0.43039,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/SR675_V3_8xH100_NVL_TRT/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Lenovo",
    "Platform": "SR675_V3_8xH100_NVL_TRT",
    "Result": 14073.6,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "ThinkSystem SR675 V3 (8x H100-NVL-94GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.5",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 84,
    "host_processor_model_name": "AMD EPYC 9634 84-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "uid": "72f6621544b648ab",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Lenovo/results/SR675_V3_8xH100_NVL_TRT/gptj-99/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 44.5999,
    "Accuracy_div_100": 0.446,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/SR675_V3_8xH100_NVL_TRT/llama2-70b-99/Offline",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "Lenovo",
    "Platform": "SR675_V3_8xH100_NVL_TRT",
    "Result": 15875.8,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "ThinkSystem SR675 V3 (8x H100-NVL-94GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.5",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 84,
    "host_processor_model_name": "AMD EPYC 9634 84-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "uid": "2eb7482bae9c45bf",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Lenovo/results/SR675_V3_8xH100_NVL_TRT/llama2-70b-99/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 44.5999,
    "Accuracy_div_100": 0.446,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/SR675_V3_8xH100_NVL_TRT/llama2-70b-99.9/Offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "Lenovo",
    "Platform": "SR675_V3_8xH100_NVL_TRT",
    "Result": 15875.8,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "ThinkSystem SR675 V3 (8x H100-NVL-94GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-NVL-94GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.5",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 84,
    "host_processor_model_name": "AMD EPYC 9634 84-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "uid": "8afab9c5deb34f29",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Lenovo/results/SR675_V3_8xH100_NVL_TRT/llama2-70b-99.9/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 44.3329,
    "Accuracy_div_100": 0.44333,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NeuralMagic/results/vLLM_8xL40S-reference-cpu-pytorch-v2.3.1-default_config/llama2-70b-99/offline",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "NeuralMagic",
    "Platform": "vLLM_8xL40S-reference-cpu-pytorch-v2.3.1-default_config",
    "Result": 948.198,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Crusoe Cloud L40S (8x L40S PCIe, vLLM, FP8)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "vLLM 0.5.2",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 4,
    "host_processor_model_name": "AMD EPYC 9254 24-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.3.3. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-5.15.0-94-generic-glibc2.35)",
    "uid": "a1400194a1394984",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/NeuralMagic/results/vLLM_8xL40S-reference-cpu-pytorch-v2.3.1-default_config/llama2-70b-99/offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 44.7986,
    "Accuracy_div_100": 0.44799,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/B200-SXM-180GBx1_TRT/llama2-70b-99/Offline",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "NVIDIA",
    "Platform": "B200-SXM-180GBx1_TRT",
    "Result": 11264.4,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA B200 (1x B200-SXM-180GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA B200-SXM-180GB",
    "accelerators_per_node": 1,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.1.0, CUDA 12.7",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 12,
    "host_processor_model_name": "Intel(R) Xeon(R) Silver 4410Y",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "B200 TGP 1000W. Private git hash for code and TRTLLM were used to generate the preview results. The git hash are eba031f9e2e6cf3d1cdce0549511d27adf01a3f4 and 4e5b175cc80320789ba6846ced80a87f25e70fb2",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "uid": "bc8882524ab64641",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/NVIDIA/results/B200-SXM-180GBx1_TRT/llama2-70b-99/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 44.7986,
    "Accuracy_div_100": 0.44799,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/B200-SXM-180GBx1_TRT/llama2-70b-99.9/Offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "NVIDIA",
    "Platform": "B200-SXM-180GBx1_TRT",
    "Result": 11264.4,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA B200 (1x B200-SXM-180GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA B200-SXM-180GB",
    "accelerators_per_node": 1,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.1.0, CUDA 12.7",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 12,
    "host_processor_model_name": "Intel(R) Xeon(R) Silver 4410Y",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "B200 TGP 1000W. Private git hash for code and TRTLLM were used to generate the preview results. The git hash are eba031f9e2e6cf3d1cdce0549511d27adf01a3f4 and 4e5b175cc80320789ba6846ced80a87f25e70fb2",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "uid": "471180cdd28f4140",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/NVIDIA/results/B200-SXM-180GBx1_TRT/llama2-70b-99.9/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 43.1017,
    "Accuracy_div_100": 0.43102,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "NVIDIA",
    "Platform": "DGX-H100_H100-SXM-80GBx8_TRT",
    "Result": 19739.8,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX H100 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "uid": "f940faef55a7460f",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT/gptj-99/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 43.1017,
    "Accuracy_div_100": 0.43102,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT/gptj-99.9/Offline",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "NVIDIA",
    "Platform": "DGX-H100_H100-SXM-80GBx8_TRT",
    "Result": 19739.8,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX H100 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "uid": "8de76fca309e4caa",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT/gptj-99.9/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 44.5437,
    "Accuracy_div_100": 0.44544,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT/llama2-70b-99/Offline",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "NVIDIA",
    "Platform": "DGX-H100_H100-SXM-80GBx8_TRT",
    "Result": 24524.9,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX H100 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "uid": "9f721ce2fd80456a",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT/llama2-70b-99/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 44.5437,
    "Accuracy_div_100": 0.44544,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT/llama2-70b-99.9/Offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "NVIDIA",
    "Platform": "DGX-H100_H100-SXM-80GBx8_TRT",
    "Result": 24524.9,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX H100 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "uid": "3b3e933aaeac43a5",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT/llama2-70b-99.9/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 43.1017,
    "Accuracy_div_100": 0.43102,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "NVIDIA",
    "Platform": "GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT",
    "Result": 2627.69,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA GH200 NVL2 Platform (1x GH200-144GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 144GB",
    "accelerators_per_node": 1,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "NVIDIA GH200 144GB HBM3e",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2",
    "uid": "15c20af9803d43db",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/NVIDIA/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/gptj-99/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 43.1017,
    "Accuracy_div_100": 0.43102,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/gptj-99.9/Offline",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "NVIDIA",
    "Platform": "GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT",
    "Result": 2627.69,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA GH200 NVL2 Platform (1x GH200-144GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 144GB",
    "accelerators_per_node": 1,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "NVIDIA GH200 144GB HBM3e",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2",
    "uid": "eb27d3a448d0499d",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/NVIDIA/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/gptj-99.9/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 44.5631,
    "Accuracy_div_100": 0.44563,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/llama2-70b-99/Offline",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "NVIDIA",
    "Platform": "GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT",
    "Result": 4067.52,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA GH200 NVL2 Platform (1x GH200-144GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 144GB",
    "accelerators_per_node": 1,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "NVIDIA GH200 144GB HBM3e",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2",
    "uid": "79a3ae1f737c4742",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/NVIDIA/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/llama2-70b-99/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 44.5631,
    "Accuracy_div_100": 0.44563,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/llama2-70b-99.9/Offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "NVIDIA",
    "Platform": "GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT",
    "Result": 4067.52,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA GH200 NVL2 Platform (1x GH200-144GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 144GB",
    "accelerators_per_node": 1,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "NVIDIA GH200 144GB HBM3e",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2",
    "uid": "d298374608954bcc",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/NVIDIA/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/llama2-70b-99.9/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 44.5631,
    "Accuracy_div_100": 0.44563,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GB-CTSx1_TRT/llama2-70b-99/Offline",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GB-CTSx1_TRT",
    "Result": 4487.88,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA H200 (1x H200-SXM-141GB-CTS, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB-CTS",
    "accelerators_per_node": 1,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 1000W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "uid": "7a53ba9aa81446fb",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/NVIDIA/results/H200-SXM-141GB-CTSx1_TRT/llama2-70b-99/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 44.5631,
    "Accuracy_div_100": 0.44563,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GB-CTSx1_TRT/llama2-70b-99.9/Offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GB-CTSx1_TRT",
    "Result": 4487.88,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA H200 (1x H200-SXM-141GB-CTS, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB-CTS",
    "accelerators_per_node": 1,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 1000W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "uid": "41e47e5ed5f947fa",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/NVIDIA/results/H200-SXM-141GB-CTSx1_TRT/llama2-70b-99.9/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 44.5631,
    "Accuracy_div_100": 0.44563,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GB-CTSx8_TRT/llama2-70b-99/Offline",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GB-CTSx8_TRT",
    "Result": 34864.2,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA H200 (8x H200-SXM-141GB-CTS, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB-CTS",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 1000W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "uid": "f9935225ae87458f",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/NVIDIA/results/H200-SXM-141GB-CTSx8_TRT/llama2-70b-99/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 44.5631,
    "Accuracy_div_100": 0.44563,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GB-CTSx8_TRT/llama2-70b-99.9/Offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GB-CTSx8_TRT",
    "Result": 34864.2,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA H200 (8x H200-SXM-141GB-CTS, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB-CTS",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 1000W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "uid": "c7a72c82427848b5",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/NVIDIA/results/H200-SXM-141GB-CTSx8_TRT/llama2-70b-99.9/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 43.1017,
    "Accuracy_div_100": 0.43102,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GBx1_TRT/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GBx1_TRT",
    "Result": 2579.51,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA H200 (1x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 1,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "uid": "7996d5bfe89a4e30",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/NVIDIA/results/H200-SXM-141GBx1_TRT/gptj-99/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 43.1017,
    "Accuracy_div_100": 0.43102,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GBx1_TRT/gptj-99.9/Offline",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GBx1_TRT",
    "Result": 2579.51,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA H200 (1x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 1,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "uid": "4156044e9a4142e9",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/NVIDIA/results/H200-SXM-141GBx1_TRT/gptj-99.9/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 90.35676151551918,
    "Accuracy_div_100": 0.90357,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GBx8_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GBx8_TRT",
    "Result": 73309.5,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA H200 (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "uid": "740dd3b51227460d",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/NVIDIA/results/H200-SXM-141GBx8_TRT/bert-99/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 90.97056894987658,
    "Accuracy_div_100": 0.90971,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GBx8_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GBx8_TRT",
    "Result": 63950.4,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA H200 (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "uid": "fc9a7ea3471843ac",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/NVIDIA/results/H200-SXM-141GBx8_TRT/bert-99.9/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 43.1017,
    "Accuracy_div_100": 0.43102,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GBx8_TRT/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GBx8_TRT",
    "Result": 20086.1,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA H200 (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "uid": "94c73333b27b4d4b",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/NVIDIA/results/H200-SXM-141GBx8_TRT/gptj-99/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 43.1017,
    "Accuracy_div_100": 0.43102,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GBx8_TRT/gptj-99.9/Offline",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GBx8_TRT",
    "Result": 20086.1,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA H200 (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "uid": "bcdb8043f5364acf",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/NVIDIA/results/H200-SXM-141GBx8_TRT/gptj-99.9/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 44.563,
    "Accuracy_div_100": 0.44563,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GBx8_TRT/llama2-70b-99/Offline",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GBx8_TRT",
    "Result": 31302.7,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA H200 (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "uid": "da2c76e1cb27433e",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/NVIDIA/results/H200-SXM-141GBx8_TRT/llama2-70b-99/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 44.563,
    "Accuracy_div_100": 0.44563,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GBx8_TRT/llama2-70b-99.9/Offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GBx8_TRT",
    "Result": 31302.7,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA H200 (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "uid": "9a9682242e1b4554",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/NVIDIA/results/H200-SXM-141GBx8_TRT/llama2-70b-99.9/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 44.5638,
    "Accuracy_div_100": 0.44564,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GBx8_TRT_Triton/llama2-70b-99/Offline",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GBx8_TRT_Triton",
    "Result": 31059.3,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA H200 (8x H200-SXM-141GB, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "uid": "89c55a28907e405a",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/NVIDIA/results/H200-SXM-141GBx8_TRT_Triton/llama2-70b-99/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 44.5638,
    "Accuracy_div_100": 0.44564,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GBx8_TRT_Triton/llama2-70b-99.9/Offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GBx8_TRT_Triton",
    "Result": 31059.3,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA H200 (8x H200-SXM-141GB, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "uid": "69d299b82f4349bc",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/NVIDIA/results/H200-SXM-141GBx8_TRT_Triton/llama2-70b-99.9/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 90.35676151551918,
    "Accuracy_div_100": 0.90357,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Oracle/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Oracle",
    "Platform": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "Result": 9864.25,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA GH200-GraceHopper-Superchip (1x GH200-96GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 96GB",
    "accelerators_per_node": 1,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "NVIDIA MGX Reference Platform;",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2",
    "uid": "3fab78d4f9fa461c",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Oracle/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/bert-99/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 90.97056894987658,
    "Accuracy_div_100": 0.90971,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Oracle/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Oracle",
    "Platform": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "Result": 8779.27,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA GH200-GraceHopper-Superchip (1x GH200-96GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 96GB",
    "accelerators_per_node": 1,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "NVIDIA MGX Reference Platform;",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2",
    "uid": "db0497877d484b95",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Oracle/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/bert-99.9/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 43.0794,
    "Accuracy_div_100": 0.43079,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Oracle/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Oracle",
    "Platform": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "Result": 2695.15,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA GH200-GraceHopper-Superchip (1x GH200-96GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 96GB",
    "accelerators_per_node": 1,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "NVIDIA MGX Reference Platform;",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2",
    "uid": "eb6479175c3b44a0",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Oracle/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/gptj-99/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 43.0794,
    "Accuracy_div_100": 0.43079,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Oracle/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/gptj-99.9/Offline",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "Oracle",
    "Platform": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "Result": 2695.15,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA GH200-GraceHopper-Superchip (1x GH200-96GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 96GB",
    "accelerators_per_node": 1,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "NVIDIA MGX Reference Platform;",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2",
    "uid": "faeaa7fffdbd4ac1",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Oracle/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/gptj-99.9/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 90.53885196505269,
    "Accuracy_div_100": 0.90539,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/1-node-2S-EMR-PyTorch/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "1-node-2S-EMR-PyTorch",
    "Result": 1612.03,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "1-node-2S-EMR-PyTorch",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": "N/A",
    "compliance": 0,
    "errors": 0,
    "framework": "PyTorch",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54X-1U",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.2",
    "uid": "d515c362f9464ab0",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Quanta_Cloud_Technology/results/1-node-2S-EMR-PyTorch/bert-99/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 43.0482,
    "Accuracy_div_100": 0.43048,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/1-node-2S-EMR-PyTorch/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "1-node-2S-EMR-PyTorch",
    "Result": 239.034,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "1-node-2S-EMR-PyTorch",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": "N/A",
    "compliance": 0,
    "errors": 0,
    "framework": "PyTorch",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54X-1U",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.2",
    "uid": "453f242c49b948ce",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Quanta_Cloud_Technology/results/1-node-2S-EMR-PyTorch/gptj-99/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 90.35676151551918,
    "Accuracy_div_100": 0.90357,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/D54U_3U_H100_PCIe_80GBx4_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "D54U_3U_H100_PCIe_80GBx4_TRT",
    "Result": 23131.4,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "D54U_3U_H100_PCIe_80GBx4_TRT",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0.19, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 52,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54U-3U",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.2",
    "uid": "08a55e09ccd64808",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Quanta_Cloud_Technology/results/D54U_3U_H100_PCIe_80GBx4_TRT/bert-99/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 90.23535730698143,
    "Accuracy_div_100": 0.90235,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/D54U_3U_L40S_PCIe_48GBx4_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "D54U_3U_L40S_PCIe_48GBx4_TRT",
    "Result": 13248.3,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "D54U_3U_L40S_PCIe_48GBx4_TRT",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 4,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0.19, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 44,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8458P",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54U-3U",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.2",
    "uid": "49b9b96525834ca6",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Quanta_Cloud_Technology/results/D54U_3U_L40S_PCIe_48GBx4_TRT/bert-99/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 43.0913,
    "Accuracy_div_100": 0.43091,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/D54U_3U_L40S_PCIe_48GBx4_TRT/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "D54U_3U_L40S_PCIe_48GBx4_TRT",
    "Result": 3463.19,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "D54U_3U_L40S_PCIe_48GBx4_TRT",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 4,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0.19, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 44,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8458P",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54U-3U",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.2",
    "uid": "4c79b7535fbe4b26",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Quanta_Cloud_Technology/results/D54U_3U_L40S_PCIe_48GBx4_TRT/gptj-99/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 43.0913,
    "Accuracy_div_100": 0.43091,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/D54U_3U_L40S_PCIe_48GBx4_TRT/gptj-99.9/Offline",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "D54U_3U_L40S_PCIe_48GBx4_TRT",
    "Result": 3463.19,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "D54U_3U_L40S_PCIe_48GBx4_TRT",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 4,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0.19, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 44,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8458P",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54U-3U",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.2",
    "uid": "f2286ea2de5f4a4a",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Quanta_Cloud_Technology/results/D54U_3U_L40S_PCIe_48GBx4_TRT/gptj-99.9/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 90.35676151551918,
    "Accuracy_div_100": 0.90357,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "Result": 9196.01,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 96GB",
    "accelerators_per_node": 1,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0.19, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "QuantaGrid S74G-2U",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.3",
    "uid": "58b96edffd9d4d17",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Quanta_Cloud_Technology/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/bert-99/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 90.97056894987658,
    "Accuracy_div_100": 0.90971,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "Result": 8092.46,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 96GB",
    "accelerators_per_node": 1,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0.19, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "QuantaGrid S74G-2U",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.3",
    "uid": "5528cf97551d4f55",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Quanta_Cloud_Technology/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/bert-99.9/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 43.0658,
    "Accuracy_div_100": 0.43066,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "Result": 2803.72,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 96GB",
    "accelerators_per_node": 1,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0.19, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "QuantaGrid S74G-2U",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.3",
    "uid": "4d89288b75f84b96",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Quanta_Cloud_Technology/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/gptj-99/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 43.0658,
    "Accuracy_div_100": 0.43066,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/gptj-99.9/Offline",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "Result": 2803.72,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 96GB",
    "accelerators_per_node": 1,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0.19, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "QuantaGrid S74G-2U",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.3",
    "uid": "1010bbaa7ea747fb",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Quanta_Cloud_Technology/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/gptj-99.9/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 44.5991,
    "Accuracy_div_100": 0.44599,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/llama2-70b-99.9/Offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "Result": 3114.03,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 96GB",
    "accelerators_per_node": 1,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0.19, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "QuantaGrid S74G-2U",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.3",
    "uid": "57798cea86114b89",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Quanta_Cloud_Technology/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/llama2-70b-99.9/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 44.6053,
    "Accuracy_div_100": 0.44605,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/RedHat/results/L40S-RedHat-OpenShift/llama2-70b-99.9/Offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "RedHat",
    "Platform": "L40S-RedHat-OpenShift",
    "Result": 1717.77,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "L40S-RedHat-OpenShift",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 4,
    "compliance": 0,
    "errors": 0,
    "framework": "CUDA 12.2",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 112,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480CL",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "NVIDIA L40S-48GB. Red Hat OpenShift Container Platform 4.14 + OpenShift AI",
    "number_of_nodes": 1,
    "operating_system": "Red Hat Enterprise Linux CoreOS release 4.14",
    "uid": "7d2d31de81b84719",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/RedHat/results/L40S-RedHat-OpenShift/llama2-70b-99.9/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 90.53885196505269,
    "Accuracy_div_100": 0.90539,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/1-node-2S-EMR-PyTorch/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Supermicro",
    "Platform": "1-node-2S-EMR-PyTorch",
    "Result": 1595.13,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "1-node-2S-EMR-PyTorch",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 0,
    "errors": 0,
    "framework": "PyTorch",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54Q-2U. N/A",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 8.10",
    "uid": "fef8f31838a5448d",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Supermicro/results/1-node-2S-EMR-PyTorch/bert-99/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 90.35676151551918,
    "Accuracy_div_100": 0.90357,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Supermicro",
    "Platform": "AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT",
    "Result": 72222.5,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AS-4125GS-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9654",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "uid": "f5b9ec7f03544c86",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Supermicro/results/AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT/bert-99/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 90.97056894987658,
    "Accuracy_div_100": 0.90971,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Supermicro",
    "Platform": "AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT",
    "Result": 61490.8,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AS-4125GS-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9654",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "uid": "b19f835cf04843d5",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Supermicro/results/AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT/bert-99.9/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 43.1017,
    "Accuracy_div_100": 0.43102,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Supermicro",
    "Platform": "AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT",
    "Result": 19539.2,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AS-4125GS-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9654",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "uid": "bebb253a540f4b9f",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Supermicro/results/AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT/gptj-99/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 43.1017,
    "Accuracy_div_100": 0.43102,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT/gptj-99.9/Offline",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "Supermicro",
    "Platform": "AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT",
    "Result": 19539.2,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AS-4125GS-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9654",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "uid": "06db4c82b8a546a1",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Supermicro/results/AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT/gptj-99.9/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 44.6153,
    "Accuracy_div_100": 0.44615,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT/llama2-70b-99/Offline",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "Supermicro",
    "Platform": "AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT",
    "Result": 24216.8,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AS-4125GS-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9654",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "uid": "f3cf5ebb55e44e02",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Supermicro/results/AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT/llama2-70b-99/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 44.6153,
    "Accuracy_div_100": 0.44615,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT/llama2-70b-99.9/Offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "Supermicro",
    "Platform": "AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT",
    "Result": 24216.8,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AS-4125GS-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9654",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "uid": "89deafc61dd94d9c",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Supermicro/results/AS_4125GS_TNHR2_LCC_H100_SXM_80GBx8_TRT/llama2-70b-99.9/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 90.35676151551918,
    "Accuracy_div_100": 0.90357,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Supermicro",
    "Platform": "AS_8125GS_TNHR_H100_SXM_80GBx8_TRT",
    "Result": 71861.8,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AS-8125GS-TNHR (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "AMD EPYC 9474F",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "uid": "82d707fc10ae42a4",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Supermicro/results/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT/bert-99/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 90.97056894987658,
    "Accuracy_div_100": 0.90971,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Supermicro",
    "Platform": "AS_8125GS_TNHR_H100_SXM_80GBx8_TRT",
    "Result": 61128,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AS-8125GS-TNHR (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "AMD EPYC 9474F",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "uid": "a91b322e40fb4417",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Supermicro/results/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT/bert-99.9/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 43.1017,
    "Accuracy_div_100": 0.43102,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Supermicro",
    "Platform": "AS_8125GS_TNHR_H100_SXM_80GBx8_TRT",
    "Result": 19418.9,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AS-8125GS-TNHR (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "AMD EPYC 9474F",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "uid": "4c4d959b1cbe44d8",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Supermicro/results/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT/gptj-99/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 43.1017,
    "Accuracy_div_100": 0.43102,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT/gptj-99.9/Offline",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "Supermicro",
    "Platform": "AS_8125GS_TNHR_H100_SXM_80GBx8_TRT",
    "Result": 19418.9,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AS-8125GS-TNHR (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "AMD EPYC 9474F",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "uid": "5a0930dff8464fad",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Supermicro/results/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT/gptj-99.9/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 44.6153,
    "Accuracy_div_100": 0.44615,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT/llama2-70b-99/Offline",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "Supermicro",
    "Platform": "AS_8125GS_TNHR_H100_SXM_80GBx8_TRT",
    "Result": 24011.7,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AS-8125GS-TNHR (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "AMD EPYC 9474F",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "uid": "9032fb3d109e4745",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Supermicro/results/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT/llama2-70b-99/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 44.6153,
    "Accuracy_div_100": 0.44615,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT/llama2-70b-99.9/Offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "Supermicro",
    "Platform": "AS_8125GS_TNHR_H100_SXM_80GBx8_TRT",
    "Result": 24011.7,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AS-8125GS-TNHR (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "AMD EPYC 9474F",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "uid": "8fce04fe76eb4930",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Supermicro/results/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT/llama2-70b-99.9/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 43.0794,
    "Accuracy_div_100": 0.43079,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Supermicro",
    "Platform": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "Result": 2659.47,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA GH200-GraceHopper-Superchip (1x GH200-96GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 96GB",
    "accelerators_per_node": 1,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "NVIDIA MGX Reference Platform;",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2",
    "uid": "b6c3296cf22741ae",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Supermicro/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/gptj-99/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 43.0794,
    "Accuracy_div_100": 0.43079,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/gptj-99.9/Offline",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "Supermicro",
    "Platform": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "Result": 2659.47,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA GH200-GraceHopper-Superchip (1x GH200-96GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GH200 Grace Hopper Superchip 96GB",
    "accelerators_per_node": 1,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "NVIDIA MGX Reference Platform;",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2",
    "uid": "6cc275f1b0474a4f",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Supermicro/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/gptj-99.9/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 90.35676151551918,
    "Accuracy_div_100": 0.90357,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Supermicro",
    "Platform": "SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT",
    "Result": 72876,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "SYS-421GE-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8570",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "uid": "e3f50113e7724f57",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Supermicro/results/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT/bert-99/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 90.97056894987658,
    "Accuracy_div_100": 0.90971,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Supermicro",
    "Platform": "SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT",
    "Result": 62036.9,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "SYS-421GE-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8570",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "uid": "2f93e60021cb44b8",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Supermicro/results/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT/bert-99.9/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 43.1017,
    "Accuracy_div_100": 0.43102,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Supermicro",
    "Platform": "SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT",
    "Result": 19808.2,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "SYS-421GE-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8570",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "uid": "8e5aacb106b549d0",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Supermicro/results/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT/gptj-99/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 43.1017,
    "Accuracy_div_100": 0.43102,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT/gptj-99.9/Offline",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "Supermicro",
    "Platform": "SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT",
    "Result": 19808.2,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "SYS-421GE-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8570",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "uid": "7305c976660e4905",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Supermicro/results/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT/gptj-99.9/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 44.6153,
    "Accuracy_div_100": 0.44615,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT/llama2-70b-99/Offline",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "Supermicro",
    "Platform": "SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT",
    "Result": 24180.6,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "SYS-421GE-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8570",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "uid": "940a36b80bb54cbe",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Supermicro/results/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT/llama2-70b-99/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 44.6153,
    "Accuracy_div_100": 0.44615,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT/llama2-70b-99.9/Offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "Supermicro",
    "Platform": "SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT",
    "Result": 24180.6,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "SYS-421GE-TNHR2-LCC (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8570",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "uid": "bf7bd053b2224d2a",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Supermicro/results/SYS_421GE_TNHR2_LCC_H100_SXM_80GBx8_TRT/llama2-70b-99.9/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 90.35676151551918,
    "Accuracy_div_100": 0.90357,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Supermicro",
    "Platform": "SYS_821GE_TNHR_H100_SXM_80GBx8_TRT",
    "Result": 71806.2,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "SYS-821GE-TNHR (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "uid": "8adcb51ab61f4ede",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/bert-99/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 90.97056894987658,
    "Accuracy_div_100": 0.90971,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Supermicro",
    "Platform": "SYS_821GE_TNHR_H100_SXM_80GBx8_TRT",
    "Result": 62153.9,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "SYS-821GE-TNHR (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "uid": "ef53c088fd264ec8",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/bert-99.9/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 43.1017,
    "Accuracy_div_100": 0.43102,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Supermicro",
    "Platform": "SYS_821GE_TNHR_H100_SXM_80GBx8_TRT",
    "Result": 19803.6,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "SYS-821GE-TNHR (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "uid": "0ff6d661a772495a",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/gptj-99/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 43.1017,
    "Accuracy_div_100": 0.43102,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/gptj-99.9/Offline",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "Supermicro",
    "Platform": "SYS_821GE_TNHR_H100_SXM_80GBx8_TRT",
    "Result": 19803.6,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "SYS-821GE-TNHR (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "uid": "b6a5bb9d652145e3",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/gptj-99.9/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 44.6153,
    "Accuracy_div_100": 0.44615,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/llama2-70b-99/Offline",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "Supermicro",
    "Platform": "SYS_821GE_TNHR_H100_SXM_80GBx8_TRT",
    "Result": 24140.1,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "SYS-821GE-TNHR (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "uid": "56635ee58d1d4015",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/llama2-70b-99/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 44.6153,
    "Accuracy_div_100": 0.44615,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/llama2-70b-99.9/Offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "Supermicro",
    "Platform": "SYS_821GE_TNHR_H100_SXM_80GBx8_TRT",
    "Result": 24140.1,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "SYS-821GE-TNHR (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS",
    "uid": "0c67eec0144542d6",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/llama2-70b-99.9/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 90.35676151551918,
    "Accuracy_div_100": 0.90357,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Sustainable_Metal_Cloud/results/SMC_H100_SXM_80GBX8_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Sustainable_Metal_Cloud",
    "Platform": "SMC_H100_SXM_80GBX8_TRT",
    "Result": 69043.2,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "SMC H100 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8462Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "uid": "cd2ae6e264f34178",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Sustainable_Metal_Cloud/results/SMC_H100_SXM_80GBX8_TRT/bert-99/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 90.97056894987658,
    "Accuracy_div_100": 0.90971,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Sustainable_Metal_Cloud/results/SMC_H100_SXM_80GBX8_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Sustainable_Metal_Cloud",
    "Platform": "SMC_H100_SXM_80GBX8_TRT",
    "Result": 61778.8,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "SMC H100 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8462Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "uid": "23f5cad206534e9f",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Sustainable_Metal_Cloud/results/SMC_H100_SXM_80GBX8_TRT/bert-99.9/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 43.0394,
    "Accuracy_div_100": 0.43039,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Sustainable_Metal_Cloud/results/SMC_H100_SXM_80GBX8_TRT/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Sustainable_Metal_Cloud",
    "Platform": "SMC_H100_SXM_80GBX8_TRT",
    "Result": 19711.1,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "SMC H100 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8462Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "uid": "43c0edfac6d54d65",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Sustainable_Metal_Cloud/results/SMC_H100_SXM_80GBX8_TRT/gptj-99/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 44.5768,
    "Accuracy_div_100": 0.44577,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Sustainable_Metal_Cloud/results/SMC_H100_SXM_80GBX8_TRT/llama2-70b-99/Offline",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "Sustainable_Metal_Cloud",
    "Platform": "SMC_H100_SXM_80GBX8_TRT",
    "Result": 24459.6,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "SMC H100 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8462Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "uid": "1815e83364284d61",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Sustainable_Metal_Cloud/results/SMC_H100_SXM_80GBX8_TRT/llama2-70b-99/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 44.5768,
    "Accuracy_div_100": 0.44577,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Sustainable_Metal_Cloud/results/SMC_H100_SXM_80GBX8_TRT/llama2-70b-99.9/Offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "Sustainable_Metal_Cloud",
    "Platform": "SMC_H100_SXM_80GBX8_TRT",
    "Result": 24459.6,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "SMC H100 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 0,
    "errors": 0,
    "framework": "TensorRT 10.2.0, CUDA 12.4",
    "git_url": "https://github.com/mlcommons/submissions_inference_v4.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8462Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4",
    "uid": "21acde386976467e",
    "url": "https://github.com/mlcommons/submissions_inference_v4.1/tree/master/closed/Sustainable_Metal_Cloud/results/SMC_H100_SXM_80GBX8_TRT/llama2-70b-99.9/Offline",
    "version": "v4.1"
  },
  {
    "Accuracy": 90.35676151551918,
    "Accuracy_div_100": 0.90357,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC8000_E11P_H100x8_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "ASUSTeK",
    "Platform": "ESC8000_E11P_H100x8_TRT",
    "Result": 45227.2,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "ESC8000-E11P (8x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Data bandwidth for GPU-PCIe: 504 GB/s; PCIe-NIC: 126 GB/s",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "5e48c454c9be4a24",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/ASUSTeK/results/ESC8000_E11P_H100x8_TRT/bert-99/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.97056894987658,
    "Accuracy_div_100": 0.90971,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC8000_E11P_H100x8_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "ASUSTeK",
    "Platform": "ESC8000_E11P_H100x8_TRT",
    "Result": 38577.4,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "ESC8000-E11P (8x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Data bandwidth for GPU-PCIe: 504 GB/s; PCIe-NIC: 126 GB/s",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "3224f5848dea431e",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/ASUSTeK/results/ESC8000_E11P_H100x8_TRT/bert-99.9/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.23848090934187,
    "Accuracy_div_100": 0.90238,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC8000_E11_L40Sx8_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "ASUSTeK",
    "Platform": "ESC8000_E11_L40Sx8_TRT",
    "Result": 26077.4,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "ESC8000-E11 (8x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6442Y",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Data bandwidth for GPU-PCIe: 252 GB/s; PCIe-NIC: 63 GB/s",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "e642c7221cca4a5e",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/ASUSTeK/results/ESC8000_E11_L40Sx8_TRT/bert-99/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.90267854577986,
    "Accuracy_div_100": 0.90903,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC8000_E11_L40Sx8_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "ASUSTeK",
    "Platform": "ESC8000_E11_L40Sx8_TRT",
    "Result": 13709.5,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "ESC8000-E11 (8x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6442Y",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Data bandwidth for GPU-PCIe: 252 GB/s; PCIe-NIC: 63 GB/s",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "ce6a2f5619254d32",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/ASUSTeK/results/ESC8000_E11_L40Sx8_TRT/bert-99.9/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 43.0915,
    "Accuracy_div_100": 0.43092,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC8000_E11_L40Sx8_TRT/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "ASUSTeK",
    "Platform": "ESC8000_E11_L40Sx8_TRT",
    "Result": 99.0366,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "ESC8000-E11 (8x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6442Y",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Data bandwidth for GPU-PCIe: 252 GB/s; PCIe-NIC: 63 GB/s",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "b24ac1e8a88547e6",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/ASUSTeK/results/ESC8000_E11_L40Sx8_TRT/gptj-99/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 43.0911,
    "Accuracy_div_100": 0.43091,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC8000_E11_L40Sx8_TRT/gptj-99.9/Offline",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "ASUSTeK",
    "Platform": "ESC8000_E11_L40Sx8_TRT",
    "Result": 98.3628,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "ESC8000-E11 (8x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6442Y",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Data bandwidth for GPU-PCIe: 252 GB/s; PCIe-NIC: 63 GB/s",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "10701d3e59db4695",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/ASUSTeK/results/ESC8000_E11_L40Sx8_TRT/gptj-99.9/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.23848090934187,
    "Accuracy_div_100": 0.90238,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC8000_E11_L4x8_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "ASUSTeK",
    "Platform": "ESC8000_E11_L4x8_TRT",
    "Result": 7597.71,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "ESC8000-E11 (8x L4, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6442Y",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Data bandwidth for GPU-PCIe: 252 GB/s; PCIe-NIC: 15.7 GB/s",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "ab9304c27730454f",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/ASUSTeK/results/ESC8000_E11_L4x8_TRT/bert-99/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.9257447258943,
    "Accuracy_div_100": 0.90926,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC8000_E11_L4x8_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "ASUSTeK",
    "Platform": "ESC8000_E11_L4x8_TRT",
    "Result": 5189.92,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "ESC8000-E11 (8x L4, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6442Y",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Data bandwidth for GPU-PCIe: 252 GB/s; PCIe-NIC: 15.7 GB/s",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "d9a5236bce0e4e19",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/ASUSTeK/results/ESC8000_E11_L4x8_TRT/bert-99.9/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 43.0417,
    "Accuracy_div_100": 0.43042,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Azure/results/NC_H100_v5_TRT/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Azure",
    "Platform": "NC_H100_v5_TRT",
    "Result": 43.5639,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NC80adis_H100_v5 (2x H100-NVL-94GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100 NVL",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 80,
    "host_processor_model_name": "AMD EPYC 9V84 96-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6 LTS",
    "uid": "3919348c4f864dcd",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Azure/results/NC_H100_v5_TRT/gptj-99/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 44.6035,
    "Accuracy_div_100": 0.44603,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Azure/results/NC_H100_v5_TRT/llama2-70b-99.9/Offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "Azure",
    "Platform": "NC_H100_v5_TRT",
    "Result": 3900.33,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NC80adis_H100_v5 (2x H100-NVL-94GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100 NVL",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 80,
    "host_processor_model_name": "AMD EPYC 9V84 96-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6 LTS",
    "uid": "5a85173070f94df7",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Azure/results/NC_H100_v5_TRT/llama2-70b-99.9/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 42.8468,
    "Accuracy_div_100": 0.42847,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Cisco/results/1-node-2S-C240M7-EMR-PyTorch-INT4/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Cisco",
    "Platform": "1-node-2S-C240M7-EMR-PyTorch-INT4",
    "Result": 2.38751,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "1-node-2S-C240M7-EMR-PyTorch-INT4",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "PyTorch",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "N/A",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "uid": "4ecbf05cd8534de2",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Cisco/results/1-node-2S-C240M7-EMR-PyTorch-INT4/gptj-99/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.53885196505269,
    "Accuracy_div_100": 0.90539,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Cisco/results/1-node-2S-C240M7-EMR-PyTorch-INT8/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Cisco",
    "Platform": "1-node-2S-C240M7-EMR-PyTorch-INT8",
    "Result": 1693.17,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "1-node-2S-C240M7-EMR-PyTorch-INT8",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "PyTorch",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "N/A",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "uid": "6e8dbae7bd95443a",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Cisco/results/1-node-2S-C240M7-EMR-PyTorch-INT8/bert-99/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.07162918629223,
    "Accuracy_div_100": 0.90072,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/CTuning/results/Cirrascale_4xQAIC_AI_100-kilt-qaic-glow-vdefault-default_config/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "CTuning",
    "Platform": "Cirrascale_4xQAIC_AI_100-kilt-qaic-glow-vdefault-default_config",
    "Result": 3150.72,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Cirrascale_QUAD_AI100 (4x QAIC Pro)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "Qualcomm Cloud AI 100 Pro",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.10.0",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "Intel(R) Xeon(R) Silver 4314 CPU @ 2.40GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-5.15.0-94-generic-glibc2.35)",
    "uid": "4cf7bb0c18744dc5",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/CTuning/results/Cirrascale_4xQAIC_AI_100-kilt-qaic-glow-vdefault-default_config/bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.53885196505269,
    "Accuracy_div_100": 0.90539,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/CTuning/results/GATEOverflow_Intel_Saphhire_Rapids-intel-cpu-pytorch-vdefault-default_config/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "CTuning",
    "Platform": "GATEOverflow_Intel_Saphhire_Rapids-intel-cpu-pytorch-vdefault-default_config",
    "Result": 370.045,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "GATEOverflow Intel Saphhire Rapids",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Intel inference implementation with CM API, Pytorch v1.12",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.2.0-39-generic-glibc2.35)",
    "uid": "1020da439f554416",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/CTuning/results/GATEOverflow_Intel_Saphhire_Rapids-intel-cpu-pytorch-vdefault-default_config/bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.2147015680108,
    "Accuracy_div_100": 0.90215,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R750xa_A100_PCIe_80GBx4_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Dell",
    "Platform": "R750xa_A100_PCIe_80GBx4_TRT",
    "Result": 12669.6,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge R750xa (4x A100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6338 CPU @ 2.00GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.1",
    "uid": "ff060525d9924001",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Dell/results/R750xa_A100_PCIe_80GBx4_TRT/bert-99/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.87751170441149,
    "Accuracy_div_100": 0.90878,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R750xa_A100_PCIe_80GBx4_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Dell",
    "Platform": "R750xa_A100_PCIe_80GBx4_TRT",
    "Result": 6491.26,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge R750xa (4x A100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6338 CPU @ 2.00GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.1",
    "uid": "aafb0381c3b0466f",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Dell/results/R750xa_A100_PCIe_80GBx4_TRT/bert-99.9/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.23535730698143,
    "Accuracy_div_100": 0.90235,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R760xa_L40Sx4_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Dell",
    "Platform": "R760xa_L40Sx4_TRT",
    "Result": 13538.2,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge R760xa (4x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6338 CPU @ 2.00GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.1",
    "uid": "dec1c44abcb0430e",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Dell/results/R760xa_L40Sx4_TRT/bert-99/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.90267854577986,
    "Accuracy_div_100": 0.90903,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R760xa_L40Sx4_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Dell",
    "Platform": "R760xa_L40Sx4_TRT",
    "Result": 7308.19,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge R760xa (4x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6338 CPU @ 2.00GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.1",
    "uid": "c9c93333631040d3",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Dell/results/R760xa_L40Sx4_TRT/bert-99.9/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 43.0999,
    "Accuracy_div_100": 0.431,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R760xa_L40Sx4_TRT/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Dell",
    "Platform": "R760xa_L40Sx4_TRT",
    "Result": 50.4519,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge R760xa (4x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6338 CPU @ 2.00GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.1",
    "uid": "8cbd9b0060c1480b",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Dell/results/R760xa_L40Sx4_TRT/gptj-99/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 43.0999,
    "Accuracy_div_100": 0.431,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R760xa_L40Sx4_TRT/gptj-99.9/Offline",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "Dell",
    "Platform": "R760xa_L40Sx4_TRT",
    "Result": 50.4519,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge R760xa (4x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6338 CPU @ 2.00GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.1",
    "uid": "4fe43a3939b043c9",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Dell/results/R760xa_L40Sx4_TRT/gptj-99.9/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.53885196505269,
    "Accuracy_div_100": 0.90539,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R760_CPU/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Dell",
    "Platform": "R760_CPU",
    "Result": 1701.39,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge R760",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "PyTorch",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "INT4 for GPT-J, Mixed for RNN-T and INT8 for all other models",
    "number_of_nodes": 1,
    "operating_system": "CentOS Stream 8",
    "uid": "d26af29da60b4154",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Dell/results/R760_CPU/bert-99/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 42.8685,
    "Accuracy_div_100": 0.42868,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R760_CPU/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Dell",
    "Platform": "R760_CPU",
    "Result": 2.37168,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge R760",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "PyTorch",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "INT4 for GPT-J, Mixed for RNN-T and INT8 for all other models",
    "number_of_nodes": 1,
    "operating_system": "CentOS Stream 8",
    "uid": "87469a05bdd94dd0",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Dell/results/R760_CPU/gptj-99/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.23535730698143,
    "Accuracy_div_100": 0.90235,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R760_L40Sx2_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Dell",
    "Platform": "R760_L40Sx2_TRT",
    "Result": 6603.3,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge R760 (2x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.3",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 120,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8580",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "uid": "c4fcae31e44f4304",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Dell/results/R760_L40Sx2_TRT/bert-99/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.87587312162347,
    "Accuracy_div_100": 0.90876,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R760_L40Sx2_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Dell",
    "Platform": "R760_L40Sx2_TRT",
    "Result": 3507.67,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge R760 (2x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.3",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 120,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8580",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "uid": "0b784b0986e04032",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Dell/results/R760_L40Sx2_TRT/bert-99.9/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.28408874066913,
    "Accuracy_div_100": 0.90284,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/Dell/results/r760_q4_ultra/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Dell",
    "Platform": "r760_q4_ultra",
    "Result": 7262.21,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge R760xa (4x QAIC100 Ultra)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 Ultra",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6448Y",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Powered by the KRAI X and KILT technologies",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS (Linux kernel 5.15.0-92-generic #102-Ubuntu SMP Wed Jan 10 09:33:48 UTC 2024 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "b69215e34956433d",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Dell/results/r760_q4_ultra/bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.8666333229796,
    "Accuracy_div_100": 0.90867,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/Dell/results/r760_q4_ultra/bert-99.9/offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Dell",
    "Platform": "r760_q4_ultra",
    "Result": 4147.77,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge R760xa (4x QAIC100 Ultra)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 Ultra",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6448Y",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Powered by the KRAI X and KILT technologies",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4 LTS (Linux kernel 5.15.0-92-generic #102-Ubuntu SMP Wed Jan 10 09:33:48 UTC 2024 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "79d0f09f647a4129",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Dell/results/r760_q4_ultra/bert-99.9/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.23535730698143,
    "Accuracy_div_100": 0.90235,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R7615_L40Sx2_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Dell",
    "Platform": "R7615_L40Sx2_TRT",
    "Result": 6576.07,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge R7615 (2x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 9354 32-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6 LTS",
    "uid": "638a5c94ba444161",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Dell/results/R7615_L40Sx2_TRT/bert-99/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.94464400815383,
    "Accuracy_div_100": 0.90945,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R7615_L40Sx2_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Dell",
    "Platform": "R7615_L40Sx2_TRT",
    "Result": 3514.4,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge R7615 (2x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 9354 32-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6 LTS",
    "uid": "5a3a576929f44fb7",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Dell/results/R7615_L40Sx2_TRT/bert-99.9/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 43.0999,
    "Accuracy_div_100": 0.431,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R7615_L40Sx2_TRT/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Dell",
    "Platform": "R7615_L40Sx2_TRT",
    "Result": 24.9955,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge R7615 (2x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 9354 32-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6 LTS",
    "uid": "5ffdf76c19e04858",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Dell/results/R7615_L40Sx2_TRT/gptj-99/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 43.0999,
    "Accuracy_div_100": 0.431,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R7615_L40Sx2_TRT/gptj-99.9/Offline",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "Dell",
    "Platform": "R7615_L40Sx2_TRT",
    "Result": 24.9898,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge R7615 (2x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 9354 32-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6 LTS",
    "uid": "a824841706134a43",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Dell/results/R7615_L40Sx2_TRT/gptj-99.9/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.23535730698143,
    "Accuracy_div_100": 0.90235,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/vR760_L40S_48Cx2_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Dell",
    "Platform": "vR760_L40S_48Cx2_TRT",
    "Result": 6082.83,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge R760 (2x L40S, TensorRT, VMware ESXi 8.0.2)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "Virtualized NVIDIA L40S",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 60,
    "host_processor_model_name": "Intel Xeon Platinum 8580",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Broadcom VM Specifications 32vCPU out of 120 and memory of 128 GB out of 1.5TB",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4, VMware ESXi 8.0.2 22380479",
    "uid": "c8ff567544594b0d",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Dell/results/vR760_L40S_48Cx2_TRT/bert-99/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.35676151551918,
    "Accuracy_div_100": 0.90357,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Dell",
    "Platform": "XE8640_H100_SXM_80GBx4_TRT",
    "Result": 35790.6,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE8640 (4x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "uid": "fd681139875b4987",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/bert-99/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.97056894987658,
    "Accuracy_div_100": 0.90971,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Dell",
    "Platform": "XE8640_H100_SXM_80GBx4_TRT",
    "Result": 31462,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE8640 (4x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "uid": "3a5adfc09ebb4c36",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/bert-99.9/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 43.0672,
    "Accuracy_div_100": 0.43067,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Dell",
    "Platform": "XE8640_H100_SXM_80GBx4_TRT",
    "Result": 116.996,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE8640 (4x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "uid": "c07b163dc9ec487e",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/gptj-99/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 43.0672,
    "Accuracy_div_100": 0.43067,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/gptj-99.9/Offline",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "Dell",
    "Platform": "XE8640_H100_SXM_80GBx4_TRT",
    "Result": 116.996,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE8640 (4x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "uid": "0ac89839828b40e8",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/gptj-99.9/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 44.5846,
    "Accuracy_div_100": 0.44585,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/llama2-70b-99.9/Offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "Dell",
    "Platform": "XE8640_H100_SXM_80GBx4_TRT",
    "Result": 9896.75,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE8640 (4x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "uid": "258481effbc44149",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/llama2-70b-99.9/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.35676151551918,
    "Accuracy_div_100": 0.90357,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9640_H100_SXM_80GBX4_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Dell",
    "Platform": "XE9640_H100_SXM_80GBX4_TRT",
    "Result": 36146,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE9640 (4x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "uid": "a335a932c38e4342",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Dell/results/XE9640_H100_SXM_80GBX4_TRT/bert-99/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.97056894987658,
    "Accuracy_div_100": 0.90971,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9640_H100_SXM_80GBX4_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Dell",
    "Platform": "XE9640_H100_SXM_80GBX4_TRT",
    "Result": 31417.9,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE9640 (4x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "uid": "f75408d34cd54603",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Dell/results/XE9640_H100_SXM_80GBX4_TRT/bert-99.9/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 43.0681,
    "Accuracy_div_100": 0.43068,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9640_H100_SXM_80GBX4_TRT/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Dell",
    "Platform": "XE9640_H100_SXM_80GBX4_TRT",
    "Result": 117.884,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE9640 (4x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "uid": "fafd9904e59c41ea",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Dell/results/XE9640_H100_SXM_80GBX4_TRT/gptj-99/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 43.0681,
    "Accuracy_div_100": 0.43068,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9640_H100_SXM_80GBX4_TRT/gptj-99.9/Offline",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "Dell",
    "Platform": "XE9640_H100_SXM_80GBX4_TRT",
    "Result": 117.884,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE9640 (4x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "uid": "cbe854a7a645472d",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Dell/results/XE9640_H100_SXM_80GBX4_TRT/gptj-99.9/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 44.604,
    "Accuracy_div_100": 0.44604,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9640_H100_SXM_80GBX4_TRT/llama2-70b-99.9/Offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "Dell",
    "Platform": "XE9640_H100_SXM_80GBX4_TRT",
    "Result": 9248.35,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE9640 (4x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "uid": "70c6afebd4e4478c",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Dell/results/XE9640_H100_SXM_80GBX4_TRT/llama2-70b-99.9/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.35676151551918,
    "Accuracy_div_100": 0.90357,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9680_H100_SXM_80GBx8_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Dell",
    "Platform": "XE9680_H100_SXM_80GBx8_TRT",
    "Result": 70189.3,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE9680 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "uid": "da30f17aa91f4017",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Dell/results/XE9680_H100_SXM_80GBx8_TRT/bert-99/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.97056894987658,
    "Accuracy_div_100": 0.90971,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9680_H100_SXM_80GBx8_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Dell",
    "Platform": "XE9680_H100_SXM_80GBx8_TRT",
    "Result": 62310.8,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE9680 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "uid": "15bc0b4e284d41ea",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Dell/results/XE9680_H100_SXM_80GBx8_TRT/bert-99.9/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 43.0675,
    "Accuracy_div_100": 0.43068,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9680_H100_SXM_80GBx8_TRT/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Dell",
    "Platform": "XE9680_H100_SXM_80GBx8_TRT",
    "Result": 231.007,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE9680 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "uid": "d19cc5ada7254d4e",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Dell/results/XE9680_H100_SXM_80GBx8_TRT/gptj-99/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 43.0675,
    "Accuracy_div_100": 0.43068,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9680_H100_SXM_80GBx8_TRT/gptj-99.9/Offline",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "Dell",
    "Platform": "XE9680_H100_SXM_80GBx8_TRT",
    "Result": 231.007,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE9680 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "uid": "95302567bc2446a9",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Dell/results/XE9680_H100_SXM_80GBx8_TRT/gptj-99.9/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 44.5998,
    "Accuracy_div_100": 0.446,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9680_H100_SXM_80GBx8_TRT/llama2-70b-99.9/Offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "Dell",
    "Platform": "XE9680_H100_SXM_80GBx8_TRT",
    "Result": 21884.2,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE9680 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "uid": "4d6ae51d3f5d4568",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Dell/results/XE9680_H100_SXM_80GBx8_TRT/llama2-70b-99.9/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.35676151551918,
    "Accuracy_div_100": 0.90357,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9680_IntelXeon8480_NVIDIA_H100_SXM_80GBx8_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Dell",
    "Platform": "XE9680_IntelXeon8480_NVIDIA_H100_SXM_80GBx8_TRT",
    "Result": 69897.7,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE9680 (8x H100-SXM-80GB, TensorRT,VMware ESXi 8.0.2) ",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "Virtualized NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel Xeon Platinum 8480",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Broadcom VM Specifications 32vCPU out of 224 and memory of 128 GB out of 1TB",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.4, VMware ESXi 8.0.2 22380479",
    "uid": "9aa267f52e684ca6",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Dell/results/XE9680_IntelXeon8480_NVIDIA_H100_SXM_80GBx8_TRT/bert-99/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 43.0936,
    "Accuracy_div_100": 0.43094,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Fujitsu/results/CDI_L40Sx8_MaxP_TRT/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Fujitsu",
    "Platform": "CDI_L40Sx8_MaxP_TRT",
    "Result": 95.4517,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "PRIMERGY CDI (8x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 36,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8452Y",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "70fc9e7ba11c416d",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Fujitsu/results/CDI_L40Sx8_MaxP_TRT/gptj-99/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 43.0936,
    "Accuracy_div_100": 0.43094,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Fujitsu/results/CDI_L40Sx8_MaxP_TRT/gptj-99.9/Offline",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "Fujitsu",
    "Platform": "CDI_L40Sx8_MaxP_TRT",
    "Result": 95.4517,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "PRIMERGY CDI (8x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 36,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8452Y",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "83bd86bd57f747f1",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Fujitsu/results/CDI_L40Sx8_MaxP_TRT/gptj-99.9/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 43.0675,
    "Accuracy_div_100": 0.43068,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Fujitsu/results/GX2560M7_H100_SXM_80GBx4_TRT/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Fujitsu",
    "Platform": "GX2560M7_H100_SXM_80GBx4_TRT",
    "Result": 112.015,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "GX2560M7_H100_SXM_80GBx4 (4x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "8ddd27198e9f4c70",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Fujitsu/results/GX2560M7_H100_SXM_80GBx4_TRT/gptj-99/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 43.0675,
    "Accuracy_div_100": 0.43068,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Fujitsu/results/GX2560M7_H100_SXM_80GBx4_TRT/gptj-99.9/Offline",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "Fujitsu",
    "Platform": "GX2560M7_H100_SXM_80GBx4_TRT",
    "Result": 112.015,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "GX2560M7_H100_SXM_80GBx4 (4x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "081cd764d32f457c",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Fujitsu/results/GX2560M7_H100_SXM_80GBx4_TRT/gptj-99.9/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 44.6154,
    "Accuracy_div_100": 0.44615,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Fujitsu/results/GX2560M7_H100_SXM_80GBx4_TRT/llama2-70b-99.9/Offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "Fujitsu",
    "Platform": "GX2560M7_H100_SXM_80GBx4_TRT",
    "Result": 8435.97,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "GX2560M7_H100_SXM_80GBx4 (4x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "6dacc8a06c7149f9",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Fujitsu/results/GX2560M7_H100_SXM_80GBx4_TRT/llama2-70b-99.9/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.35676151551918,
    "Accuracy_div_100": 0.90357,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/GigaComputing/results/GIGABYTE-G593-SD1_DGX-H100_H100-SXM-80GBx8_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "GigaComputing",
    "Platform": "GIGABYTE-G593-SD1_DGX-H100_H100-SXM-80GBx8_TRT",
    "Result": 70438.4,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "GIGABYTE G593-SD1",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Data bandwidth for GPU-PCIe: 504 GB/s; PCIe-NIC: 600GB/s",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "uid": "ae26e71392a44dd0",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/GigaComputing/results/GIGABYTE-G593-SD1_DGX-H100_H100-SXM-80GBx8_TRT/bert-99/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.97056894987658,
    "Accuracy_div_100": 0.90971,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/GigaComputing/results/GIGABYTE-G593-SD1_DGX-H100_H100-SXM-80GBx8_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "GigaComputing",
    "Platform": "GIGABYTE-G593-SD1_DGX-H100_H100-SXM-80GBx8_TRT",
    "Result": 61805.5,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "GIGABYTE G593-SD1",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Data bandwidth for GPU-PCIe: 504 GB/s; PCIe-NIC: 600GB/s",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "uid": "4adcece3d42e4883",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/GigaComputing/results/GIGABYTE-G593-SD1_DGX-H100_H100-SXM-80GBx8_TRT/bert-99.9/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 43.0576,
    "Accuracy_div_100": 0.43058,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/GigaComputing/results/GIGABYTE-G593-SD1_DGX-H100_H100-SXM-80GBx8_TRT/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "GigaComputing",
    "Platform": "GIGABYTE-G593-SD1_DGX-H100_H100-SXM-80GBx8_TRT",
    "Result": 240.935,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "GIGABYTE G593-SD1",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Data bandwidth for GPU-PCIe: 504 GB/s; PCIe-NIC: 600GB/s",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "uid": "946fa3e9d6754745",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/GigaComputing/results/GIGABYTE-G593-SD1_DGX-H100_H100-SXM-80GBx8_TRT/gptj-99/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 43.0576,
    "Accuracy_div_100": 0.43058,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/GigaComputing/results/GIGABYTE-G593-SD1_DGX-H100_H100-SXM-80GBx8_TRT/gptj-99.9/Offline",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "GigaComputing",
    "Platform": "GIGABYTE-G593-SD1_DGX-H100_H100-SXM-80GBx8_TRT",
    "Result": 240.935,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "GIGABYTE G593-SD1",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Data bandwidth for GPU-PCIe: 504 GB/s; PCIe-NIC: 600GB/s",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "uid": "c5937cbe5f9b4a1e",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/GigaComputing/results/GIGABYTE-G593-SD1_DGX-H100_H100-SXM-80GBx8_TRT/gptj-99.9/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 44.6091,
    "Accuracy_div_100": 0.44609,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/GigaComputing/results/GIGABYTE-G593-SD1_DGX-H100_H100-SXM-80GBx8_TRT/llama2-70b-99.9/Offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "GigaComputing",
    "Platform": "GIGABYTE-G593-SD1_DGX-H100_H100-SXM-80GBx8_TRT",
    "Result": 22289.7,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "GIGABYTE G593-SD1",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Data bandwidth for GPU-PCIe: 504 GB/s; PCIe-NIC: 600GB/s",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "uid": "2db457bbaee0463d",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/GigaComputing/results/GIGABYTE-G593-SD1_DGX-H100_H100-SXM-80GBx8_TRT/llama2-70b-99.9/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.35676151551918,
    "Accuracy_div_100": 0.90357,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Google/results/H100-SXM-80GBx8_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Google",
    "Platform": "H100-SXM-80GBx8_TRT",
    "Result": 69671.7,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX H100 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 208,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8481C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "e0dcb0b7dfcc449f",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Google/results/H100-SXM-80GBx8_TRT/bert-99/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.97056894987658,
    "Accuracy_div_100": 0.90971,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Google/results/H100-SXM-80GBx8_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Google",
    "Platform": "H100-SXM-80GBx8_TRT",
    "Result": 61292.5,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX H100 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 208,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8481C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "05ec55f6a3b14c90",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Google/results/H100-SXM-80GBx8_TRT/bert-99.9/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 43.0576,
    "Accuracy_div_100": 0.43058,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Google/results/H100-SXM-80GBx8_TRT/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Google",
    "Platform": "H100-SXM-80GBx8_TRT",
    "Result": 235.733,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX H100 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 208,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8481C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "9831fdf0633249db",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Google/results/H100-SXM-80GBx8_TRT/gptj-99/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 43.0576,
    "Accuracy_div_100": 0.43058,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Google/results/H100-SXM-80GBx8_TRT/gptj-99.9/Offline",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "Google",
    "Platform": "H100-SXM-80GBx8_TRT",
    "Result": 235.733,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX H100 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 208,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8481C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "60c2f395e8464cdd",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Google/results/H100-SXM-80GBx8_TRT/gptj-99.9/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 44.605,
    "Accuracy_div_100": 0.44605,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Google/results/H100-SXM-80GBx8_TRT/llama2-70b-99.9/Offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "Google",
    "Platform": "H100-SXM-80GBx8_TRT",
    "Result": 20992,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX H100 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 208,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8481C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "8144c4e5bbda4251",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Google/results/H100-SXM-80GBx8_TRT/llama2-70b-99.9/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 42.7933,
    "Accuracy_div_100": 0.42793,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Google/results/tpu_v5e_x4/gptj-99/offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Google",
    "Platform": "tpu_v5e_x4",
    "Result": 10.1502,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "tpu-v5e-4",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "TPU v5e",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "Saxml",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "AMD EPYC 7B13",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Powered by the KRAI X technology",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3 LTS (Linux mlperf2 5.19.0-1030-gcp #32~22.04.1-Ubuntu SMP Thu Jul 13 09:36:23 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "361f6fa1a1bf4e17",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Google/results/tpu_v5e_x4/gptj-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.28408874066913,
    "Accuracy_div_100": 0.90284,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/HPE/results/dl380_q8_ultra/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "HPE",
    "Platform": "dl380_q8_ultra",
    "Result": 13132.4,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "HPE ProLiant DL380a Gen11 (8x Qualcomm QAIC100 Ultra)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 Ultra",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6448H",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Powered by the KRAI X and KILT technologies",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3 LTS (Linux kernel 5.15.0-94-generic #104-Ubuntu SMP Tue Jan 9 15:25:40 UTC 2024 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "e7de35295fbc4bf3",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/HPE/results/dl380_q8_ultra/bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.35676151551918,
    "Accuracy_div_100": 0.90357,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/HPE_Cray_XD670_H100_SXM_80GBx8_TRT_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "HPE",
    "Platform": "HPE_Cray_XD670_H100_SXM_80GBx8_TRT_TRT",
    "Result": 70758.8,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "HPE Cray XD670 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.3",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.3",
    "uid": "76ae1abc1eea4797",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/HPE/results/HPE_Cray_XD670_H100_SXM_80GBx8_TRT_TRT/bert-99/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 44.604,
    "Accuracy_div_100": 0.44604,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/HPE_Cray_XD670_H100_SXM_80GBx8_TRT_TRT/llama2-70b-99.9/Offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "HPE",
    "Platform": "HPE_Cray_XD670_H100_SXM_80GBx8_TRT_TRT",
    "Result": 20973.2,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "HPE Cray XD670 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.3",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.3",
    "uid": "5735f077e5534309",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/HPE/results/HPE_Cray_XD670_H100_SXM_80GBx8_TRT_TRT/llama2-70b-99.9/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 44.5312,
    "Accuracy_div_100": 0.44531,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/HPE_ProLiant_DL380a_H100_PCIe_80GBx4_TRT_TRT/llama2-70b-99.9/Offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "HPE",
    "Platform": "HPE_ProLiant_DL380a_H100_PCIe_80GBx4_TRT_TRT",
    "Result": 6335.7,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "HPE ProLiant DL380a Gen11 (4x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "uid": "24fcb21ca2f74ddb",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/HPE/results/HPE_ProLiant_DL380a_H100_PCIe_80GBx4_TRT_TRT/llama2-70b-99.9/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.23848090934187,
    "Accuracy_div_100": 0.90238,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/HPE_ProLiant_DL380a_L40S_PCIe_48GBx4_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "HPE",
    "Platform": "HPE_ProLiant_DL380a_L40S_PCIe_48GBx4_TRT",
    "Result": 12928.7,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "HPE ProLiant DL380a Gen11 (4x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 60,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8580",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "uid": "a899c22be0434a1a",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/HPE/results/HPE_ProLiant_DL380a_L40S_PCIe_48GBx4_TRT/bert-99/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 43.0966,
    "Accuracy_div_100": 0.43097,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Intel/results/1-node-2S-EMR-ITREX/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Intel",
    "Platform": "1-node-2S-EMR-ITREX",
    "Result": 3.61232,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "1-node-2S-EMR-ITREX",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "PyTorch",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54Q-2U. N/A",
    "number_of_nodes": 1,
    "operating_system": "CentOS Stream 8",
    "uid": "d99c5af8fc1d4ddd",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Intel/results/1-node-2S-EMR-ITREX/gptj-99/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.53885196505269,
    "Accuracy_div_100": 0.90539,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Intel/results/1-node-2S-EMR-PyTorch/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Intel",
    "Platform": "1-node-2S-EMR-PyTorch",
    "Result": 1668.5,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "1-node-2S-EMR-PyTorch",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "PyTorch",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "INTEL(R) XEON(R) PLATINUM 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54Q-2U. N/A",
    "number_of_nodes": 1,
    "operating_system": "CentOS Stream 8",
    "uid": "d31cee7929584819",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Intel/results/1-node-2S-EMR-PyTorch/bert-99/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 44.5769,
    "Accuracy_div_100": 0.44577,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Intel-HabanaLabs/results/HLS-Gaudi2-PT/llama2-70b-99.9/Offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "Intel-HabanaLabs",
    "Platform": "HLS-Gaudi2-PT",
    "Result": 8034.85,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "HLS-Gaudi2-PT",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "Intel\u00ae Gaudi\u00ae 2 AI Accelerator",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "PyTorch 2.1.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8380",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "587c17f925b0469d",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Intel-HabanaLabs/results/HLS-Gaudi2-PT/llama2-70b-99.9/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.8841890658254,
    "Accuracy_div_100": 0.90884,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/SE455_L40x2_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Lenovo",
    "Platform": "SE455_L40x2_TRT",
    "Result": 1699.69,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Lenovo SE455 (2x NVIDIA L40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.3",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "AMD EPYC 8124P 16-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "uid": "23943b71d62b48b0",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Lenovo/results/SE455_L40x2_TRT/bert-99.9/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.28408874066913,
    "Accuracy_div_100": 0.90284,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/Lenovo/results/sr670_q4_ultra/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Lenovo",
    "Platform": "sr670_q4_ultra",
    "Result": 7286.26,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Lenovo ThinkSystem SR670 V2 (4x QAIC100 Ultra)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 Ultra",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.14.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 36,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8360Y CPU @ 2.40GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Powered by the KRAI X and KILT technologies",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3 LTS (Linux kernel 5.15.0-94-generic #104-Ubuntu SMP Tue Jan 9 15:25:40 UTC 2024 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "2702494dfbe7439d",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Lenovo/results/sr670_q4_ultra/bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.8666333229796,
    "Accuracy_div_100": 0.90867,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/Lenovo/results/sr670_q4_ultra/bert-99.9/offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Lenovo",
    "Platform": "sr670_q4_ultra",
    "Result": 4140.89,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Lenovo ThinkSystem SR670 V2 (4x QAIC100 Ultra)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 Ultra",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.14.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 36,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8360Y CPU @ 2.40GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Powered by the KRAI X and KILT technologies",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3 LTS (Linux kernel 5.15.0-94-generic #104-Ubuntu SMP Tue Jan 9 15:25:40 UTC 2024 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "73e1e0fdf4af4ff8",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Lenovo/results/sr670_q4_ultra/bert-99.9/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.35676151551918,
    "Accuracy_div_100": 0.90357,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx1_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "NVIDIA",
    "Platform": "DGX-H100_H100-SXM-80GBx1_TRT",
    "Result": 9081.51,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX H100 (1x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "825ecfdfb35f4424",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx1_TRT/bert-99/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.97056894987658,
    "Accuracy_div_100": 0.90971,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx1_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "NVIDIA",
    "Platform": "DGX-H100_H100-SXM-80GBx1_TRT",
    "Result": 7939.77,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX H100 (1x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "8c6fe4c709ce4cd3",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx1_TRT/bert-99.9/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 43.0675,
    "Accuracy_div_100": 0.43068,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx1_TRT/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "NVIDIA",
    "Platform": "DGX-H100_H100-SXM-80GBx1_TRT",
    "Result": 31.0737,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX H100 (1x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "619025f1e29e483b",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx1_TRT/gptj-99/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 43.0675,
    "Accuracy_div_100": 0.43068,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx1_TRT/gptj-99.9/Offline",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "NVIDIA",
    "Platform": "DGX-H100_H100-SXM-80GBx1_TRT",
    "Result": 31.0737,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX H100 (1x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "e0179f7eafcf4480",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx1_TRT/gptj-99.9/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 44.604,
    "Accuracy_div_100": 0.44604,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx2_TRT/llama2-70b-99.9/Offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "NVIDIA",
    "Platform": "DGX-H100_H100-SXM-80GBx2_TRT",
    "Result": 5539.47,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX H100 (2x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "d25bdca85c5a41ec",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx2_TRT/llama2-70b-99.9/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.35676151551918,
    "Accuracy_div_100": 0.90357,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "NVIDIA",
    "Platform": "DGX-H100_H100-SXM-80GBx8_TRT",
    "Result": 70116.2,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX H100 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "cb108a5eec444258",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT/bert-99/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.97056894987658,
    "Accuracy_div_100": 0.90971,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "NVIDIA",
    "Platform": "DGX-H100_H100-SXM-80GBx8_TRT",
    "Result": 62182.5,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX H100 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "100ce180fadb47cc",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT/bert-99.9/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 43.0672,
    "Accuracy_div_100": 0.43067,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "NVIDIA",
    "Platform": "DGX-H100_H100-SXM-80GBx8_TRT",
    "Result": 239.895,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX H100 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "aa034cb428904f7c",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT/gptj-99/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 43.0672,
    "Accuracy_div_100": 0.43067,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT/gptj-99.9/Offline",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "NVIDIA",
    "Platform": "DGX-H100_H100-SXM-80GBx8_TRT",
    "Result": 239.895,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX H100 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "7b90dfeb5b504a0e",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT/gptj-99.9/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 44.6041,
    "Accuracy_div_100": 0.44604,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT/llama2-70b-99.9/Offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "NVIDIA",
    "Platform": "DGX-H100_H100-SXM-80GBx8_TRT",
    "Result": 21805.8,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX H100 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "89db67f1acb941de",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT/llama2-70b-99.9/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 44.4538,
    "Accuracy_div_100": 0.44454,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/llama2-70b-99.9/Offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "NVIDIA",
    "Platform": "GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT",
    "Result": 3871.47,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA GH200-GraceHopper-Superchip (1x GH200-144GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GH200-GraceHopper-Superchip",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "NVIDIA MGX Reference Platform;",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2",
    "uid": "f31376435a7840fe",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/NVIDIA/results/GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT/llama2-70b-99.9/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 43.067,
    "Accuracy_div_100": 0.43067,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "NVIDIA",
    "Platform": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "Result": 31.9178,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA GH200-GraceHopper-Superchip (1x GH200-96GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GH200-GraceHopper-Superchip",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "NVIDIA MGX Reference Platform;",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2",
    "uid": "2bc7f020738c4e76",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/NVIDIA/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/gptj-99/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 43.067,
    "Accuracy_div_100": 0.43067,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/gptj-99.9/Offline",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "NVIDIA",
    "Platform": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "Result": 31.9178,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA GH200-GraceHopper-Superchip (1x GH200-96GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GH200-GraceHopper-Superchip",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "NVIDIA MGX Reference Platform;",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2",
    "uid": "1809474500854776",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/NVIDIA/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/gptj-99.9/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 44.6173,
    "Accuracy_div_100": 0.44617,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H100-NVL-94GBx8_TRT/llama2-70b-99.9/Offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "NVIDIA",
    "Platform": "H100-NVL-94GBx8_TRT",
    "Result": 15085.7,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "SYS-521GE-TNRT (8x H100-NVL-94GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100 NVL",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "4e2acbe03ffa4744",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/NVIDIA/results/H100-NVL-94GBx8_TRT/llama2-70b-99.9/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 44.4538,
    "Accuracy_div_100": 0.44454,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GB-CTSx1_TRT/llama2-70b-99.9/Offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GB-CTSx1_TRT",
    "Result": 4020.31,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA H200 (1x H200-SXM-141GB-CTS, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB-CTS",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 1000W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "7406de9d59754bbe",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/NVIDIA/results/H200-SXM-141GB-CTSx1_TRT/llama2-70b-99.9/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 44.4538,
    "Accuracy_div_100": 0.44454,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GB-CTSx8_TRT/llama2-70b-99.9/Offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GB-CTSx8_TRT",
    "Result": 31712,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA H200 (8x H200-SXM-141GB-CTS, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB-CTS",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 1000W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "166284a3653a4109",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/NVIDIA/results/H200-SXM-141GB-CTSx8_TRT/llama2-70b-99.9/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 43.0675,
    "Accuracy_div_100": 0.43068,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GBx1_TRT/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GBx1_TRT",
    "Result": 30.7624,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA H200 (1x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "6b70ae795e1844b0",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/NVIDIA/results/H200-SXM-141GBx1_TRT/gptj-99/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 43.0675,
    "Accuracy_div_100": 0.43068,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GBx1_TRT/gptj-99.9/Offline",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GBx1_TRT",
    "Result": 30.7624,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA H200 (1x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "752119f3a7534578",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/NVIDIA/results/H200-SXM-141GBx1_TRT/gptj-99.9/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 43.0674,
    "Accuracy_div_100": 0.43067,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GBx8_TRT/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GBx8_TRT",
    "Result": 241.285,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA H200 (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "95c140db4b4943ef",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/NVIDIA/results/H200-SXM-141GBx8_TRT/gptj-99/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 43.0674,
    "Accuracy_div_100": 0.43067,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GBx8_TRT/gptj-99.9/Offline",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GBx8_TRT",
    "Result": 241.285,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA H200 (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "c92ba8c805c5459c",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/NVIDIA/results/H200-SXM-141GBx8_TRT/gptj-99.9/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 44.4538,
    "Accuracy_div_100": 0.44454,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H200-SXM-141GBx8_TRT/llama2-70b-99.9/Offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "NVIDIA",
    "Platform": "H200-SXM-141GBx8_TRT",
    "Result": 27738.3,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA H200 (8x H200-SXM-141GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H200-SXM-141GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "H200 TGP 700W",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "a09e6a1ac03b49d6",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/NVIDIA/results/H200-SXM-141GBx8_TRT/llama2-70b-99.9/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 43.0999,
    "Accuracy_div_100": 0.431,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/L40Sx8_TRT/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "NVIDIA",
    "Platform": "L40Sx8_TRT",
    "Result": 94.5702,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "ASROCKRACK 4U8G-ROME2/4E (8x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "5c60f5652e3642d5",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/NVIDIA/results/L40Sx8_TRT/gptj-99/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 43.0999,
    "Accuracy_div_100": 0.431,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/L40Sx8_TRT/gptj-99.9/Offline",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "NVIDIA",
    "Platform": "L40Sx8_TRT",
    "Result": 94.5702,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "ASROCKRACK 4U8G-ROME2/4E (8x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "1d07f976bc3d4084",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/NVIDIA/results/L40Sx8_TRT/gptj-99.9/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.35676151551918,
    "Accuracy_div_100": 0.90357,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Oracle/results/OCI-H100_H100-SXM-80GBx8_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Oracle",
    "Platform": "OCI-H100_H100-SXM-80GBx8_TRT",
    "Result": 69820.8,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "BM.GPU.H100.8",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0.1, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "uid": "d396075d63c34b8d",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Oracle/results/OCI-H100_H100-SXM-80GBx8_TRT/bert-99/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.97056894987658,
    "Accuracy_div_100": 0.90971,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Oracle/results/OCI-H100_H100-SXM-80GBx8_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Oracle",
    "Platform": "OCI-H100_H100-SXM-80GBx8_TRT",
    "Result": 61817.5,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "BM.GPU.H100.8",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0.1, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "uid": "562dcd8ee4074a21",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Oracle/results/OCI-H100_H100-SXM-80GBx8_TRT/bert-99.9/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 43.0678,
    "Accuracy_div_100": 0.43068,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Oracle/results/OCI-H100_H100-SXM-80GBx8_TRT/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Oracle",
    "Platform": "OCI-H100_H100-SXM-80GBx8_TRT",
    "Result": 237.145,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "BM.GPU.H100.8",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0.1, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "uid": "087b8d7b66704221",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Oracle/results/OCI-H100_H100-SXM-80GBx8_TRT/gptj-99/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 43.0672,
    "Accuracy_div_100": 0.43067,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Oracle/results/OCI-H100_H100-SXM-80GBx8_TRT/gptj-99.9/Offline",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "Oracle",
    "Platform": "OCI-H100_H100-SXM-80GBx8_TRT",
    "Result": 235.755,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "BM.GPU.H100.8",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0.1, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "uid": "836d7a6f3a7245a3",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Oracle/results/OCI-H100_H100-SXM-80GBx8_TRT/gptj-99.9/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 44.6041,
    "Accuracy_div_100": 0.44604,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Oracle/results/OCI-H100_H100-SXM-80GBx8_TRT/llama2-70b-99.9/Offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "Oracle",
    "Platform": "OCI-H100_H100-SXM-80GBx8_TRT",
    "Result": 21032.4,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "BM.GPU.H100.8",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0.1, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "uid": "01d8755b1873484a",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Oracle/results/OCI-H100_H100-SXM-80GBx8_TRT/llama2-70b-99.9/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.28408874066913,
    "Accuracy_div_100": 0.90284,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/Qualcomm/results/g293_q16_ultra_pp/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Qualcomm",
    "Platform": "g293_q16_ultra_pp",
    "Result": 30965.7,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "GIGABYTE G293-Z43 (16x QAIC100 Ultra, PP)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 Ultra",
    "accelerators_per_node": 16,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 9554 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Powered by the KRAI X and KILT technologies",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3 LTS (Linux kernel 6.2.0-37-generic #38~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov  2 18:01:13 UTC 2 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "8f0199bae9594f68",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Qualcomm/results/g293_q16_ultra_pp/bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.8666333229796,
    "Accuracy_div_100": 0.90867,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/Qualcomm/results/g293_q16_ultra_pp/bert-99.9/offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Qualcomm",
    "Platform": "g293_q16_ultra_pp",
    "Result": 16468.2,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "GIGABYTE G293-Z43 (16x QAIC100 Ultra, PP)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 Ultra",
    "accelerators_per_node": 16,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 9554 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Powered by the KRAI X and KILT technologies",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3 LTS (Linux kernel 6.2.0-37-generic #38~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov  2 18:01:13 UTC 2 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "e9a938c8f9bf4b52",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Qualcomm/results/g293_q16_ultra_pp/bert-99.9/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.53885196505269,
    "Accuracy_div_100": 0.90539,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/1-node-2S-EMR-PyTorch/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "1-node-2S-EMR-PyTorch",
    "Result": 1660.75,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "1-node-2S-EMR-PyTorch-INT8",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": "N/A",
    "compliance": 1,
    "errors": 0,
    "framework": "PyTorch",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54X-1U",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.1",
    "uid": "e832edd7324e466b",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Quanta_Cloud_Technology/results/1-node-2S-EMR-PyTorch/bert-99/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 42.8304,
    "Accuracy_div_100": 0.4283,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/1-node-2S-EMR-PyTorch/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "1-node-2S-EMR-PyTorch",
    "Result": 2.29347,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "1-node-2S-EMR-PyTorch-INT8",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": "N/A",
    "compliance": 1,
    "errors": 0,
    "framework": "PyTorch",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8592+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54X-1U",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.1",
    "uid": "ff1caebaac4c45d3",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Quanta_Cloud_Technology/results/1-node-2S-EMR-PyTorch/gptj-99/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.35676151551918,
    "Accuracy_div_100": 0.90357,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/D54U_3U_H100_PCIe_80GBx4_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "D54U_3U_H100_PCIe_80GBx4_TRT",
    "Result": 23347,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "D54U_3U_H100_PCIe_80GBx4_TRT",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.3",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 52,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54U-3U",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.2",
    "uid": "580daef2cc584105",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Quanta_Cloud_Technology/results/D54U_3U_H100_PCIe_80GBx4_TRT/bert-99/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.97056894987658,
    "Accuracy_div_100": 0.90971,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/D54U_3U_H100_PCIe_80GBx4_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "D54U_3U_H100_PCIe_80GBx4_TRT",
    "Result": 19441.4,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "D54U_3U_H100_PCIe_80GBx4_TRT",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.3",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 52,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54U-3U",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.2",
    "uid": "96d60102f2f44ec3",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Quanta_Cloud_Technology/results/D54U_3U_H100_PCIe_80GBx4_TRT/bert-99.9/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 43.0554,
    "Accuracy_div_100": 0.43055,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/D54U_3U_H100_PCIe_80GBx4_TRT/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "D54U_3U_H100_PCIe_80GBx4_TRT",
    "Result": 82.3302,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "D54U_3U_H100_PCIe_80GBx4_TRT",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.3",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 52,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54U-3U",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.2",
    "uid": "83b11601073b4cd2",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Quanta_Cloud_Technology/results/D54U_3U_H100_PCIe_80GBx4_TRT/gptj-99/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 43.0554,
    "Accuracy_div_100": 0.43055,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/D54U_3U_H100_PCIe_80GBx4_TRT/gptj-99.9/Offline",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "D54U_3U_H100_PCIe_80GBx4_TRT",
    "Result": 82.3302,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "D54U_3U_H100_PCIe_80GBx4_TRT",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.3",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 52,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54U-3U",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.2",
    "uid": "880950352e2d4ab3",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Quanta_Cloud_Technology/results/D54U_3U_H100_PCIe_80GBx4_TRT/gptj-99.9/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 44.5188,
    "Accuracy_div_100": 0.44519,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/D54U_3U_H100_PCIe_80GBx4_TRT/llama2-70b-99.9/Offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "D54U_3U_H100_PCIe_80GBx4_TRT",
    "Result": 4407.75,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "D54U_3U_H100_PCIe_80GBx4_TRT",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.3",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 52,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54U-3U",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.2",
    "uid": "ee72bb8975e04aa4",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Quanta_Cloud_Technology/results/D54U_3U_H100_PCIe_80GBx4_TRT/llama2-70b-99.9/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.23848090934187,
    "Accuracy_div_100": 0.90238,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/D54U_3U_L40S_PCIe_48GBx4_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "D54U_3U_L40S_PCIe_48GBx4_TRT",
    "Result": 13226.2,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "D54U_3U_L40S_PCIe_48GBx4_TRT",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.3",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 52,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54U-3U",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.2",
    "uid": "7dc6bd3e37174a6d",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Quanta_Cloud_Technology/results/D54U_3U_L40S_PCIe_48GBx4_TRT/bert-99/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.91791846752544,
    "Accuracy_div_100": 0.90918,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/D54U_3U_L40S_PCIe_48GBx4_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "D54U_3U_L40S_PCIe_48GBx4_TRT",
    "Result": 6845.14,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "D54U_3U_L40S_PCIe_48GBx4_TRT",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.3",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 52,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54U-3U",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.2",
    "uid": "2bb7732ef75446c2",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Quanta_Cloud_Technology/results/D54U_3U_L40S_PCIe_48GBx4_TRT/bert-99.9/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 43.2269,
    "Accuracy_div_100": 0.43227,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/D54U_3U_L40S_PCIe_48GBx4_TRT/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "D54U_3U_L40S_PCIe_48GBx4_TRT",
    "Result": 50.3072,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "D54U_3U_L40S_PCIe_48GBx4_TRT",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.3",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 52,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54U-3U",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.2",
    "uid": "dfa9faf48f244640",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Quanta_Cloud_Technology/results/D54U_3U_L40S_PCIe_48GBx4_TRT/gptj-99/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 43.2269,
    "Accuracy_div_100": 0.43227,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/D54U_3U_L40S_PCIe_48GBx4_TRT/gptj-99.9/Offline",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "D54U_3U_L40S_PCIe_48GBx4_TRT",
    "Result": 50.3268,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "D54U_3U_L40S_PCIe_48GBx4_TRT",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.3",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 52,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54U-3U",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.2",
    "uid": "4cf6018e499947f2",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Quanta_Cloud_Technology/results/D54U_3U_L40S_PCIe_48GBx4_TRT/gptj-99.9/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 43.0279,
    "Accuracy_div_100": 0.43028,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "Result": 32.7257,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GH200-GraceHopper-Superchip",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "QuantaGrid S74G-2U",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.1",
    "uid": "881a834cd56b45b9",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Quanta_Cloud_Technology/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/gptj-99/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.23535730698143,
    "Accuracy_div_100": 0.90235,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS-521GE-TNRT_L40S_PCIe_48GBx8_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Supermicro",
    "Platform": "SYS-521GE-TNRT_L40S_PCIe_48GBx8_TRT",
    "Result": 26430.1,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "SYS-521GE-TNRT (8xL40S-PCIe-48GB)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8462Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "uid": "2a1110eff27c4de8",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Supermicro/results/SYS-521GE-TNRT_L40S_PCIe_48GBx8_TRT/bert-99/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.885212568049,
    "Accuracy_div_100": 0.90885,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS-521GE-TNRT_L40S_PCIe_48GBx8_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Supermicro",
    "Platform": "SYS-521GE-TNRT_L40S_PCIe_48GBx8_TRT",
    "Result": 14002.1,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "SYS-521GE-TNRT (8xL40S-PCIe-48GB)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8462Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "uid": "886bf92f0dfd457d",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Supermicro/results/SYS-521GE-TNRT_L40S_PCIe_48GBx8_TRT/bert-99.9/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.35676151551918,
    "Accuracy_div_100": 0.90357,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Supermicro",
    "Platform": "SYS_821GE_TNHR_H100_SXM_80GBx8_TRT",
    "Result": 70342.2,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "SYS-821GE-TNHR (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8568Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3 LTS",
    "uid": "7faabcc815324f4c",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/bert-99/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.97056894987658,
    "Accuracy_div_100": 0.90971,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Supermicro",
    "Platform": "SYS_821GE_TNHR_H100_SXM_80GBx8_TRT",
    "Result": 62226.4,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "SYS-821GE-TNHR (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8568Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3 LTS",
    "uid": "1a49527433954134",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/bert-99.9/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 43.0672,
    "Accuracy_div_100": 0.43067,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Supermicro",
    "Platform": "SYS_821GE_TNHR_H100_SXM_80GBx8_TRT",
    "Result": 242.977,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "SYS-821GE-TNHR (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8568Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3 LTS",
    "uid": "aa6042ce79354f06",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/gptj-99/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 43.0672,
    "Accuracy_div_100": 0.43067,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/gptj-99.9/Offline",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "Supermicro",
    "Platform": "SYS_821GE_TNHR_H100_SXM_80GBx8_TRT",
    "Result": 242.977,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "SYS-821GE-TNHR (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8568Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3 LTS",
    "uid": "a225141090d4494a",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/gptj-99.9/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 44.6052,
    "Accuracy_div_100": 0.44605,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/llama2-70b-99.9/Offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "Supermicro",
    "Platform": "SYS_821GE_TNHR_H100_SXM_80GBx8_TRT",
    "Result": 22202.2,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "SYS-821GE-TNHR (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8568Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3 LTS",
    "uid": "4f0ff29f08d24cc7",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/llama2-70b-99.9/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.53885196505269,
    "Accuracy_div_100": 0.90539,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Wiwynn/results/1-node-1S-EMR-PyTorch/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Wiwynn",
    "Platform": "1-node-1S-EMR-PyTorch",
    "Result": 467.942,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Wiwynn ES200G2 (1-node-1S-EMR-PyTorch)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "PyTorch",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "INTEL(R) XEON(R) GOLD 6538Y+",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Wiwynn ES200G2. N/A",
    "number_of_nodes": 1,
    "operating_system": "Centos 8 (linux-6.6.8-1.el8.elrepo.x86_64-glibc2.28)",
    "uid": "b48c565b841742e3",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Wiwynn/results/1-node-1S-EMR-PyTorch/bert-99/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 42.8066,
    "Accuracy_div_100": 0.42807,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Wiwynn/results/1-node-1S-EMR-PyTorch/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Wiwynn",
    "Platform": "1-node-1S-EMR-PyTorch",
    "Result": 0.638686,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Wiwynn ES200G2 (1-node-1S-EMR-PyTorch)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "PyTorch",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "INTEL(R) XEON(R) GOLD 6538Y+",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Wiwynn ES200G2. N/A",
    "number_of_nodes": 1,
    "operating_system": "Centos 8 (linux-6.6.8-1.el8.elrepo.x86_64-glibc2.28)",
    "uid": "4f5cf5628ca048eb",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Wiwynn/results/1-node-1S-EMR-PyTorch/gptj-99/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.22174729668266,
    "Accuracy_div_100": 0.90222,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/IEI/results/NF5468M6_A40x8_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "IEI",
    "Platform": "NF5468M6_A40x8_TRT",
    "Result": 14022,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NF5468M6 (8x A40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A40",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8380",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5",
    "uid": "82531325461c43d5",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/IEI/results/NF5468M6_A40x8_TRT/bert-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.88066528372401,
    "Accuracy_div_100": 0.90881,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/IEI/results/NF5468M6_A40x8_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "IEI",
    "Platform": "NF5468M6_A40x8_TRT",
    "Result": 6863.7,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NF5468M6 (8x A40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A40",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8380",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5",
    "uid": "ec558e9c4a634bec",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/IEI/results/NF5468M6_A40x8_TRT/bert-99.9/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.46798543449019,
    "Accuracy_div_100": 0.90468,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Krai/results/7920t-kilt-tensorrt/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Krai",
    "Platform": "7920t-kilt-tensorrt",
    "Result": 2493.04,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell Precision 7920 Tower (2x NVIDIA RTX A5000 GPU)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA RTX A5000 GPU",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "KRAI Inference Library Technology (KILT) with TensorRT support",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6240R CPU @ 2.40GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Powered by the KRAI X and KILT technologies",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3 LTS (Linux chai 5.15.0-76-generic #83-Ubuntu SMP Thu Jun 15 19:16:32 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "667077fd81194079",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Krai/results/7920t-kilt-tensorrt/bert-99/offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.88006360431436,
    "Accuracy_div_100": 0.9088,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Krai/results/7920t-kilt-tensorrt/bert-99.9/offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Krai",
    "Platform": "7920t-kilt-tensorrt",
    "Result": 1183.87,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell Precision 7920 Tower (2x NVIDIA RTX A5000 GPU)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA RTX A5000 GPU",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "KRAI Inference Library Technology (KILT) with TensorRT support",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6240R CPU @ 2.40GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Powered by the KRAI X and KILT technologies",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3 LTS (Linux chai 5.15.0-76-generic #83-Ubuntu SMP Thu Jun 15 19:16:32 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "1c55003d59ee4b6e",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Krai/results/7920t-kilt-tensorrt/bert-99.9/offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.35676151551918,
    "Accuracy_div_100": 0.90357,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Supermicro",
    "Platform": "SYS_821GE_TNHR_H100_SXM_80GBx8_TRT",
    "Result": 70682.6,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "SYS-821GE-TNHR (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2 LTS",
    "uid": "1e2a594674d746f5",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/bert-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.97056894987658,
    "Accuracy_div_100": 0.90971,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Supermicro",
    "Platform": "SYS_821GE_TNHR_H100_SXM_80GBx8_TRT",
    "Result": 62479.8,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "SYS-821GE-TNHR (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2 LTS",
    "uid": "2705d02d54ec4e4d",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/bert-99.9/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 43.0722,
    "Accuracy_div_100": 0.43072,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Supermicro",
    "Platform": "SYS_821GE_TNHR_H100_SXM_80GBx8_TRT",
    "Result": 107.326,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "SYS-821GE-TNHR (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2 LTS",
    "uid": "7445332c0062430e",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/gptj-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 43.0722,
    "Accuracy_div_100": 0.43072,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/gptj-99.9/Offline",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "Supermicro",
    "Platform": "SYS_821GE_TNHR_H100_SXM_80GBx8_TRT",
    "Result": 107.056,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "SYS-821GE-TNHR (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2 LTS",
    "uid": "adfe95feac02466f",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Supermicro/results/SYS_821GE_TNHR_H100_SXM_80GBx8_TRT/gptj-99.9/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.35676151551918,
    "Accuracy_div_100": 0.90357,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS_521GE_TNRT_H100_PCIe_80GBX8_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Supermicro",
    "Platform": "SYS_521GE_TNRT_H100_PCIe_80GBX8_TRT",
    "Result": 46250.7,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "SYS-521GE-TNRT (8xH100-PCIe-80GB)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8462Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "uid": "b561dd564f3b4fc5",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Supermicro/results/SYS_521GE_TNRT_H100_PCIe_80GBX8_TRT/bert-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.97056894987658,
    "Accuracy_div_100": 0.90971,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS_521GE_TNRT_H100_PCIe_80GBX8_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Supermicro",
    "Platform": "SYS_521GE_TNRT_H100_PCIe_80GBX8_TRT",
    "Result": 40132.9,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "SYS-521GE-TNRT (8xH100-PCIe-80GB)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8462Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "uid": "49eed5aff7944b8d",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Supermicro/results/SYS_521GE_TNRT_H100_PCIe_80GBX8_TRT/bert-99.9/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.35676151551918,
    "Accuracy_div_100": 0.90357,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Supermicro",
    "Platform": "AS_8125GS_TNHR_H100_SXM_80GBx8_TRT",
    "Result": 70619.7,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AS-8125GS-TNHR (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 9554",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2 LTS",
    "uid": "1980947b15464325",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Supermicro/results/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT/bert-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.97056894987658,
    "Accuracy_div_100": 0.90971,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Supermicro",
    "Platform": "AS_8125GS_TNHR_H100_SXM_80GBx8_TRT",
    "Result": 62456.1,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AS-8125GS-TNHR (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 9554",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2 LTS",
    "uid": "d4e7f1b0e5494f13",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Supermicro/results/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT/bert-99.9/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 43.0722,
    "Accuracy_div_100": 0.43072,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Supermicro",
    "Platform": "AS_8125GS_TNHR_H100_SXM_80GBx8_TRT",
    "Result": 105.532,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AS-8125GS-TNHR (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 9554",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2 LTS",
    "uid": "55fb04b383df43c2",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Supermicro/results/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT/gptj-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 43.0722,
    "Accuracy_div_100": 0.43072,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT/gptj-99.9/Offline",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "Supermicro",
    "Platform": "AS_8125GS_TNHR_H100_SXM_80GBx8_TRT",
    "Result": 105.911,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AS-8125GS-TNHR (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 9554",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2 LTS",
    "uid": "0cbaa14dac624e4c",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Supermicro/results/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT/gptj-99.9/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 43.0737,
    "Accuracy_div_100": 0.43074,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS_421GU_TNXR/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Supermicro",
    "Platform": "SYS_421GU_TNXR",
    "Result": 37.9331,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "SYS-421GU-TNXR (4x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 52,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470Q",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2",
    "uid": "43d5149964e9495f",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Supermicro/results/SYS_421GU_TNXR/gptj-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 43.0737,
    "Accuracy_div_100": 0.43074,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS_421GU_TNXR/gptj-99.9/Offline",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "Supermicro",
    "Platform": "SYS_421GU_TNXR",
    "Result": 37.9331,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "SYS-421GU-TNXR (4x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 52,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470Q",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2",
    "uid": "5be79e7fac6f4cfa",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Supermicro/results/SYS_421GU_TNXR/gptj-99.9/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.35676151551918,
    "Accuracy_div_100": 0.90357,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H100-PCIe-80GBx1_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "NVIDIA",
    "Platform": "H100-PCIe-80GBx1_TRT",
    "Result": 5711,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G482-Z54 (1x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "2eb8df97726e4576",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/NVIDIA/results/H100-PCIe-80GBx1_TRT/bert-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.97056894987658,
    "Accuracy_div_100": 0.90971,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H100-PCIe-80GBx1_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "NVIDIA",
    "Platform": "H100-PCIe-80GBx1_TRT",
    "Result": 4961.92,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G482-Z54 (1x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "464480c4e2104d20",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/NVIDIA/results/H100-PCIe-80GBx1_TRT/bert-99.9/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.24991228842381,
    "Accuracy_div_100": 0.9025,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/L4x1_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "NVIDIA",
    "Platform": "L4x1_TRT",
    "Result": 1028.95,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "ASROCKRACK 1U1G-MILAN (1x L4, TensorRT)",
    "SystemType": "datacenter,edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 7313P 16-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "a443dcb000a84bc1",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/NVIDIA/results/L4x1_TRT/bert-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.9257447258943,
    "Accuracy_div_100": 0.90926,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/L4x1_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "NVIDIA",
    "Platform": "L4x1_TRT",
    "Result": 631.457,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "ASROCKRACK 1U1G-MILAN (1x L4, TensorRT)",
    "SystemType": "datacenter,edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 7313P 16-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "3e432fb95c13400f",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/NVIDIA/results/L4x1_TRT/bert-99.9/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 43.0646,
    "Accuracy_div_100": 0.43065,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/L4x1_TRT/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "NVIDIA",
    "Platform": "L4x1_TRT",
    "Result": 1.30094,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "ASROCKRACK 1U1G-MILAN (1x L4, TensorRT)",
    "SystemType": "datacenter,edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 7313P 16-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "28e1f3014963467c",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/NVIDIA/results/L4x1_TRT/gptj-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 43.0646,
    "Accuracy_div_100": 0.43065,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/L4x1_TRT/gptj-99.9/Offline",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "NVIDIA",
    "Platform": "L4x1_TRT",
    "Result": 1.30094,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "ASROCKRACK 1U1G-MILAN (1x L4, TensorRT)",
    "SystemType": "datacenter,edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 7313P 16-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "faa4e99acf4a4a3a",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/NVIDIA/results/L4x1_TRT/gptj-99.9/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.35676151551918,
    "Accuracy_div_100": 0.90357,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "NVIDIA",
    "Platform": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "Result": 10163.4,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA GH200-GraceHopper-Superchip (1x GH200-96GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GH200-GraceHopper-Superchip",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "NVIDIA MGX Reference Platform",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2",
    "uid": "0dada96bc91342b0",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/NVIDIA/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/bert-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.97056894987658,
    "Accuracy_div_100": 0.90971,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "NVIDIA",
    "Platform": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "Result": 8645.74,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA GH200-GraceHopper-Superchip (1x GH200-96GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GH200-GraceHopper-Superchip",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "NVIDIA MGX Reference Platform",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2",
    "uid": "a3512fa9aa4a4106",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/NVIDIA/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/bert-99.9/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 43.0894,
    "Accuracy_div_100": 0.43089,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "NVIDIA",
    "Platform": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "Result": 13.3364,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA GH200-GraceHopper-Superchip (1x GH200-96GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GH200-GraceHopper-Superchip",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "NVIDIA MGX Reference Platform",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2",
    "uid": "ec15d362c31e463a",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/NVIDIA/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/gptj-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 43.0894,
    "Accuracy_div_100": 0.43089,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/gptj-99.9/Offline",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "NVIDIA",
    "Platform": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "Result": 13.3364,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA GH200-GraceHopper-Superchip (1x GH200-96GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GH200-GraceHopper-Superchip",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "NVIDIA MGX Reference Platform",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2",
    "uid": "c907db582ddb447e",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/NVIDIA/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/gptj-99.9/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.35676151551918,
    "Accuracy_div_100": 0.90357,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H100-PCIe-80GBx8_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "NVIDIA",
    "Platform": "H100-PCIe-80GBx8_TRT",
    "Result": 45698.5,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G482-Z54 (8x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "af3b4180daa84c59",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/NVIDIA/results/H100-PCIe-80GBx8_TRT/bert-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.97056894987658,
    "Accuracy_div_100": 0.90971,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H100-PCIe-80GBx8_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "NVIDIA",
    "Platform": "H100-PCIe-80GBx8_TRT",
    "Result": 39412.8,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G482-Z54 (8x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "e1fba10f35154e59",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/NVIDIA/results/H100-PCIe-80GBx8_TRT/bert-99.9/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.35676151551918,
    "Accuracy_div_100": 0.90357,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "NVIDIA",
    "Platform": "DGX-H100_H100-SXM-80GBx8_TRT",
    "Result": 70169.7,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX H100 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "3a5267fd104145f6",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT/bert-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.97056894987658,
    "Accuracy_div_100": 0.90971,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "NVIDIA",
    "Platform": "DGX-H100_H100-SXM-80GBx8_TRT",
    "Result": 62136.7,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX H100 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "e031454ef5fb4856",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT/bert-99.9/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 43.0722,
    "Accuracy_div_100": 0.43072,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "NVIDIA",
    "Platform": "DGX-H100_H100-SXM-80GBx8_TRT",
    "Result": 106.315,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX H100 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "7a8d9139fa6047d6",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT/gptj-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 43.0722,
    "Accuracy_div_100": 0.43072,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT/gptj-99.9/Offline",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "NVIDIA",
    "Platform": "DGX-H100_H100-SXM-80GBx8_TRT",
    "Result": 106.315,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX H100 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "9f776f1517d54aca",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT/gptj-99.9/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.35676151551918,
    "Accuracy_div_100": 0.90357,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx1_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "NVIDIA",
    "Platform": "DGX-H100_H100-SXM-80GBx1_TRT",
    "Result": 9102.26,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX H100 (1x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "7e3050f9e6fa413c",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx1_TRT/bert-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.97056894987658,
    "Accuracy_div_100": 0.90971,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx1_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "NVIDIA",
    "Platform": "DGX-H100_H100-SXM-80GBx1_TRT",
    "Result": 7877.73,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX H100 (1x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "b861db330e674b8a",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx1_TRT/bert-99.9/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 43.0488,
    "Accuracy_div_100": 0.43049,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx1_TRT/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "NVIDIA",
    "Platform": "DGX-H100_H100-SXM-80GBx1_TRT",
    "Result": 13.0687,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX H100 (1x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "ac43569606d74a77",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx1_TRT/gptj-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 43.0488,
    "Accuracy_div_100": 0.43049,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx1_TRT/gptj-99.9/Offline",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "NVIDIA",
    "Platform": "DGX-H100_H100-SXM-80GBx1_TRT",
    "Result": 13.0687,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX H100 (1x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "622a7a5c93854d48",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx1_TRT/gptj-99.9/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 92.41458991458985,
    "Accuracy_div_100": 0.92415,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/CTuning/results/gcp_g2.standard.4-nvidia_original-gpu-tensorrt-vdefault-default_config/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "CTuning",
    "Platform": "gcp_g2.standard.4-nvidia_original-gpu-tensorrt-vdefault-default_config",
    "Result": 893.473,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Google Cloud Platform (g2.standard.4)",
    "SystemType": "datacenter,edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Nvidia inference implementation with CM API, TensorRT v8.6.1.6",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 2,
    "host_processor_model_name": "Intel(R) Xeon(R) CPU @ 2.20GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Powered by MLCommons CM automation language and CK playground. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-5.19.0-1030-gcp-glibc2.35)",
    "uid": "e96166cf757042d5",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/CTuning/results/gcp_g2.standard.4-nvidia_original-gpu-tensorrt-vdefault-default_config/bert-99/offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 92.18451021082596,
    "Accuracy_div_100": 0.92185,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/CTuning/results/gcp_g2.standard.4-nvidia_original-gpu-tensorrt-vdefault-default_config/bert-99.9/offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "CTuning",
    "Platform": "gcp_g2.standard.4-nvidia_original-gpu-tensorrt-vdefault-default_config",
    "Result": 406.713,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Google Cloud Platform (g2.standard.4)",
    "SystemType": "datacenter,edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Nvidia inference implementation with CM API, TensorRT v8.6.1.6",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 2,
    "host_processor_model_name": "Intel(R) Xeon(R) CPU @ 2.20GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Powered by MLCommons CM automation language and CK playground. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-5.19.0-1030-gcp-glibc2.35)",
    "uid": "c971bd2321c64606",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/CTuning/results/gcp_g2.standard.4-nvidia_original-gpu-tensorrt-vdefault-default_config/bert-99.9/offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.23848090934187,
    "Accuracy_div_100": 0.90238,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC4000A_E12_L4x8_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "ASUSTeK",
    "Platform": "ESC4000A_E12_L4x8_TRT",
    "Result": 7559.83,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "ESC4000A-E12 (8x L4, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9654 96-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "13e39dcaa08c4a32",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/ASUSTeK/results/ESC4000A_E12_L4x8_TRT/bert-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.9257447258943,
    "Accuracy_div_100": 0.90926,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC4000A_E12_L4x8_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "ASUSTeK",
    "Platform": "ESC4000A_E12_L4x8_TRT",
    "Result": 5186.72,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "ESC4000A-E12 (8x L4, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9654 96-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "147a162f06ef42d5",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/ASUSTeK/results/ESC4000A_E12_L4x8_TRT/bert-99.9/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.35676151551918,
    "Accuracy_div_100": 0.90357,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/H100_PCIe_80GBx8_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "ASUSTeK",
    "Platform": "H100_PCIe_80GBx8_TRT",
    "Result": 46010.9,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "ESC8000A-E12 (8xH100-PCIe-80GB, TensorRT",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9654 96-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "6c62774d073b4333",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/ASUSTeK/results/H100_PCIe_80GBx8_TRT/bert-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.97056894987658,
    "Accuracy_div_100": 0.90971,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/H100_PCIe_80GBx8_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "ASUSTeK",
    "Platform": "H100_PCIe_80GBx8_TRT",
    "Result": 38875,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "ESC8000A-E12 (8xH100-PCIe-80GB, TensorRT",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9654 96-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "929f0306338c4088",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/ASUSTeK/results/H100_PCIe_80GBx8_TRT/bert-99.9/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 42.7811,
    "Accuracy_div_100": 0.42781,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/Google/results/TPU-v5e-4_SAX/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Google",
    "Platform": "TPU-v5e-4_SAX",
    "Result": 9.81226,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "tpu-v5e-4",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "TPU v5e",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "SAX",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 112,
    "host_processor_model_name": "AMD EPYC 7B13",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2 LTS",
    "uid": "08dd179f088b4245",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Google/results/TPU-v5e-4_SAX/gptj-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 43.0722,
    "Accuracy_div_100": 0.43072,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Azure/results/ND_H100_v5_TRT/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Azure",
    "Platform": "ND_H100_v5_TRT",
    "Result": 105.756,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "ND_H100_v5 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2 LTS",
    "uid": "8d3833652d6d46c8",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Azure/results/ND_H100_v5_TRT/gptj-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 43.0722,
    "Accuracy_div_100": 0.43072,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Azure/results/ND_H100_v5_TRT/gptj-99.9/Offline",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "Azure",
    "Platform": "ND_H100_v5_TRT",
    "Result": 105.756,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "ND_H100_v5 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2 LTS",
    "uid": "34f7c2cec3f44ebe",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Azure/results/ND_H100_v5_TRT/gptj-99.9/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.2147015680108,
    "Accuracy_div_100": 0.90215,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Fujitsu/results/PRIMERGY_CDI_V1_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Fujitsu",
    "Platform": "PRIMERGY_CDI_V1_TRT",
    "Result": 12496.1,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "PRIMERGY_CDI_V1 (4x A100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIE-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6430 CPU @ 2.10GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "GPUs are installed in an external PCIe box.",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "6be8d65dd1af47b5",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Fujitsu/results/PRIMERGY_CDI_V1_TRT/bert-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.87751170441149,
    "Accuracy_div_100": 0.90878,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Fujitsu/results/PRIMERGY_CDI_V1_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Fujitsu",
    "Platform": "PRIMERGY_CDI_V1_TRT",
    "Result": 6416.1,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "PRIMERGY_CDI_V1 (4x A100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIE-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6430 CPU @ 2.10GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "GPUs are installed in an external PCIe box.",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "75443c2dc49d4b7c",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Fujitsu/results/PRIMERGY_CDI_V1_TRT/bert-99.9/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.28408874066913,
    "Accuracy_div_100": 0.90284,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/sr665_q5_pro/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Lenovo",
    "Platform": "sr665_q5_pro",
    "Result": 3833.7,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Lenovo ThinkSystem SR665v1 (5x QAIC100 Pro)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 5,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.9.1",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "AMD EPYC 75F3 32-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Powered by the KRAI X and KILT technologies",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2 LTS (Jammy Jellyfish) (Linux kernel: 5.15.0-76-generic #83-Ubuntu SMP Thu Jun 15 19:16:32 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux",
    "uid": "51e691bc1a584d56",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Lenovo/results/sr665_q5_pro/bert-99/offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.8666333229796,
    "Accuracy_div_100": 0.90867,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/sr665_q5_pro/bert-99.9/offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Lenovo",
    "Platform": "sr665_q5_pro",
    "Result": 1894.73,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Lenovo ThinkSystem SR665v1 (5x QAIC100 Pro)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 5,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.9.1",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "AMD EPYC 75F3 32-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Powered by the KRAI X and KILT technologies",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2 LTS (Jammy Jellyfish) (Linux kernel: 5.15.0-76-generic #83-Ubuntu SMP Thu Jun 15 19:16:32 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux",
    "uid": "a9bcb68d9e714833",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Lenovo/results/sr665_q5_pro/bert-99.9/offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.35676151551918,
    "Accuracy_div_100": 0.90357,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/Lenovo_H100_PCIe_80GBx8_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Lenovo",
    "Platform": "Lenovo_H100_PCIe_80GBx8_TRT",
    "Result": 46720.2,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Lenovo ThinkSystem SR675 V3 (8x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 9554 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2",
    "uid": "88b1bd43a33e4366",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Lenovo/results/Lenovo_H100_PCIe_80GBx8_TRT/bert-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.28408874066913,
    "Accuracy_div_100": 0.90284,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Qualcomm/results/g292_z43_q16/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Qualcomm",
    "Platform": "g292_z43_q16",
    "Result": 12536.8,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "GIGABYTE G292-Z43 (16x QAIC100 Pro)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 16,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.9.1",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7713 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Powered by the KRAI X and KILT technologies",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6 LTS (Linux kernel 5.4.0-139-generic #156-Ubuntu SMP Fri Jan 20 17:27:18 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "b998df0411d248de",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Qualcomm/results/g292_z43_q16/bert-99/offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.8666333229796,
    "Accuracy_div_100": 0.90867,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Qualcomm/results/g292_z43_q16/bert-99.9/offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Qualcomm",
    "Platform": "g292_z43_q16",
    "Result": 6315.87,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "GIGABYTE G292-Z43 (16x QAIC100 Pro)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 16,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.9.1",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7713 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Powered by the KRAI X and KILT technologies",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6 LTS (Linux kernel 5.4.0-139-generic #156-Ubuntu SMP Fri Jan 20 17:27:18 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "516fadfd79ac410a",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Qualcomm/results/g292_z43_q16/bert-99.9/offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 42.9801,
    "Accuracy_div_100": 0.4298,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Intel-HabanaLabs/results/HLS-Gaudi2-PT/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Intel-HabanaLabs",
    "Platform": "HLS-Gaudi2-PT",
    "Result": 84.075,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "HLS-Gaudi2-PT",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "Habana Gaudi2",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "PyTorch 2.0.1a0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8380",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04",
    "uid": "23419171b2b84200",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Intel-HabanaLabs/results/HLS-Gaudi2-PT/gptj-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 42.9801,
    "Accuracy_div_100": 0.4298,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Intel-HabanaLabs/results/HLS-Gaudi2-PT/gptj-99.9/Offline",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "Intel-HabanaLabs",
    "Platform": "HLS-Gaudi2-PT",
    "Result": 84.075,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "HLS-Gaudi2-PT",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "Habana Gaudi2",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "PyTorch 2.0.1a0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8380",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04",
    "uid": "6df7e4f5f3b64fcc",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Intel-HabanaLabs/results/HLS-Gaudi2-PT/gptj-99.9/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 42.9454,
    "Accuracy_div_100": 0.42945,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R750xa_A100_PCIe_80GBx4_TRT/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Dell",
    "Platform": "R750xa_A100_PCIe_80GBx4_TRT",
    "Result": 14.7035,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge R750xa (4x A100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6338 CPU @ 2.00GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.1",
    "uid": "c5f1a51776594dfd",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Dell/results/R750xa_A100_PCIe_80GBx4_TRT/gptj-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.35676151551918,
    "Accuracy_div_100": 0.90357,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R760xa_H100_PCIe_80GBx2_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Dell",
    "Platform": "R760xa_H100_PCIe_80GBx2_TRT",
    "Result": 11834.2,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge R760xa (2x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "ba222732e54044d8",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Dell/results/R760xa_H100_PCIe_80GBx2_TRT/bert-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.97056894987658,
    "Accuracy_div_100": 0.90971,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R760xa_H100_PCIe_80GBx2_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Dell",
    "Platform": "R760xa_H100_PCIe_80GBx2_TRT",
    "Result": 9824.04,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge R760xa (2x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "3d59c39389bb46f2",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Dell/results/R760xa_H100_PCIe_80GBx2_TRT/bert-99.9/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.35676151551918,
    "Accuracy_div_100": 0.90357,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9640_H100_SXM_80GBx4_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Dell",
    "Platform": "XE9640_H100_SXM_80GBx4_TRT",
    "Result": 35402.3,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE9640 (4x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "b5a69934321d4df3",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Dell/results/XE9640_H100_SXM_80GBx4_TRT/bert-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.97056894987658,
    "Accuracy_div_100": 0.90971,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9640_H100_SXM_80GBx4_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Dell",
    "Platform": "XE9640_H100_SXM_80GBx4_TRT",
    "Result": 31369.4,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE9640 (4x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "02b6246007ce403d",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Dell/results/XE9640_H100_SXM_80GBx4_TRT/bert-99.9/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 43.0722,
    "Accuracy_div_100": 0.43072,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9640_H100_SXM_80GBx4_TRT/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Dell",
    "Platform": "XE9640_H100_SXM_80GBx4_TRT",
    "Result": 51.9877,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE9640 (4x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "a0a2e424ee074960",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Dell/results/XE9640_H100_SXM_80GBx4_TRT/gptj-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 43.0722,
    "Accuracy_div_100": 0.43072,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9640_H100_SXM_80GBx4_TRT/gptj-99.9/Offline",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "Dell",
    "Platform": "XE9640_H100_SXM_80GBx4_TRT",
    "Result": 51.9877,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE9640 (4x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "9b68f6ef072b4152",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Dell/results/XE9640_H100_SXM_80GBx4_TRT/gptj-99.9/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.35676151551918,
    "Accuracy_div_100": 0.90357,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R750xa_H100_PCIe_80GBx4_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Dell",
    "Platform": "R750xa_H100_PCIe_80GBx4_TRT",
    "Result": 21392.5,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge R750xa (4x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6338 CPU @ 2.00GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "NVIDIA H100-PCIe-80GB (TDP: 310W)",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "uid": "0c1e96d5401e46f0",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Dell/results/R750xa_H100_PCIe_80GBx4_TRT/bert-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.97056894987658,
    "Accuracy_div_100": 0.90971,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R750xa_H100_PCIe_80GBx4_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Dell",
    "Platform": "R750xa_H100_PCIe_80GBx4_TRT",
    "Result": 17895.5,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge R750xa (4x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6338 CPU @ 2.00GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "NVIDIA H100-PCIe-80GB (TDP: 310W)",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "uid": "d493c35c403e4bb0",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Dell/results/R750xa_H100_PCIe_80GBx4_TRT/bert-99.9/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 42.9833,
    "Accuracy_div_100": 0.42983,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9680_A100_SXM_80GBx8_TRT/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Dell",
    "Platform": "XE9680_A100_SXM_80GBx8_TRT",
    "Result": 42.3161,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE9680 (8x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB CTS",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "NVIDIA A100-SXM4-80GB (TDP: 500W)",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "028f7b2c9f6b4fed",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Dell/results/XE9680_A100_SXM_80GBx8_TRT/gptj-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.35676151551918,
    "Accuracy_div_100": 0.90357,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R760xa_H100_PCIe_80GBx4_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Dell",
    "Platform": "R760xa_H100_PCIe_80GBx4_TRT",
    "Result": 22940.6,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge R760xa (4x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "2578efb8573743a9",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Dell/results/R760xa_H100_PCIe_80GBx4_TRT/bert-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.97056894987658,
    "Accuracy_div_100": 0.90971,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R760xa_H100_PCIe_80GBx4_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Dell",
    "Platform": "R760xa_H100_PCIe_80GBx4_TRT",
    "Result": 19467.1,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge R760xa (4x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "047f5e33c6de474f",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Dell/results/R760xa_H100_PCIe_80GBx4_TRT/bert-99.9/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.35676151551918,
    "Accuracy_div_100": 0.90357,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9680_H100_SXM_80GBx8_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Dell",
    "Platform": "XE9680_H100_SXM_80GBx8_TRT",
    "Result": 70307.4,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE9680 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 52,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "e358202fdb5c44b4",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Dell/results/XE9680_H100_SXM_80GBx8_TRT/bert-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.97056894987658,
    "Accuracy_div_100": 0.90971,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9680_H100_SXM_80GBx8_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Dell",
    "Platform": "XE9680_H100_SXM_80GBx8_TRT",
    "Result": 62520.9,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE9680 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 52,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "37960ab9b5974edb",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Dell/results/XE9680_H100_SXM_80GBx8_TRT/bert-99.9/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 43.0395,
    "Accuracy_div_100": 0.43039,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9680_H100_SXM_80GBx8_TRT/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Dell",
    "Platform": "XE9680_H100_SXM_80GBx8_TRT",
    "Result": 101.832,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE9680 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 52,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "6c5451cec08c4684",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Dell/results/XE9680_H100_SXM_80GBx8_TRT/gptj-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 43.0395,
    "Accuracy_div_100": 0.43039,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9680_H100_SXM_80GBx8_TRT/gptj-99.9/Offline",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "Dell",
    "Platform": "XE9680_H100_SXM_80GBx8_TRT",
    "Result": 101.832,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE9680 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 52,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "dcc29d7aede84bb1",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Dell/results/XE9680_H100_SXM_80GBx8_TRT/gptj-99.9/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.2147015680108,
    "Accuracy_div_100": 0.90215,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R750xa_A100_PCIE_80GBx4_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Dell",
    "Platform": "R750xa_A100_PCIE_80GBx4_TRT",
    "Result": 12652.9,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge R750xa (4x A100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter,edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6338 CPU @ 2.00GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.1",
    "uid": "51a4262b93e0468a",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Dell/results/R750xa_A100_PCIE_80GBx4_TRT/bert-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.87751170441149,
    "Accuracy_div_100": 0.90878,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R750xa_A100_PCIE_80GBx4_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Dell",
    "Platform": "R750xa_A100_PCIE_80GBx4_TRT",
    "Result": 6533,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge R750xa (4x A100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter,edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6338 CPU @ 2.00GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.1",
    "uid": "388321423a80441c",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Dell/results/R750xa_A100_PCIE_80GBx4_TRT/bert-99.9/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.53885196505269,
    "Accuracy_div_100": 0.90539,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/1-node-2S-SPR-PyTorch-INT8/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Dell",
    "Platform": "1-node-2S-SPR-PyTorch-INT8",
    "Result": 1386.38,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge Server R760 (1x Intel Xeon Platinum 8480+)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "PyTorch",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 224,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "CentOS Stream 8",
    "uid": "823c1f5a6ad34adc",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Dell/results/1-node-2S-SPR-PyTorch-INT8/bert-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 42.9056,
    "Accuracy_div_100": 0.42906,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/1-node-2S-SPR-PyTorch-INT8/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Dell",
    "Platform": "1-node-2S-SPR-PyTorch-INT8",
    "Result": 2.06763,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge Server R760 (1x Intel Xeon Platinum 8480+)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "PyTorch",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 224,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "CentOS Stream 8",
    "uid": "58eb802f08bc46b7",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Dell/results/1-node-2S-SPR-PyTorch-INT8/gptj-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.23848090934187,
    "Accuracy_div_100": 0.90238,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R760xa_L40x4_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Dell",
    "Platform": "R760xa_L40x4_TRT",
    "Result": 8311.43,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge R760xa (4x L40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8460Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.1",
    "uid": "cfb8fa4147584801",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Dell/results/R760xa_L40x4_TRT/bert-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.88066528372401,
    "Accuracy_div_100": 0.90881,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R760xa_L40x4_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Dell",
    "Platform": "R760xa_L40x4_TRT",
    "Result": 3853.08,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge R760xa (4x L40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8460Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.1",
    "uid": "4ebc648a074e4cf9",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Dell/results/R760xa_L40x4_TRT/bert-99.9/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 43.0746,
    "Accuracy_div_100": 0.43075,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R760xa_L40x4_TRT/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Dell",
    "Platform": "R760xa_L40x4_TRT",
    "Result": 18.502,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge R760xa (4x L40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8460Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.1",
    "uid": "630670add8624738",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Dell/results/R760xa_L40x4_TRT/gptj-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 43.0746,
    "Accuracy_div_100": 0.43075,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R760xa_L40x4_TRT/gptj-99.9/Offline",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "Dell",
    "Platform": "R760xa_L40x4_TRT",
    "Result": 18.502,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge R760xa (4x L40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8460Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.1",
    "uid": "adb2fae028504153",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Dell/results/R760xa_L40x4_TRT/gptj-99.9/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.35676151551918,
    "Accuracy_div_100": 0.90357,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Dell",
    "Platform": "XE8640_H100_SXM_80GBx4_TRT",
    "Result": 36155.7,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE8640 (4x NVIDIA H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.1",
    "uid": "b10bdf2de319422c",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/bert-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.97056894987658,
    "Accuracy_div_100": 0.90971,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Dell",
    "Platform": "XE8640_H100_SXM_80GBx4_TRT",
    "Result": 31595.1,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE8640 (4x NVIDIA H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.1",
    "uid": "f4036f51c64245da",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/bert-99.9/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 43.0722,
    "Accuracy_div_100": 0.43072,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Dell",
    "Platform": "XE8640_H100_SXM_80GBx4_TRT",
    "Result": 51.7954,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE8640 (4x NVIDIA H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.1",
    "uid": "22b30a2c42a34efe",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/gptj-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 43.0722,
    "Accuracy_div_100": 0.43072,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/gptj-99.9/Offline",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "Dell",
    "Platform": "XE8640_H100_SXM_80GBx4_TRT",
    "Result": 51.7954,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE8640 (4x NVIDIA H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.1",
    "uid": "5ea11f19d8dc4b97",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/gptj-99.9/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.2147015680108,
    "Accuracy_div_100": 0.90215,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/xFusion/results/G5500V7_A30x10_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "xFusion",
    "Platform": "G5500V7_A30x10_TRT",
    "Result": 17263.5,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "xFusion FusionServer G5500V7(10x NVIDIA A30, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 10,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6458Q @ 3.1 GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "c80f949ed2e44a73",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/xFusion/results/G5500V7_A30x10_TRT/bert-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.87751170441149,
    "Accuracy_div_100": 0.90878,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/xFusion/results/G5500V7_A30x10_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "xFusion",
    "Platform": "G5500V7_A30x10_TRT",
    "Result": 8687.66,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "xFusion FusionServer G5500V7(10x NVIDIA A30, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 10,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6458Q @ 3.1 GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "3dd36469235140b6",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/xFusion/results/G5500V7_A30x10_TRT/bert-99.9/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.2147015680108,
    "Accuracy_div_100": 0.90215,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/xFusion/results/G5500V7_L40x8_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "xFusion",
    "Platform": "G5500V7_L40x8_TRT",
    "Result": 14439.7,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "xFusion FusionServer G5500V7(8x NVIDIA L40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6458Q @ 3.1 GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "b89854c2aa0d4ccc",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/xFusion/results/G5500V7_L40x8_TRT/bert-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.92793580748601,
    "Accuracy_div_100": 0.90928,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/xFusion/results/G5500V7_L40x8_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "xFusion",
    "Platform": "G5500V7_L40x8_TRT",
    "Result": 8797.1,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "xFusion FusionServer G5500V7(8x NVIDIA L40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6458Q @ 3.1 GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "ef587b81f2e444be",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/xFusion/results/G5500V7_L40x8_TRT/bert-99.9/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 43.0641,
    "Accuracy_div_100": 0.43064,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/xFusion/results/G5500V7_L40x8_TRT/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "xFusion",
    "Platform": "G5500V7_L40x8_TRT",
    "Result": 40.194,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "xFusion FusionServer G5500V7(8x NVIDIA L40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6458Q @ 3.1 GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "99b61a992a65424d",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/xFusion/results/G5500V7_L40x8_TRT/gptj-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 43.0641,
    "Accuracy_div_100": 0.43064,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/xFusion/results/G5500V7_L40x8_TRT/gptj-99.9/Offline",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "xFusion",
    "Platform": "G5500V7_L40x8_TRT",
    "Result": 40.194,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "xFusion FusionServer G5500V7(8x NVIDIA L40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6458Q @ 3.1 GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "1c3ad8951acd4c50",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/xFusion/results/G5500V7_L40x8_TRT/gptj-99.9/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.2147015680108,
    "Accuracy_div_100": 0.90215,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/xFusion/results/G5500V7_A30x8_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "xFusion",
    "Platform": "G5500V7_A30x8_TRT",
    "Result": 13609.6,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "xFusion FusionServer G5500V7(8x NVIDIA A30, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6458Q @ 3.1 GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "73d7d81568524500",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/xFusion/results/G5500V7_A30x8_TRT/bert-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.87751170441149,
    "Accuracy_div_100": 0.90878,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/xFusion/results/G5500V7_A30x8_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "xFusion",
    "Platform": "G5500V7_A30x8_TRT",
    "Result": 6954.59,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "xFusion FusionServer G5500V7(8x NVIDIA A30, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6458Q @ 3.1 GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "c029aa6d84ee409a",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/xFusion/results/G5500V7_A30x8_TRT/bert-99.9/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 42.9451,
    "Accuracy_div_100": 0.42945,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/xFusion/results/G5500V7_A30x8_TRT/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "xFusion",
    "Platform": "G5500V7_A30x8_TRT",
    "Result": 9.82758,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "xFusion FusionServer G5500V7(8x NVIDIA A30, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6458Q @ 3.1 GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "16e6bbf340da4d94",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/xFusion/results/G5500V7_A30x8_TRT/gptj-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 43.0704,
    "Accuracy_div_100": 0.4307,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/xFusion/results/G5500V7_A30x8_TRT/gptj-99.9/Offline",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "xFusion",
    "Platform": "G5500V7_A30x8_TRT",
    "Result": 9.81969,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "xFusion FusionServer G5500V7(8x NVIDIA A30, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6458Q @ 3.1 GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "2d91c72cf5094775",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/xFusion/results/G5500V7_A30x8_TRT/gptj-99.9/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.23848090934187,
    "Accuracy_div_100": 0.90238,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/xFusion/results/L4x6_2288H_V7_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "xFusion",
    "Platform": "L4x6_2288H_V7_TRT",
    "Result": 5748.72,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "xFusion FusionServer 2288H V7(6x NVIDIA L4, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 6,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 44,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8458P CPU @ 2.7 GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "9ad5bab896304252",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/xFusion/results/L4x6_2288H_V7_TRT/bert-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.9257447258943,
    "Accuracy_div_100": 0.90926,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/xFusion/results/L4x6_2288H_V7_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "xFusion",
    "Platform": "L4x6_2288H_V7_TRT",
    "Result": 3942.95,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "xFusion FusionServer 2288H V7(6x NVIDIA L4, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 6,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 44,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8458P CPU @ 2.7 GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "c84eda10cbfd4079",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/xFusion/results/L4x6_2288H_V7_TRT/bert-99.9/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 43.0646,
    "Accuracy_div_100": 0.43065,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/xFusion/results/L4x6_2288H_V7_TRT/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "xFusion",
    "Platform": "L4x6_2288H_V7_TRT",
    "Result": 8.82616,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "xFusion FusionServer 2288H V7(6x NVIDIA L4, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 6,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 44,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8458P CPU @ 2.7 GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "015752c23e184369",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/xFusion/results/L4x6_2288H_V7_TRT/gptj-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 43.0646,
    "Accuracy_div_100": 0.43065,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/xFusion/results/L4x6_2288H_V7_TRT/gptj-99.9/Offline",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "xFusion",
    "Platform": "L4x6_2288H_V7_TRT",
    "Result": 8.8494,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "xFusion FusionServer 2288H V7(6x NVIDIA L4, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 6,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 44,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8458P CPU @ 2.7 GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "052cd085a48848c6",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/xFusion/results/L4x6_2288H_V7_TRT/gptj-99.9/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.2147015680108,
    "Accuracy_div_100": 0.90215,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/xFusion/results/G5500V7_L40x10_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "xFusion",
    "Platform": "G5500V7_L40x10_TRT",
    "Result": 17996.3,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "xFusion FusionServer G5500V7(10x NVIDIA L40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40",
    "accelerators_per_node": 10,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6458Q @ 3.1 GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "21cce291ec494ba5",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/xFusion/results/G5500V7_L40x10_TRT/bert-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.87751170441149,
    "Accuracy_div_100": 0.90878,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/xFusion/results/G5500V7_L40x10_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "xFusion",
    "Platform": "G5500V7_L40x10_TRT",
    "Result": 8527.61,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "xFusion FusionServer G5500V7(10x NVIDIA L40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40",
    "accelerators_per_node": 10,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6458Q @ 3.1 GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "9e884c5334384f5a",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/xFusion/results/G5500V7_L40x10_TRT/bert-99.9/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 43.0169,
    "Accuracy_div_100": 0.43017,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Intel/results/1-node-2S-SPRHBM-PyTorch-BF16/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Intel",
    "Platform": "1-node-2S-SPRHBM-PyTorch-BF16",
    "Result": 1.02826,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "1-node-2S-SPRHBM-PyTorch-BF16",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "PyTorch",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel (R) Xeon (R) CPU Max 9480",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "SC09WPRF0134SR. N/A",
    "number_of_nodes": 1,
    "operating_system": "CentOS Stream 8",
    "uid": "6ca9d7d390af4646",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Intel/results/1-node-2S-SPRHBM-PyTorch-BF16/gptj-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 43.0169,
    "Accuracy_div_100": 0.43017,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Intel/results/1-node-2S-SPRHBM-PyTorch-BF16/gptj-99.9/Offline",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "Intel",
    "Platform": "1-node-2S-SPRHBM-PyTorch-BF16",
    "Result": 1.02826,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "1-node-2S-SPRHBM-PyTorch-BF16",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "PyTorch",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel (R) Xeon (R) CPU Max 9480",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "SC09WPRF0134SR. N/A",
    "number_of_nodes": 1,
    "operating_system": "CentOS Stream 8",
    "uid": "0335291018cb447b",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Intel/results/1-node-2S-SPRHBM-PyTorch-BF16/gptj-99.9/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.53885196505269,
    "Accuracy_div_100": 0.90539,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Intel/results/1-node-2S-SPR-PyTorch-INT8/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Intel",
    "Platform": "1-node-2S-SPR-PyTorch-INT8",
    "Result": 1357.33,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "1-node-2S-SPR-PyTorch-INT8",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "PyTorch",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54Q-2U. N/A",
    "number_of_nodes": 1,
    "operating_system": "CentOS Stream 8",
    "uid": "f7665d4a2a334e6b",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Intel/results/1-node-2S-SPR-PyTorch-INT8/bert-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 42.9056,
    "Accuracy_div_100": 0.42906,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Intel/results/1-node-2S-SPR-PyTorch-INT8/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Intel",
    "Platform": "1-node-2S-SPR-PyTorch-INT8",
    "Result": 2.04507,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "1-node-2S-SPR-PyTorch-INT8",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "PyTorch",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54Q-2U. N/A",
    "number_of_nodes": 1,
    "operating_system": "CentOS Stream 8",
    "uid": "fdab48c6a7df48fb",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Intel/results/1-node-2S-SPR-PyTorch-INT8/gptj-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 42.8729,
    "Accuracy_div_100": 0.42873,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Intel/results/1-node-2S-SPR-PyTorch-INT4/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Intel",
    "Platform": "1-node-2S-SPR-PyTorch-INT4",
    "Result": 1.89914,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "1-node-2S-SPR-PyTorch-INT4+INT8",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "PyTorch",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54Q-2U. N/A",
    "number_of_nodes": 1,
    "operating_system": "CentOS Stream 8",
    "uid": "f5bd2daf212540e1",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Intel/results/1-node-2S-SPR-PyTorch-INT4/gptj-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.22397444450428,
    "Accuracy_div_100": 0.90224,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Oracle/results/OCI-A100_A100-SXM-80GBx8_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Oracle",
    "Platform": "OCI-A100_A100-SXM-80GBx8_TRT",
    "Result": 28028.6,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "BM.GPU.A100-v2.8",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7J13 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "077b79cd4ff54e09",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Oracle/results/OCI-A100_A100-SXM-80GBx8_TRT/bert-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.88066528372401,
    "Accuracy_div_100": 0.90881,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Oracle/results/OCI-A100_A100-SXM-80GBx8_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Oracle",
    "Platform": "OCI-A100_A100-SXM-80GBx8_TRT",
    "Result": 14534.4,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "BM.GPU.A100-v2.8",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7J13 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "963fe1a219074694",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Oracle/results/OCI-A100_A100-SXM-80GBx8_TRT/bert-99.9/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 42.9314,
    "Accuracy_div_100": 0.42931,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Oracle/results/OCI-A100_A100-SXM-80GBx8_TRT/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Oracle",
    "Platform": "OCI-A100_A100-SXM-80GBx8_TRT",
    "Result": 27.1314,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "BM.GPU.A100-v2.8",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7J13 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "5ffe58cbd7c242a5",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Oracle/results/OCI-A100_A100-SXM-80GBx8_TRT/gptj-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 42.9494,
    "Accuracy_div_100": 0.42949,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Oracle/results/OCI-A100_A100-SXM-80GBx8_TRT/gptj-99.9/Offline",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "Oracle",
    "Platform": "OCI-A100_A100-SXM-80GBx8_TRT",
    "Result": 25.2893,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "BM.GPU.A100-v2.8",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7J13 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "989d7d2b91204279",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Oracle/results/OCI-A100_A100-SXM-80GBx8_TRT/gptj-99.9/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.35676151551918,
    "Accuracy_div_100": 0.90357,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Oracle/results/OCI-H100_H100-SXM-80GBx8_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Oracle",
    "Platform": "OCI-H100_H100-SXM-80GBx8_TRT",
    "Result": 70689.9,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "BM.GPU.H100.8",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "6c8b6fbbb4224367",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Oracle/results/OCI-H100_H100-SXM-80GBx8_TRT/bert-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.97056894987658,
    "Accuracy_div_100": 0.90971,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Oracle/results/OCI-H100_H100-SXM-80GBx8_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Oracle",
    "Platform": "OCI-H100_H100-SXM-80GBx8_TRT",
    "Result": 62285.5,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "BM.GPU.H100.8",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "9077e1d1e09345af",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Oracle/results/OCI-H100_H100-SXM-80GBx8_TRT/bert-99.9/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 43.0286,
    "Accuracy_div_100": 0.43029,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Oracle/results/OCI-H100_H100-SXM-80GBx8_TRT/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Oracle",
    "Platform": "OCI-H100_H100-SXM-80GBx8_TRT",
    "Result": 106.692,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "BM.GPU.H100.8",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "76ae4a017d4d46b5",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Oracle/results/OCI-H100_H100-SXM-80GBx8_TRT/gptj-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.35676151551918,
    "Accuracy_div_100": 0.90357,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/GigaComputing/results/GIGABYTE-G593-SD0_H100-SXM-80GBx8_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "GigaComputing",
    "Platform": "GIGABYTE-G593-SD0_H100-SXM-80GBx8_TRT",
    "Result": 71212.8,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "GIGABYTE G593-SD0",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "7310d78055c14da4",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/GigaComputing/results/GIGABYTE-G593-SD0_H100-SXM-80GBx8_TRT/bert-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.97056894987658,
    "Accuracy_div_100": 0.90971,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/GigaComputing/results/GIGABYTE-G593-SD0_H100-SXM-80GBx8_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "GigaComputing",
    "Platform": "GIGABYTE-G593-SD0_H100-SXM-80GBx8_TRT",
    "Result": 62556.4,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "GIGABYTE G593-SD0",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "46f8b714b9a54f39",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/GigaComputing/results/GIGABYTE-G593-SD0_H100-SXM-80GBx8_TRT/bert-99.9/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 43.0722,
    "Accuracy_div_100": 0.43072,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/GigaComputing/results/GIGABYTE-G593-SD0_H100-SXM-80GBx8_TRT/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "GigaComputing",
    "Platform": "GIGABYTE-G593-SD0_H100-SXM-80GBx8_TRT",
    "Result": 103.446,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "GIGABYTE G593-SD0",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "d2c5e2c2ac72414a",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/GigaComputing/results/GIGABYTE-G593-SD0_H100-SXM-80GBx8_TRT/gptj-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 43.0722,
    "Accuracy_div_100": 0.43072,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/GigaComputing/results/GIGABYTE-G593-SD0_H100-SXM-80GBx8_TRT/gptj-99.9/Offline",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "GigaComputing",
    "Platform": "GIGABYTE-G593-SD0_H100-SXM-80GBx8_TRT",
    "Result": 103.446,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "GIGABYTE G593-SD0",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "68543fb532d14122",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/GigaComputing/results/GIGABYTE-G593-SD0_H100-SXM-80GBx8_TRT/gptj-99.9/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.23343518244184,
    "Accuracy_div_100": 0.90233,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/R5350G6_L40x8_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "H3C",
    "Platform": "R5350G6_L40x8_TRT",
    "Result": 15360.8,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "H3C UniServer R5350 G6 (8x L40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "AMD EPYC 9754 128-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5",
    "uid": "d808cdcf2fd84860",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/H3C/results/R5350G6_L40x8_TRT/bert-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.23848090934187,
    "Accuracy_div_100": 0.90238,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/R5300G6_L40x8_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "H3C",
    "Platform": "R5300G6_L40x8_TRT",
    "Result": 17448.4,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "H3C UniServer R5300 G6 (8x L40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 44,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8458P",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5",
    "uid": "4447b1dcd764425d",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/H3C/results/R5300G6_L40x8_TRT/bert-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.35676151551918,
    "Accuracy_div_100": 0.90357,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/D54Q_2U_H100_PCIe_80GBx2_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "D54Q_2U_H100_PCIe_80GBx2_TRT",
    "Result": 11251.9,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "D54Q_2U (2x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6430 32-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.0",
    "uid": "b3c0102a9ff94203",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Quanta_Cloud_Technology/results/D54Q_2U_H100_PCIe_80GBx2_TRT/bert-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.97056894987658,
    "Accuracy_div_100": 0.90971,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/D54Q_2U_H100_PCIe_80GBx2_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "D54Q_2U_H100_PCIe_80GBx2_TRT",
    "Result": 9491.09,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "D54Q_2U (2x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6430 32-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.0",
    "uid": "5fe16721c6964e41",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Quanta_Cloud_Technology/results/D54Q_2U_H100_PCIe_80GBx2_TRT/bert-99.9/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.35676151551918,
    "Accuracy_div_100": 0.90357,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/D54U_3U_H100_PCIe_80GBx4_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "D54U_3U_H100_PCIe_80GBx4_TRT",
    "Result": 22801.6,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "D54U-3U (4x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.0",
    "uid": "2b0a611631f74de4",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Quanta_Cloud_Technology/results/D54U_3U_H100_PCIe_80GBx4_TRT/bert-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.97056894987658,
    "Accuracy_div_100": 0.90971,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/D54U_3U_H100_PCIe_80GBx4_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "D54U_3U_H100_PCIe_80GBx4_TRT",
    "Result": 19285.1,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "D54U-3U (4x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.0",
    "uid": "7f60583f50694b47",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Quanta_Cloud_Technology/results/D54U_3U_H100_PCIe_80GBx4_TRT/bert-99.9/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.53885196505269,
    "Accuracy_div_100": 0.90539,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/1-node-2S-SPR-PyTorch-INT8/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "1-node-2S-SPR-PyTorch-INT8",
    "Result": 1354.06,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "1-node-2S-SPR-PyTorch-INT8",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": "N/A",
    "compliance": 1,
    "errors": 0,
    "framework": "PyTorch",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+ 56-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54Q-2U",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.1",
    "uid": "533efe56972c4058",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Quanta_Cloud_Technology/results/1-node-2S-SPR-PyTorch-INT8/bert-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 42.9056,
    "Accuracy_div_100": 0.42906,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/1-node-2S-SPR-PyTorch-INT8/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "1-node-2S-SPR-PyTorch-INT8",
    "Result": 2.07078,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "1-node-2S-SPR-PyTorch-INT8",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": "N/A",
    "compliance": 1,
    "errors": 0,
    "framework": "PyTorch",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+ 56-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54Q-2U",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.1",
    "uid": "53e94b154e5d4ca3",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Quanta_Cloud_Technology/results/1-node-2S-SPR-PyTorch-INT8/gptj-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.22954523825543,
    "Accuracy_div_100": 0.9023,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/D54Q_2U_L4_PCIe_24GBx4_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "D54Q_2U_L4_PCIe_24GBx4_TRT",
    "Result": 3733.81,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "D54Q_2U (4x L4-PCIe-24GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L4-PCIe-24GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6430 32-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.0",
    "uid": "19a9a92627454e15",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Quanta_Cloud_Technology/results/D54Q_2U_L4_PCIe_24GBx4_TRT/bert-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.9257447258943,
    "Accuracy_div_100": 0.90926,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/D54Q_2U_L4_PCIe_24GBx4_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "D54Q_2U_L4_PCIe_24GBx4_TRT",
    "Result": 2554.79,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "D54Q_2U (4x L4-PCIe-24GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L4-PCIe-24GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6430 32-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.0",
    "uid": "20a8327b640e46cd",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Quanta_Cloud_Technology/results/D54Q_2U_L4_PCIe_24GBx4_TRT/bert-99.9/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 43.0646,
    "Accuracy_div_100": 0.43065,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/D54Q_2U_L4_PCIe_24GBx4_TRT/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "D54Q_2U_L4_PCIe_24GBx4_TRT",
    "Result": 5.21171,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "D54Q_2U (4x L4-PCIe-24GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L4-PCIe-24GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6430 32-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.0",
    "uid": "9589932c99df4afc",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Quanta_Cloud_Technology/results/D54Q_2U_L4_PCIe_24GBx4_TRT/gptj-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.22397444450428,
    "Accuracy_div_100": 0.90224,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/HPE_ProLiant_XL675d_Gen10_Plus_A100_SXM_80GBx8_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "HPE",
    "Platform": "HPE_ProLiant_XL675d_Gen10_Plus_A100_SXM_80GBx8_TRT",
    "Result": 28464.2,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "HPE ProLiant XL675d Gen10 Plus (8x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7763 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "RHEL 9.1",
    "uid": "b02b50967b034504",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/HPE/results/HPE_ProLiant_XL675d_Gen10_Plus_A100_SXM_80GBx8_TRT/bert-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.88066528372401,
    "Accuracy_div_100": 0.90881,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/HPE_ProLiant_XL675d_Gen10_Plus_A100_SXM_80GBx8_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "HPE",
    "Platform": "HPE_ProLiant_XL675d_Gen10_Plus_A100_SXM_80GBx8_TRT",
    "Result": 14688.2,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "HPE ProLiant XL675d Gen10 Plus (8x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7763 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "RHEL 9.1",
    "uid": "b26eb61dfada4e89",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/HPE/results/HPE_ProLiant_XL675d_Gen10_Plus_A100_SXM_80GBx8_TRT/bert-99.9/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.28408874066913,
    "Accuracy_div_100": 0.90284,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/dl385_q8_std/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "HPE",
    "Platform": "dl385_q8_std",
    "Result": 5917.47,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "HPE ProLiant DL385 Gen10 Plus v2 (8x QAIC100 Standard)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Standard",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.9.1",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "AMD EPYC 7543 32-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Powered by the KRAI X and KILT technologies",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6 LTS (Linux kernel 5.15.0-75-generic #82~20.04.1-Ubuntu SMP Wed Jun 7 19:37:37 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "cdcb26d629204654",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/HPE/results/dl385_q8_std/bert-99/offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.8666333229796,
    "Accuracy_div_100": 0.90867,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/dl385_q8_std/bert-99.9/offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "HPE",
    "Platform": "dl385_q8_std",
    "Result": 2956.58,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "HPE ProLiant DL385 Gen10 Plus v2 (8x QAIC100 Standard)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Standard",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.9.1",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "AMD EPYC 7543 32-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Powered by the KRAI X and KILT technologies",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6 LTS (Linux kernel 5.15.0-75-generic #82~20.04.1-Ubuntu SMP Wed Jun 7 19:37:37 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "ae78ce4004654f73",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/HPE/results/dl385_q8_std/bert-99.9/offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.35676151551918,
    "Accuracy_div_100": 0.90357,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/HPE_ProLiant_DL380a_Gen11_H100_PCIe_80GBx4_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "HPE",
    "Platform": "HPE_ProLiant_DL380a_Gen11_H100_PCIe_80GBx4_TRT",
    "Result": 23441.1,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "HPE ProLiant DL380a Gen11 (4x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "uid": "f7fa67c65dd944ba",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/HPE/results/HPE_ProLiant_DL380a_Gen11_H100_PCIe_80GBx4_TRT/bert-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.97056894987658,
    "Accuracy_div_100": 0.90971,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/HPE_ProLiant_DL380a_Gen11_H100_PCIe_80GBx4_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "HPE",
    "Platform": "HPE_ProLiant_DL380a_Gen11_H100_PCIe_80GBx4_TRT",
    "Result": 20329.9,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "HPE ProLiant DL380a Gen11 (4x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "uid": "01306224b26a45f5",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/HPE/results/HPE_ProLiant_DL380a_Gen11_H100_PCIe_80GBx4_TRT/bert-99.9/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.53885196505269,
    "Accuracy_div_100": 0.90539,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/1-node-2S-SPR-PyTorch-INT8/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "HPE",
    "Platform": "1-node-2S-SPR-PyTorch-INT8",
    "Result": 1469.64,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "1-node-2S-SPR-PyTorch-INT8",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "PyTorch",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "HPE ProLiant DL380a Gen11. N/A",
    "number_of_nodes": 1,
    "operating_system": "Red Hat Enterprise Linux 8.8 (Ootpa)",
    "uid": "1b1be91448a2403b",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/HPE/results/1-node-2S-SPR-PyTorch-INT8/bert-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 42.9093,
    "Accuracy_div_100": 0.42909,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/1-node-2S-SPR-PyTorch-INT8/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "HPE",
    "Platform": "1-node-2S-SPR-PyTorch-INT8",
    "Result": 2.13903,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "1-node-2S-SPR-PyTorch-INT8",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "PyTorch",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "HPE ProLiant DL380a Gen11. N/A",
    "number_of_nodes": 1,
    "operating_system": "Red Hat Enterprise Linux 8.8 (Ootpa)",
    "uid": "8907be2b65a1478e",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/HPE/results/1-node-2S-SPR-PyTorch-INT8/gptj-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.36306105137962,
    "Accuracy_div_100": 0.90363,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Krai/results/r282_z93_q5-qaic-v1.6.80-aic100/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Krai",
    "Platform": "r282_z93_q5-qaic-v1.6.80-aic100",
    "Result": 3597.91,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte R282-Z93 (5x QAIC100)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 5,
    "compliance": 1,
    "errors": 0,
    "framework": "Qualcomm Cloud AI SDK v1.6.80",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 7282 16-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "CentOS 7 (Linux kernel: 5.4.1-1.el7.elrepo.x86_64 #1 SMP Fri Nov 29 10:21:13 EST 2019 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "b0dddce7ca804d94",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Krai/results/r282_z93_q5-qaic-v1.6.80-aic100/bert-99/offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.87603921605954,
    "Accuracy_div_100": 0.90876,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Krai/results/r282_z93_q5-qaic-v1.6.80-aic100/bert-99.9/offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Krai",
    "Platform": "r282_z93_q5-qaic-v1.6.80-aic100",
    "Result": 1769.71,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte R282-Z93 (5x QAIC100)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 5,
    "compliance": 1,
    "errors": 0,
    "framework": "Qualcomm Cloud AI SDK v1.6.80",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 7282 16-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "CentOS 7 (Linux kernel: 5.4.1-1.el7.elrepo.x86_64 #1 SMP Fri Nov 29 10:21:13 EST 2019 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "a83bea3364804aad",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Krai/results/r282_z93_q5-qaic-v1.6.80-aic100/bert-99.9/offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.93259027866519,
    "Accuracy_div_100": 0.90933,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/Triton_Inferentia_INF1_2XLARGEx1/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "NVIDIA",
    "Platform": "Triton_Inferentia_INF1_2XLARGEx1",
    "Result": 63.7585,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS Inf1.2xlarge",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "Inferentia",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Pytorch 1.9.1, AWS Neuron 1.9.1.2",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 8,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8275CL CPU @ 3.00GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Triton Inference Server on AWS Inf1 instance",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04",
    "uid": "6bfe630586d04a62",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/Triton_Inferentia_INF1_2XLARGEx1/bert-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.93259027866519,
    "Accuracy_div_100": 0.90933,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/Triton_Inferentia_INF1_2XLARGEx1/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "NVIDIA",
    "Platform": "Triton_Inferentia_INF1_2XLARGEx1",
    "Result": 63.7585,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS Inf1.2xlarge",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "Inferentia",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Pytorch 1.9.1, AWS Neuron 1.9.1.2",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 8,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8275CL CPU @ 3.00GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Triton Inference Server on AWS Inf1 instance",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04",
    "uid": "abf4a9749259462b",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/Triton_Inferentia_INF1_2XLARGEx1/bert-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.38529083707651,
    "Accuracy_div_100": 0.90385,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A100-PCIe-80GBx8_TRT_Triton/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "NVIDIA",
    "Platform": "A100-PCIe-80GBx8_TRT_Triton",
    "Result": 25256.6,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G482-Z54 (8x A100-PCIe-80GB, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "a5d90597db2e480e",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/A100-PCIe-80GBx8_TRT_Triton/bert-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.86087496792462,
    "Accuracy_div_100": 0.90861,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A100-PCIe-80GBx8_TRT_Triton/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "NVIDIA",
    "Platform": "A100-PCIe-80GBx8_TRT_Triton",
    "Result": 12863.4,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G482-Z54 (8x A100-PCIe-80GB, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "9cd266a83e594073",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/A100-PCIe-80GBx8_TRT_Triton/bert-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.39033939936255,
    "Accuracy_div_100": 0.9039,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A30-MIG_1x1g.6gb_TRT_Triton/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "NVIDIA",
    "Platform": "A30-MIG_1x1g.6gb_TRT_Triton",
    "Result": 502.174,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G482-Z54 (1x A30-MIG-1x1g.6gb, TensorRT, Triton)",
    "SystemType": "datacenter,edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A30 (1x1g.6gb MIG)",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "22cba8bff99c4189",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/A30-MIG_1x1g.6gb_TRT_Triton/bert-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.86345516918031,
    "Accuracy_div_100": 0.90863,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A30-MIG_1x1g.6gb_TRT_Triton/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "NVIDIA",
    "Platform": "A30-MIG_1x1g.6gb_TRT_Triton",
    "Result": 245.131,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G482-Z54 (1x A30-MIG-1x1g.6gb, TensorRT, Triton)",
    "SystemType": "datacenter,edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A30 (1x1g.6gb MIG)",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "37ef7262254a4458",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/A30-MIG_1x1g.6gb_TRT_Triton/bert-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.93259027866519,
    "Accuracy_div_100": 0.90933,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/Triton_Inferentia_INF1_6XLARGEx1/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "NVIDIA",
    "Platform": "Triton_Inferentia_INF1_6XLARGEx1",
    "Result": 250.817,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS Inf1.6xlarge",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "Inferentia",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "Pytorch 1.9.1, AWS Neuron 1.9.1.2",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8275CL CPU @ 3.00GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Triton Inference Server on AWS Inf1 instance",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04",
    "uid": "6daa26fc564a4437",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/Triton_Inferentia_INF1_6XLARGEx1/bert-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.93259027866519,
    "Accuracy_div_100": 0.90933,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/Triton_Inferentia_INF1_6XLARGEx1/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "NVIDIA",
    "Platform": "Triton_Inferentia_INF1_6XLARGEx1",
    "Result": 250.817,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS Inf1.6xlarge",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "Inferentia",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "Pytorch 1.9.1, AWS Neuron 1.9.1.2",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8275CL CPU @ 3.00GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Triton Inference Server on AWS Inf1 instance",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04",
    "uid": "1beec5e242ee46d4",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/Triton_Inferentia_INF1_6XLARGEx1/bert-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.40121712891282,
    "Accuracy_div_100": 0.90401,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A100-PCIe-80GB_aarch64x4_TRT_Triton/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "NVIDIA",
    "Platform": "A100-PCIe-80GB_aarch64x4_TRT_Triton",
    "Result": 12693.3,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G242-P31 (4x A100-PCIe-80GB_aarch64, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 80,
    "host_processor_model_name": "Ampere Altra Q80-30",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "233abdc85ec14e96",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/A100-PCIe-80GB_aarch64x4_TRT_Triton/bert-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.86087496792462,
    "Accuracy_div_100": 0.90861,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A100-PCIe-80GB_aarch64x4_TRT_Triton/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "NVIDIA",
    "Platform": "A100-PCIe-80GB_aarch64x4_TRT_Triton",
    "Result": 6411.13,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G242-P31 (4x A100-PCIe-80GB_aarch64, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 80,
    "host_processor_model_name": "Ampere Altra Q80-30",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "325949f8a6e64f1c",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/A100-PCIe-80GB_aarch64x4_TRT_Triton/bert-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.38529083707651,
    "Accuracy_div_100": 0.90385,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A30x8_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "NVIDIA",
    "Platform": "A30x8_TRT",
    "Result": 13340.2,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G482-Z54 (8x A30, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "349c4ebd34f74c8d",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/A30x8_TRT/bert-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.86087496792462,
    "Accuracy_div_100": 0.90861,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A30x8_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "NVIDIA",
    "Platform": "A30x8_TRT",
    "Result": 6643.49,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G482-Z54 (8x A30, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "e250792c67804d53",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/A30x8_TRT/bert-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.39033939936255,
    "Accuracy_div_100": 0.9039,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-A100_A100-SXM-80GB-MIG_1x1g.10gb_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "NVIDIA",
    "Platform": "DGX-A100_A100-SXM-80GB-MIG_1x1g.10gb_TRT",
    "Result": 484.021,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX A100 (1x A100-SXM-80GB-MIG-1x1g.10gb, TensorRT)",
    "SystemType": "datacenter,edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB (1x1g.10gb MIG)",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "2aec515473224542",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GB-MIG_1x1g.10gb_TRT/bert-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.86345516918031,
    "Accuracy_div_100": 0.90863,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-A100_A100-SXM-80GB-MIG_1x1g.10gb_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "NVIDIA",
    "Platform": "DGX-A100_A100-SXM-80GB-MIG_1x1g.10gb_TRT",
    "Result": 246.289,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX A100 (1x A100-SXM-80GB-MIG-1x1g.10gb, TensorRT)",
    "SystemType": "datacenter,edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB (1x1g.10gb MIG)",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "c9154ebcd87843f8",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GB-MIG_1x1g.10gb_TRT/bert-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.39680495326127,
    "Accuracy_div_100": 0.90397,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A100-SXM-80GB_aarch64x8_TRT_Triton/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "NVIDIA",
    "Platform": "A100-SXM-80GB_aarch64x8_TRT_Triton",
    "Result": 27645.3,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G492-PD0 (8x A100-SXM-80GB_aarch64, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 80,
    "host_processor_model_name": "Ampere Altra Q80-30",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "3352a52514684f8c",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/A100-SXM-80GB_aarch64x8_TRT_Triton/bert-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.86087496792462,
    "Accuracy_div_100": 0.90861,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A100-SXM-80GB_aarch64x8_TRT_Triton/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "NVIDIA",
    "Platform": "A100-SXM-80GB_aarch64x8_TRT_Triton",
    "Result": 14063.9,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G492-PD0 (8x A100-SXM-80GB_aarch64, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 80,
    "host_processor_model_name": "Ampere Altra Q80-30",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "f72f8511f3374f1b",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/A100-SXM-80GB_aarch64x8_TRT_Triton/bert-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.39033939936255,
    "Accuracy_div_100": 0.9039,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-A100_A100-SXM-80GB-MIG_1x1g.10gb_TRT_Triton/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "NVIDIA",
    "Platform": "DGX-A100_A100-SXM-80GB-MIG_1x1g.10gb_TRT_Triton",
    "Result": 491.834,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX A100 (1x A100-SXM-80GB-MIG-1x1g.10gb, TensorRT, Triton)",
    "SystemType": "datacenter,edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB (1x1g.10gb MIG)",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "d09002a0bbec4410",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GB-MIG_1x1g.10gb_TRT_Triton/bert-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.86345516918031,
    "Accuracy_div_100": 0.90863,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-A100_A100-SXM-80GB-MIG_1x1g.10gb_TRT_Triton/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "NVIDIA",
    "Platform": "DGX-A100_A100-SXM-80GB-MIG_1x1g.10gb_TRT_Triton",
    "Result": 244.55,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX A100 (1x A100-SXM-80GB-MIG-1x1g.10gb, TensorRT, Triton)",
    "SystemType": "datacenter,edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB (1x1g.10gb MIG)",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "bc7d3a0b80284ebd",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GB-MIG_1x1g.10gb_TRT_Triton/bert-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.32079354407065,
    "Accuracy_div_100": 0.90321,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A2x2_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "NVIDIA",
    "Platform": "A2x2_TRT",
    "Result": 490.654,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Supermicro AS-1114S-WTRT (2x A2, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A2",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 8,
    "host_processor_model_name": "AMD EPYC 7232P 8-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "baee78c954234459",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/A2x2_TRT/bert-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.86345516918031,
    "Accuracy_div_100": 0.90863,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A2x2_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "NVIDIA",
    "Platform": "A2x2_TRT",
    "Result": 239.874,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Supermicro AS-1114S-WTRT (2x A2, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A2",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 8,
    "host_processor_model_name": "AMD EPYC 7232P 8-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "83d7afcd68024d9e",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/A2x2_TRT/bert-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.38087866142499,
    "Accuracy_div_100": 0.90381,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT_Triton/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "NVIDIA",
    "Platform": "DGX-A100_A100-SXM-80GBx8_TRT_Triton",
    "Result": 27831.5,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX A100 (8x A100-SXM-80GB, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "a84cb371ba8f4059",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT_Triton/bert-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.86087496792462,
    "Accuracy_div_100": 0.90861,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT_Triton/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "NVIDIA",
    "Platform": "DGX-A100_A100-SXM-80GBx8_TRT_Triton",
    "Result": 14110.6,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX A100 (8x A100-SXM-80GB, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "c8a4fc98b91448fa",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT_Triton/bert-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 89.9980895214958,
    "Accuracy_div_100": 0.89998,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/Triton_CPU_2S_8380x1/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "NVIDIA",
    "Platform": "Triton_CPU_2S_8380x1",
    "Result": 75.3064,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte R282-3C0 (Ice Lake running Triton)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "OpenVino 2022",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8380 CPU @ 2.30GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "CPU Inference on Triton Inference Server",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "ae2132f5375844c4",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/Triton_CPU_2S_8380x1/bert-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.38087866142499,
    "Accuracy_div_100": 0.90381,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "NVIDIA",
    "Platform": "DGX-A100_A100-SXM-80GBx8_TRT",
    "Result": 27971.4,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX A100 (8x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "03fec2bda94a4ac9",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT/bert-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.86345516918031,
    "Accuracy_div_100": 0.90863,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "NVIDIA",
    "Platform": "DGX-A100_A100-SXM-80GBx8_TRT",
    "Result": 14052.2,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX A100 (8x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "5418b209aa83421e",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT/bert-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.39033939936255,
    "Accuracy_div_100": 0.9039,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A30-MIG_1x1g.6gb_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "NVIDIA",
    "Platform": "A30-MIG_1x1g.6gb_TRT",
    "Result": 502.019,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G482-Z54 (1x A30-MIG-1x1g.6gb, TensorRT)",
    "SystemType": "datacenter,edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A30 (1x1g.6gb MIG)",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "fcd34b1a5ab848ab",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/A30-MIG_1x1g.6gb_TRT/bert-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.86345516918031,
    "Accuracy_div_100": 0.90863,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A30-MIG_1x1g.6gb_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "NVIDIA",
    "Platform": "A30-MIG_1x1g.6gb_TRT",
    "Result": 246.689,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G482-Z54 (1x A30-MIG-1x1g.6gb, TensorRT)",
    "SystemType": "datacenter,edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A30 (1x1g.6gb MIG)",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "63cfcc54bdfd4f30",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/A30-MIG_1x1g.6gb_TRT/bert-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.38529083707651,
    "Accuracy_div_100": 0.90385,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A30x8_TRT_Triton/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "NVIDIA",
    "Platform": "A30x8_TRT_Triton",
    "Result": 13450.5,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G482-Z54 (8x A30, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "2a06878567f64ad7",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/A30x8_TRT_Triton/bert-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.86087496792462,
    "Accuracy_div_100": 0.90861,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A30x8_TRT_Triton/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "NVIDIA",
    "Platform": "A30x8_TRT_Triton",
    "Result": 6633.06,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G482-Z54 (8x A30, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "23af5ba18da34a6d",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/A30x8_TRT_Triton/bert-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.39033939936255,
    "Accuracy_div_100": 0.9039,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-A100_A100-SXM-80GB-MIG_1x1g.10gb_TRT_HeteroMultiUse/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "NVIDIA",
    "Platform": "DGX-A100_A100-SXM-80GB-MIG_1x1g.10gb_TRT_HeteroMultiUse",
    "Result": 483.641,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX A100 (1x A100-SXM-80GB-MIG-1x1g.10gb, TensorRT, HeteroMultiUse)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB (1x1g.10gb MIG)",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "fd307107cd1840da",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GB-MIG_1x1g.10gb_TRT_HeteroMultiUse/bert-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.86345516918031,
    "Accuracy_div_100": 0.90863,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-A100_A100-SXM-80GB-MIG_1x1g.10gb_TRT_HeteroMultiUse/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "NVIDIA",
    "Platform": "DGX-A100_A100-SXM-80GB-MIG_1x1g.10gb_TRT_HeteroMultiUse",
    "Result": 242.269,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX A100 (1x A100-SXM-80GB-MIG-1x1g.10gb, TensorRT, HeteroMultiUse)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB (1x1g.10gb MIG)",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "aef992ddaa12450b",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GB-MIG_1x1g.10gb_TRT_HeteroMultiUse/bert-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.39033939936255,
    "Accuracy_div_100": 0.9039,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A30-MIG_1x1g.6gb_TRT_HeteroMultiUse/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "NVIDIA",
    "Platform": "A30-MIG_1x1g.6gb_TRT_HeteroMultiUse",
    "Result": 461.493,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G482-Z54 (1x A30-MIG-1x1g.6gb, TensorRT, HeteroMultiUse)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A30 (1x1g.6gb MIG)",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "17cb825f5e5b4e32",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/A30-MIG_1x1g.6gb_TRT_HeteroMultiUse/bert-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.86345516918031,
    "Accuracy_div_100": 0.90863,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A30-MIG_1x1g.6gb_TRT_HeteroMultiUse/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "NVIDIA",
    "Platform": "A30-MIG_1x1g.6gb_TRT_HeteroMultiUse",
    "Result": 222.779,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G482-Z54 (1x A30-MIG-1x1g.6gb, TensorRT, HeteroMultiUse)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A30 (1x1g.6gb MIG)",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "be3ee36dbd8f4d03",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/A30-MIG_1x1g.6gb_TRT_HeteroMultiUse/bert-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.38529083707651,
    "Accuracy_div_100": 0.90385,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A100-PCIe-80GBx8_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "NVIDIA",
    "Platform": "A100-PCIe-80GBx8_TRT",
    "Result": 25034.5,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G482-Z54 (8x A100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "882f5e2bd3f54a98",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/A100-PCIe-80GBx8_TRT/bert-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.86087496792462,
    "Accuracy_div_100": 0.90861,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A100-PCIe-80GBx8_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "NVIDIA",
    "Platform": "A100-PCIe-80GBx8_TRT",
    "Result": 12730.3,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G482-Z54 (8x A100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "df7bcb0092e34d04",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/A100-PCIe-80GBx8_TRT/bert-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.37586600946241,
    "Accuracy_div_100": 0.90376,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-A100_A100-SXM-80GB-MIG_56x1g.10gb_TRT_Triton/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "NVIDIA",
    "Platform": "DGX-A100_A100-SXM-80GB-MIG_56x1g.10gb_TRT_Triton",
    "Result": 25547.6,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX A100 (8x A100-SXM-80GB-MIG-7x1g.10gb, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB (7x1g.10gb MIG)",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "25b0c0ed2286487d",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GB-MIG_56x1g.10gb_TRT_Triton/bert-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.86345516918031,
    "Accuracy_div_100": 0.90863,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-A100_A100-SXM-80GB-MIG_56x1g.10gb_TRT_Triton/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "NVIDIA",
    "Platform": "DGX-A100_A100-SXM-80GB-MIG_56x1g.10gb_TRT_Triton",
    "Result": 12548.4,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX A100 (8x A100-SXM-80GB-MIG-7x1g.10gb, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB (7x1g.10gb MIG)",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "4d023ff25df9472f",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GB-MIG_56x1g.10gb_TRT_Triton/bert-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.39680495326127,
    "Accuracy_div_100": 0.90397,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A100-SXM-80GB_aarch64x8_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "NVIDIA",
    "Platform": "A100-SXM-80GB_aarch64x8_TRT",
    "Result": 27893.6,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G492-PD0 (8x A100-SXM-80GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 80,
    "host_processor_model_name": "Ampere Altra Q80-30",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "73ca693d4e8a4752",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/A100-SXM-80GB_aarch64x8_TRT/bert-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.86345516918031,
    "Accuracy_div_100": 0.90863,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A100-SXM-80GB_aarch64x8_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "NVIDIA",
    "Platform": "A100-SXM-80GB_aarch64x8_TRT",
    "Result": 14002.9,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G492-PD0 (8x A100-SXM-80GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 80,
    "host_processor_model_name": "Ampere Altra Q80-30",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "c793e4726f7245bc",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/A100-SXM-80GB_aarch64x8_TRT/bert-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 89.9980895214958,
    "Accuracy_div_100": 0.89998,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/Triton_CPU_4S_8380Hx1/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "NVIDIA",
    "Platform": "Triton_CPU_4S_8380Hx1",
    "Result": 114.746,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Supermicro SYS-240P-TNRT (Cooper Lake running Triton)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "OpenVino 2021",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 28,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 8380H CPU @ 2.70GHz",
    "host_processors_per_node": 4,
    "inferred": 0,
    "notes": "CPU Inference on Triton Inference Server",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "adf970b5bec948a2",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/Triton_CPU_4S_8380Hx1/bert-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.38286500683611,
    "Accuracy_div_100": 0.90383,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A30-MIG_32x1g.6gb_TRT_Triton/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "NVIDIA",
    "Platform": "A30-MIG_32x1g.6gb_TRT_Triton",
    "Result": 12874.9,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G482-Z54 (8x A30-MIG-4x1g.6gb, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A30 (4x1g.6gb MIG)",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "45b65489d20f4d1e",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/A30-MIG_32x1g.6gb_TRT_Triton/bert-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.86513229999652,
    "Accuracy_div_100": 0.90865,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A30-MIG_32x1g.6gb_TRT_Triton/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "NVIDIA",
    "Platform": "A30-MIG_32x1g.6gb_TRT_Triton",
    "Result": 6219.25,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G482-Z54 (8x A30-MIG-4x1g.6gb, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A30 (4x1g.6gb MIG)",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "5bd2083a19dc4b7c",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/A30-MIG_32x1g.6gb_TRT_Triton/bert-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.32079354407065,
    "Accuracy_div_100": 0.90321,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A2x2_TRT_Triton/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "NVIDIA",
    "Platform": "A2x2_TRT_Triton",
    "Result": 495.781,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Supermicro AS-1114S-WTRT (2x A2, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A2",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 8,
    "host_processor_model_name": "AMD EPYC 7232P 8-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "79e0296bccdd4e79",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/A2x2_TRT_Triton/bert-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.86345516918031,
    "Accuracy_div_100": 0.90863,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A2x2_TRT_Triton/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "NVIDIA",
    "Platform": "A2x2_TRT_Triton",
    "Result": 240.067,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Supermicro AS-1114S-WTRT (2x A2, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A2",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 8,
    "host_processor_model_name": "AMD EPYC 7232P 8-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "92cc694a2d074881",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/A2x2_TRT_Triton/bert-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.38087866142499,
    "Accuracy_div_100": 0.90381,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-Station-A100_A100-SXM-80GBx4_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "NVIDIA",
    "Platform": "DGX-Station-A100_A100-SXM-80GBx4_TRT",
    "Result": 11386.5,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX Station A100 (4x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "ed18b25da31b435a",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/DGX-Station-A100_A100-SXM-80GBx4_TRT/bert-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.86087496792462,
    "Accuracy_div_100": 0.90861,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-Station-A100_A100-SXM-80GBx4_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "NVIDIA",
    "Platform": "DGX-Station-A100_A100-SXM-80GBx4_TRT",
    "Result": 5525.37,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX Station A100 (4x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "a6151a8d27f84ff9",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/DGX-Station-A100_A100-SXM-80GBx4_TRT/bert-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.38087866142499,
    "Accuracy_div_100": 0.90381,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-Station-A100_A100-SXM-80GBx4_TRT_Triton/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "NVIDIA",
    "Platform": "DGX-Station-A100_A100-SXM-80GBx4_TRT_Triton",
    "Result": 11424.3,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX Station A100 (4x A100-SXM-80GB, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "2b04ee2372804bff",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/DGX-Station-A100_A100-SXM-80GBx4_TRT_Triton/bert-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.86087496792462,
    "Accuracy_div_100": 0.90861,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-Station-A100_A100-SXM-80GBx4_TRT_Triton/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "NVIDIA",
    "Platform": "DGX-Station-A100_A100-SXM-80GBx4_TRT_Triton",
    "Result": 5523.73,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX Station A100 (4x A100-SXM-80GB, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "e4871e7fe377481d",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/DGX-Station-A100_A100-SXM-80GBx4_TRT_Triton/bert-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.40121712891282,
    "Accuracy_div_100": 0.90401,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A100-PCIe-80GB_aarch64x4_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "NVIDIA",
    "Platform": "A100-PCIe-80GB_aarch64x4_TRT",
    "Result": 12595.2,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G242-P31 (4x A100-PCIe-80GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 80,
    "host_processor_model_name": "Ampere Altra Q80-30",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "e57d4054ab9e42df",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/A100-PCIe-80GB_aarch64x4_TRT/bert-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.86087496792462,
    "Accuracy_div_100": 0.90861,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A100-PCIe-80GB_aarch64x4_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "NVIDIA",
    "Platform": "A100-PCIe-80GB_aarch64x4_TRT",
    "Result": 6408.93,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G242-P31 (4x A100-PCIe-80GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 80,
    "host_processor_model_name": "Ampere Altra Q80-30",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "1f73b7393021490f",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/A100-PCIe-80GB_aarch64x4_TRT/bert-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.38529083707651,
    "Accuracy_div_100": 0.90385,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Azure/results/NC48ads_A100_v4_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Azure",
    "Platform": "NC48ads_A100_v4_TRT",
    "Result": 6177.75,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NC48ads_A100_v4 (2x A100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "AMD EPYC 7V13 64-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.6 LTS",
    "uid": "8aaf0719fda54b61",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Azure/results/NC48ads_A100_v4_TRT/bert-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.86087496792462,
    "Accuracy_div_100": 0.90861,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Azure/results/NC48ads_A100_v4_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Azure",
    "Platform": "NC48ads_A100_v4_TRT",
    "Result": 3084.71,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NC48ads_A100_v4 (2x A100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "AMD EPYC 7V13 64-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.6 LTS",
    "uid": "5594a183dd4247b1",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Azure/results/NC48ads_A100_v4_TRT/bert-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.38087866142499,
    "Accuracy_div_100": 0.90381,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Azure/results/ND96amsr_A100_v4_TRT_Triton/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Azure",
    "Platform": "ND96amsr_A100_v4_TRT_Triton",
    "Result": 27520.3,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "ND96amsr_A100_v4 (8x A100-SXM-80GB, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 7V12 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.6 LTS",
    "uid": "969d212ed8724a92",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Azure/results/ND96amsr_A100_v4_TRT_Triton/bert-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.86087496792462,
    "Accuracy_div_100": 0.90861,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Azure/results/ND96amsr_A100_v4_TRT_Triton/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Azure",
    "Platform": "ND96amsr_A100_v4_TRT_Triton",
    "Result": 13978.2,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "ND96amsr_A100_v4 (8x A100-SXM-80GB, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 7V12 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.6 LTS",
    "uid": "7d929c7289264047",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Azure/results/ND96amsr_A100_v4_TRT_Triton/bert-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.38087866142499,
    "Accuracy_div_100": 0.90381,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Azure/results/ND96amsr_A100_v4_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Azure",
    "Platform": "ND96amsr_A100_v4_TRT",
    "Result": 27675.5,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "ND96amsr_A100_v4 (8x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 7V12 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.6 LTS",
    "uid": "29fb0c12049a4eb8",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Azure/results/ND96amsr_A100_v4_TRT/bert-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.86345516918031,
    "Accuracy_div_100": 0.90863,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Azure/results/ND96amsr_A100_v4_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Azure",
    "Platform": "ND96amsr_A100_v4_TRT",
    "Result": 13901.9,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "ND96amsr_A100_v4 (8x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 7V12 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.6 LTS",
    "uid": "392a53da811d436f",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Azure/results/ND96amsr_A100_v4_TRT/bert-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.86087496792462,
    "Accuracy_div_100": 0.90861,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Azure/results/NC96ads_A100_v4_TRT_Triton/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Azure",
    "Platform": "NC96ads_A100_v4_TRT_Triton",
    "Result": 6273.11,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NC96ads_A100_v4 (4x A100-PCIe-80GB, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 7V13 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.6 LTS",
    "uid": "0aa5479603344e3f",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Azure/results/NC96ads_A100_v4_TRT_Triton/bert-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.38529083707651,
    "Accuracy_div_100": 0.90385,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Azure/results/NC48ads_A100_v4_TRT_Triton/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Azure",
    "Platform": "NC48ads_A100_v4_TRT_Triton",
    "Result": 6219.91,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NC48ads_A100_v4 (2x A100-PCIe-80GB, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "AMD EPYC 7V13 64-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.6 LTS",
    "uid": "ffb2ce7dde674034",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Azure/results/NC48ads_A100_v4_TRT_Triton/bert-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.86087496792462,
    "Accuracy_div_100": 0.90861,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Azure/results/NC48ads_A100_v4_TRT_Triton/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Azure",
    "Platform": "NC48ads_A100_v4_TRT_Triton",
    "Result": 3119.86,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NC48ads_A100_v4 (2x A100-PCIe-80GB, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "AMD EPYC 7V13 64-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.6 LTS",
    "uid": "f130b3d01a1747a9",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Azure/results/NC48ads_A100_v4_TRT_Triton/bert-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.86087496792462,
    "Accuracy_div_100": 0.90861,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Azure/results/NC96ads_A100_v4_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Azure",
    "Platform": "NC96ads_A100_v4_TRT",
    "Result": 6239.17,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NC96ads_A100_v4 (4x A100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 7V13 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.6 LTS",
    "uid": "12e735bbbf464513",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Azure/results/NC96ads_A100_v4_TRT/bert-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.35948979736393,
    "Accuracy_div_100": 0.90359,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Fujitsu/results/GX2460M1_A30x4_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Fujitsu",
    "Platform": "GX2460M1_A30x4_TRT",
    "Result": 5926.72,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "PRIMERGY GX2460M1 (4x A30, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7302",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.3 LTS",
    "uid": "8adf392e5b304d34",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Fujitsu/results/GX2460M1_A30x4_TRT/bert-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.86345516918031,
    "Accuracy_div_100": 0.90863,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Fujitsu/results/GX2460M1_A30x4_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Fujitsu",
    "Platform": "GX2460M1_A30x4_TRT",
    "Result": 3238.42,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "PRIMERGY GX2460M1 (4x A30, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7302",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.3 LTS",
    "uid": "3dc22551b01e4d80",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Fujitsu/results/GX2460M1_A30x4_TRT/bert-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.38529083707651,
    "Accuracy_div_100": 0.90385,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Fujitsu/results/GX2570M6_A100-SXM4-40GBx8_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Fujitsu",
    "Platform": "GX2570M6_A100-SXM4-40GBx8_TRT",
    "Result": 27385.1,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "PRIMERGY GX2570M6 (8x A100-SXM-40GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM4-40GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 144,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8352V CPU @ 2.10GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.3",
    "uid": "f1976e3fbf3d4ffc",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Fujitsu/results/GX2570M6_A100-SXM4-40GBx8_TRT/bert-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.35549246102956,
    "Accuracy_div_100": 0.90355,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Qualcomm/results/g292_z43_q18-qaic-v1.6.80-aic100/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Qualcomm",
    "Platform": "g292_z43_q18-qaic-v1.6.80-aic100",
    "Result": 13223.9,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G292-Z43 (18x QAIC100)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 18,
    "compliance": 1,
    "errors": 0,
    "framework": "Qualcomm Cloud AI SDK v1.6.80",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7713 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "CentOS 7 (Linux kernel: 5.4.1-1.el7.elrepo.x86_64 #1 SMP Fri Nov 29 10:21:13 EST 2019 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "c5e0fa0253744822",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Qualcomm/results/g292_z43_q18-qaic-v1.6.80-aic100/bert-99/offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.87603921605954,
    "Accuracy_div_100": 0.90876,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Qualcomm/results/g292_z43_q18-qaic-v1.6.80-aic100/bert-99.9/offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Qualcomm",
    "Platform": "g292_z43_q18-qaic-v1.6.80-aic100",
    "Result": 6560.78,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G292-Z43 (18x QAIC100)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 18,
    "compliance": 1,
    "errors": 0,
    "framework": "Qualcomm Cloud AI SDK v1.6.80",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7713 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "CentOS 7 (Linux kernel: 5.4.1-1.el7.elrepo.x86_64 #1 SMP Fri Nov 29 10:21:13 EST 2019 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "2c5002467acf411c",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Qualcomm/results/g292_z43_q18-qaic-v1.6.80-aic100/bert-99.9/offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.35738460861708,
    "Accuracy_div_100": 0.90357,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Qualcomm/results/r282_z93_q8-qaic-v1.6.80-aic100/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Qualcomm",
    "Platform": "r282_z93_q8-qaic-v1.6.80-aic100",
    "Result": 5796.53,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte R282-Z93 (8x QAIC100)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "Qualcomm Cloud AI SDK v1.6.80",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 7282 16-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026. Powered by Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "CentOS 7 (Linux kernel: 5.4.1-1.el7.elrepo.x86_64 #1 SMP Fri Nov 29 10:21:13 EST 2019 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "7cdd86b4429e4cd0",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Qualcomm/results/r282_z93_q8-qaic-v1.6.80-aic100/bert-99/offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.87603921605954,
    "Accuracy_div_100": 0.90876,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Qualcomm/results/r282_z93_q8-qaic-v1.6.80-aic100/bert-99.9/offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Qualcomm",
    "Platform": "r282_z93_q8-qaic-v1.6.80-aic100",
    "Result": 2906.18,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte R282-Z93 (8x QAIC100)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "Qualcomm Cloud AI SDK v1.6.80",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 7282 16-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026. Powered by Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "CentOS 7 (Linux kernel: 5.4.1-1.el7.elrepo.x86_64 #1 SMP Fri Nov 29 10:21:13 EST 2019 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "8b5ff1ee63714b63",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Qualcomm/results/r282_z93_q8-qaic-v1.6.80-aic100/bert-99.9/offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.38529083707651,
    "Accuracy_div_100": 0.90385,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE2420_A30x2_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Dell",
    "Platform": "XE2420_A30x2_TRT",
    "Result": 3404.25,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE2420 (2x A30, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6252N CPU @ 2.30GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "39af625332634750",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Dell/results/XE2420_A30x2_TRT/bert-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.86087496792462,
    "Accuracy_div_100": 0.90861,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE2420_A30x2_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Dell",
    "Platform": "XE2420_A30x2_TRT",
    "Result": 1685.4,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE2420 (2x A30, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6252N CPU @ 2.30GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "96438129a546469a",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Dell/results/XE2420_A30x2_TRT/bert-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.32079354407065,
    "Accuracy_div_100": 0.90321,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XR12_A2x1_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Dell",
    "Platform": "XR12_A2x1_TRT",
    "Result": 244.468,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XR12 (1x A2, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A2",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6312U CPU @ 2.40GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "CentOS 8.2",
    "uid": "a66df8b412dc45ff",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Dell/results/XR12_A2x1_TRT/bert-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.86345516918031,
    "Accuracy_div_100": 0.90863,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XR12_A2x1_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Dell",
    "Platform": "XR12_A2x1_TRT",
    "Result": 119.51,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XR12 (1x A2, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A2",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6312U CPU @ 2.40GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "CentOS 8.2",
    "uid": "338ac6dc3ecf4fb7",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Dell/results/XR12_A2x1_TRT/bert-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.38529083707651,
    "Accuracy_div_100": 0.90385,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R750xa_A100_PCIE_80GBx4_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Dell",
    "Platform": "R750xa_A100_PCIE_80GBx4_TRT",
    "Result": 12847.4,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge R750xa (4x A100-PCIE-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6338 CPU @ 2.00GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "CentOS 8.2",
    "uid": "5bf8f0eb341e4612",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Dell/results/R750xa_A100_PCIE_80GBx4_TRT/bert-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.86087496792462,
    "Accuracy_div_100": 0.90861,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R750xa_A100_PCIE_80GBx4_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Dell",
    "Platform": "R750xa_A100_PCIE_80GBx4_TRT",
    "Result": 6477.96,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge R750xa (4x A100-PCIE-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6338 CPU @ 2.00GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "CentOS 8.2",
    "uid": "c5062c6532824819",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Dell/results/R750xa_A100_PCIE_80GBx4_TRT/bert-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.38087866142499,
    "Accuracy_div_100": 0.90381,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE8545_A100_SXM_80GBx4_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Dell",
    "Platform": "XE8545_A100_SXM_80GBx4_TRT",
    "Result": 14989.9,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE8545 (4x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7763",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "500W A100-SXM-80GB",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.3",
    "uid": "884ebad16c1e4439",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Dell/results/XE8545_A100_SXM_80GBx4_TRT/bert-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.86345516918031,
    "Accuracy_div_100": 0.90863,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE8545_A100_SXM_80GBx4_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Dell",
    "Platform": "XE8545_A100_SXM_80GBx4_TRT",
    "Result": 7499.55,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE8545 (4x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7763",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "500W A100-SXM-80GB",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.3",
    "uid": "bcab945e37fc4706",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Dell/results/XE8545_A100_SXM_80GBx4_TRT/bert-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.38529083707651,
    "Accuracy_div_100": 0.90385,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/DSS8440_A100_PCIE_80GBx10_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Dell",
    "Platform": "DSS8440_A100_PCIE_80GBx10_TRT",
    "Result": 31817.2,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell DSS 8440 (10x NVIDIA A100-PCIE-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIE-80GB",
    "accelerators_per_node": 10,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6248R CPU @ 3.00GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "CentOS 8.2",
    "uid": "f29f17c1335c4b90",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Dell/results/DSS8440_A100_PCIE_80GBx10_TRT/bert-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.86087496792462,
    "Accuracy_div_100": 0.90861,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/DSS8440_A100_PCIE_80GBx10_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Dell",
    "Platform": "DSS8440_A100_PCIE_80GBx10_TRT",
    "Result": 15869.4,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell DSS 8440 (10x NVIDIA A100-PCIE-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIE-80GB",
    "accelerators_per_node": 10,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6248R CPU @ 3.00GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "CentOS 8.2",
    "uid": "4b91b08750f8434c",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Dell/results/DSS8440_A100_PCIE_80GBx10_TRT/bert-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.38087866142499,
    "Accuracy_div_100": 0.90381,
    "Availability": "rdi",
    "Division": "closed",
    "Location": "closed/Inspur/results/NF5468M6_A100-PCIe-80GBx12_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Inspur",
    "Platform": "NF5468M6_A100-PCIe-80GBx12_TRT",
    "Result": 38776.7,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NF5468M6J (12x A100-PCIe, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 12,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8358",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "NF5468M6(8x A100-PCIe)+JBOG(4x A100-PCIe)",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "6a71c31ae24840b9",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Inspur/results/NF5468M6_A100-PCIe-80GBx12_TRT/bert-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.86087496792462,
    "Accuracy_div_100": 0.90861,
    "Availability": "rdi",
    "Division": "closed",
    "Location": "closed/Inspur/results/NF5468M6_A100-PCIe-80GBx12_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Inspur",
    "Platform": "NF5468M6_A100-PCIe-80GBx12_TRT",
    "Result": 19370.4,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NF5468M6J (12x A100-PCIe, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 12,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8358",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "NF5468M6(8x A100-PCIe)+JBOG(4x A100-PCIe)",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "6891125eda2a477d",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Inspur/results/NF5468M6_A100-PCIe-80GBx12_TRT/bert-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.38087866142499,
    "Accuracy_div_100": 0.90381,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Inspur/results/NF5488A5_A100-SXM-80GBx8_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Inspur",
    "Platform": "NF5488A5_A100-SXM-80GBx8_TRT",
    "Result": 29700.6,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NF5488A5 (8x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "8cbf3f01c8c84d34",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Inspur/results/NF5488A5_A100-SXM-80GBx8_TRT/bert-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.86087496792462,
    "Accuracy_div_100": 0.90861,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Inspur/results/NF5488A5_A100-SXM-80GBx8_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Inspur",
    "Platform": "NF5488A5_A100-SXM-80GBx8_TRT",
    "Result": 14909.3,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NF5488A5 (8x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "8823f7b52293413c",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Inspur/results/NF5488A5_A100-SXM-80GBx8_TRT/bert-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.38529083707651,
    "Accuracy_div_100": 0.90385,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/A100-PCIe-80GBx8_TRT_Triton/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "H3C",
    "Platform": "A100-PCIe-80GBx8_TRT_Triton",
    "Result": 24935.6,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "H3C UniServer R5300 G5 (8x A100-PCIe-80GB, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8380 CPU @ 2.30GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "3cfe0756fb944ed1",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/H3C/results/A100-PCIe-80GBx8_TRT_Triton/bert-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.86087496792462,
    "Accuracy_div_100": 0.90861,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/A100-PCIe-80GBx8_TRT_Triton/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "H3C",
    "Platform": "A100-PCIe-80GBx8_TRT_Triton",
    "Result": 12776.9,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "H3C UniServer R5300 G5 (8x A100-PCIe-80GB, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8380 CPU @ 2.30GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "f7ea43174b534cce",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/H3C/results/A100-PCIe-80GBx8_TRT_Triton/bert-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.38529083707651,
    "Accuracy_div_100": 0.90385,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/A100-PCIe-80GBx8_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "H3C",
    "Platform": "A100-PCIe-80GBx8_TRT",
    "Result": 24902,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "H3C UniServer R5300 G5 (8x A100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8380 CPU @ 2.30GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "e8e9ccf81659411b",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/H3C/results/A100-PCIe-80GBx8_TRT/bert-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.86087496792462,
    "Accuracy_div_100": 0.90861,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/A100-PCIe-80GBx8_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "H3C",
    "Platform": "A100-PCIe-80GBx8_TRT",
    "Result": 12660.5,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "H3C UniServer R5300 G5 (8x A100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8380 CPU @ 2.30GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "e1c0b1063adf4814",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/H3C/results/A100-PCIe-80GBx8_TRT/bert-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.38087866142499,
    "Accuracy_div_100": 0.90381,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/R5500G5_A100-SXM-80GBx8_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "H3C",
    "Platform": "R5500G5_A100-SXM-80GBx8_TRT",
    "Result": 27889.2,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "H3C UniServer R5500 G5 (8x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8380 CPU @ 2.30GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "400W_A100-SXM-80GB",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "f43ab3ac37764b87",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/H3C/results/R5500G5_A100-SXM-80GBx8_TRT/bert-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.86087496792462,
    "Accuracy_div_100": 0.90861,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/R5500G5_A100-SXM-80GBx8_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "H3C",
    "Platform": "R5500G5_A100-SXM-80GBx8_TRT",
    "Result": 13953,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "H3C UniServer R5500 G5 (8x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8380 CPU @ 2.30GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "400W_A100-SXM-80GB",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "7836a72a5f0b4d84",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/H3C/results/R5500G5_A100-SXM-80GBx8_TRT/bert-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.38529083707651,
    "Accuracy_div_100": 0.90385,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/A30x8_Custom_R5300G5_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "H3C",
    "Platform": "A30x8_Custom_R5300G5_TRT",
    "Result": 13506.6,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "H3C UniServer R5300 G5 (8x A30, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8380 CPU @ 2.30GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "960f50e1dc3e470d",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/H3C/results/A30x8_Custom_R5300G5_TRT/bert-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.86087496792462,
    "Accuracy_div_100": 0.90861,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/A30x8_Custom_R5300G5_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "H3C",
    "Platform": "A30x8_Custom_R5300G5_TRT",
    "Result": 6666.31,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "H3C UniServer R5300 G5 (8x A30, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8380 CPU @ 2.30GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "b9d655408bcc4d9e",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/H3C/results/A30x8_Custom_R5300G5_TRT/bert-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.87595439490713,
    "Accuracy_div_100": 0.90876,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/AS-4124GS-TNR_8_A100-PCIe-80GB_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Supermicro",
    "Platform": "AS-4124GS-TNR_8_A100-PCIe-80GB_TRT",
    "Result": 12483.6,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AS-4124GS-TNR (8xA100-PCIe-80GB)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7713 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "5d28cfac0a4a4d5a",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/Supermicro/results/AS-4124GS-TNR_8_A100-PCIe-80GB_TRT/bert-99.9/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 90.38529083707651,
    "Accuracy_div_100": 0.90385,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A100-PCIe-80GBx8_TRT_Triton/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "NVIDIA",
    "Platform": "A100-PCIe-80GBx8_TRT_Triton",
    "Result": 25551,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G482-Z54 (8x A100-PCIe-80GB, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "82eac700dc7e4796",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/NVIDIA/results/A100-PCIe-80GBx8_TRT_Triton/bert-99/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 90.87595439490713,
    "Accuracy_div_100": 0.90876,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A100-PCIe-80GBx8_TRT_Triton/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "NVIDIA",
    "Platform": "A100-PCIe-80GBx8_TRT_Triton",
    "Result": 12834.6,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G482-Z54 (8x A100-PCIe-80GB, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "2faff14cf6b44a0d",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/NVIDIA/results/A100-PCIe-80GBx8_TRT_Triton/bert-99.9/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 90.87585883189767,
    "Accuracy_div_100": 0.90876,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx1_TRT_DATACENTER/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "NVIDIA",
    "Platform": "DGX-A100_A100-SXM-80GBx1_TRT_DATACENTER",
    "Result": 1756.84,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX A100 (1x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "2d6a12dfc8fb42e0",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx1_TRT_DATACENTER/bert-99.9/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 90.39033939936255,
    "Accuracy_div_100": 0.9039,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-A100_A100-SXM-80GB-MIG_1x1g.10gb_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "NVIDIA",
    "Platform": "DGX-A100_A100-SXM-80GB-MIG_1x1g.10gb_TRT",
    "Result": 493.11,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX A100 (1x A100-SXM-80GB-MIG-1x1g.10gb, TensorRT)",
    "SystemType": "datacenter,edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB (1x1g.10gb MIG)",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "15a762a59fb5404e",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GB-MIG_1x1g.10gb_TRT/bert-99/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 90.87585883189767,
    "Accuracy_div_100": 0.90876,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-A100_A100-SXM-80GB-MIG_1x1g.10gb_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "NVIDIA",
    "Platform": "DGX-A100_A100-SXM-80GB-MIG_1x1g.10gb_TRT",
    "Result": 246.844,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX A100 (1x A100-SXM-80GB-MIG-1x1g.10gb, TensorRT)",
    "SystemType": "datacenter,edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB (1x1g.10gb MIG)",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "9159a4ad5fea4903",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GB-MIG_1x1g.10gb_TRT/bert-99.9/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 90.39033939936255,
    "Accuracy_div_100": 0.9039,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-A100_A100-SXM-80GB-MIG_1x1g.10gb_TRT_Triton/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "NVIDIA",
    "Platform": "DGX-A100_A100-SXM-80GB-MIG_1x1g.10gb_TRT_Triton",
    "Result": 492.804,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX A100 (1x A100-SXM-80GB-MIG-1x1g.10gb, TensorRT, Triton)",
    "SystemType": "datacenter,edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB (1x1g.10gb MIG)",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "606a553d1c7848b3",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GB-MIG_1x1g.10gb_TRT_Triton/bert-99/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 90.87585883189767,
    "Accuracy_div_100": 0.90876,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-A100_A100-SXM-80GB-MIG_1x1g.10gb_TRT_Triton/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "NVIDIA",
    "Platform": "DGX-A100_A100-SXM-80GB-MIG_1x1g.10gb_TRT_Triton",
    "Result": 244.86,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX A100 (1x A100-SXM-80GB-MIG-1x1g.10gb, TensorRT, Triton)",
    "SystemType": "datacenter,edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB (1x1g.10gb MIG)",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "e081c326ce9941f6",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GB-MIG_1x1g.10gb_TRT_Triton/bert-99.9/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 90.38087866142499,
    "Accuracy_div_100": 0.90381,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT_Triton/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "NVIDIA",
    "Platform": "DGX-A100_A100-SXM-80GBx8_TRT_Triton",
    "Result": 27820.6,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX A100 (8x A100-SXM-80GB, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "2acdc15dcc134794",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT_Triton/bert-99/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 90.87595439490713,
    "Accuracy_div_100": 0.90876,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT_Triton/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "NVIDIA",
    "Platform": "DGX-A100_A100-SXM-80GBx8_TRT_Triton",
    "Result": 14012.5,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX A100 (8x A100-SXM-80GB, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "9f9d90dbec5747e5",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT_Triton/bert-99.9/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 90.38087866142499,
    "Accuracy_div_100": 0.90381,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "NVIDIA",
    "Platform": "DGX-A100_A100-SXM-80GBx8_TRT",
    "Result": 28049,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX A100 (8x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "6f7f62899aff4d2b",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT/bert-99/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 90.87585883189767,
    "Accuracy_div_100": 0.90876,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "NVIDIA",
    "Platform": "DGX-A100_A100-SXM-80GBx8_TRT",
    "Result": 13967.5,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX A100 (8x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "b6868de55f2a4608",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT/bert-99.9/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 90.17137167790902,
    "Accuracy_div_100": 0.90171,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H100-SXM-80GBx1_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "NVIDIA",
    "Platform": "H100-SXM-80GBx1_TRT",
    "Result": 8366.86,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA H100 (1x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.5.0, CUDA 11.8",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 7252 8-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Private git branch used to produce all NVIDIA H100 results. The git hash of the private branch is 35fc4b9a7758edc6063bb3a4ba4bfa94ce7aa9e1",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "b7806c8354dd4429",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/NVIDIA/results/H100-SXM-80GBx1_TRT/bert-99/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 91.05353768410248,
    "Accuracy_div_100": 0.91054,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H100-SXM-80GBx1_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "NVIDIA",
    "Platform": "H100-SXM-80GBx1_TRT",
    "Result": 7921.1,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA H100 (1x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.5.0, CUDA 11.8",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 7252 8-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Private git branch used to produce all NVIDIA H100 results. The git hash of the private branch is 35fc4b9a7758edc6063bb3a4ba4bfa94ce7aa9e1",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "6e1abf3fd76c4f59",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/NVIDIA/results/H100-SXM-80GBx1_TRT/bert-99.9/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 90.38529083707651,
    "Accuracy_div_100": 0.90385,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A100-PCIe-80GBx8_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "NVIDIA",
    "Platform": "A100-PCIe-80GBx8_TRT",
    "Result": 25406.8,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G482-Z54 (8x A100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "010cc1d59947457a",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/NVIDIA/results/A100-PCIe-80GBx8_TRT/bert-99/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 90.87595439490713,
    "Accuracy_div_100": 0.90876,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A100-PCIe-80GBx8_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "NVIDIA",
    "Platform": "A100-PCIe-80GBx8_TRT",
    "Result": 12822.4,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G482-Z54 (8x A100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "936b961e7014464f",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/NVIDIA/results/A100-PCIe-80GBx8_TRT/bert-99.9/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 90.31511710130813,
    "Accuracy_div_100": 0.90315,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC4000_A2x8_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "ASUSTeK",
    "Platform": "ESC4000_A2x8_TRT",
    "Result": 2021.6,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "ASUS ESC4000-E10S (8x A2, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A2",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 8,
    "host_processor_model_name": " Intel(R) Xeon(R) Platinum 8352M 32-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "f68e95b0700b4e23",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/ASUSTeK/results/ESC4000_A2x8_TRT/bert-99/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 90.87585883189767,
    "Accuracy_div_100": 0.90876,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC4000_A2x8_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "ASUSTeK",
    "Platform": "ESC4000_A2x8_TRT",
    "Result": 981.774,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "ASUS ESC4000-E10S (8x A2, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A2",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 8,
    "host_processor_model_name": " Intel(R) Xeon(R) Platinum 8352M 32-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "66cfc979bed54cdc",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/ASUSTeK/results/ESC4000_A2x8_TRT/bert-99.9/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 90.38529083707651,
    "Accuracy_div_100": 0.90385,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/A100-PCIe-80GBx8_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "ASUSTeK",
    "Platform": "A100-PCIe-80GBx8_TRT",
    "Result": 25949.1,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "ASUS ESC8000A-E11 (8x A100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7763 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "84acf8ec40ee4bab",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/ASUSTeK/results/A100-PCIe-80GBx8_TRT/bert-99/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 90.87595439490713,
    "Accuracy_div_100": 0.90876,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/A100-PCIe-80GBx8_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "ASUSTeK",
    "Platform": "A100-PCIe-80GBx8_TRT",
    "Result": 13129.4,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "ASUS ESC8000A-E11 (8x A100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7763 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "93cc73c2c2dc4ec3",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/ASUSTeK/results/A100-PCIe-80GBx8_TRT/bert-99.9/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 90.38087866142499,
    "Accuracy_div_100": 0.90381,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Azure/results/ND96amsr_A100_v4_TRT_Triton/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Azure",
    "Platform": "ND96amsr_A100_v4_TRT_Triton",
    "Result": 27458.3,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "ND96amsr_A100_v4 (8x A100-SXM-80GB, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 7V12 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.6 LTS",
    "uid": "3c111e8ecafb454d",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/Azure/results/ND96amsr_A100_v4_TRT_Triton/bert-99/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 90.87595439490713,
    "Accuracy_div_100": 0.90876,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Azure/results/ND96amsr_A100_v4_TRT_Triton/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Azure",
    "Platform": "ND96amsr_A100_v4_TRT_Triton",
    "Result": 13824.5,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "ND96amsr_A100_v4 (8x A100-SXM-80GB, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 7V12 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.6 LTS",
    "uid": "fcbf1cb209134de9",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/Azure/results/ND96amsr_A100_v4_TRT_Triton/bert-99.9/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 90.38087866142499,
    "Accuracy_div_100": 0.90381,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Azure/results/ND96amsr_A100_v4_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Azure",
    "Platform": "ND96amsr_A100_v4_TRT",
    "Result": 27591.2,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "ND96amsr_A100_v4 (8x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 7V12 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.6 LTS",
    "uid": "30f629f95ea6420a",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/Azure/results/ND96amsr_A100_v4_TRT/bert-99/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 90.87585883189767,
    "Accuracy_div_100": 0.90876,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Azure/results/ND96amsr_A100_v4_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Azure",
    "Platform": "ND96amsr_A100_v4_TRT",
    "Result": 13771.7,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "ND96amsr_A100_v4 (8x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 7V12 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.6 LTS",
    "uid": "a86fea22ca8340fc",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/Azure/results/ND96amsr_A100_v4_TRT/bert-99.9/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 90.38529083707651,
    "Accuracy_div_100": 0.90385,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Azure/results/NC96ads_A100_v4_TRT_Triton/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Azure",
    "Platform": "NC96ads_A100_v4_TRT_Triton",
    "Result": 12741.2,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NC96ads_A100_v4 (4x A100-PCIe-80GB, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 7V13 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.6 LTS",
    "uid": "5122a5ebb5de4702",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/Azure/results/NC96ads_A100_v4_TRT_Triton/bert-99/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 90.87595439490713,
    "Accuracy_div_100": 0.90876,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Azure/results/NC96ads_A100_v4_TRT_Triton/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Azure",
    "Platform": "NC96ads_A100_v4_TRT_Triton",
    "Result": 6422.45,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NC96ads_A100_v4 (4x A100-PCIe-80GB, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 7V13 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.6 LTS",
    "uid": "f26536da39324761",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/Azure/results/NC96ads_A100_v4_TRT_Triton/bert-99.9/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 90.31511710130813,
    "Accuracy_div_100": 0.90315,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Azure/results/NV72ads_A10_v5_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Azure",
    "Platform": "NV72ads_A10_v5_TRT",
    "Result": 2074.74,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NV72ads_A10_v5 (2x NVIDIA A10-24Q, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A10-24Q",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2.3, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "AMD EPYC 74F3 24-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.6 LTS",
    "uid": "765f095466934f77",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/Azure/results/NV72ads_A10_v5_TRT/bert-99/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 90.87585883189767,
    "Accuracy_div_100": 0.90876,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Azure/results/NV72ads_A10_v5_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Azure",
    "Platform": "NV72ads_A10_v5_TRT",
    "Result": 1010.66,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NV72ads_A10_v5 (2x NVIDIA A10-24Q, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A10-24Q",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2.3, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "AMD EPYC 74F3 24-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.6 LTS",
    "uid": "ff8f61612d6844cd",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/Azure/results/NV72ads_A10_v5_TRT/bert-99.9/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 90.38529083707651,
    "Accuracy_div_100": 0.90385,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Azure/results/NC96ads_A100_v4_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Azure",
    "Platform": "NC96ads_A100_v4_TRT",
    "Result": 12490.5,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NC96ads_A100_v4 (4x A100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 7V13 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.6 LTS",
    "uid": "ace4c2a99e544d19",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/Azure/results/NC96ads_A100_v4_TRT/bert-99/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 90.87595439490713,
    "Accuracy_div_100": 0.90876,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Azure/results/NC96ads_A100_v4_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Azure",
    "Platform": "NC96ads_A100_v4_TRT",
    "Result": 6407.51,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NC96ads_A100_v4 (4x A100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 7V13 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.6 LTS",
    "uid": "85236933c4304f41",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/Azure/results/NC96ads_A100_v4_TRT/bert-99.9/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 90.38529083707651,
    "Accuracy_div_100": 0.90385,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/A100-PCIe-80GBx8_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Lenovo",
    "Platform": "A100-PCIe-80GBx8_TRT",
    "Result": 25683.5,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Lenovo SR670v2 (8x A100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 36,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8360Y CPU @ 2.40GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "d1e3055e171543de",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/Lenovo/results/A100-PCIe-80GBx8_TRT/bert-99/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 90.87595439490713,
    "Accuracy_div_100": 0.90876,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/A100-PCIe-80GBx8_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Lenovo",
    "Platform": "A100-PCIe-80GBx8_TRT",
    "Result": 13019.1,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Lenovo SR670v2 (8x A100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 36,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8360Y CPU @ 2.40GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "ca3d74f569864331",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/Lenovo/results/A100-PCIe-80GBx8_TRT/bert-99.9/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 90.22951222279839,
    "Accuracy_div_100": 0.9023,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Qualcomm/results/g292_z43_q18-qaic-v1.7.1.12-aic100/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Qualcomm",
    "Platform": "g292_z43_q18-qaic-v1.7.1.12-aic100",
    "Result": 13541.1,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G292-Z43 (18x QAIC100 Pro)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 18,
    "compliance": 1,
    "errors": 0,
    "framework": "Qualcomm Cloud AI SDK v1.7.1",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7713 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Powered by MLCommons Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "CentOS 7 (Linux kernel: 5.4.1-1.el7.elrepo.x86_64 #1 SMP Fri Nov 29 10:21:13 EST 2019 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "30ffbc2235344a23",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/Qualcomm/results/g292_z43_q18-qaic-v1.7.1.12-aic100/bert-99/offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 90.8666333229796,
    "Accuracy_div_100": 0.90867,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Qualcomm/results/g292_z43_q18-qaic-v1.7.1.12-aic100/bert-99.9/offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Qualcomm",
    "Platform": "g292_z43_q18-qaic-v1.7.1.12-aic100",
    "Result": 6556.65,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G292-Z43 (18x QAIC100 Pro)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 18,
    "compliance": 1,
    "errors": 0,
    "framework": "Qualcomm Cloud AI SDK v1.7.1",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7713 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Powered by MLCommons Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "CentOS 7 (Linux kernel: 5.4.1-1.el7.elrepo.x86_64 #1 SMP Fri Nov 29 10:21:13 EST 2019 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "77c00551983d4fcf",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/Qualcomm/results/g292_z43_q18-qaic-v1.7.1.12-aic100/bert-99.9/offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 90.22951222279839,
    "Accuracy_div_100": 0.9023,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Qualcomm/results/r282_z93_q8-qaic-v1.7.1.12-aic100/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Qualcomm",
    "Platform": "r282_z93_q8-qaic-v1.7.1.12-aic100",
    "Result": 6149.99,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte R282-Z93 (8x QAIC100 Pro)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "Qualcomm Cloud AI SDK v1.7.1",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 7282 16-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026. Powered by MLCommons Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "CentOS 7 (Linux kernel: 5.4.1-1.el7.elrepo.x86_64 #1 SMP Fri Nov 29 10:21:13 EST 2019 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "dcaaf52f9f984542",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/Qualcomm/results/r282_z93_q8-qaic-v1.7.1.12-aic100/bert-99/offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 90.8666333229796,
    "Accuracy_div_100": 0.90867,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Qualcomm/results/r282_z93_q8-qaic-v1.7.1.12-aic100/bert-99.9/offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Qualcomm",
    "Platform": "r282_z93_q8-qaic-v1.7.1.12-aic100",
    "Result": 2799.24,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte R282-Z93 (8x QAIC100 Pro)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "Qualcomm Cloud AI SDK v1.7.1",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 7282 16-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026. Powered by MLCommons Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "CentOS 7 (Linux kernel: 5.4.1-1.el7.elrepo.x86_64 #1 SMP Fri Nov 29 10:21:13 EST 2019 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "2c954572339d46dd",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/Qualcomm/results/r282_z93_q8-qaic-v1.7.1.12-aic100/bert-99.9/offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 90.22951222279839,
    "Accuracy_div_100": 0.9023,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Qualcomm/results/g292_z43_q16-qaic-v1.7.1.12-aic100/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Qualcomm",
    "Platform": "g292_z43_q16-qaic-v1.7.1.12-aic100",
    "Result": 12373.3,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G292-Z43 (16x QAIC100 Pro)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 16,
    "compliance": 1,
    "errors": 0,
    "framework": "Qualcomm Cloud AI SDK v1.7.1",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7713 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Powered by MLCommons Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "CentOS 7 (Linux kernel: 5.4.1-1.el7.elrepo.x86_64 #1 SMP Fri Nov 29 10:21:13 EST 2019 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "9412d7760ad04ca2",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/Qualcomm/results/g292_z43_q16-qaic-v1.7.1.12-aic100/bert-99/offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 90.8666333229796,
    "Accuracy_div_100": 0.90867,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Qualcomm/results/g292_z43_q16-qaic-v1.7.1.12-aic100/bert-99.9/offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Qualcomm",
    "Platform": "g292_z43_q16-qaic-v1.7.1.12-aic100",
    "Result": 5859.43,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G292-Z43 (16x QAIC100 Pro)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 16,
    "compliance": 1,
    "errors": 0,
    "framework": "Qualcomm Cloud AI SDK v1.7.1",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7713 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Powered by MLCommons Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "CentOS 7 (Linux kernel: 5.4.1-1.el7.elrepo.x86_64 #1 SMP Fri Nov 29 10:21:13 EST 2019 x86_64 x86_64 x86_64 GNU/Linux)",
    "uid": "e1c6b4501edb452e",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/Qualcomm/results/g292_z43_q16-qaic-v1.7.1.12-aic100/bert-99.9/offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 90.89504265590276,
    "Accuracy_div_100": 0.90895,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Biren/results/BR104-300W-PCIex8/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Biren",
    "Platform": "BR104-300W-PCIex8",
    "Result": 22133.7,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NF5468M6-P (8x BR104-300W PCIe, suInfer)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "BR104-300W PCIe",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "suInfer",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 38,
    "host_processor_model_name": "Intel Ice Lake-SP 8368",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.1",
    "uid": "21190702ae8a4333",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/Biren/results/BR104-300W-PCIex8/bert-99.9/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 89.9980895214958,
    "Accuracy_div_100": 0.89998,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R750xa_CPU_2S_6338/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Dell",
    "Platform": "R750xa_CPU_2S_6338",
    "Result": 47.092,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge R750xa Intel 6338",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "",
    "accelerators_per_node": "",
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6338 CPU @ 2.00GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "CentOS 8.2",
    "uid": "6ac5913f38324107",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/Dell/results/R750xa_CPU_2S_6338/bert-99/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 90.38529083707651,
    "Accuracy_div_100": 0.90385,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R750xa_A100_PCIE_80GBx4_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Dell",
    "Platform": "R750xa_A100_PCIE_80GBx4_TRT",
    "Result": 12798.4,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge R750xa (4x A100-PCIE-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6338 CPU @ 2.00GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "CentOS 8.2",
    "uid": "130ba97cfd7b4a92",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/Dell/results/R750xa_A100_PCIE_80GBx4_TRT/bert-99/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 90.87595439490713,
    "Accuracy_div_100": 0.90876,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R750xa_A100_PCIE_80GBx4_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Dell",
    "Platform": "R750xa_A100_PCIE_80GBx4_TRT",
    "Result": 6483.01,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge R750xa (4x A100-PCIE-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6338 CPU @ 2.00GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "CentOS 8.2",
    "uid": "f5c90c4f7cb94eac",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/Dell/results/R750xa_A100_PCIE_80GBx4_TRT/bert-99.9/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 90.38087866142499,
    "Accuracy_div_100": 0.90381,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE8545_A100_SXM_80GBx4_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Dell",
    "Platform": "XE8545_A100_SXM_80GBx4_TRT",
    "Result": 14939.6,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE8545 (4x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB CTS",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7763",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "NVIDIA A100-SXM-80GB (TDP: 500W)",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "490449127f114f96",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/Dell/results/XE8545_A100_SXM_80GBx4_TRT/bert-99/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 90.87585883189767,
    "Accuracy_div_100": 0.90876,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE8545_A100_SXM_80GBx4_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Dell",
    "Platform": "XE8545_A100_SXM_80GBx4_TRT",
    "Result": 7496.65,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE8545 (4x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB CTS",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7763",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "NVIDIA A100-SXM-80GB (TDP: 500W)",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "10e6ab0d580c416b",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/Dell/results/XE8545_A100_SXM_80GBx4_TRT/bert-99.9/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 90.38087866142499,
    "Accuracy_div_100": 0.90381,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/GIGABYTE/results/G492-ID0_A100-SXM-80GBx8_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "GIGABYTE",
    "Platform": "G492-ID0_A100-SXM-80GBx8_TRT",
    "Result": 27944.1,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "G492-ID0 (8x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.7",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8380",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.3",
    "uid": "8e25624d66ef43a5",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/GIGABYTE/results/G492-ID0_A100-SXM-80GBx8_TRT/bert-99/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 90.87585883189767,
    "Accuracy_div_100": 0.90876,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/GIGABYTE/results/G492-ID0_A100-SXM-80GBx8_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "GIGABYTE",
    "Platform": "G492-ID0_A100-SXM-80GBx8_TRT",
    "Result": 14046.6,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "G492-ID0 (8x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.7",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8380",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.3",
    "uid": "4c0e59218add4743",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/GIGABYTE/results/G492-ID0_A100-SXM-80GBx8_TRT/bert-99.9/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 90.53885196505269,
    "Accuracy_div_100": 0.90539,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/Intel/results/1-node-2S-SPR-PyTorch-INT8/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Intel",
    "Platform": "1-node-2S-SPR-PyTorch-INT8",
    "Result": 1373.47,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "1-node-2S-SPR-PyTorch-INT8",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "PyTorch",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": "",
    "host_processor_model_name": "Intel(R) Xeon(R) (code named Sapphire Rapids)",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Intel Devlopment Platform (2U Server)",
    "number_of_nodes": 1,
    "operating_system": "CentOS Stream 8",
    "uid": "dd50ab5f24724415",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/Intel/results/1-node-2S-SPR-PyTorch-INT8/bert-99/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 90.38529083707651,
    "Accuracy_div_100": 0.90385,
    "Availability": "rdi",
    "Division": "closed",
    "Location": "closed/Nettrix/results/A100_PCIE_80GBx20_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Nettrix",
    "Platform": "A100_PCIE_80GBx20_TRT",
    "Result": 63393.2,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "X640 G40 (20x A100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 20,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6346 CPU",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04",
    "uid": "2e102a30fece41cf",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/Nettrix/results/A100_PCIE_80GBx20_TRT/bert-99/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 90.87595439490713,
    "Accuracy_div_100": 0.90876,
    "Availability": "rdi",
    "Division": "closed",
    "Location": "closed/Nettrix/results/A100_PCIE_80GBx20_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Nettrix",
    "Platform": "A100_PCIE_80GBx20_TRT",
    "Result": 32193.5,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "X640 G40 (20x A100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 20,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6346 CPU",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04",
    "uid": "9a6aa84423374c82",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/Nettrix/results/A100_PCIE_80GBx20_TRT/bert-99.9/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 90.38087866142499,
    "Accuracy_div_100": 0.90381,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Nettrix/results/A100_SXM4_80GBx8_Custom_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Nettrix",
    "Platform": "A100_SXM4_80GBx8_Custom_TRT",
    "Result": 29023.8,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "X660G45L (8x A100-SXM4-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM4-80GB CTS",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 38,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8368Q",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "NVIDIA A100-SXM4-80GB (TDP:500W)",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "f7770060751a41f1",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/Nettrix/results/A100_SXM4_80GBx8_Custom_TRT/bert-99/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 90.87595439490713,
    "Accuracy_div_100": 0.90876,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Nettrix/results/A100_SXM4_80GBx8_Custom_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Nettrix",
    "Platform": "A100_SXM4_80GBx8_Custom_TRT",
    "Result": 14605.6,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "X660G45L (8x A100-SXM4-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM4-80GB CTS",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 38,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8368Q",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "NVIDIA A100-SXM4-80GB (TDP:500W)",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "3908a9bc7b9944f4",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/Nettrix/results/A100_SXM4_80GBx8_Custom_TRT/bert-99.9/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 90.31511710130813,
    "Accuracy_div_100": 0.90315,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/A2x6_R4950G5_TRT_Triton/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "H3C",
    "Platform": "A2x6_R4950G5_TRT_Triton",
    "Result": 1523.66,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "H3C UniServer R4950 G5(6x A2, TensorRT,Triton)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A2",
    "accelerators_per_node": 6,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 128,
    "host_processor_model_name": "AMD EPYC 7513 32-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "13eb277490674f37",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/H3C/results/A2x6_R4950G5_TRT_Triton/bert-99/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 90.87585883189767,
    "Accuracy_div_100": 0.90876,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/A2x6_R4950G5_TRT_Triton/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "H3C",
    "Platform": "A2x6_R4950G5_TRT_Triton",
    "Result": 730.047,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "H3C UniServer R4950 G5(6x A2, TensorRT,Triton)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A2",
    "accelerators_per_node": 6,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 128,
    "host_processor_model_name": "AMD EPYC 7513 32-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "10f952d5c2874f39",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/H3C/results/A2x6_R4950G5_TRT_Triton/bert-99.9/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 90.38529083707651,
    "Accuracy_div_100": 0.90385,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/A100-PCIe-80GBx3_R4900G5_TRT_Triton/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "H3C",
    "Platform": "A100-PCIe-80GBx3_R4900G5_TRT_Triton",
    "Result": 9385.34,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "H3C UniServer R4900 G5(3x A100-PCIe-80GB, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 3,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8380 CPU @ 2.30GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "ff9a53caa5e54930",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/H3C/results/A100-PCIe-80GBx3_R4900G5_TRT_Triton/bert-99/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 90.87595439490713,
    "Accuracy_div_100": 0.90876,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/A100-PCIe-80GBx3_R4900G5_TRT_Triton/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "H3C",
    "Platform": "A100-PCIe-80GBx3_R4900G5_TRT_Triton",
    "Result": 4736.75,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "H3C UniServer R4900 G5(3x A100-PCIe-80GB, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 3,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8380 CPU @ 2.30GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "224aed9305e541a6",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/H3C/results/A100-PCIe-80GBx3_R4900G5_TRT_Triton/bert-99.9/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 90.31511710130813,
    "Accuracy_div_100": 0.90315,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/A2x5_R4900G5_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "H3C",
    "Platform": "A2x5_R4900G5_TRT",
    "Result": 1192.02,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "H3C UniServer R4900 G5(5x A2, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A2",
    "accelerators_per_node": 5,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8380 CPU @ 2.30GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "d574c109cae8420e",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/H3C/results/A2x5_R4900G5_TRT/bert-99/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 90.38529083707651,
    "Accuracy_div_100": 0.90385,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/R5300G5_A30x8_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "H3C",
    "Platform": "R5300G5_A30x8_TRT",
    "Result": 13839.4,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "H3C UniServer R5300 G5 (8x A30, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8362 CPU @ 2.80GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "807715150d354fbc",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/H3C/results/R5300G5_A30x8_TRT/bert-99/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 90.87595439490713,
    "Accuracy_div_100": 0.90876,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/R5300G5_A30x8_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "H3C",
    "Platform": "R5300G5_A30x8_TRT",
    "Result": 6782.13,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "H3C UniServer R5300 G5 (8x A30, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8362 CPU @ 2.80GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "e6513976b4c74251",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/H3C/results/R5300G5_A30x8_TRT/bert-99.9/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 90.38529083707651,
    "Accuracy_div_100": 0.90385,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/A30x3_R4900G5_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "H3C",
    "Platform": "A30x3_R4900G5_TRT",
    "Result": 4990.25,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "H3C UniServer R4900 G5(3x A30, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 3,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8380 CPU @ 2.30GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "ed78297ab1264ac3",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/H3C/results/A30x3_R4900G5_TRT/bert-99/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 90.87595439490713,
    "Accuracy_div_100": 0.90876,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/A30x3_R4900G5_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "H3C",
    "Platform": "A30x3_R4900G5_TRT",
    "Result": 2483.48,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "H3C UniServer R4900 G5(3x A30, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 3,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8380 CPU @ 2.30GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "d57e46ca6df64830",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/H3C/results/A30x3_R4900G5_TRT/bert-99.9/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 90.38087866142499,
    "Accuracy_div_100": 0.90381,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/R5500G5_Intel_A100_A100-SXM-80GBx8_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "H3C",
    "Platform": "R5500G5_Intel_A100_A100-SXM-80GBx8_TRT",
    "Result": 27920,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "H3C UniServer R5500 G5 Intel (8x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8378A",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "8070bc0d34734dea",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/H3C/results/R5500G5_Intel_A100_A100-SXM-80GBx8_TRT/bert-99/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 90.87585883189767,
    "Accuracy_div_100": 0.90876,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/R5500G5_Intel_A100_A100-SXM-80GBx8_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "H3C",
    "Platform": "R5500G5_Intel_A100_A100-SXM-80GBx8_TRT",
    "Result": 14085.8,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "H3C UniServer R5500 G5 Intel (8x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8378A",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "29b4254098664109",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/H3C/results/R5500G5_Intel_A100_A100-SXM-80GBx8_TRT/bert-99.9/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 90.38529083707651,
    "Accuracy_div_100": 0.90385,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/A100-PCIe-80GBx3_R4900G5_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "H3C",
    "Platform": "A100-PCIe-80GBx3_R4900G5_TRT",
    "Result": 9202.94,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "H3C UniServer R4900 G5(3x A100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 3,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8380 CPU @ 2.30GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "d6e6d4e7693a4d62",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/H3C/results/A100-PCIe-80GBx3_R4900G5_TRT/bert-99/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 90.87595439490713,
    "Accuracy_div_100": 0.90876,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/A100-PCIe-80GBx3_R4900G5_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "H3C",
    "Platform": "A100-PCIe-80GBx3_R4900G5_TRT",
    "Result": 4759.87,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "H3C UniServer R4900 G5(3x A100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 3,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8380 CPU @ 2.30GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "413da356e3344ec2",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/H3C/results/A100-PCIe-80GBx3_R4900G5_TRT/bert-99.9/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 90.38087866142499,
    "Accuracy_div_100": 0.90381,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/R5500G5_AMD_A100_A100-SXM-80GBx8_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "H3C",
    "Platform": "R5500G5_AMD_A100_A100-SXM-80GBx8_TRT",
    "Result": 27840.3,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "H3C UniServer R5500 G5 AMD (8x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7773X",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "7fec4ea2ad96492a",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/H3C/results/R5500G5_AMD_A100_A100-SXM-80GBx8_TRT/bert-99/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 90.87585883189767,
    "Accuracy_div_100": 0.90876,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/R5500G5_AMD_A100_A100-SXM-80GBx8_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "H3C",
    "Platform": "R5500G5_AMD_A100_A100-SXM-80GBx8_TRT",
    "Result": 13994.9,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "H3C UniServer R5500 G5 AMD (8x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7773X",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "51747b16c2df4100",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/H3C/results/R5500G5_AMD_A100_A100-SXM-80GBx8_TRT/bert-99.9/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 90.38529083707651,
    "Accuracy_div_100": 0.90385,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/A30x3_R4900G5_TRT_Triton/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "H3C",
    "Platform": "A30x3_R4900G5_TRT_Triton",
    "Result": 5092.36,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "H3C UniServer R4900 G5(3x A30, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 3,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8380 CPU @ 2.30GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "62af7f746e8f4a16",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/H3C/results/A30x3_R4900G5_TRT_Triton/bert-99/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 90.87595439490713,
    "Accuracy_div_100": 0.90876,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/A30x3_R4900G5_TRT_Triton/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "H3C",
    "Platform": "A30x3_R4900G5_TRT_Triton",
    "Result": 2477.33,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "H3C UniServer R4900 G5(3x A30, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 3,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8380 CPU @ 2.30GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "86dfa4f64dff4375",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/H3C/results/A30x3_R4900G5_TRT_Triton/bert-99.9/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 90.38087866142499,
    "Accuracy_div_100": 0.90381,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/R5300G5_A100_SXM_80GBx4_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "H3C",
    "Platform": "R5300G5_A100_SXM_80GBx4_TRT",
    "Result": 14158.3,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "H3C UniServer R5300 G5(4x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8362 CPU @ 2.80GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "af41f9af88b840c3",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/H3C/results/R5300G5_A100_SXM_80GBx4_TRT/bert-99/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 90.87585883189767,
    "Accuracy_div_100": 0.90876,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/R5300G5_A100_SXM_80GBx4_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "H3C",
    "Platform": "R5300G5_A100_SXM_80GBx4_TRT",
    "Result": 7108.46,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "H3C UniServer R5300 G5(4x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8362 CPU @ 2.80GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "bd328a8e50b34c58",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/H3C/results/R5300G5_A100_SXM_80GBx4_TRT/bert-99.9/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 90.38529083707651,
    "Accuracy_div_100": 0.90385,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/R5300G5_A100_PCIE_80GBX4_TRT_Triton/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "H3C",
    "Platform": "R5300G5_A100_PCIE_80GBX4_TRT_Triton",
    "Result": 12990.2,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "H3C UniServer R5300 G5 (4x A100-PCIe-80GB, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.5",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8362 CPU @ 2.80GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "780275043f4e4c58",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/H3C/results/R5300G5_A100_PCIE_80GBX4_TRT_Triton/bert-99/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 90.87595439490713,
    "Accuracy_div_100": 0.90876,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/R5300G5_A100_PCIE_80GBX4_TRT_Triton/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "H3C",
    "Platform": "R5300G5_A100_PCIE_80GBX4_TRT_Triton",
    "Result": 6530.71,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "H3C UniServer R5300 G5 (4x A100-PCIe-80GB, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.5",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8362 CPU @ 2.80GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "0e21fdec8cf04527",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/H3C/results/R5300G5_A100_PCIE_80GBX4_TRT_Triton/bert-99.9/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 90.38529083707651,
    "Accuracy_div_100": 0.90385,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/A30x2_R4950G5_TRT_Triton/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "H3C",
    "Platform": "A30x2_R4950G5_TRT_Triton",
    "Result": 3418.19,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "H3C UniServer R4950 G5(2x A30, TensorRT,Triton)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 128,
    "host_processor_model_name": "AMD EPYC 7513 32-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "24e9db9ec1684670",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/H3C/results/A30x2_R4950G5_TRT_Triton/bert-99/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 90.38529083707651,
    "Accuracy_div_100": 0.90385,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/R5300G5_A100_PCIE_80GBX4_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "H3C",
    "Platform": "R5300G5_A100_PCIE_80GBX4_TRT",
    "Result": 12922.8,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "H3C UniServer R5300 G5 (4x A100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.5",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8362 CPU @ 2.80GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "491a3bfbadf74a61",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/H3C/results/R5300G5_A100_PCIE_80GBX4_TRT/bert-99/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 90.38529083707651,
    "Accuracy_div_100": 0.90385,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/R5300G5_A30x8_TRT_Triton/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "H3C",
    "Platform": "R5300G5_A30x8_TRT_Triton",
    "Result": 14004,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "H3C UniServer R5300 G5 (8x A30, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8362 CPU @ 2.80GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "9d74bbdee7fb4e09",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/H3C/results/R5300G5_A30x8_TRT_Triton/bert-99/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 90.87595439490713,
    "Accuracy_div_100": 0.90876,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/R5300G5_A30x8_TRT_Triton/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "H3C",
    "Platform": "R5300G5_A30x8_TRT_Triton",
    "Result": 6790.74,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "H3C UniServer R5300 G5 (8x A30, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8362 CPU @ 2.80GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "47fb35221e7d4339",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/H3C/results/R5300G5_A30x8_TRT_Triton/bert-99.9/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 90.38529083707651,
    "Accuracy_div_100": 0.90385,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/Apollo_6500_gen10_plus_A100-SXM-40GBx8_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "HPE",
    "Platform": "Apollo_6500_gen10_plus_A100-SXM-40GBx8_TRT",
    "Result": 26899.6,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "HPE Apollo 6500 Gen10+ (675d - 8x A100 SXM 40GB)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-40GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7763",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "RHEL 8.5",
    "uid": "2431dd4de0924400",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/HPE/results/Apollo_6500_gen10_plus_A100-SXM-40GBx8_TRT/bert-99/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 90.87595439490713,
    "Accuracy_div_100": 0.90876,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/Apollo_6500_gen10_plus_A100-SXM-40GBx8_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "HPE",
    "Platform": "Apollo_6500_gen10_plus_A100-SXM-40GBx8_TRT",
    "Result": 13345.1,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "HPE Apollo 6500 Gen10+ (675d - 8x A100 SXM 40GB)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-40GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7763",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "RHEL 8.5",
    "uid": "efb7a365bf6a4f16",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/HPE/results/Apollo_6500_gen10_plus_A100-SXM-40GBx8_TRT/bert-99.9/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 90.38529083707651,
    "Accuracy_div_100": 0.90385,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/Apollo_6500_gen10_plus_A100-SXM-40GBx4_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "HPE",
    "Platform": "Apollo_6500_gen10_plus_A100-SXM-40GBx4_TRT",
    "Result": 13952.4,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "HPE Apollo 6500 Gen10+ (645d - 4x A100 SXM 40GB)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-40GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7702",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "RHEL 8.5",
    "uid": "74f8069c5ee2404b",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/HPE/results/Apollo_6500_gen10_plus_A100-SXM-40GBx4_TRT/bert-99/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 90.87585883189767,
    "Accuracy_div_100": 0.90876,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/Apollo_6500_gen10_plus_A100-SXM-80GBx8_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "HPE",
    "Platform": "Apollo_6500_gen10_plus_A100-SXM-80GBx8_TRT",
    "Result": 14109.1,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "HPE Apollo 6500 Gen10+ (675d - 8x A100 SXM 80GB)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7763",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "RHEL 8.5",
    "uid": "f0f3d2bcf62d46b1",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/HPE/results/Apollo_6500_gen10_plus_A100-SXM-80GBx8_TRT/bert-99.9/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 90.39033939936255,
    "Accuracy_div_100": 0.9039,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/Apollo_6500_gen10_plus_A100-SXM-80GB-MIG_1x1g.10gb_TRT_Triton/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "HPE",
    "Platform": "Apollo_6500_gen10_plus_A100-SXM-80GB-MIG_1x1g.10gb_TRT_Triton",
    "Result": 489.796,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "HPE Apollo 6500 Gen10+ (675d - 8x A100-SXM-80GB-MIG-1x1g.10gb), TensorRT, Triton",
    "SystemType": "datacenter,edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB (1x1g.10gb MIG)",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7763",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "RHEL 8.5",
    "uid": "e348937355ea4936",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/HPE/results/Apollo_6500_gen10_plus_A100-SXM-80GB-MIG_1x1g.10gb_TRT_Triton/bert-99/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 90.39033939936255,
    "Accuracy_div_100": 0.9039,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/Apollo_6500_gen10_plus_A100-SXM-80GB-MIG_1x1g.10gb_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "HPE",
    "Platform": "Apollo_6500_gen10_plus_A100-SXM-80GB-MIG_1x1g.10gb_TRT",
    "Result": 489.993,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "HPE Apollo 6500 Gen10+ (675d - 8x A100-SXM-80GB-MIG-1x1g.10gb), TensorRT",
    "SystemType": "datacenter,edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB (1x1g.10gb MIG)",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7763",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "RHEL 8.5",
    "uid": "a3c42f90a108448b",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/HPE/results/Apollo_6500_gen10_plus_A100-SXM-80GB-MIG_1x1g.10gb_TRT/bert-99/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 90.87585883189767,
    "Accuracy_div_100": 0.90876,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/Apollo_6500_gen10_plus_A100-SXM-80GB-MIG_1x1g.10gb_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "HPE",
    "Platform": "Apollo_6500_gen10_plus_A100-SXM-80GB-MIG_1x1g.10gb_TRT",
    "Result": 245.402,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "HPE Apollo 6500 Gen10+ (675d - 8x A100-SXM-80GB-MIG-1x1g.10gb), TensorRT",
    "SystemType": "datacenter,edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB (1x1g.10gb MIG)",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7763",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "RHEL 8.5",
    "uid": "333c140f717f4137",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/HPE/results/Apollo_6500_gen10_plus_A100-SXM-80GB-MIG_1x1g.10gb_TRT/bert-99.9/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 90.11113134712532,
    "Accuracy_div_100": 0.90111,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Krai/results/dyson/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Krai",
    "Platform": "dyson",
    "Result": 3824.68,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "GIGABYTE R282-Z93 (5x QAIC100 Pro)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 5,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.8.3",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 7282 16-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Powered by the KRAI X and KILT technologies",
    "number_of_nodes": 1,
    "operating_system": "CentOS 7 (Linux kernel: 5.4.1-1.el7.elrepo.x86_64 #1 SMP Fri Nov 29 10:21:13 EST 2019)",
    "uid": "c760c7ba740248cc",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Krai/results/dyson/bert-99/offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.34992722790872,
    "Accuracy_div_100": 0.9035,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS-741GE-TNRT_4_H100-PCIe-80GB_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Supermicro",
    "Platform": "SYS-741GE-TNRT_4_H100-PCIe-80GB_TRT",
    "Result": 22705.5,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "SYS-741GE-TNRT (4xH100-PCIe-80GB)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6448Y",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5",
    "uid": "ff82d5cc823d475e",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Supermicro/results/SYS-741GE-TNRT_4_H100-PCIe-80GB_TRT/bert-99/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.97056894987658,
    "Accuracy_div_100": 0.90971,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS-741GE-TNRT_4_H100-PCIe-80GB_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Supermicro",
    "Platform": "SYS-741GE-TNRT_4_H100-PCIe-80GB_TRT",
    "Result": 19503.3,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "SYS-741GE-TNRT (4xH100-PCIe-80GB)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6448Y",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5",
    "uid": "39a0b3c7b4644991",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Supermicro/results/SYS-741GE-TNRT_4_H100-PCIe-80GB_TRT/bert-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.34992722790872,
    "Accuracy_div_100": 0.9035,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS-221HE-FTNR-DATACENTER_2_H100-PCIe-80GB_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Supermicro",
    "Platform": "SYS-221HE-FTNR-DATACENTER_2_H100-PCIe-80GB_TRT",
    "Result": 11007.6,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "SYS-221HE-FTNR (2xH100-PCIe-80GB)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "ddc9d1702de14c0a",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Supermicro/results/SYS-221HE-FTNR-DATACENTER_2_H100-PCIe-80GB_TRT/bert-99/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.97056894987658,
    "Accuracy_div_100": 0.90971,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS-221HE-FTNR-DATACENTER_2_H100-PCIe-80GB_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Supermicro",
    "Platform": "SYS-221HE-FTNR-DATACENTER_2_H100-PCIe-80GB_TRT",
    "Result": 9642.43,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "SYS-221HE-FTNR (2xH100-PCIe-80GB)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "39ada12672d84659",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Supermicro/results/SYS-221HE-FTNR-DATACENTER_2_H100-PCIe-80GB_TRT/bert-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.34992722790872,
    "Accuracy_div_100": 0.9035,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/AS-4125GS-TNRT_8_H100-PCIe-80GB_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Supermicro",
    "Platform": "AS-4125GS-TNRT_8_H100-PCIe-80GB_TRT",
    "Result": 45831.2,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AS-4125GS-TNRT (8xH100-PCIe-80GB)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 9174F 16-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2",
    "uid": "9ecc0e1bd93f408d",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Supermicro/results/AS-4125GS-TNRT_8_H100-PCIe-80GB_TRT/bert-99/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.97056894987658,
    "Accuracy_div_100": 0.90971,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/AS-4125GS-TNRT_8_H100-PCIe-80GB_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Supermicro",
    "Platform": "AS-4125GS-TNRT_8_H100-PCIe-80GB_TRT",
    "Result": 40347.4,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AS-4125GS-TNRT (8xH100-PCIe-80GB)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 9174F 16-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2",
    "uid": "9add63b496cb4c06",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Supermicro/results/AS-4125GS-TNRT_8_H100-PCIe-80GB_TRT/bert-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.34992722790872,
    "Accuracy_div_100": 0.9035,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H100-PCIe-80GBx1_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "NVIDIA",
    "Platform": "H100-PCIe-80GBx1_TRT",
    "Result": 5878.44,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G482-Z54 (1x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "9b01f8ad2f194d33",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/NVIDIA/results/H100-PCIe-80GBx1_TRT/bert-99/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.97056894987658,
    "Accuracy_div_100": 0.90971,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H100-PCIe-80GBx1_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "NVIDIA",
    "Platform": "H100-PCIe-80GBx1_TRT",
    "Result": 4922.54,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G482-Z54 (1x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "ab2e4e53f8104c7b",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/NVIDIA/results/H100-PCIe-80GBx1_TRT/bert-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.38982811354983,
    "Accuracy_div_100": 0.9039,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A100-PCIe-80GBx8_TRT_Triton/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "NVIDIA",
    "Platform": "A100-PCIe-80GBx8_TRT_Triton",
    "Result": 25712.8,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G482-Z54 (8x A100-PCIe-80GB, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "232264c0dead4a26",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/NVIDIA/results/A100-PCIe-80GBx8_TRT_Triton/bert-99/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.88273936857954,
    "Accuracy_div_100": 0.90883,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A100-PCIe-80GBx8_TRT_Triton/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "NVIDIA",
    "Platform": "A100-PCIe-80GBx8_TRT_Triton",
    "Result": 13541.8,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G482-Z54 (8x A100-PCIe-80GB, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "8d2864ced7784f59",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/NVIDIA/results/A100-PCIe-80GBx8_TRT_Triton/bert-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.4513703999554,
    "Accuracy_div_100": 0.90451,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/L4x1_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "NVIDIA",
    "Platform": "L4x1_TRT",
    "Result": 1032.08,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA L4 (1x L4, TensorRT)",
    "SystemType": "datacenter,edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 7313P 16-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "fa18a7bb93b34a9e",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/NVIDIA/results/L4x1_TRT/bert-99/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.9257447258943,
    "Accuracy_div_100": 0.90926,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/L4x1_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "NVIDIA",
    "Platform": "L4x1_TRT",
    "Result": 630.644,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA L4 (1x L4, TensorRT)",
    "SystemType": "datacenter,edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 7313P 16-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "bb1d707beb6940fa",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/NVIDIA/results/L4x1_TRT/bert-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.34992722790872,
    "Accuracy_div_100": 0.9035,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H100-PCIe-80GBx8_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "NVIDIA",
    "Platform": "H100-PCIe-80GBx8_TRT",
    "Result": 46538.2,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G482-Z54 (8x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "ed207c2659824044",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/NVIDIA/results/H100-PCIe-80GBx8_TRT/bert-99/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.97056894987658,
    "Accuracy_div_100": 0.90971,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H100-PCIe-80GBx8_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "NVIDIA",
    "Platform": "H100-PCIe-80GBx8_TRT",
    "Result": 39418.6,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G482-Z54 (8x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "8e6a043db95a49b3",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/NVIDIA/results/H100-PCIe-80GBx8_TRT/bert-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.37771628970668,
    "Accuracy_div_100": 0.90378,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT_Triton/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "NVIDIA",
    "Platform": "DGX-A100_A100-SXM-80GBx8_TRT_Triton",
    "Result": 28088.8,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX A100 (8x A100-SXM-80GB, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "bddc81dc66a340a5",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT_Triton/bert-99/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.88273936857954,
    "Accuracy_div_100": 0.90883,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT_Triton/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "NVIDIA",
    "Platform": "DGX-A100_A100-SXM-80GBx8_TRT_Triton",
    "Result": 14826.9,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX A100 (8x A100-SXM-80GB, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "4b19db9b80404f1e",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT_Triton/bert-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.37771628970668,
    "Accuracy_div_100": 0.90378,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "NVIDIA",
    "Platform": "DGX-A100_A100-SXM-80GBx8_TRT",
    "Result": 28275.7,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX A100 (8x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "fda7bdf62c7d40b5",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT/bert-99/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.88006360431436,
    "Accuracy_div_100": 0.9088,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "NVIDIA",
    "Platform": "DGX-A100_A100-SXM-80GBx8_TRT",
    "Result": 14620.9,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX A100 (8x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "7fc18c8059684020",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT/bert-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.34992722790872,
    "Accuracy_div_100": 0.9035,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "NVIDIA",
    "Platform": "DGX-H100_H100-SXM-80GBx8_TRT",
    "Result": 73107.6,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX H100 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "6bb8740279584977",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT/bert-99/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.97056894987658,
    "Accuracy_div_100": 0.90971,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "NVIDIA",
    "Platform": "DGX-H100_H100-SXM-80GBx8_TRT",
    "Result": 62398.7,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX H100 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "9f6df3fb0eca4914",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT/bert-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.34992722790872,
    "Accuracy_div_100": 0.9035,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx1_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "NVIDIA",
    "Platform": "DGX-H100_H100-SXM-80GBx1_TRT",
    "Result": 9369.12,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX H100 (1x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "1365b2535e6a4671",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx1_TRT/bert-99/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.97056894987658,
    "Accuracy_div_100": 0.90971,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx1_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "NVIDIA",
    "Platform": "DGX-H100_H100-SXM-80GBx1_TRT",
    "Result": 8006.64,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX H100 (1x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "1864d5787e384c77",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx1_TRT/bert-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.38982811354983,
    "Accuracy_div_100": 0.9039,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A100-PCIe-80GBx8_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "NVIDIA",
    "Platform": "A100-PCIe-80GBx8_TRT",
    "Result": 25602,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G482-Z54 (8x A100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "71bb4bf29ed047e2",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/NVIDIA/results/A100-PCIe-80GBx8_TRT/bert-99/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.88273936857954,
    "Accuracy_div_100": 0.90883,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A100-PCIe-80GBx8_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "NVIDIA",
    "Platform": "A100-PCIe-80GBx8_TRT",
    "Result": 13534.3,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G482-Z54 (8x A100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "12013e1606bf49bc",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/NVIDIA/results/A100-PCIe-80GBx8_TRT/bert-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.4513703999554,
    "Accuracy_div_100": 0.90451,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC4000A_E12_L4x8_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "ASUSTeK",
    "Platform": "ESC4000A_E12_L4x8_TRT",
    "Result": 7552.83,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "ASUS ESC4000A-E12 (8x L4, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9654 96-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "d24f1e6913914d70",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/ASUSTeK/results/ESC4000A_E12_L4x8_TRT/bert-99/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.88739520479311,
    "Accuracy_div_100": 0.90887,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC4000A_E12_L4x8_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "ASUSTeK",
    "Platform": "ESC4000A_E12_L4x8_TRT",
    "Result": 3549.77,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "ASUS ESC4000A-E12 (8x L4, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9654 96-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "772f7b6250c443df",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/ASUSTeK/results/ESC4000A_E12_L4x8_TRT/bert-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.34992722790872,
    "Accuracy_div_100": 0.9035,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/H100_PCIe_80GBx8_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "ASUSTeK",
    "Platform": "H100_PCIe_80GBx8_TRT",
    "Result": 45555.6,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "ESC8000-E12 (8xH100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8460Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "5fb588a1c7a947cf",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/ASUSTeK/results/H100_PCIe_80GBx8_TRT/bert-99/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.38982811354983,
    "Accuracy_div_100": 0.9039,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Azure/results/NC96ads_A100_v4_TRT_Triton/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Azure",
    "Platform": "NC96ads_A100_v4_TRT_Triton",
    "Result": 12482.6,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NC96ads_A100_v4 (4x A100-PCIe-80GB, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 7V13 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5 LTS",
    "uid": "42da9f8ea13c4a4d",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Azure/results/NC96ads_A100_v4_TRT_Triton/bert-99/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.88273936857954,
    "Accuracy_div_100": 0.90883,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Azure/results/NC96ads_A100_v4_TRT_Triton/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Azure",
    "Platform": "NC96ads_A100_v4_TRT_Triton",
    "Result": 6467.31,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NC96ads_A100_v4 (4x A100-PCIe-80GB, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 7V13 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5 LTS",
    "uid": "d211e606080b4b25",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Azure/results/NC96ads_A100_v4_TRT_Triton/bert-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.36510197245661,
    "Accuracy_div_100": 0.90365,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Azure/results/NC96ads_A100_v4_MIG_1g_10gb_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Azure",
    "Platform": "NC96ads_A100_v4_MIG_1g_10gb_TRT",
    "Result": 491.528,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NC96ads_A100_v4 (4x A100-PCIe-80GB-MIG-1x1g.10gb, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB (1x1g.10gb MIG)",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 7V13 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5 LTS",
    "uid": "48fc1d357b36476a",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Azure/results/NC96ads_A100_v4_MIG_1g_10gb_TRT/bert-99/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.88006360431436,
    "Accuracy_div_100": 0.9088,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Azure/results/NC96ads_A100_v4_MIG_1g_10gb_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Azure",
    "Platform": "NC96ads_A100_v4_MIG_1g_10gb_TRT",
    "Result": 255.502,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NC96ads_A100_v4 (4x A100-PCIe-80GB-MIG-1x1g.10gb, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB (1x1g.10gb MIG)",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 7V13 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5 LTS",
    "uid": "f1fe1dbc495b478b",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Azure/results/NC96ads_A100_v4_MIG_1g_10gb_TRT/bert-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.38982811354983,
    "Accuracy_div_100": 0.9039,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Azure/results/NC96ads_A100_v4_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Azure",
    "Platform": "NC96ads_A100_v4_TRT",
    "Result": 12455.7,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NC96ads_A100_v4 (4x A100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 7V13 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5 LTS",
    "uid": "55838a79c5ac42d7",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Azure/results/NC96ads_A100_v4_TRT/bert-99/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.88273936857954,
    "Accuracy_div_100": 0.90883,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Azure/results/NC96ads_A100_v4_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Azure",
    "Platform": "NC96ads_A100_v4_TRT",
    "Result": 6470.04,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NC96ads_A100_v4 (4x A100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 7V13 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5 LTS",
    "uid": "e3e5689e38f740f9",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Azure/results/NC96ads_A100_v4_TRT/bert-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.38982811354983,
    "Accuracy_div_100": 0.9039,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/A100-PCIe-80GBx8_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Lenovo",
    "Platform": "A100-PCIe-80GBx8_TRT",
    "Result": 25696.3,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Lenovo ThinkSystem SR670 V2 Server with 8x 80GB PCIe A100",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "NGC MLPerf v3.0.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 36,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8360Y CPU @ 2.40GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Air Cooling",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2 LTS",
    "uid": "56a1d2eacf144093",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Lenovo/results/A100-PCIe-80GBx8_TRT/bert-99/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.88273936857954,
    "Accuracy_div_100": 0.90883,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/A100-PCIe-80GBx8_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Lenovo",
    "Platform": "A100-PCIe-80GBx8_TRT",
    "Result": 13385.1,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Lenovo ThinkSystem SR670 V2 Server with 8x 80GB PCIe A100",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "NGC MLPerf v3.0.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 36,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8360Y CPU @ 2.40GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Air Cooling",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2 LTS",
    "uid": "4f47e62a92f74cbd",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Lenovo/results/A100-PCIe-80GBx8_TRT/bert-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.2426510242233,
    "Accuracy_div_100": 0.90243,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Qualcomm/results/r282_z93_q8-qaic-v1.8.3.7-aic100/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Qualcomm",
    "Platform": "r282_z93_q8-qaic-v1.8.3.7-aic100",
    "Result": 6206.85,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "GIGABYTE R282-Z93 (8x QAIC100 Pro)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.8.3",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 7282 16-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026.. Powered by Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5 LTS (Linux kernel: 5.4.0-135-generic #152-Ubuntu SMP Wed Nov 23 20:19:22 UTC 2022)",
    "uid": "298b4e1e44d94c3e",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Qualcomm/results/r282_z93_q8-qaic-v1.8.3.7-aic100/bert-99/offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.8666333229796,
    "Accuracy_div_100": 0.90867,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Qualcomm/results/r282_z93_q8-qaic-v1.8.3.7-aic100/bert-99.9/offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Qualcomm",
    "Platform": "r282_z93_q8-qaic-v1.8.3.7-aic100",
    "Result": 3117.64,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "GIGABYTE R282-Z93 (8x QAIC100 Pro)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.8.3",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 7282 16-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. 3x QAIC100 on riser CRS2033; 3x QAIC100 on riser CRS2033; 2x QAIC100 on riser CRS2026.. Powered by Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5 LTS (Linux kernel: 5.4.0-135-generic #152-Ubuntu SMP Wed Nov 23 20:19:22 UTC 2022)",
    "uid": "3a15a3cb5533426b",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Qualcomm/results/r282_z93_q8-qaic-v1.8.3.7-aic100/bert-99.9/offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.2426510242233,
    "Accuracy_div_100": 0.90243,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Qualcomm/results/g292_z43_q16-qaic-v1.8.3.7-aic100/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Qualcomm",
    "Platform": "g292_z43_q16-qaic-v1.8.3.7-aic100",
    "Result": 12537.5,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "GIGABYTE G292-Z43 (16x QAIC100 Pro)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 16,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.8.3",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7713 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5 LTS (Linux kernel: 5.4.0-135-generic #152-Ubuntu SMP Wed Nov 23 20:19:22 UTC 2022)",
    "uid": "88b86650814048e9",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Qualcomm/results/g292_z43_q16-qaic-v1.8.3.7-aic100/bert-99/offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.8666333229796,
    "Accuracy_div_100": 0.90867,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Qualcomm/results/g292_z43_q16-qaic-v1.8.3.7-aic100/bert-99.9/offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Qualcomm",
    "Platform": "g292_z43_q16-qaic-v1.8.3.7-aic100",
    "Result": 6395.01,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "GIGABYTE G292-Z43 (16x QAIC100 Pro)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 16,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.8.3",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7713 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5 LTS (Linux kernel: 5.4.0-135-generic #152-Ubuntu SMP Wed Nov 23 20:19:22 UTC 2022)",
    "uid": "9298d0b0ebac4ca2",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Qualcomm/results/g292_z43_q16-qaic-v1.8.3.7-aic100/bert-99.9/offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.2426510242233,
    "Accuracy_div_100": 0.90243,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Qualcomm/results/g292_z43_q18-qaic-v1.8.3.7-aic100/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Qualcomm",
    "Platform": "g292_z43_q18-qaic-v1.8.3.7-aic100",
    "Result": 14091.8,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "GIGABYTE G292-Z43 (18x QAIC100 Pro)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 18,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.8.3",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7713 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5 LTS (Linux kernel: 5.4.0-135-generic #152-Ubuntu SMP Wed Nov 23 20:19:22 UTC 2022)",
    "uid": "369e730cb0384b58",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Qualcomm/results/g292_z43_q18-qaic-v1.8.3.7-aic100/bert-99/offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.8666333229796,
    "Accuracy_div_100": 0.90867,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Qualcomm/results/g292_z43_q18-qaic-v1.8.3.7-aic100/bert-99.9/offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Qualcomm",
    "Platform": "g292_z43_q18-qaic-v1.8.3.7-aic100",
    "Result": 7183.15,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "GIGABYTE G292-Z43 (18x QAIC100 Pro)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 18,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.8.3",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7713 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5 LTS (Linux kernel: 5.4.0-135-generic #152-Ubuntu SMP Wed Nov 23 20:19:22 UTC 2022)",
    "uid": "de725ad7bbc44289",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Qualcomm/results/g292_z43_q18-qaic-v1.8.3.7-aic100/bert-99.9/offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.35400833054847,
    "Accuracy_div_100": 0.90354,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9680_H100_SXM_80GBx8_TRT_Triton/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Dell",
    "Platform": "XE9680_H100_SXM_80GBx8_TRT_Triton",
    "Result": 66545.5,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE9680 (8x H100-SXM-80GB, Triton)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "Triton 2.30.0 , CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 52,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "b4f72b97a20c4cfe",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Dell/results/XE9680_H100_SXM_80GBx8_TRT_Triton/bert-99/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.30050110717718,
    "Accuracy_div_100": 0.90301,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE2420_T4x1_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Dell",
    "Platform": "XE2420_T4x1_TRT",
    "Result": 427.452,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE2420 (1x T4, TensorRT)",
    "SystemType": "datacenter,edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA T4",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 22,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6238 CPU @ 2.10GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "ECC on",
    "number_of_nodes": 1,
    "operating_system": "CentOS 8.2.2004",
    "uid": "48657f0ef9f24faa",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Dell/results/XE2420_T4x1_TRT/bert-99/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.38982811354983,
    "Accuracy_div_100": 0.9039,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XR4520c_A30x1_TRT_DATACENTER/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Dell",
    "Platform": "XR4520c_A30x1_TRT_DATACENTER",
    "Result": 1731.91,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XR4520c (1x A30, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "Intel(R) Xeon(R) D-2776NT CPU @ 2.10GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "09f68e06663e4381",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Dell/results/XR4520c_A30x1_TRT_DATACENTER/bert-99/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.88273936857954,
    "Accuracy_div_100": 0.90883,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XR4520c_A30x1_TRT_DATACENTER/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Dell",
    "Platform": "XR4520c_A30x1_TRT_DATACENTER",
    "Result": 866.788,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XR4520c (1x A30, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "Intel(R) Xeon(R) D-2776NT CPU @ 2.10GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "f113c5e330184efe",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Dell/results/XR4520c_A30x1_TRT_DATACENTER/bert-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.34992722790872,
    "Accuracy_div_100": 0.9035,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R750xa_H100_PCIe_80GBx4_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Dell",
    "Platform": "R750xa_H100_PCIe_80GBx4_TRT",
    "Result": 20838.9,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge R750xa (4x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6338 CPU @ 2.00GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "NVIDIA H100-PCIe-80GB (TDP: 310W)",
    "number_of_nodes": 1,
    "operating_system": "CentOS 8.2",
    "uid": "5362db40b8db4076",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Dell/results/R750xa_H100_PCIe_80GBx4_TRT/bert-99/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.97056894987658,
    "Accuracy_div_100": 0.90971,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R750xa_H100_PCIe_80GBx4_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Dell",
    "Platform": "R750xa_H100_PCIe_80GBx4_TRT",
    "Result": 17729.8,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge R750xa (4x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6338 CPU @ 2.00GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "NVIDIA H100-PCIe-80GB (TDP: 310W)",
    "number_of_nodes": 1,
    "operating_system": "CentOS 8.2",
    "uid": "a1a6ae8dcc7a4368",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Dell/results/R750xa_H100_PCIe_80GBx4_TRT/bert-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.37771628970668,
    "Accuracy_div_100": 0.90378,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/vXE8545_A100_SXM_80GBx4_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Dell",
    "Platform": "vXE8545_A100_SXM_80GBx4_TRT",
    "Result": 14923.1,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE8545, VMware vSphere 8.0.1 (4x A100-SXM-80C, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80C",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 128,
    "host_processor_model_name": "AMD EPYC 7543",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "VMware vSphere 8.0.1, Ubuntu 20.04.2",
    "uid": "90371013fbe74c88",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Dell/results/vXE8545_A100_SXM_80GBx4_TRT/bert-99/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.88006360431436,
    "Accuracy_div_100": 0.9088,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/vXE8545_A100_SXM_80GBx4_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Dell",
    "Platform": "vXE8545_A100_SXM_80GBx4_TRT",
    "Result": 7767.84,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE8545, VMware vSphere 8.0.1 (4x A100-SXM-80C, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80C",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 128,
    "host_processor_model_name": "AMD EPYC 7543",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "VMware vSphere 8.0.1, Ubuntu 20.04.2",
    "uid": "df74df37ac0142d7",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Dell/results/vXE8545_A100_SXM_80GBx4_TRT/bert-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.33545135956516,
    "Accuracy_div_100": 0.90335,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE8545_A100_SXM4_80GBx4_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Dell",
    "Platform": "XE8545_A100_SXM4_80GBx4_TRT",
    "Result": 15090,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE8545 (4x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB CTS",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7763",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "NVIDIA A100-SXM4-80GB (TDP: 500W)",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "3f3082113d4140ac",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Dell/results/XE8545_A100_SXM4_80GBx4_TRT/bert-99/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.88006360431436,
    "Accuracy_div_100": 0.9088,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE8545_A100_SXM4_80GBx4_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Dell",
    "Platform": "XE8545_A100_SXM4_80GBx4_TRT",
    "Result": 7880.67,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE8545 (4x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB CTS",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7763",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "NVIDIA A100-SXM4-80GB (TDP: 500W)",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "843fe04a44c442d2",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Dell/results/XE8545_A100_SXM4_80GBx4_TRT/bert-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.34259515600714,
    "Accuracy_div_100": 0.90343,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9680_H100_SXM_80GBx8_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Dell",
    "Platform": "XE9680_H100_SXM_80GBx8_TRT",
    "Result": 70747.3,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE9680 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 52,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "d5669beeb12b472b",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Dell/results/XE9680_H100_SXM_80GBx8_TRT/bert-99/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.97056894987658,
    "Accuracy_div_100": 0.90971,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9680_H100_SXM_80GBx8_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Dell",
    "Platform": "XE9680_H100_SXM_80GBx8_TRT",
    "Result": 63181.2,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE9680 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 52,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "955519c327004a6b",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Dell/results/XE9680_H100_SXM_80GBx8_TRT/bert-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.38982811354983,
    "Accuracy_div_100": 0.9039,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R750xa_A100_PCIE_80GBx4_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Dell",
    "Platform": "R750xa_A100_PCIE_80GBx4_TRT",
    "Result": 12908.5,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge R750xa (4x A100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6338 CPU @ 2.00GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "CentOS 8.2",
    "uid": "cab4e369fe414000",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Dell/results/R750xa_A100_PCIE_80GBx4_TRT/bert-99/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.88273936857954,
    "Accuracy_div_100": 0.90883,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R750xa_A100_PCIE_80GBx4_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Dell",
    "Platform": "R750xa_A100_PCIE_80GBx4_TRT",
    "Result": 6719.42,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge R750xa (4x A100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6338 CPU @ 2.00GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "CentOS 8.2",
    "uid": "f3ada2e55ce146a3",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Dell/results/R750xa_A100_PCIE_80GBx4_TRT/bert-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.37771628970668,
    "Accuracy_div_100": 0.90378,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9680_A100_SXM4_80GBx8_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Dell",
    "Platform": "XE9680_A100_SXM4_80GBx8_TRT",
    "Result": 30183.9,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE9680 (8x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB CTS",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 52,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "NVIDIA A100-SXM4-80GB (TDP: 500W)",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "c9c264f907cd4585",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Dell/results/XE9680_A100_SXM4_80GBx8_TRT/bert-99/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.88006360431436,
    "Accuracy_div_100": 0.9088,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9680_A100_SXM4_80GBx8_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Dell",
    "Platform": "XE9680_A100_SXM4_80GBx8_TRT",
    "Result": 15783.4,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XE9680 (8x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB CTS",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 52,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "NVIDIA A100-SXM4-80GB (TDP: 500W)",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "cb1eb087556244cd",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Dell/results/XE9680_A100_SXM4_80GBx8_TRT/bert-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.53885196505269,
    "Accuracy_div_100": 0.90539,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/1-node-2S-SPR-PyTorch-INT8/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Dell",
    "Platform": "1-node-2S-SPR-PyTorch-INT8",
    "Result": 1376.05,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge Server R760 (1x Intel Xeon Platinum 8480+)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "PyTorch",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 224,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "CentOS Stream 8",
    "uid": "01eb08388d814e31",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Dell/results/1-node-2S-SPR-PyTorch-INT8/bert-99/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.38982811354983,
    "Accuracy_div_100": 0.9039,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/xFusion/results/G5500V7_A30x10_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "xFusion",
    "Platform": "G5500V7_A30x10_TRT",
    "Result": 16885.5,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "xFusion FusionServer G5500V7(10x NVIDIA A30, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 10,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 44,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8458P CPU @ 2.7 GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "766950df38804f2e",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/xFusion/results/G5500V7_A30x10_TRT/bert-99/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.88273936857954,
    "Accuracy_div_100": 0.90883,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/xFusion/results/G5500V7_A30x10_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "xFusion",
    "Platform": "G5500V7_A30x10_TRT",
    "Result": 8507.5,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "xFusion FusionServer G5500V7(10x NVIDIA A30, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 10,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 44,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8458P CPU @ 2.7 GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "4e89b0021d2349fe",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/xFusion/results/G5500V7_A30x10_TRT/bert-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.45671228608292,
    "Accuracy_div_100": 0.90457,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/xFusion/results/G5500V7_L40x8_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "xFusion",
    "Platform": "G5500V7_L40x8_TRT",
    "Result": 15524.8,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "xFusion FusionServer G5500V7(8x NVIDIA L40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 44,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8458P CPU @ 2.7 GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "de94ed3cddb04aec",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/xFusion/results/G5500V7_L40x8_TRT/bert-99/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.88273936857954,
    "Accuracy_div_100": 0.90883,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/xFusion/results/G5500V7_L40x8_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "xFusion",
    "Platform": "G5500V7_L40x8_TRT",
    "Result": 7994.39,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "xFusion FusionServer G5500V7(8x NVIDIA L40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 44,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8458P CPU @ 2.7 GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "8fffa32eb6ab4e2f",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/xFusion/results/G5500V7_L40x8_TRT/bert-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.38982811354983,
    "Accuracy_div_100": 0.9039,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/xFusion/results/G5500V7_A30x8_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "xFusion",
    "Platform": "G5500V7_A30x8_TRT",
    "Result": 13573.2,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "xFusion FusionServer G5500V7(8x NVIDIA A30, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 44,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8458P CPU @ 2.7 GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "26e8a86872054e51",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/xFusion/results/G5500V7_A30x8_TRT/bert-99/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.88273936857954,
    "Accuracy_div_100": 0.90883,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/xFusion/results/G5500V7_A30x8_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "xFusion",
    "Platform": "G5500V7_A30x8_TRT",
    "Result": 6856.5,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "xFusion FusionServer G5500V7(8x NVIDIA A30, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 44,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8458P CPU @ 2.7 GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "fb215afd55ed43ac",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/xFusion/results/G5500V7_A30x8_TRT/bert-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.44711306788348,
    "Accuracy_div_100": 0.90447,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/xFusion/results/L4x6_2288H_V7_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "xFusion",
    "Platform": "L4x6_2288H_V7_TRT",
    "Result": 5649.56,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "xFusion FusionServer 2288H V7(6x NVIDIA L4, TensorRT)",
    "SystemType": "datacenter,edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 6,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 44,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8458P CPU @ 2.7 GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "c8aded9bd6fa4a98",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/xFusion/results/L4x6_2288H_V7_TRT/bert-99/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.9257447258943,
    "Accuracy_div_100": 0.90926,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/xFusion/results/L4x6_2288H_V7_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "xFusion",
    "Platform": "L4x6_2288H_V7_TRT",
    "Result": 3860.63,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "xFusion FusionServer 2288H V7(6x NVIDIA L4, TensorRT)",
    "SystemType": "datacenter,edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 6,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 44,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8458P CPU @ 2.7 GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "c8ff68e7421549d6",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/xFusion/results/L4x6_2288H_V7_TRT/bert-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.45671228608292,
    "Accuracy_div_100": 0.90457,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/xFusion/results/G5500V7_L40x10_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "xFusion",
    "Platform": "G5500V7_L40x10_TRT",
    "Result": 19191.5,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "xFusion FusionServer G5500V7(10x NVIDIA L40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40",
    "accelerators_per_node": 10,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 44,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8458P CPU @ 2.7 GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "03532f4f6f984f83",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/xFusion/results/G5500V7_L40x10_TRT/bert-99/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.88273936857954,
    "Accuracy_div_100": 0.90883,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/xFusion/results/G5500V7_L40x10_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "xFusion",
    "Platform": "G5500V7_L40x10_TRT",
    "Result": 9876.03,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "xFusion FusionServer G5500V7(10x NVIDIA L40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40",
    "accelerators_per_node": 10,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 44,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8458P CPU @ 2.7 GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "96d81c4ad2634ad1",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/xFusion/results/G5500V7_L40x10_TRT/bert-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.34992722790872,
    "Accuracy_div_100": 0.9035,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/GIGABYTE/results/GIGABYTE-G493-SB0_H100-PCIe-80GBx8_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "GIGABYTE",
    "Platform": "GIGABYTE-G493-SB0_H100-PCIe-80GBx8_TRT",
    "Result": 47349.5,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "GIGABYTE G493-SB0",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "44e9d881b438419b",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/GIGABYTE/results/GIGABYTE-G493-SB0_H100-PCIe-80GBx8_TRT/bert-99/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.97056894987658,
    "Accuracy_div_100": 0.90971,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/GIGABYTE/results/GIGABYTE-G493-SB0_H100-PCIe-80GBx8_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "GIGABYTE",
    "Platform": "GIGABYTE-G493-SB0_H100-PCIe-80GBx8_TRT",
    "Result": 39712.2,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "GIGABYTE G493-SB0",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "bf0968c5d5b248c8",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/GIGABYTE/results/GIGABYTE-G493-SB0_H100-PCIe-80GBx8_TRT/bert-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.53885196505269,
    "Accuracy_div_100": 0.90539,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Intel/results/1-node-2S-SPR-PyTorch-INT8/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Intel",
    "Platform": "1-node-2S-SPR-PyTorch-INT8",
    "Result": 1382.79,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "1-node-2S-SPR-PyTorch-INT8",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "PyTorch",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54Q-2U",
    "number_of_nodes": 2,
    "operating_system": "CentOS Stream 8",
    "uid": "a1e02613b865416c",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Intel/results/1-node-2S-SPR-PyTorch-INT8/bert-99/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.4513703999554,
    "Accuracy_div_100": 0.90451,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Nettrix/results/L40x8_Custom_X640_G40_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Nettrix",
    "Platform": "L40x8_Custom_X640_G40_TRT",
    "Result": 17278.9,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "X640 G40 (8xL40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8380",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "678df709d9e64e68",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/L40x8_Custom_X640_G40_TRT/bert-99/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.88273936857954,
    "Accuracy_div_100": 0.90883,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Nettrix/results/L40x8_Custom_X640_G40_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Nettrix",
    "Platform": "L40x8_Custom_X640_G40_TRT",
    "Result": 8166.68,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "X640 G40 (8xL40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8380",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "dd1a9ff1610a49f0",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/L40x8_Custom_X640_G40_TRT/bert-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.45671228608292,
    "Accuracy_div_100": 0.90457,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Nettrix/results/A40X3_CUSTOM_X620_G50_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Nettrix",
    "Platform": "A40X3_CUSTOM_X620_G50_TRT",
    "Result": 5228,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "X620 G50 (3x A40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A40",
    "accelerators_per_node": 3,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "c5b5d8a1bbf846e6",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/A40X3_CUSTOM_X620_G50_TRT/bert-99/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.88273936857954,
    "Accuracy_div_100": 0.90883,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Nettrix/results/A40X3_CUSTOM_X620_G50_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Nettrix",
    "Platform": "A40X3_CUSTOM_X620_G50_TRT",
    "Result": 2538.9,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "X620 G50 (3x A40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A40",
    "accelerators_per_node": 3,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "e0c3196861074942",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/A40X3_CUSTOM_X620_G50_TRT/bert-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.38982811354983,
    "Accuracy_div_100": 0.9039,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/Nettrix/results/A30x8_Custom_X640_G50_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Nettrix",
    "Platform": "A30x8_Custom_X640_G50_TRT",
    "Result": 13414.3,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "X640 G50 (8x A30, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "f3d3ef0e205241ce",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/A30x8_Custom_X640_G50_TRT/bert-99/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.88273936857954,
    "Accuracy_div_100": 0.90883,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/Nettrix/results/A30x8_Custom_X640_G50_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Nettrix",
    "Platform": "A30x8_Custom_X640_G50_TRT",
    "Result": 6790.17,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "X640 G50 (8x A30, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "11ed1796ddbd471f",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/A30x8_Custom_X640_G50_TRT/bert-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.4513703999554,
    "Accuracy_div_100": 0.90451,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/Nettrix/results/L4x8_Custom_X640_G40_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Nettrix",
    "Platform": "L4x8_Custom_X640_G40_TRT",
    "Result": 7447.22,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "X640 G40 (8x L4, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 38,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8368",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "ce20ae7a36484cba",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/L4x8_Custom_X640_G40_TRT/bert-99/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.9257447258943,
    "Accuracy_div_100": 0.90926,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/Nettrix/results/L4x8_Custom_X640_G40_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Nettrix",
    "Platform": "L4x8_Custom_X640_G40_TRT",
    "Result": 5071.43,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "X640 G40 (8x L4, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 38,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8368",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "48eb89a3b08542b2",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/L4x8_Custom_X640_G40_TRT/bert-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.4513703999554,
    "Accuracy_div_100": 0.90451,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Nettrix/results/L40x3_Custom_X620_G40_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Nettrix",
    "Platform": "L40x3_Custom_X620_G40_TRT",
    "Result": 6442.9,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "X620 G40 (3xL40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40",
    "accelerators_per_node": 3,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 28,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6348",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "04e10af8b12742c3",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/L40x3_Custom_X620_G40_TRT/bert-99/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.88006360431436,
    "Accuracy_div_100": 0.9088,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Nettrix/results/L40x3_Custom_X620_G40_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Nettrix",
    "Platform": "L40x3_Custom_X620_G40_TRT",
    "Result": 2712.83,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "X620 G40 (3xL40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40",
    "accelerators_per_node": 3,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 28,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6348",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "6d15f9624edc4e5e",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/L40x3_Custom_X620_G40_TRT/bert-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.4513703999554,
    "Accuracy_div_100": 0.90451,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Nettrix/results/L40x3_Custom_X620_G50_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Nettrix",
    "Platform": "L40x3_Custom_X620_G50_TRT",
    "Result": 6330.47,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "X620 G50 (3xL40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40",
    "accelerators_per_node": 3,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6442Y",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "730e9cc8112244b9",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/L40x3_Custom_X620_G50_TRT/bert-99/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.88006360431436,
    "Accuracy_div_100": 0.9088,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Nettrix/results/L40x3_Custom_X620_G50_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Nettrix",
    "Platform": "L40x3_Custom_X620_G50_TRT",
    "Result": 2675.99,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "X620 G50 (3xL40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40",
    "accelerators_per_node": 3,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6442Y",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "762344f0d2dc4462",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/L40x3_Custom_X620_G50_TRT/bert-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.34091530467309,
    "Accuracy_div_100": 0.90341,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Nettrix/results/A40X8_CUSTOM_X640_G40_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Nettrix",
    "Platform": "A40X8_CUSTOM_X640_G40_TRT",
    "Result": 13679.6,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "X640 G40 (8x A40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A40",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 38,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8368",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "1446e5afd6df420f",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/A40X8_CUSTOM_X640_G40_TRT/bert-99/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.88273936857954,
    "Accuracy_div_100": 0.90883,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Nettrix/results/A40X8_CUSTOM_X640_G40_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Nettrix",
    "Platform": "A40X8_CUSTOM_X640_G40_TRT",
    "Result": 6647.11,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "X640 G40 (8x A40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A40",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 38,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8368",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "92905cdb16bf44c5",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/A40X8_CUSTOM_X640_G40_TRT/bert-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.38982811354983,
    "Accuracy_div_100": 0.9039,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Nettrix/results/A30x3_Custom_X620_G40_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Nettrix",
    "Platform": "A30x3_Custom_X620_G40_TRT",
    "Result": 5089.45,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "X620 G40 (3x A30, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 3,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 28,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6348 CPU @ 2.60GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "b43db38167804f48",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/A30x3_Custom_X620_G40_TRT/bert-99/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.88273936857954,
    "Accuracy_div_100": 0.90883,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Nettrix/results/A30x3_Custom_X620_G40_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Nettrix",
    "Platform": "A30x3_Custom_X620_G40_TRT",
    "Result": 2576.82,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "X620 G40 (3x A30, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 3,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 28,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6348 CPU @ 2.60GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "ec2c090217eb4d4a",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/A30x3_Custom_X620_G40_TRT/bert-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.47029187583051,
    "Accuracy_div_100": 0.9047,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/Nettrix/results/L4x4_Custom_X620_G40_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Nettrix",
    "Platform": "L4x4_Custom_X620_G40_TRT",
    "Result": 3746.12,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "X620 G40 (4x L4, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 28,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6348",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "67ad82af99274536",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/L4x4_Custom_X620_G40_TRT/bert-99/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.9257447258943,
    "Accuracy_div_100": 0.90926,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/Nettrix/results/L4x4_Custom_X620_G40_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Nettrix",
    "Platform": "L4x4_Custom_X620_G40_TRT",
    "Result": 2313.74,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "X620 G40 (4x L4, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 28,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6348",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "76fbe8d981324d3a",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/L4x4_Custom_X620_G40_TRT/bert-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.38982811354983,
    "Accuracy_div_100": 0.9039,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Nettrix/results/A30x4_Custom_X620_G50_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Nettrix",
    "Platform": "A30x4_Custom_X620_G50_TRT",
    "Result": 6581.57,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "X620 G50 (4x A30, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 44,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8458P",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "0f20e611ae5c4b6e",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/A30x4_Custom_X620_G50_TRT/bert-99/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.88273936857954,
    "Accuracy_div_100": 0.90883,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Nettrix/results/A30x4_Custom_X620_G50_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Nettrix",
    "Platform": "A30x4_Custom_X620_G50_TRT",
    "Result": 3347.68,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "X620 G50 (4x A30, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 44,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8458P",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "9eb4589a2d7d40c0",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/A30x4_Custom_X620_G50_TRT/bert-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.4513703999554,
    "Accuracy_div_100": 0.90451,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/Nettrix/results/L40x8_Custom_X640_G50_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Nettrix",
    "Platform": "L40x8_Custom_X640_G50_TRT",
    "Result": 17273,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "X640 G50 (8xL40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "7d4da0a3a09f4208",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/L40x8_Custom_X640_G50_TRT/bert-99/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.88273936857954,
    "Accuracy_div_100": 0.90883,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/Nettrix/results/L40x8_Custom_X640_G50_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Nettrix",
    "Platform": "L40x8_Custom_X640_G50_TRT",
    "Result": 8391.3,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "X640 G50 (8xL40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "7d4162baeaff4449",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/L40x8_Custom_X640_G50_TRT/bert-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.45671228608292,
    "Accuracy_div_100": 0.90457,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/Nettrix/results/A40X8_CUSTOM_X640_G50_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Nettrix",
    "Platform": "A40X8_CUSTOM_X640_G50_TRT",
    "Result": 13794.9,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "X640 G50 (8x A40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A40",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "ad9e49c18f56464e",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/A40X8_CUSTOM_X640_G50_TRT/bert-99/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.88273936857954,
    "Accuracy_div_100": 0.90883,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/Nettrix/results/A40X8_CUSTOM_X640_G50_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Nettrix",
    "Platform": "A40X8_CUSTOM_X640_G50_TRT",
    "Result": 6687.04,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "X640 G50 (8x A40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A40",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "2ca4f9d6f26d4208",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/A40X8_CUSTOM_X640_G50_TRT/bert-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.38982811354983,
    "Accuracy_div_100": 0.9039,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Nettrix/results/A30x8_Custom_X640_G40_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Nettrix",
    "Platform": "A30x8_Custom_X640_G40_TRT",
    "Result": 13388.2,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "X640 G40 (8x A30, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 18,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6354",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "d047023ba25d43bf",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/A30x8_Custom_X640_G40_TRT/bert-99/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.88273936857954,
    "Accuracy_div_100": 0.90883,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Nettrix/results/A30x8_Custom_X640_G40_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Nettrix",
    "Platform": "A30x8_Custom_X640_G40_TRT",
    "Result": 6784.13,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "X640 G40 (8x A30, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 18,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6354",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "b61cbe0a8c7243d3",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/A30x8_Custom_X640_G40_TRT/bert-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.45671228608292,
    "Accuracy_div_100": 0.90457,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Nettrix/results/A40X3_CUSTOM_X620_G40_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Nettrix",
    "Platform": "A40X3_CUSTOM_X620_G40_TRT",
    "Result": 5147.79,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "X620 G40 (3x A40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A40",
    "accelerators_per_node": 3,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 28,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6348",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "d1299e79bfcf466e",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/A40X3_CUSTOM_X620_G40_TRT/bert-99/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.88273936857954,
    "Accuracy_div_100": 0.90883,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Nettrix/results/A40X3_CUSTOM_X620_G40_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Nettrix",
    "Platform": "A40X3_CUSTOM_X620_G40_TRT",
    "Result": 2499.88,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "X620 G40 (3x A40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A40",
    "accelerators_per_node": 3,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 28,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6348",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "513601c1d3684abd",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/A40X3_CUSTOM_X620_G40_TRT/bert-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.47422172081995,
    "Accuracy_div_100": 0.90474,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/Nettrix/results/L4x8_Custom_X640_G50_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Nettrix",
    "Platform": "L4x8_Custom_X640_G50_TRT",
    "Result": 7670.79,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "X640 G50 (8x L4, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "9a4b23dde3ad4ebc",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/L4x8_Custom_X640_G50_TRT/bert-99/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.9257447258943,
    "Accuracy_div_100": 0.90926,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/Nettrix/results/L4x8_Custom_X640_G50_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Nettrix",
    "Platform": "L4x8_Custom_X640_G50_TRT",
    "Result": 5202.76,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "X640 G50 (8x L4, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "a9c1b782dabc4ddc",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/L4x8_Custom_X640_G50_TRT/bert-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.45051033287017,
    "Accuracy_div_100": 0.90451,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/Nettrix/results/L4x5_Custom_X620_G50_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Nettrix",
    "Platform": "L4x5_Custom_X620_G50_TRT",
    "Result": 4794.58,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "X620 G50 (5x L4, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 5,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 6458Q",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "9c06eb3f82544f67",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/L4x5_Custom_X620_G50_TRT/bert-99/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.9257447258943,
    "Accuracy_div_100": 0.90926,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/Nettrix/results/L4x5_Custom_X620_G50_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Nettrix",
    "Platform": "L4x5_Custom_X620_G50_TRT",
    "Result": 2947.58,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "X620 G50 (5x L4, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 5,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 6458Q",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "40d2d2bb41974c7f",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/L4x5_Custom_X620_G50_TRT/bert-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.24821866958023,
    "Accuracy_div_100": 0.90248,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/cTuning/results/aws_g4dn.xlarge.497G-nvidia_original-gpu-tensorrt-v8.5.2.2-default_config/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "cTuning",
    "Platform": "aws_g4dn.xlarge.497G-nvidia_original-gpu-tensorrt-v8.5.2.2-default_config",
    "Result": 317.058,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance g4dn.xlarge",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "Tesla T4",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.5.2.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 2,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8259CL CPU @ 2.50GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Powered by MLCommons Collective Mind framework (CK2). ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-5.15.0-1028-aws-glibc2.35)",
    "uid": "44c1a609056d4417",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/cTuning/results/aws_g4dn.xlarge.497G-nvidia_original-gpu-tensorrt-v8.5.2.2-default_config/bert-99/offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.45775588277255,
    "Accuracy_div_100": 0.90458,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Inspur/results/NF5468M6_A40x8_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Inspur",
    "Platform": "NF5468M6_A40x8_TRT",
    "Result": 14135.8,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NF5468M6 (8x A40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A40",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8380",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5",
    "uid": "f3a5f13026ce4c2b",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Inspur/results/NF5468M6_A40x8_TRT/bert-99/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.88273936857954,
    "Accuracy_div_100": 0.90883,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Inspur/results/NF5468M6_A40x8_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Inspur",
    "Platform": "NF5468M6_A40x8_TRT",
    "Result": 6759.95,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NF5468M6 (8x A40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A40",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8380",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5",
    "uid": "76b582a1d83f48bd",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Inspur/results/NF5468M6_A40x8_TRT/bert-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.38982811354983,
    "Accuracy_div_100": 0.9039,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/R5350G6_A30x10_TRT_Triton/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "H3C",
    "Platform": "R5350G6_A30x10_TRT_Triton",
    "Result": 17425.6,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "H3C UniServer R5350 G6 (10x A30, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 10,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "AMD EPYC 9654 96-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5",
    "uid": "6e97d029f5ab4e83",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/H3C/results/R5350G6_A30x10_TRT_Triton/bert-99/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.88273936857954,
    "Accuracy_div_100": 0.90883,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/R5350G6_A30x10_TRT_Triton/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "H3C",
    "Platform": "R5350G6_A30x10_TRT_Triton",
    "Result": 8746.12,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "H3C UniServer R5350 G6 (10x A30, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 10,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "AMD EPYC 9654 96-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5",
    "uid": "b965ec2b7db546c9",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/H3C/results/R5350G6_A30x10_TRT_Triton/bert-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.88273936857954,
    "Accuracy_div_100": 0.90883,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/R5300G6_A30x4_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "H3C",
    "Platform": "R5300G6_A30x4_TRT",
    "Result": 3512.99,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "H3C UniServer R5300 G6 (4x A30, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 11.7",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 44,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8458P",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5",
    "uid": "a122675d96b84623",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/H3C/results/R5300G6_A30x4_TRT/bert-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.46798543449019,
    "Accuracy_div_100": 0.90468,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/A2x2_TRT_Triton/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "H3C",
    "Platform": "A2x2_TRT_Triton",
    "Result": 509.911,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "H3C UniServer R4950 G6 (2x A2, TensorRT,Triton)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A2",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 384,
    "host_processor_model_name": "AMD EPYC 9654 96-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "5f2cfd820550414b",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/H3C/results/A2x2_TRT_Triton/bert-99/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.38982811354983,
    "Accuracy_div_100": 0.9039,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/R5300G6_A30x4_TRT_Triton/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "H3C",
    "Platform": "R5300G6_A30x4_TRT_Triton",
    "Result": 6990.58,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "H3C UniServer R5300 G6 (4x A30, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 11.7",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 44,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8458P",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5",
    "uid": "bdb89b552787443f",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/H3C/results/R5300G6_A30x4_TRT_Triton/bert-99/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.38982811354983,
    "Accuracy_div_100": 0.9039,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/R5350G6_A30x10_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "H3C",
    "Platform": "R5350G6_A30x10_TRT",
    "Result": 17353.2,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "H3C UniServer R5350 G6 (10x A30, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 10,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "AMD EPYC 9654 96-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5",
    "uid": "52f564622a7f4993",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/H3C/results/R5350G6_A30x10_TRT/bert-99/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.88273936857954,
    "Accuracy_div_100": 0.90883,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/R5350G6_A30x10_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "H3C",
    "Platform": "R5350G6_A30x10_TRT",
    "Result": 8776.93,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "H3C UniServer R5350 G6 (10x A30, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 10,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "AMD EPYC 9654 96-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5",
    "uid": "b6204794c0d0414a",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/H3C/results/R5350G6_A30x10_TRT/bert-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.53885196505269,
    "Accuracy_div_100": 0.90539,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/1-node-2S-SPR-PyTorch-INT8/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "1-node-2S-SPR-PyTorch-INT8",
    "Result": 1373.09,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "1-node-2S-SPR-PyTorch-INT8",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "PyTorch",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 2,
    "operating_system": "Rocky Linux release 9.0 (Blue Onyx)",
    "uid": "a2b30a1f721f4aae",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Quanta_Cloud_Technology/results/1-node-2S-SPR-PyTorch-INT8/bert-99/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.2426510242233,
    "Accuracy_div_100": 0.90243,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/dl385_q8_std-qaic-v1.8.3.7-aic100/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "HPE",
    "Platform": "dl385_q8_std-qaic-v1.8.3.7-aic100",
    "Result": 5880.04,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "HPE ProLiant DL385 Gen10 Plus v2 (8x QAIC100 Standard)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Standard",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.8.3",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "AMD EPYC 7543 32-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5 LTS (Linux kernel: 5.15.0-60-generic #66~20.04.1-Ubuntu SMP Wed Jan 25 09:41:30 UTC 2023)",
    "uid": "cfe45b2e21e043d9",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/HPE/results/dl385_q8_std-qaic-v1.8.3.7-aic100/bert-99/offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.8666333229796,
    "Accuracy_div_100": 0.90867,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/dl385_q8_std-qaic-v1.8.3.7-aic100/bert-99.9/offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "HPE",
    "Platform": "dl385_q8_std-qaic-v1.8.3.7-aic100",
    "Result": 2711.72,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "HPE ProLiant DL385 Gen10 Plus v2 (8x QAIC100 Standard)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Standard",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.8.3",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "AMD EPYC 7543 32-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5 LTS (Linux kernel: 5.15.0-60-generic #66~20.04.1-Ubuntu SMP Wed Jan 25 09:41:30 UTC 2023)",
    "uid": "595d219c547b4c40",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/HPE/results/dl385_q8_std-qaic-v1.8.3.7-aic100/bert-99.9/offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.53885196505269,
    "Accuracy_div_100": 0.90539,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/1-node-2S-SPR-PyTorch-INT8/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "HPE",
    "Platform": "1-node-2S-SPR-PyTorch-INT8",
    "Result": 1398.89,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "1-node-2S-SPR-PyTorch-INT8",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "PyTorch",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "ProLiant DL380a Gen11",
    "number_of_nodes": 2,
    "operating_system": "Red Hat Enterprise Linux 8.7",
    "uid": "539761eb3dc448cc",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/HPE/results/1-node-2S-SPR-PyTorch-INT8/bert-99/Offline",
    "version": "v3.0"
  }
]
