[
  {
    "Accuracy": 92.56578502333763,
    "Accuracy_div_100": 0.92566,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/CTuning/results/PCSPECIALIST_AMD_AM5_PC_with_Nvidia_RTX_4090-nvidia_original-gpu-tensorrt-vdefault-default_config/rnnt/singlestream",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "CTuning",
    "Platform": "PCSPECIALIST_AMD_AM5_PC_with_Nvidia_RTX_4090-nvidia_original-gpu-tensorrt-vdefault-default_config",
    "Result": 10.034956,
    "Result_Units": "Latency (ms)",
    "Scenario": "SingleStream",
    "SystemName": "PCSPECIALIST AMD AM5 PC (1x RTX 4090)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "NVIDIA GeForce RTX 4090",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Nvidia inference implementation with CM API, TensorRT v9.0.0",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": true,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD Ryzen 9 7950X 16-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.6.2. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04 (linux-6.5.0-14-generic-glibc2.31)",
    "uid": "f13ad54b742a4d84",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/CTuning/results/PCSPECIALIST_AMD_AM5_PC_with_Nvidia_RTX_4090-nvidia_original-gpu-tensorrt-vdefault-default_config/rnnt/singlestream",
    "version": "v4.0"
  },
  {
    "Accuracy": 92.56578502333763,
    "Accuracy_div_100": 0.92566,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/CTuning/results/PCSPECIALIST_AMD_AM5_PC_with_Nvidia_RTX_4090-nvidia_original-gpu-tensorrt-vdefault-default_config/rnnt/singlestream",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "CTuning",
    "Platform": "PCSPECIALIST_AMD_AM5_PC_with_Nvidia_RTX_4090-nvidia_original-gpu-tensorrt-vdefault-default_config",
    "Result": null,
    "Result_Power": 2409.652434760668,
    "Result_Units": "millijoules",
    "Scenario": "SingleStream",
    "SystemName": "PCSPECIALIST AMD AM5 PC (1x RTX 4090)",
    "SystemType": "edge",
    "Units": "millijoules",
    "accelerator_model_name": "NVIDIA GeForce RTX 4090",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Nvidia inference implementation with CM API, TensorRT v9.0.0",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": true,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD Ryzen 9 7950X 16-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.6.2. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04 (linux-6.5.0-14-generic-glibc2.31)",
    "uid": "03f40cc5e67c4b2c",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/CTuning/results/PCSPECIALIST_AMD_AM5_PC_with_Nvidia_RTX_4090-nvidia_original-gpu-tensorrt-vdefault-default_config/rnnt/singlestream",
    "version": "v4.0"
  },
  {
    "Accuracy": 92.56353018106384,
    "Accuracy_div_100": 0.92564,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XR8620_L4x1_MaxQ_TRT_MaxQ/rnnt/SingleStream",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Dell",
    "Platform": "XR8620_L4x1_MaxQ_TRT_MaxQ",
    "Result": 19.49433,
    "Result_Units": "Latency (ms)",
    "Scenario": "SingleStream",
    "SystemName": "Dell PowerEdge XR8620t (1x L4, MaxQ, TensorRT)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2,",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": true,
    "host_processor_core_count": 20,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6433N",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "uid": "f65a2948d47643f1",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Dell/results/XR8620_L4x1_MaxQ_TRT_MaxQ/rnnt/SingleStream",
    "version": "v4.0"
  },
  {
    "Accuracy": 92.56353018106384,
    "Accuracy_div_100": 0.92564,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XR8620_L4x1_MaxQ_TRT_MaxQ/rnnt/SingleStream",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Dell",
    "Platform": "XR8620_L4x1_MaxQ_TRT_MaxQ",
    "Result": null,
    "Result_Power": 3600.771535233179,
    "Result_Units": "millijoules",
    "Scenario": "SingleStream",
    "SystemName": "Dell PowerEdge XR8620t (1x L4, MaxQ, TensorRT)",
    "SystemType": "edge",
    "Units": "millijoules",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2,",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": true,
    "host_processor_core_count": 20,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6433N",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "uid": "06f8a067a59b4540",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/Dell/results/XR8620_L4x1_MaxQ_TRT_MaxQ/rnnt/SingleStream",
    "version": "v4.0"
  },
  {
    "Accuracy": 92.56578502333763,
    "Accuracy_div_100": 0.92566,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 0.4123989069949172,
    "Location": "closed/NVIDIA/results/Orin_NX_TRT_MaxQ/rnnt/SingleStream",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "NVIDIA",
    "Platform": "Orin_NX_TRT_MaxQ",
    "Result": 297.0874,
    "Result_Power": 2424.836688551953,
    "Result_Power_Units": "millijoules",
    "Result_Units": "Latency (ms)",
    "Scenario": "SingleStream",
    "SystemName": "NVIDIA Orin NX 16G (MaxQ, TensorRT)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "NVIDIA Orin NX 16G",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Jetpack 5.1.1, TensorRT 8.5.2, CUDA 11.4",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": true,
    "host_processor_core_count": 8,
    "host_processor_model_name": "8-core ARM Cortex-A78AE CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "NVIDIA Orin Nano Developer kit is used as the carrier board. GPU and both DLAs are used in resnet50 and Retinanet, in Offline scenario; WIFI module is physically removed.",
    "number_of_nodes": 1,
    "operating_system": "Jetson r35.3.1 L4T",
    "uid": "88e17a9459064f3c",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/NVIDIA/results/Orin_NX_TRT_MaxQ/rnnt/SingleStream",
    "version": "v3.1"
  },
  {
    "Accuracy": 92.57254955015897,
    "Accuracy_div_100": 0.92573,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 0.4340269347544872,
    "Location": "closed/CTuning/results/orin-nvidia_original-gpu-tensorrt-vdefault-default_config/rnnt/singlestream",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "CTuning",
    "Platform": "orin-nvidia_original-gpu-tensorrt-vdefault-default_config",
    "Result": 112.051448,
    "Result_Power": 2304.004475127016,
    "Result_Power_Units": "millijoules",
    "Result_Units": "Latency (ms)",
    "Scenario": "SingleStream",
    "SystemName": "Siliconhighway NVIDIA Jetson AGX Orin (non MaxN image)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "NVIDIA Jetson AGX Orin 32G",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Nvidia inference implementation with CM API, Jetpack 5.1.1 with TensorRT 8.5.2, cuDNN 8.6.0, CUDA 11.4.19",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": true,
    "host_processor_core_count": 4,
    "host_processor_model_name": "ARMv8 Processor rev 1 (v8l)",
    "host_processors_per_node": 3,
    "inferred": 0,
    "notes": "Powered by MLCommons CM automation language and CK playground. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04 (linux-5.10.104-tegra-glibc2.31)",
    "uid": "90d0313781824044",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/CTuning/results/orin-nvidia_original-gpu-tensorrt-vdefault-default_config/rnnt/singlestream",
    "version": "v3.1"
  },
  {
    "Accuracy": 92.54549144287357,
    "Accuracy_div_100": 0.92545,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 0.17772806502293273,
    "Location": "closed/CTuning/results/amd_zen4_workstation-nvidia_original-gpu-tensorrt-vdefault-default_config/rnnt/singlestream",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "CTuning",
    "Platform": "amd_zen4_workstation-nvidia_original-gpu-tensorrt-vdefault-default_config",
    "Result": 23.224466,
    "Result_Power": 5626.5733826054275,
    "Result_Power_Units": "millijoules",
    "Result_Units": "Latency (ms)",
    "Scenario": "SingleStream",
    "SystemName": "PCSPECIALIST AMD AM5 PC with Nvidia RTX 4090",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "NVIDIA GeForce RTX 4090 (Ada Lovelace)",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Nvidia inference implementation with CM API, TensorRT v8.6.1.6",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": true,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD Ryzen 9 7950X 16-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Powered by MLCommons CM automation language and CK playground. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-5.19.0-46-generic-glibc2.35)",
    "uid": "d15e397231734049",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/CTuning/results/amd_zen4_workstation-nvidia_original-gpu-tensorrt-vdefault-default_config/rnnt/singlestream",
    "version": "v3.1"
  },
  {
    "Accuracy": 92.57480439243275,
    "Accuracy_div_100": 0.92575,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 0.38513007280369305,
    "Location": "closed/CTuning/results/nvidia_orin_64k_default_jetpack-nvidia_original-gpu-tensorrt-vdefault-default_config/rnnt/singlestream",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "CTuning",
    "Platform": "nvidia_orin_64k_default_jetpack-nvidia_original-gpu-tensorrt-vdefault-default_config",
    "Result": 94.808318,
    "Result_Power": 2596.5253575763118,
    "Result_Power_Units": "millijoules",
    "Result_Units": "Latency (ms)",
    "Scenario": "SingleStream",
    "SystemName": "Siliconhighway NVIDIA Jetson AGX Orin (64K page size)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "NVIDIA Jetson AGX Orin 32G",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Jetpack 5.1.1 with TensorRT 8.5.2, cuDNN 8.6.0, CUDA 11.4.19",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": true,
    "host_processor_core_count": 4,
    "host_processor_model_name": "ARMv8 Processor rev 1 (v8l)",
    "host_processors_per_node": 3,
    "inferred": 0,
    "notes": "Powered by MLCommons CM automation language and CK playground. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04 (linux-5.10.104-tegra-glibc2.31)",
    "uid": "0e717f2566104a68",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/CTuning/results/nvidia_orin_64k_default_jetpack-nvidia_original-gpu-tensorrt-vdefault-default_config/rnnt/singlestream",
    "version": "v3.1"
  },
  {
    "Accuracy": 92.57480439243275,
    "Accuracy_div_100": 0.92575,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 0.38403011204607984,
    "Location": "closed/CTuning/results/nvidia_orin_maxn_pagesize.4k-nvidia_original-gpu-tensorrt-vdefault-default_config/rnnt/singlestream",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "CTuning",
    "Platform": "nvidia_orin_maxn_pagesize.4k-nvidia_original-gpu-tensorrt-vdefault-default_config",
    "Result": 94.791138,
    "Result_Power": 2603.9624722969897,
    "Result_Power_Units": "millijoules",
    "Result_Units": "Latency (ms)",
    "Scenario": "SingleStream",
    "SystemName": "Siliconhighway NVIDIA Jetson AGX Orin (4K page size)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "NVIDIA Jetson AGX Orin 32G",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Jetpack 5.1.1 with TensorRT 8.5.2, cuDNN 8.6.0, CUDA 11.4.19",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": true,
    "host_processor_core_count": 4,
    "host_processor_model_name": "ARMv8 Processor rev 1 (v8l)",
    "host_processors_per_node": 3,
    "inferred": 0,
    "notes": "Powered by MLCommons CM automation language and CK playground. ",
    "number_of_nodes": 1,
    "operating_system": "Jetson Linux 35.3.1, Ubuntu 20.04 (linux-5.10.104-tegra-glibc2.31)",
    "uid": "8954d21c80b64fe9",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/CTuning/results/nvidia_orin_maxn_pagesize.4k-nvidia_original-gpu-tensorrt-vdefault-default_config/rnnt/singlestream",
    "version": "v3.1"
  },
  {
    "Accuracy": 92.56127533879005,
    "Accuracy_div_100": 0.92561,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 0.2459912236198203,
    "Location": "closed/Dell/results/XR5610_L4x1_TRT_MaxQ/rnnt/SingleStream",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Dell",
    "Platform": "XR5610_L4x1_TRT_MaxQ",
    "Result": 19.216151,
    "Result_Power": 4065.1856813619543,
    "Result_Power_Units": "millijoules",
    "Result_Units": "Latency (ms)",
    "Scenario": "SingleStream",
    "SystemName": "Dell PowerEdge XR5610 (1x L4, MaxQ, TensorRT)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2,",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": true,
    "host_processor_core_count": 20,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 5423N CPU @ 2.10GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "CentOS 8.2",
    "uid": "3be22042d4a34689",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Dell/results/XR5610_L4x1_TRT_MaxQ/rnnt/SingleStream",
    "version": "v3.1"
  },
  {
    "Accuracy": 92.5545108119687,
    "Accuracy_div_100": 0.92555,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 0.28618605866551006,
    "Location": "closed/NVIDIA/results/Xavier_NX_TRT_MaxQ/rnnt/SingleStream",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "NVIDIA",
    "Platform": "Xavier_NX_TRT_MaxQ",
    "Result": 388.160791,
    "Result_Power": 3494.2303082931967,
    "Result_Power_Units": "millijoules",
    "Result_Units": "Latency (ms)",
    "Scenario": "SingleStream",
    "SystemName": "Auvidea JNX30 Xavier NX (MaxQ, TensorRT)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "NVIDIA Xavier NX",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "JetPack 4.6, TensorRT 8.0.1, CUDA 10.2",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 6,
    "host_processor_model_name": "NVIDIA Carmel (ARMv8.2)",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "GPU and both DLAs are used in resnet50, ssd-mobilenet, and ssd-resnet34, in Offline scenario",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04",
    "uid": "d2c6254a89ff43d4",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/Xavier_NX_TRT_MaxQ/rnnt/SingleStream",
    "version": "v2.0"
  },
  {
    "Accuracy": 92.5680398656114,
    "Accuracy_div_100": 0.92568,
    "Availability": "preview",
    "Division": "closed",
    "Inference_per_Joule": 0.3560154311566588,
    "Location": "closed/NVIDIA/results/Orin_TRT_MaxQ/rnnt/SingleStream",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "NVIDIA",
    "Platform": "Orin_TRT_MaxQ",
    "Result": 158.651885,
    "Result_Power": 2808.8670110480866,
    "Result_Power_Units": "millijoules",
    "Result_Units": "Latency (ms)",
    "Scenario": "SingleStream",
    "SystemName": "NVIDIA Orin (MaxQ, TensorRT)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "NVIDIA Orin",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "JetPack 5.0, TensorRT 8.4.0, CUDA 11.4",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 12,
    "host_processor_model_name": "12-core Cortex-A78 CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "GPU and both DLAs are used in resnet50, ssd-mobilenet, and ssd-resnet34, in Offline scenario. DLA loadable for resnet50 in offline scenario generated using preview compiler. Private harness code to run loadables. git hash: f23b7273986f02d3136673e5d18558c9a9d63799",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04",
    "uid": "1cfb1763dc6c47f3",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/Orin_TRT_MaxQ/rnnt/SingleStream",
    "version": "v2.0"
  },
  {
    "Accuracy": 92.56353018106384,
    "Accuracy_div_100": 0.92564,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 0.18219492052672243,
    "Location": "closed/Dell/results/XE2420_A30x1_TRT_MaxQ/rnnt/SingleStream",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Dell",
    "Platform": "XE2420_A30x1_TRT_MaxQ",
    "Result": 33.311964,
    "Result_Power": 5488.627219183812,
    "Result_Power_Units": "millijoules",
    "Result_Units": "Latency (ms)",
    "Scenario": "SingleStream",
    "SystemName": "Dell PowerEdge XE2420 (1x A30, MaxQ, TensorRT)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 16,
    "host_processor_model_name": "Intel(R) Xeon(R) Silver 4216 CPU @ 2.10GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "1e5b5ef5fdeb4717",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Dell/results/XE2420_A30x1_TRT_MaxQ/rnnt/SingleStream",
    "version": "v2.0"
  },
  {
    "Accuracy": 92.5567656542425,
    "Accuracy_div_100": 0.92557,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 0.11473797905771337,
    "Location": "closed/Inspur/results/NE5260M5_A100-PCIe-80GBx2_TRT_MaxQ/rnnt/SingleStream",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Inspur",
    "Platform": "NE5260M5_A100-PCIe-80GBx2_TRT_MaxQ",
    "Result": 25.38322,
    "Result_Power": 8715.509966381738,
    "Result_Power_Units": "millijoules",
    "Result_Units": "Latency (ms)",
    "Scenario": "SingleStream",
    "SystemName": "NE5260M5 (2x A100-PCIe-80GB, TensorRT, MaxQ)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 28,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6258R",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "3194c9981f624889",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Inspur/results/NE5260M5_A100-PCIe-80GBx2_TRT_MaxQ/rnnt/SingleStream",
    "version": "v2.0"
  },
  {
    "Accuracy": 92.5680398656114,
    "Accuracy_div_100": 0.92568,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 0.47661191202005543,
    "Location": "closed/NVIDIA/results/Orin_TRT_MaxQ/rnnt/SingleStream",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "NVIDIA",
    "Platform": "Orin_TRT_MaxQ",
    "Result": 101.519728,
    "Result_Power": 2098.1431113662993,
    "Result_Power_Units": "millijoules",
    "Result_Units": "Latency (ms)",
    "Scenario": "SingleStream",
    "SystemName": "NVIDIA Orin (MaxQ, TensorRT)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "NVIDIA Orin",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "22.08 Jetson CUDA-X AI Developer Preview, TensorRT 8.5.0, CUDA 11.4",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": true,
    "host_processor_core_count": 12,
    "host_processor_model_name": "12-core Cortex-A78 CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "GPU and both DLAs are used in resnet50, in Offline scenario",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04",
    "uid": "9960a2fd2ab44842",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/NVIDIA/results/Orin_TRT_MaxQ/rnnt/SingleStream",
    "version": "v2.1"
  },
  {
    "Accuracy": 92.56578502333763,
    "Accuracy_div_100": 0.92566,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 0.5816709276550117,
    "Location": "closed/NVIDIA/results/Orin_TRT_MaxQ/rnnt/SingleStream",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "NVIDIA",
    "Platform": "Orin_TRT_MaxQ",
    "Result": 115.624383,
    "Result_Power": 1719.1851138778227,
    "Result_Power_Units": "millijoules",
    "Result_Units": "Latency (ms)",
    "Scenario": "SingleStream",
    "SystemName": "NVIDIA Jetson AGX Orin (MaxQ, TensorRT)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "NVIDIA Jetson AGX Orin",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "23.02 Jetson CUDA-X AI Developer Preview, TensorRT 8.5.2, CUDA 11.4",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": true,
    "host_processor_core_count": 12,
    "host_processor_model_name": "12-core ARM Cortex-A78AE CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "GPU and both DLAs are used in resnet50 and Retinanet, in Offline scenario",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04",
    "uid": "d101044d5aa0460d",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/NVIDIA/results/Orin_TRT_MaxQ/rnnt/SingleStream",
    "version": "v3.0"
  },
  {
    "Accuracy": 92.56127533879005,
    "Accuracy_div_100": 0.92561,
    "Availability": "preview",
    "Division": "closed",
    "Inference_per_Joule": 0.05033111728200821,
    "Location": "closed/Dell/results/XR5610_L4x1_TRT_MaxQ/rnnt/SingleStream",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Dell",
    "Platform": "XR5610_L4x1_TRT_MaxQ",
    "Result": 49.795234,
    "Result_Power": 19868.424426124722,
    "Result_Power_Units": "millijoules",
    "Result_Units": "Latency (ms)",
    "Scenario": "SingleStream",
    "SystemName": "Dell PowerEdge XR5610 (1x L4, MaxQ, TensorRT)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": true,
    "host_processor_core_count": 20,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 5423N CPU @ 2.10GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "CentOS 8.2",
    "uid": "770502806a964224",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Dell/results/XR5610_L4x1_TRT_MaxQ/rnnt/SingleStream",
    "version": "v3.0"
  },
  {
    "Accuracy": 92.57029470788518,
    "Accuracy_div_100": 0.9257,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 0.0448548309703702,
    "Location": "closed/Dell/results/XR4520c_MaxQ_A2x1_TRT_MaxQ/rnnt/SingleStream",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Dell",
    "Platform": "XR4520c_MaxQ_A2x1_TRT_MaxQ",
    "Result": 177.246958,
    "Result_Power": 22294.142645651056,
    "Result_Power_Units": "millijoules",
    "Result_Units": "Latency (ms)",
    "Scenario": "SingleStream",
    "SystemName": "Dell PowerEdge XR4520c (1x A2, MaxQ, TensorRT)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "NVIDIA A2",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": true,
    "host_processor_core_count": 16,
    "host_processor_model_name": "Intel(R) Xeon(R) D-2776NT CPU @ 2.10GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "32ae4f48ac954e7d",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Dell/results/XR4520c_MaxQ_A2x1_TRT_MaxQ/rnnt/SingleStream",
    "version": "v3.0"
  },
  {
    "Accuracy": 92.57029470788518,
    "Accuracy_div_100": 0.9257,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 0.39486459985847583,
    "Location": "closed/cTuning/results/amd_zen4_workstation-nvidia_original-gpu-tensorrt-v8.5.2.2-default_config/rnnt/singlestream",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "cTuning",
    "Platform": "amd_zen4_workstation-nvidia_original-gpu-tensorrt-v8.5.2.2-default_config",
    "Result": 9.993138,
    "Result_Power": 2532.5136777477946,
    "Result_Power_Units": "millijoules",
    "Result_Units": "Latency (ms)",
    "Scenario": "SingleStream",
    "SystemName": "AMD Ryzen Zen4 workstation with Nvidia RTX 4090",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "NVIDIA GeForce RTX 4090 (Ada Lovelace)",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT v8.5.2.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": true,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD Ryzen 9 7950X 16-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Result donated by GATE Overflow Educational Foundation. Powered by MLCommons Collective Mind framework (CK2). ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-5.19.0-32-generic-glibc2.35)",
    "uid": "60f1d4837d204827",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/cTuning/results/amd_zen4_workstation-nvidia_original-gpu-tensorrt-v8.5.2.2-default_config/rnnt/singlestream",
    "version": "v3.0"
  }
]
