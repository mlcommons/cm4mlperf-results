[
  {
    "Accuracy": 90.87487229720105,
    "Accuracy_div_100": 0.90875,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/arjun_spr-reference-cpu-pytorch-v2.1.0-default_config/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "CTuning",
    "Platform": "arjun_spr-reference-cpu-pytorch-v2.1.0-default_config",
    "Result": 145.36,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Network SUT GATE Overflow Intel Sapphire Rapids (1x RTX 4090)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GeForce RTX 4090",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "MLCommons python reference implementation with CM API, Onnxruntime v1.16.3",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.6.2. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 23.04 (linux-6.2.0-39-generic-glibc2.37)",
    "uid": "62a0c11b72af45d3",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/arjun_spr-reference-cpu-pytorch-v2.1.0-default_config/bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 42.0595,
    "Accuracy_div_100": 0.42059,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/GATE_Overflow_Intel_Sapphire_Rapids-reference-gpu-pytorch-v2.1.1-default_config/llama2-70b-99/offline",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "CTuning",
    "Platform": "GATE_Overflow_Intel_Sapphire_Rapids-reference-gpu-pytorch-v2.1.1-default_config",
    "Result": 199.333,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "GATEOverflow Intel Sapphire Rapids (2x RTX 4090)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GeForce RTX 4090",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "MLCommons python reference implementation with CM API, Pytorch v2.1.1",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.6.2. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 23.04 (linux-6.2.0-39-generic-glibc2.37)",
    "uid": "3994518c59364056",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/GATE_Overflow_Intel_Sapphire_Rapids-reference-gpu-pytorch-v2.1.1-default_config/llama2-70b-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.87487229720105,
    "Accuracy_div_100": 0.90875,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/PCSPECIALIST_AMD_AM5_PC_with_Nvidia_RTX_4090-reference-cpu-pytorch-v2.2.0-network_loadgen/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "CTuning",
    "Platform": "PCSPECIALIST_AMD_AM5_PC_with_Nvidia_RTX_4090-reference-cpu-pytorch-v2.2.0-network_loadgen",
    "Result": 3.0418,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Network SUT PCSPECIALIST AMD AM5 PC",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "MLCommons python reference implementation with CM API, Pytorch v2.2.0",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD Ryzen 9 7950X 16-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.5.0-14-generic-glibc2.35)",
    "uid": "1874a96ec6d94e39",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/PCSPECIALIST_AMD_AM5_PC_with_Nvidia_RTX_4090-reference-cpu-pytorch-v2.2.0-network_loadgen/bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.87487229720105,
    "Accuracy_div_100": 0.90875,
    "Availability": "available",
    "Division": "open",
    "Location": "open/CTuning/results/PCSPECIALIST_AMD_AM5_PC_with_Nvidia_RTX_4090-reference-gpu-onnxruntime-v1.16.3-network_loadgen/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "CTuning",
    "Platform": "PCSPECIALIST_AMD_AM5_PC_with_Nvidia_RTX_4090-reference-gpu-onnxruntime-v1.16.3-network_loadgen",
    "Result": 184.308,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Network SUT PCSPECIALIST AMD AM5 PC (1x RTX 4090)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA GeForce RTX 4090",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "MLCommons python reference implementation with CM API, Onnxruntime v1.16.3",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD Ryzen 9 7950X 16-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v2.0.0. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-6.5.0-14-generic-glibc2.35)",
    "uid": "ddfff81d6e3b46e0",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/CTuning/results/PCSPECIALIST_AMD_AM5_PC_with_Nvidia_RTX_4090-reference-gpu-onnxruntime-v1.16.3-network_loadgen/bert-99/offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.97056894987658,
    "Accuracy_div_100": 0.90971,
    "Availability": "available",
    "Division": "open",
    "Location": "open/HPE/results/HPE_Cray_XD670_H100_SXM_80GBx8_TRT_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "HPE",
    "Platform": "HPE_Cray_XD670_H100_SXM_80GBx8_TRT_TRT",
    "Result": 62986.7,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "HPE Cray XD670 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.3",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.3",
    "uid": "601c691553c94616",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/HPE/results/HPE_Cray_XD670_H100_SXM_80GBx8_TRT_TRT/bert-99.9/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 43.0675,
    "Accuracy_div_100": 0.43068,
    "Availability": "available",
    "Division": "open",
    "Location": "open/HPE/results/HPE_Cray_XD670_H100_SXM_80GBx8_TRT_TRT/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "HPE",
    "Platform": "HPE_Cray_XD670_H100_SXM_80GBx8_TRT_TRT",
    "Result": 223.211,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "HPE Cray XD670 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.3",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.3",
    "uid": "340cedea4c894fde",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/HPE/results/HPE_Cray_XD670_H100_SXM_80GBx8_TRT_TRT/gptj-99/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 43.0675,
    "Accuracy_div_100": 0.43068,
    "Availability": "available",
    "Division": "open",
    "Location": "open/HPE/results/HPE_Cray_XD670_H100_SXM_80GBx8_TRT_TRT/gptj-99.9/Offline",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "HPE",
    "Platform": "HPE_Cray_XD670_H100_SXM_80GBx8_TRT_TRT",
    "Result": 223.951,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "HPE Cray XD670 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.3",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.3",
    "uid": "78da5e8cedec4d52",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/HPE/results/HPE_Cray_XD670_H100_SXM_80GBx8_TRT_TRT/gptj-99.9/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.35676151551918,
    "Accuracy_div_100": 0.90357,
    "Availability": "available",
    "Division": "open",
    "Location": "open/HPE/results/HPE_ProLiant_DL380a_H100_PCIe_80GBx4_TRT_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "HPE",
    "Platform": "HPE_ProLiant_DL380a_H100_PCIe_80GBx4_TRT_TRT",
    "Result": 22620.8,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "HPE ProLiant DL380a Gen11 (4x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "uid": "84b73827e4294e55",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/HPE/results/HPE_ProLiant_DL380a_H100_PCIe_80GBx4_TRT_TRT/bert-99/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.97056894987658,
    "Accuracy_div_100": 0.90971,
    "Availability": "available",
    "Division": "open",
    "Location": "open/HPE/results/HPE_ProLiant_DL380a_H100_PCIe_80GBx4_TRT_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "HPE",
    "Platform": "HPE_ProLiant_DL380a_H100_PCIe_80GBx4_TRT_TRT",
    "Result": 19512.3,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "HPE ProLiant DL380a Gen11 (4x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.3.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "uid": "c1bd180b82a94d55",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/HPE/results/HPE_ProLiant_DL380a_H100_PCIe_80GBx4_TRT_TRT/bert-99.9/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.89637138715483,
    "Accuracy_div_100": 0.90896,
    "Availability": "available",
    "Division": "open",
    "Location": "open/HPE/results/HPE_ProLiant_DL380a_L40S_PCIe_48GBx4_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "HPE",
    "Platform": "HPE_ProLiant_DL380a_L40S_PCIe_48GBx4_TRT",
    "Result": 6874.3,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "HPE ProLiant DL380a Gen11 (4x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 60,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8580",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "uid": "c5ebc6b33bc84aa6",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/HPE/results/HPE_ProLiant_DL380a_L40S_PCIe_48GBx4_TRT/bert-99.9/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 43.0936,
    "Accuracy_div_100": 0.43094,
    "Availability": "available",
    "Division": "open",
    "Location": "open/HPE/results/HPE_ProLiant_DL380a_L40S_PCIe_48GBx4_TRT/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "HPE",
    "Platform": "HPE_ProLiant_DL380a_L40S_PCIe_48GBx4_TRT",
    "Result": 49.8357,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "HPE ProLiant DL380a Gen11 (4x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 60,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8580",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "uid": "245df76604e843a8",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/HPE/results/HPE_ProLiant_DL380a_L40S_PCIe_48GBx4_TRT/gptj-99/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 43.0936,
    "Accuracy_div_100": 0.43094,
    "Availability": "available",
    "Division": "open",
    "Location": "open/HPE/results/HPE_ProLiant_DL380a_L40S_PCIe_48GBx4_TRT/gptj-99.9/Offline",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "HPE",
    "Platform": "HPE_ProLiant_DL380a_L40S_PCIe_48GBx4_TRT",
    "Result": 49.8357,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "HPE ProLiant DL380a Gen11 (4x L40S, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L40S",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 60,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8580",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.3",
    "uid": "2049d05162fb4564",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/HPE/results/HPE_ProLiant_DL380a_L40S_PCIe_48GBx4_TRT/gptj-99.9/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 38.7559,
    "Accuracy_div_100": 0.38756,
    "Availability": "available",
    "Division": "open",
    "Location": "open/JuniperNetworks/results/A100-2N-80GB/llama2-70b-99/Offline",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "JuniperNetworks",
    "Platform": "A100-2N-80GB",
    "Result": 3659.41,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "A100-2N-80GB",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "A100-SXM-80GB",
    "accelerators_per_node": 16,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.2.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 128,
    "host_processor_model_name": "AMD EPYC 7763 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 2,
    "operating_system": "Ubuntu 22.04.3",
    "uid": "5f8816fce2db4c48",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/JuniperNetworks/results/A100-2N-80GB/llama2-70b-99/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 38.5151,
    "Accuracy_div_100": 0.38515,
    "Availability": "available",
    "Division": "open",
    "Location": "open/JuniperNetworks/results/H100-2N-80GB/llama2-70b-99/Offline",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "JuniperNetworks",
    "Platform": "H100-2N-80GB",
    "Result": 6235.72,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "H100-2N-80GB",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "H100-SXM-80GB",
    "accelerators_per_node": 16,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.2.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 112,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480CL",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 2,
    "operating_system": "Ubuntu 22.04.3",
    "uid": "19b25c388b2d4228",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/JuniperNetworks/results/H100-2N-80GB/llama2-70b-99/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 42.3672,
    "Accuracy_div_100": 0.42367,
    "Availability": "available",
    "Division": "open",
    "Location": "open/NVIDIA/results/DGX-H100_H100-SXM-80GBx1_TRT_PRUNED/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "NVIDIA",
    "Platform": "DGX-H100_H100-SXM-80GBx1_TRT_PRUNED",
    "Result": 43.3445,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX H100 (1x H100-SXM-80GB)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "2b1216c067b34eb9",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/NVIDIA/results/DGX-H100_H100-SXM-80GBx1_TRT_PRUNED/gptj-99/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 44.4855,
    "Accuracy_div_100": 0.44486,
    "Availability": "available",
    "Division": "open",
    "Location": "open/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT_SPARSE/llama2-70b-99/Offline",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "NVIDIA",
    "Platform": "DGX-H100_H100-SXM-80GBx8_TRT_SPARSE",
    "Result": 28931.9,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX H100 (1x H100-SXM-80GB)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "dcad1ef6652d4680",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT_SPARSE/llama2-70b-99/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 44.4855,
    "Accuracy_div_100": 0.44486,
    "Availability": "available",
    "Division": "open",
    "Location": "open/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT_SPARSE/llama2-70b-99.9/Offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "NVIDIA",
    "Platform": "DGX-H100_H100-SXM-80GBx8_TRT_SPARSE",
    "Result": 28931.9,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX H100 (1x H100-SXM-80GB)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "3b3388e53e0b4109",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT_SPARSE/llama2-70b-99.9/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 43.0965,
    "Accuracy_div_100": 0.43096,
    "Availability": "available",
    "Division": "open",
    "Location": "open/RedHat/results/DGX-RedHat-OpenShift/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "RedHat",
    "Platform": "DGX-RedHat-OpenShift",
    "Result": 138.338,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX H100 (8xH100-SXM-80GB, Red Hat OpenShift AI, vLLM(fp16))",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 112,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480CL",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "NVIDIA H100-SXM-80GB. Red Hat OpenShift Container Platform 4.14 + OpenShift AI",
    "number_of_nodes": 1,
    "operating_system": "Red Hat Enterprise Linux CoreOS release 4.14",
    "uid": "594f522597da405a",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/RedHat/results/DGX-RedHat-OpenShift/gptj-99/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 43.0965,
    "Accuracy_div_100": 0.43096,
    "Availability": "available",
    "Division": "open",
    "Location": "open/RedHat/results/DGX-RedHat-OpenShift/gptj-99.9/Offline",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "RedHat",
    "Platform": "DGX-RedHat-OpenShift",
    "Result": 138.338,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX H100 (8xH100-SXM-80GB, Red Hat OpenShift AI, vLLM(fp16))",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 112,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480CL",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "NVIDIA H100-SXM-80GB. Red Hat OpenShift Container Platform 4.14 + OpenShift AI",
    "number_of_nodes": 1,
    "operating_system": "Red Hat Enterprise Linux CoreOS release 4.14",
    "uid": "31908750ea034411",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/RedHat/results/DGX-RedHat-OpenShift/gptj-99.9/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 44.4162,
    "Accuracy_div_100": 0.44416,
    "Availability": "available",
    "Division": "open",
    "Location": "open/RedHat-Supermicro/results/AS-4125GS-TNRT-RedHat-OpenShift-AI/llama2-70b-99/Offline",
    "MlperfModel": "llama2-70b-99",
    "Model": "llama2-70b-99",
    "Organization": "RedHat-Supermicro",
    "Platform": "AS-4125GS-TNRT-RedHat-OpenShift-AI",
    "Result": 3038.78,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AS-4125GS-TNRT(8xH100-PCIe-80GB, Red Hat OpenShift AI, vLLM(fp16))",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 9554 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "NVIDIA H100-PCIe-80GB. Red Hat OpenShift Container Platform 4.14 + OpenShift AI",
    "number_of_nodes": 1,
    "operating_system": "Red Hat Enterprise Linux CoreOS release 4.14",
    "uid": "532cc6fa1f394da8",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/RedHat-Supermicro/results/AS-4125GS-TNRT-RedHat-OpenShift-AI/llama2-70b-99/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 44.4162,
    "Accuracy_div_100": 0.44416,
    "Availability": "available",
    "Division": "open",
    "Location": "open/RedHat-Supermicro/results/AS-4125GS-TNRT-RedHat-OpenShift-AI/llama2-70b-99.9/Offline",
    "MlperfModel": "llama2-70b-99.9",
    "Model": "llama2-70b-99.9",
    "Organization": "RedHat-Supermicro",
    "Platform": "AS-4125GS-TNRT-RedHat-OpenShift-AI",
    "Result": 3038.78,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AS-4125GS-TNRT(8xH100-PCIe-80GB, Red Hat OpenShift AI, vLLM(fp16))",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 9554 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "NVIDIA H100-PCIe-80GB. Red Hat OpenShift Container Platform 4.14 + OpenShift AI",
    "number_of_nodes": 1,
    "operating_system": "Red Hat Enterprise Linux CoreOS release 4.14",
    "uid": "bae52634f430445d",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/open/RedHat-Supermicro/results/AS-4125GS-TNRT-RedHat-OpenShift-AI/llama2-70b-99.9/Offline",
    "version": "v4.0"
  },
  {
    "Accuracy": 42.9603,
    "Accuracy_div_100": 0.4296,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Moffett/results/Moffett_S30x8_Inspur/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Moffett",
    "Platform": "Moffett_S30x8_Inspur",
    "Result": 170.586,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Inspur NF5468M6 (8x SparseOne S30, PCIe/FHFL, Moffett-SDK)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "MOFFETT S30-PCIe/FHFL-60GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "Moffett SDK",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 80,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8380 CPU @ 2.30GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.5 LTS",
    "uid": "13e0a3ab44e24bd4",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/open/Moffett/results/Moffett_S30x8_Inspur/gptj-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 42.9604,
    "Accuracy_div_100": 0.4296,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Moffett/results/Moffett_S30_H3C/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Moffett",
    "Platform": "Moffett_S30_H3C",
    "Result": 23.2809,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "H3C R5300 G5 (1x SparseOne S30, PCIe/FHFL, Moffett-SDK)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "MOFFETT S30-PCIe/FHFL-60GB",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Moffett SDK",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 112,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6348",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.5 LTS",
    "uid": "d952c9c5762641b5",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/open/Moffett/results/Moffett_S30_H3C/gptj-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 42.9604,
    "Accuracy_div_100": 0.4296,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Moffett/results/Moffett_S30x4_H3C/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Moffett",
    "Platform": "Moffett_S30x4_H3C",
    "Result": 91.574,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "H3C R5300 G5 (4x SparseOne S30, PCIe/FHFL, Moffett-SDK)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "MOFFETT S30-PCIe/FHFL-60GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "Moffett SDK",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 112,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6348",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.5 LTS",
    "uid": "a29aa195339a4c8b",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/open/Moffett/results/Moffett_S30x4_H3C/gptj-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 42.9177,
    "Accuracy_div_100": 0.42918,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Supermicro/results/1-node-4S-SPR-PyTorch-INT8/gptj-99/Offline",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "Supermicro",
    "Platform": "1-node-4S-SPR-PyTorch-INT8",
    "Result": 2.81426,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "1-node-4S-SPR-PyTorch-INT8",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "PyTorch",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 4,
    "inferred": 0,
    "notes": "N/A",
    "number_of_nodes": 1,
    "operating_system": "CentOS Stream 8",
    "uid": "7ed3bb418af044cf",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/open/Supermicro/results/1-node-4S-SPR-PyTorch-INT8/gptj-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.18328497411034,
    "Accuracy_div_100": 0.90183,
    "Availability": "rdi",
    "Division": "open",
    "Location": "open/NVIDIA/results/L4x1_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "NVIDIA",
    "Platform": "L4x1_TRT",
    "Result": 4609.04,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA L4 (1x L4, TensorRT)",
    "SystemType": "datacenter,edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 7313P 16-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "052c17c80c2d4dc2",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/open/NVIDIA/results/L4x1_TRT/bert-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.79625788222037,
    "Accuracy_div_100": 0.90796,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Intel/results/1-node-2S-SPR-Neural_Engine-INT8/bert-99.9_MiniLM/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9_MiniLM",
    "Organization": "Intel",
    "Platform": "1-node-2S-SPR-Neural_Engine-INT8",
    "Result": 6543.62,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "1-node-2S-SPR-PyTorch-INT8",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "PyTorch",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54Q-2U. N/A",
    "number_of_nodes": 1,
    "operating_system": "CentOS Stream 8",
    "uid": "b6d1922156774da4",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/open/Intel/results/1-node-2S-SPR-Neural_Engine-INT8/bert-99.9_MiniLM/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 89.90716435557265,
    "Accuracy_div_100": 0.89907,
    "Availability": "rdi",
    "Division": "open",
    "Location": "open/Deci/results/aws-c6i.16xlarge-openvino/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Deci",
    "Platform": "aws-c6i.16xlarge-openvino",
    "Result": 120.51,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Amazon EC2 (c6i.16xlarge)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "OpenVINO",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8375C CPU @ 2.90GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.5 LTS",
    "uid": "8cb2aa13102c4400",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/open/Deci/results/aws-c6i.16xlarge-openvino/bert-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 91.03472601136613,
    "Accuracy_div_100": 0.91035,
    "Availability": "rdi",
    "Division": "open",
    "Location": "open/Deci/results/aws-c6i.16xlarge-openvino/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Deci",
    "Platform": "aws-c6i.16xlarge-openvino",
    "Result": 91.4175,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Amazon EC2 (c6i.16xlarge)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "OpenVINO",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8375C CPU @ 2.90GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.5 LTS",
    "uid": "a5d59afdfe91422e",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/open/Deci/results/aws-c6i.16xlarge-openvino/bert-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 89.90716435557265,
    "Accuracy_div_100": 0.89907,
    "Availability": "rdi",
    "Division": "open",
    "Location": "open/Deci/results/aws-m5dn.8xlarge-openvino/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Deci",
    "Platform": "aws-m5dn.8xlarge-openvino",
    "Result": 66.6036,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Amazon EC2 (m5dn.8xlarge)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "OpenVINO",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8259CL CPU @ 2.50GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.5 LTS",
    "uid": "e05696175f9f4282",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/open/Deci/results/aws-m5dn.8xlarge-openvino/bert-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 91.03472601136613,
    "Accuracy_div_100": 0.91035,
    "Availability": "rdi",
    "Division": "open",
    "Location": "open/Deci/results/aws-m5dn.8xlarge-openvino/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Deci",
    "Platform": "aws-m5dn.8xlarge-openvino",
    "Result": 48.7853,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Amazon EC2 (m5dn.8xlarge)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "OpenVINO",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8259CL CPU @ 2.50GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.5 LTS",
    "uid": "a723c1b493484777",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/open/Deci/results/aws-m5dn.8xlarge-openvino/bert-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.38529083707651,
    "Accuracy_div_100": 0.90385,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Azure/results/ND96asr_v4_TRT_Triton/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Azure",
    "Platform": "ND96asr_v4_TRT_Triton",
    "Result": 27625,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "ND96asr_v4 (8x A100-SXM-40GB, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-40GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 7V12 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.6",
    "uid": "e2b283d2b7974339",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/open/Azure/results/ND96asr_v4_TRT_Triton/bert-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.86087496792462,
    "Accuracy_div_100": 0.90861,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Azure/results/ND96asr_v4_TRT_Triton/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Azure",
    "Platform": "ND96asr_v4_TRT_Triton",
    "Result": 13928.3,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "ND96asr_v4 (8x A100-SXM-40GB, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-40GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 7V12 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.6",
    "uid": "2335819c7fae4936",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/open/Azure/results/ND96asr_v4_TRT_Triton/bert-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.38529083707651,
    "Accuracy_div_100": 0.90385,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Azure/results/ND96asr_v4_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Azure",
    "Platform": "ND96asr_v4_TRT",
    "Result": 27688.7,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "ND96asr_v4 (8x A100-SXM-40GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-40GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 7V12 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.6",
    "uid": "e5e4af10ec634291",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/open/Azure/results/ND96asr_v4_TRT/bert-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.86087496792462,
    "Accuracy_div_100": 0.90861,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Azure/results/ND96asr_v4_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Azure",
    "Platform": "ND96asr_v4_TRT",
    "Result": 13802.1,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "ND96asr_v4 (8x A100-SXM-40GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-40GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 7V12 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.6",
    "uid": "7c302968a56146b5",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/open/Azure/results/ND96asr_v4_TRT/bert-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 90.8575190748761,
    "Accuracy_div_100": 0.90858,
    "Availability": "preview",
    "Division": "open",
    "Location": "open/Moffett/results/Moffett_S10_DELL/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Moffett",
    "Platform": "Moffett_S10_DELL",
    "Result": 2535.96,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "DELL-R750 (1x SparseOne S10, PCIe/FHFL, Moffett-SDK)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "MOFFETT S10-PCIe/FHFL-40GB",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Moffett SDK",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6326 CPU @ 2.90GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.5 LTS",
    "uid": "4f170c9cbfd54b40",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/open/Moffett/results/Moffett_S10_DELL/bert-99.9/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 90.8575190748761,
    "Accuracy_div_100": 0.90858,
    "Availability": "preview",
    "Division": "open",
    "Location": "open/Moffett/results/Moffett_S30_DELL/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Moffett",
    "Platform": "Moffett_S30_DELL",
    "Result": 3836.89,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "DELL-R750 (1x SparseOne S30, PCIe/FHFL, Moffett-SDK)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "MOFFETT S30-PCIe/FHFL-60GB",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Moffett SDK",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6326 CPU @ 2.90GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.5 LTS",
    "uid": "23af32a3782e442e",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/open/Moffett/results/Moffett_S30_DELL/bert-99.9/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 90.8575190748761,
    "Accuracy_div_100": 0.90858,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Moffett/results/Moffett_S4_Inspur/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Moffett",
    "Platform": "Moffett_S4_Inspur",
    "Result": 1219.41,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Inspur-NF5280M6 (1x SparseOne S4, PCIe/HHHL, Moffett-SDK)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "MOFFETT S4-PCIe/HHHL-20GB",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Moffett SDK",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6326 CPU @ 2.90GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.5 LTS",
    "uid": "49ac56e28d3b494f",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/open/Moffett/results/Moffett_S4_Inspur/bert-99.9/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 91.09565477598386,
    "Accuracy_div_100": 0.91096,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Dell/results/Dell-PowerEdge-R7525-2xAMD-EPYC-7773X/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Dell",
    "Platform": "Dell-PowerEdge-R7525-2xAMD-EPYC-7773X",
    "Result": 116.741,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge R7525 2x AMD EPYC 7773X",
    "SystemType": "datacenter,edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "OnnxRuntime",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 128,
    "host_processor_model_name": "AMD EPYC 7773X 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Deci AutoNAC",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu SMP",
    "uid": "61dde63fabcc4897",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/open/Dell/results/Dell-PowerEdge-R7525-2xAMD-EPYC-7773X/bert-99.9/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 90.8575190748761,
    "Accuracy_div_100": 0.90858,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Moffett/results/Moffett_S10_Inspur/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Moffett",
    "Platform": "Moffett_S10_Inspur",
    "Result": 2548.22,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Inspur NF5468M6-P (1x SparseOne S10, PCIe/FHFL, Moffett-SDK)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "MOFFETT S10-PCIe/FHFL-40GB",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Moffett SDK",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platium 8380",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.5 LTS",
    "uid": "589909f02e7d496b",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/Moffett/results/Moffett_S10_Inspur/bert-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.8575190748761,
    "Accuracy_div_100": 0.90858,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Moffett/results/Moffett_S30_Inspur/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Moffett",
    "Platform": "Moffett_S30_Inspur",
    "Result": 3840.74,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Inspur NF5468M6-P (1x SparseOne S30, PCIe/FHFL, Moffett-SDK)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "MOFFETT S30-PCIe/FHFL-60GB",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Moffett SDK",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platium 8380",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.5 LTS",
    "uid": "53ef56a3432740ac",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/Moffett/results/Moffett_S30_Inspur/bert-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.8575190748761,
    "Accuracy_div_100": 0.90858,
    "Availability": "preview",
    "Division": "open",
    "Location": "open/Moffett/results/Moffett_S40_Inspur/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Moffett",
    "Platform": "Moffett_S40_Inspur",
    "Result": 5068.94,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Inspur NF5468M6-P (1x SparseOne S40, PCIe/FHFL, Moffett-SDK)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "MOFFETT S40-PCIe/FHFL-80GB",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Moffett SDK",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platium 8380",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.5 LTS",
    "uid": "16436b3cc195493b",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/Moffett/results/Moffett_S40_Inspur/bert-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.38982811354983,
    "Accuracy_div_100": 0.9039,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Supermicro/results/A100X4_751GE_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Supermicro",
    "Platform": "A100X4_751GE_TRT",
    "Result": 12392.9,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "SYS-751GE-TNRT, TensorRT",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "INTEL XEON GOLD 6444Y 16-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.3",
    "uid": "4779f7f7e9fd4724",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/Supermicro/results/A100X4_751GE_TRT/bert-99/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.88273936857954,
    "Accuracy_div_100": 0.90883,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Supermicro/results/A100X4_751GE_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Supermicro",
    "Platform": "A100X4_751GE_TRT",
    "Result": 6476.1,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "SYS-751GE-TNRT, TensorRT",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "INTEL XEON GOLD 6444Y 16-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.3",
    "uid": "8a556437b3d3426b",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/Supermicro/results/A100X4_751GE_TRT/bert-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.38982811354983,
    "Accuracy_div_100": 0.9039,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Supermicro/results/A100X4_751GE_TRT_Triton/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Supermicro",
    "Platform": "A100X4_751GE_TRT_Triton",
    "Result": 12359.8,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "SYS-751GE-TNRT, TensorRT, Triton",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "INTEL XEON GOLD 6444Y 16-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.3",
    "uid": "27fa86c591374df8",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/Supermicro/results/A100X4_751GE_TRT_Triton/bert-99/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.88273936857954,
    "Accuracy_div_100": 0.90883,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Supermicro/results/A100X4_751GE_TRT_Triton/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Supermicro",
    "Platform": "A100X4_751GE_TRT_Triton",
    "Result": 6485.91,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "SYS-751GE-TNRT, TensorRT, Triton",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "INTEL XEON GOLD 6444Y 16-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.3",
    "uid": "6ca68b0678554204",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/Supermicro/results/A100X4_751GE_TRT_Triton/bert-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.41431155207196,
    "Accuracy_div_100": 0.90414,
    "Availability": "available",
    "Division": "open",
    "Location": "open/NeuralMagic/results/nm192ca_genoa_deepsparse/bert-99_obert-mobilebert/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99_obert-mobilebert",
    "Organization": "NeuralMagic",
    "Platform": "nm192ca_genoa_deepsparse",
    "Result": 5578.73,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NM192ca_genoa (2x AMD EPYC 9654, DeepSparse)",
    "SystemType": "datacenter,edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "DeepSparse 1.4.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9654 96-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "DeepSparse 1.4.0",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-5.15.0-58-generic-glibc2.35)",
    "uid": "23edd8ae06304a93",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/NeuralMagic/results/nm192ca_genoa_deepsparse/bert-99_obert-mobilebert/offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.79990624075134,
    "Accuracy_div_100": 0.908,
    "Availability": "available",
    "Division": "open",
    "Location": "open/NeuralMagic/results/nm192ca_genoa_deepsparse/bert-99.9_obert-mobilebert/offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9_obert-mobilebert",
    "Organization": "NeuralMagic",
    "Platform": "nm192ca_genoa_deepsparse",
    "Result": 3275.62,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NM192ca_genoa (2x AMD EPYC 9654, DeepSparse)",
    "SystemType": "datacenter,edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "DeepSparse 1.4.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9654 96-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "DeepSparse 1.4.0",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-5.15.0-58-generic-glibc2.35)",
    "uid": "d8569532eb3f410e",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/NeuralMagic/results/nm192ca_genoa_deepsparse/bert-99.9_obert-mobilebert/offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.0299132434367,
    "Accuracy_div_100": 0.9003,
    "Availability": "available",
    "Division": "open",
    "Location": "open/NeuralMagic/results/nm192ca_genoa_deepsparse/bert-99_obert-large/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99_obert-large",
    "Organization": "NeuralMagic",
    "Platform": "nm192ca_genoa_deepsparse",
    "Result": 1367.14,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NM192ca_genoa (2x AMD EPYC 9654, DeepSparse)",
    "SystemType": "datacenter,edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "DeepSparse 1.4.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9654 96-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "DeepSparse 1.4.0",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-5.15.0-58-generic-glibc2.35)",
    "uid": "a465524645084dd5",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/NeuralMagic/results/nm192ca_genoa_deepsparse/bert-99_obert-large/offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.87487229720105,
    "Accuracy_div_100": 0.90875,
    "Availability": "available",
    "Division": "open",
    "Location": "open/NeuralMagic/results/nm192ca_genoa_onnxruntime/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "NeuralMagic",
    "Platform": "nm192ca_genoa_onnxruntime",
    "Result": 4.59599,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NM192ca_genoa (2x AMD EPYC 9654, ONNXRuntime)",
    "SystemType": "datacenter,edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "onnxruntime v1.14.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9654 96-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "onnxruntime v1.14.0",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-5.15.0-58-generic-glibc2.35)",
    "uid": "de923e122d014363",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/NeuralMagic/results/nm192ca_genoa_onnxruntime/bert-99/offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 91.43001450212992,
    "Accuracy_div_100": 0.9143,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Deci/results/DGX-A100_A100-SXM-80GBx1_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Deci",
    "Platform": "DGX-A100_A100-SXM-80GBx1_TRT",
    "Result": 13377.2,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX A100 (1x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0.6, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7543",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.3",
    "uid": "5d8df7b79e48423a",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/Deci/results/DGX-A100_A100-SXM-80GBx1_TRT/bert-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 91.43001450212992,
    "Accuracy_div_100": 0.9143,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Deci/results/DGX-A100_A100-SXM-80GBx8_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Deci",
    "Platform": "DGX-A100_A100-SXM-80GBx8_TRT",
    "Result": 103053,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX A100 (8x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0.6, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7543",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.3",
    "uid": "2a226f9267e64099",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/Deci/results/DGX-A100_A100-SXM-80GBx8_TRT/bert-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.91720943580663,
    "Accuracy_div_100": 0.90917,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Deci/results/Intel-SPR-112-cores/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Deci",
    "Platform": "Intel-SPR-112-cores",
    "Result": 1189.33,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Intel Sapphire Rapids 112 Cores",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Intel Extension For Pytorch",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+ (Sapphire Rapids) CPU @ 2.00GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Intel IPEX with Deci AutoNAC",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 LTS",
    "uid": "cd6ef3b9193046c2",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/Deci/results/Intel-SPR-112-cores/bert-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 91.34622413544257,
    "Accuracy_div_100": 0.91346,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Deci/results/H100_PCIe-80GBx1_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Deci",
    "Platform": "H100_PCIe-80GBx1_TRT",
    "Result": 17584.2,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA H100 (1x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.5.3.1, CUDA 11.8",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6354",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5",
    "uid": "7bdee6e407c545b6",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/Deci/results/H100_PCIe-80GBx1_TRT/bert-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 91.28163424674494,
    "Accuracy_div_100": 0.91282,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Deci/results/A30x1_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Deci",
    "Platform": "A30x1_TRT",
    "Result": 5885.46,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA A30 (A30x1, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0.6, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6354",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.3",
    "uid": "f968bb56f0f34256",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/Deci/results/A30x1_TRT/bert-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.91678269111374,
    "Accuracy_div_100": 0.90917,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Qualcomm/results/g292_z43_q18-qaic-v1.8.3.7-aic100/bert_pruned_83.2_mp/offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert_pruned_83.2_mp",
    "Organization": "Qualcomm",
    "Platform": "g292_z43_q18-qaic-v1.8.3.7-aic100",
    "Result": 31944.1,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "GIGABYTE G292-Z43 (18x QAIC100 Pro)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 18,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.8.3",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7713 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5 LTS (Linux kernel: 5.4.0-135-generic #152-Ubuntu SMP Wed Nov 23 20:19:22 UTC 2022)",
    "uid": "f424bd7429314241",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/Qualcomm/results/g292_z43_q18-qaic-v1.8.3.7-aic100/bert_pruned_83.2_mp/offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 86.13436789084363,
    "Accuracy_div_100": 0.86134,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Qualcomm/results/g292_z43_q18-qaic-v1.8.3.7-aic100/distilbert_mp/offline",
    "MlperfModel": "bert-99",
    "Model": "distilbert_mp",
    "Organization": "Qualcomm",
    "Platform": "g292_z43_q18-qaic-v1.8.3.7-aic100",
    "Result": 59177.5,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "GIGABYTE G292-Z43 (18x QAIC100 Pro)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 18,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.8.3",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7713 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5 LTS (Linux kernel: 5.4.0-135-generic #152-Ubuntu SMP Wed Nov 23 20:19:22 UTC 2022)",
    "uid": "b173a5335a904283",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/Qualcomm/results/g292_z43_q18-qaic-v1.8.3.7-aic100/distilbert_mp/offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.03424083183069,
    "Accuracy_div_100": 0.90034,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Qualcomm/results/g292_z43_q18-qaic-v1.8.3.7-aic100/bert_pruned_82.6_mp/offline",
    "MlperfModel": "bert-99",
    "Model": "bert_pruned_82.6_mp",
    "Organization": "Qualcomm",
    "Platform": "g292_z43_q18-qaic-v1.8.3.7-aic100",
    "Result": 39443.8,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "GIGABYTE G292-Z43 (18x QAIC100 Pro)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 18,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.8.3",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7713 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5 LTS (Linux kernel: 5.4.0-135-generic #152-Ubuntu SMP Wed Nov 23 20:19:22 UTC 2022)",
    "uid": "4a6ca103b2a14cdf",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/Qualcomm/results/g292_z43_q18-qaic-v1.8.3.7-aic100/bert_pruned_82.6_mp/offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 91.07451933296576,
    "Accuracy_div_100": 0.91075,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Intel/results/1-node-2S-SPR-Neural_Engine-INT8/bert-99.9_MiniLM/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9_MiniLM",
    "Organization": "Intel",
    "Platform": "1-node-2S-SPR-Neural_Engine-INT8",
    "Result": 4260.95,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "1-node-2S-SPR-Neural_Engine-INT8",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "PyTorch",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54Q-2U",
    "number_of_nodes": 2,
    "operating_system": "CentOS Stream 8",
    "uid": "e7f32cc10d254b39",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/Intel/results/1-node-2S-SPR-Neural_Engine-INT8/bert-99.9_MiniLM/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.2931675957547,
    "Accuracy_div_100": 0.90293,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Intel/results/1-node-2S-SPR-OpenVINO-INT8/bert-99_jpqd-mobilebert/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99_jpqd-mobilebert",
    "Organization": "Intel",
    "Platform": "1-node-2S-SPR-OpenVINO-INT8",
    "Result": 1678.28,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "1-node-2S-SPR-OpenVINO-INT8",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "OpenVINO",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Intel Devlopment Platform (2U Server)",
    "number_of_nodes": 1,
    "operating_system": "CentOS Stream release 8",
    "uid": "a7abb577a1184522",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/Intel/results/1-node-2S-SPR-OpenVINO-INT8/bert-99_jpqd-mobilebert/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.94478332426705,
    "Accuracy_div_100": 0.90945,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Intel/results/1-node-2S-SPR-OpenVINO-INT8/bert-99.9_jpqd-large/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9_jpqd-large",
    "Organization": "Intel",
    "Platform": "1-node-2S-SPR-OpenVINO-INT8",
    "Result": 768.596,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "1-node-2S-SPR-OpenVINO-INT8",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "OpenVINO",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Intel Devlopment Platform (2U Server)",
    "number_of_nodes": 1,
    "operating_system": "CentOS Stream release 8",
    "uid": "612cb4173f72444e",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/Intel/results/1-node-2S-SPR-OpenVINO-INT8/bert-99.9_jpqd-large/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.15430667223764,
    "Accuracy_div_100": 0.90154,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Intel/results/1-node-2S-SPR-OpenVINO-INT8/bert-99_jpqd-large/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99_jpqd-large",
    "Organization": "Intel",
    "Platform": "1-node-2S-SPR-OpenVINO-INT8",
    "Result": 865.76,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "1-node-2S-SPR-OpenVINO-INT8",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "OpenVINO",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Intel Devlopment Platform (2U Server)",
    "number_of_nodes": 1,
    "operating_system": "CentOS Stream release 8",
    "uid": "1793bcfc56864eb6",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/Intel/results/1-node-2S-SPR-OpenVINO-INT8/bert-99_jpqd-large/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.14092926702556,
    "Accuracy_div_100": 0.90141,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Intel/results/1-node-2S-SPR-OpenVINO-INT8/bert-99_jpqd-base/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99_jpqd-base",
    "Organization": "Intel",
    "Platform": "1-node-2S-SPR-OpenVINO-INT8",
    "Result": 1105.24,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "1-node-2S-SPR-OpenVINO-INT8",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "OpenVINO",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Intel Devlopment Platform (2U Server)",
    "number_of_nodes": 1,
    "operating_system": "CentOS Stream release 8",
    "uid": "883ed8a0587a497e",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/Intel/results/1-node-2S-SPR-OpenVINO-INT8/bert-99_jpqd-base/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.24891234802074,
    "Accuracy_div_100": 0.90249,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Intel/results/1-node-2S-ICX-Neural_Engine-INT8/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Intel",
    "Platform": "1-node-2S-ICX-Neural_Engine-INT8",
    "Result": 333.134,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "1-node-2S-ICX-Neural_Engine-INT8",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural_Engine",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8380",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54Q-2U",
    "number_of_nodes": 2,
    "operating_system": "Ubuntu 20.04.1 LTS",
    "uid": "d8d00cc6cc514fe7",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/Intel/results/1-node-2S-ICX-Neural_Engine-INT8/bert-99/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.92786470887266,
    "Accuracy_div_100": 0.90928,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Intel/results/1-node-2S-ICX-Neural_Engine-INT8/bert-99.9_MiniLM/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9_MiniLM",
    "Organization": "Intel",
    "Platform": "1-node-2S-ICX-Neural_Engine-INT8",
    "Result": 2227.79,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "1-node-2S-ICX-Neural_Engine-INT8",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural_Engine",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8380",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54Q-2U",
    "number_of_nodes": 2,
    "operating_system": "Ubuntu 20.04.1 LTS",
    "uid": "19013ac40eb74dd5",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/Intel/results/1-node-2S-ICX-Neural_Engine-INT8/bert-99.9_MiniLM/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.87487229720105,
    "Accuracy_div_100": 0.90875,
    "Availability": "available",
    "Division": "open",
    "Location": "open/cTuning/results/aws_g4dn.xlarge-reference-gpu-pytorch-v2.1.0.dev20230303-default_config/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "cTuning",
    "Platform": "aws_g4dn.xlarge-reference-gpu-pytorch-v2.1.0.dev20230303-default_config",
    "Result": 11.273,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance g4dn.xlarge",
    "SystemType": "datacenter,edge",
    "Units": "Samples/s",
    "accelerator_model_name": "Tesla T4",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Pytorch 2.1.0 Dev version",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 2,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8259CL CPU @ 2.50GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Powered by MLCommons Collective Mind framework (CK2). ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-5.15.0-1028-aws-glibc2.35)",
    "uid": "3c1edb1228154369",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/cTuning/results/aws_g4dn.xlarge-reference-gpu-pytorch-v2.1.0.dev20230303-default_config/bert-99/offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.87487229720105,
    "Accuracy_div_100": 0.90875,
    "Availability": "available",
    "Division": "open",
    "Location": "open/cTuning/results/aws_g4dn.xlarge.497G-reference-gpu-pytorch-v1.13.1-default_config/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "cTuning",
    "Platform": "aws_g4dn.xlarge.497G-reference-gpu-pytorch-v1.13.1-default_config",
    "Result": 10.4627,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance g4dn.xlarge",
    "SystemType": "datacenter,edge",
    "Units": "Samples/s",
    "accelerator_model_name": "Tesla T4",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Pytorch v1.13.1",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 2,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8259CL CPU @ 2.50GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Powered by MLCommons Collective Mind framework (CK2). ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-5.15.0-1028-aws-glibc2.35)",
    "uid": "4a238d5e3ff1476f",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/cTuning/results/aws_g4dn.xlarge.497G-reference-gpu-pytorch-v1.13.1-default_config/bert-99/offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.87487229720105,
    "Accuracy_div_100": 0.90875,
    "Availability": "available",
    "Division": "open",
    "Location": "open/cTuning/results/aws_g4dn.xlarge-reference-gpu-pytorch-v1.13.1-default_config/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "cTuning",
    "Platform": "aws_g4dn.xlarge-reference-gpu-pytorch-v1.13.1-default_config",
    "Result": 11.3458,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance g4dn.xlarge",
    "SystemType": "datacenter,edge",
    "Units": "Samples/s",
    "accelerator_model_name": "Tesla T4",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Pytorch 1.13.1",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 2,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8259CL CPU @ 2.50GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Powered by MLCommons Collective Mind framework (CK2). ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-5.15.0-1028-aws-glibc2.35)",
    "uid": "cb426ced8d274a00",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/cTuning/results/aws_g4dn.xlarge-reference-gpu-pytorch-v1.13.1-default_config/bert-99/offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.87487229720105,
    "Accuracy_div_100": 0.90875,
    "Availability": "available",
    "Division": "open",
    "Location": "open/cTuning/results/aws_g4dn.xlarge.497G-reference-gpu-onnxruntime-v1.14.0-default_config/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "cTuning",
    "Platform": "aws_g4dn.xlarge.497G-reference-gpu-onnxruntime-v1.14.0-default_config",
    "Result": 12.3217,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance g4dn.xlarge",
    "SystemType": "datacenter,edge",
    "Units": "Samples/s",
    "accelerator_model_name": "Tesla T4",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Onnxruntime v1.14.0 with GPU support",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 2,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8259CL CPU @ 2.50GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Powered by MLCommons Collective Mind framework (CK2). ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-5.15.0-1028-aws-glibc2.35)",
    "uid": "771ad41bf8864121",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/cTuning/results/aws_g4dn.xlarge.497G-reference-gpu-onnxruntime-v1.14.0-default_config/bert-99/offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.24821866958023,
    "Accuracy_div_100": 0.90248,
    "Availability": "available",
    "Division": "open",
    "Location": "open/cTuning/results/aws_g4dn.xlarge.497G-nvidia_original-gpu-tensorrt-v8.5.2.2-default_config/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "cTuning",
    "Platform": "aws_g4dn.xlarge.497G-nvidia_original-gpu-tensorrt-v8.5.2.2-default_config",
    "Result": 317.058,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance g4dn.xlarge",
    "SystemType": "datacenter,edge",
    "Units": "Samples/s",
    "accelerator_model_name": "Tesla T4",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.5.2.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 2,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8259CL CPU @ 2.50GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Powered by MLCommons Collective Mind framework (CK2). ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-5.15.0-1028-aws-glibc2.35)",
    "uid": "356d05294780412c",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/cTuning/results/aws_g4dn.xlarge.497G-nvidia_original-gpu-tensorrt-v8.5.2.2-default_config/bert-99/offline",
    "version": "v3.0"
  }
]
