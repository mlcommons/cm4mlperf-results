[
  {
    "Accuracy": 92.5680398656114,
    "Accuracy_div_100": 0.92568,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/Orin_TRT_MaxQ/rnnt/SingleStream",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "NVIDIA",
    "Platform": "Orin_TRT_MaxQ",
    "Result": 101.519728,
    "Result_Units": "Latency (ms)",
    "Scenario": "SingleStream",
    "SystemName": "NVIDIA Orin (MaxQ, TensorRT)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "NVIDIA Orin",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "22.08 Jetson CUDA-X AI Developer Preview, TensorRT 8.5.0, CUDA 11.4",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": true,
    "host_processor_core_count": 12,
    "host_processor_model_name": "12-core Cortex-A78 CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "GPU and both DLAs are used in resnet50, in Offline scenario",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04",
    "uid": "9960a2fd2ab44842",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/NVIDIA/results/Orin_TRT_MaxQ/rnnt/SingleStream",
    "version": "v2.1",
    "Result_Power": 2098.1431113662993,
    "Result_Power_Units": "millijoules"
  },
  {
    "Accuracy": 92.5680398656114,
    "Accuracy_div_100": 0.92568,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/Orin_TRT_MaxQ/rnnt/SingleStream",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "NVIDIA",
    "Platform": "Orin_TRT_MaxQ",
    "Result": 101.519728,
    "Result_Units": "Latency (ms)",
    "Scenario": "SingleStream",
    "SystemName": "NVIDIA Orin (MaxQ, TensorRT)",
    "SystemType": "edge",
    "Units": "Latency (ms)",
    "accelerator_model_name": "NVIDIA Orin",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "22.08 Jetson CUDA-X AI Developer Preview, TensorRT 8.5.0, CUDA 11.4",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": true,
    "host_processor_core_count": 12,
    "host_processor_model_name": "12-core Cortex-A78 CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "GPU and both DLAs are used in resnet50, in Offline scenario",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04",
    "uid": "9960a2fd2ab44842",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/NVIDIA/results/Orin_TRT_MaxQ/rnnt/SingleStream",
    "version": "v2.1",
    "Result_Power": 2098.1431113662993,
    "Result_Power_Units": "millijoules"
  }
]
