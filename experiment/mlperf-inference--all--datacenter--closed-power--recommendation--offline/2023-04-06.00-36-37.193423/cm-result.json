[
  {
    "Accuracy": 80.312,
    "Accuracy_div_100": 0.80312,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 54.91016003615014,
    "Location": "closed/NVIDIA/results/H100-PCIe-80GBx8_TRT_MaxQ/dlrm-v2-99.9/Offline",
    "MlperfModel": "dlrm-v2-99.9",
    "Model": "dlrm-v2-99.9",
    "Organization": "NVIDIA",
    "Platform": "H100-PCIe-80GBx8_TRT_MaxQ",
    "Result": 162281,
    "Result_Power": 2955.391131498473,
    "Result_Power_Units": "Watts",
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G482-Z54 (8x H100-PCIe-80GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": true,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "42ee81f80d9a4c0b",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/NVIDIA/results/H100-PCIe-80GBx8_TRT_MaxQ/dlrm-v2-99.9/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 80.312,
    "Accuracy_div_100": 0.80312,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 54.91016003615014,
    "Location": "closed/NVIDIA/results/H100-PCIe-80GBx8_TRT_MaxQ/dlrm-v2-99.9/Offline",
    "MlperfModel": "dlrm-v2-99.9",
    "Model": "dlrm-v2-99.9",
    "Organization": "NVIDIA",
    "Platform": "H100-PCIe-80GBx8_TRT_MaxQ",
    "Result": 162281,
    "Result_Power": 2955.391131498473,
    "Result_Power_Units": "Watts",
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G482-Z54 (8x H100-PCIe-80GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": true,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "42ee81f80d9a4c0b",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/NVIDIA/results/H100-PCIe-80GBx8_TRT_MaxQ/dlrm-v2-99.9/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 80.312,
    "Accuracy_div_100": 0.80312,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 54.91016003615014,
    "Location": "closed/NVIDIA/results/H100-PCIe-80GBx8_TRT_MaxQ/dlrm-v2-99/Offline",
    "MlperfModel": "dlrm-v2-99",
    "Model": "dlrm-v2-99",
    "Organization": "NVIDIA",
    "Platform": "H100-PCIe-80GBx8_TRT_MaxQ",
    "Result": 162281,
    "Result_Power": 2955.391131498473,
    "Result_Power_Units": "Watts",
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G482-Z54 (8x H100-PCIe-80GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": true,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "8ed81068474041d6",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/NVIDIA/results/H100-PCIe-80GBx8_TRT_MaxQ/dlrm-v2-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 80.312,
    "Accuracy_div_100": 0.80312,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 54.91016003615014,
    "Location": "closed/NVIDIA/results/H100-PCIe-80GBx8_TRT_MaxQ/dlrm-v2-99/Offline",
    "MlperfModel": "dlrm-v2-99",
    "Model": "dlrm-v2-99",
    "Organization": "NVIDIA",
    "Platform": "H100-PCIe-80GBx8_TRT_MaxQ",
    "Result": 162281,
    "Result_Power": 2955.391131498473,
    "Result_Power_Units": "Watts",
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G482-Z54 (8x H100-PCIe-80GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": true,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "8ed81068474041d6",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/NVIDIA/results/H100-PCIe-80GBx8_TRT_MaxQ/dlrm-v2-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 80.312,
    "Accuracy_div_100": 0.80312,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 48.58495660872718,
    "Location": "closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT_MaxQ/dlrm-v2-99.9/Offline",
    "MlperfModel": "dlrm-v2-99.9",
    "Model": "dlrm-v2-99.9",
    "Organization": "NVIDIA",
    "Platform": "DGX-H100_H100-SXM-80GBx8_TRT_MaxQ",
    "Result": 273527,
    "Result_Power": 5629.8702127659635,
    "Result_Power_Units": "Watts",
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX H100 (8x H100-SXM-80GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": true,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "73816c408cf54b96",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT_MaxQ/dlrm-v2-99.9/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 80.312,
    "Accuracy_div_100": 0.80312,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 48.58495660872718,
    "Location": "closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT_MaxQ/dlrm-v2-99.9/Offline",
    "MlperfModel": "dlrm-v2-99.9",
    "Model": "dlrm-v2-99.9",
    "Organization": "NVIDIA",
    "Platform": "DGX-H100_H100-SXM-80GBx8_TRT_MaxQ",
    "Result": 273527,
    "Result_Power": 5629.8702127659635,
    "Result_Power_Units": "Watts",
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX H100 (8x H100-SXM-80GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": true,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "73816c408cf54b96",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT_MaxQ/dlrm-v2-99.9/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 80.312,
    "Accuracy_div_100": 0.80312,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 48.58495660872718,
    "Location": "closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT_MaxQ/dlrm-v2-99/Offline",
    "MlperfModel": "dlrm-v2-99",
    "Model": "dlrm-v2-99",
    "Organization": "NVIDIA",
    "Platform": "DGX-H100_H100-SXM-80GBx8_TRT_MaxQ",
    "Result": 273527,
    "Result_Power": 5629.8702127659635,
    "Result_Power_Units": "Watts",
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX H100 (8x H100-SXM-80GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": true,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "885dc83de34a40f0",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT_MaxQ/dlrm-v2-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 80.312,
    "Accuracy_div_100": 0.80312,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 48.58495660872718,
    "Location": "closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT_MaxQ/dlrm-v2-99/Offline",
    "MlperfModel": "dlrm-v2-99",
    "Model": "dlrm-v2-99",
    "Organization": "NVIDIA",
    "Platform": "DGX-H100_H100-SXM-80GBx8_TRT_MaxQ",
    "Result": 273527,
    "Result_Power": 5629.8702127659635,
    "Result_Power_Units": "Watts",
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX H100 (8x H100-SXM-80GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": true,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "885dc83de34a40f0",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT_MaxQ/dlrm-v2-99/Offline",
    "version": "v3.1"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 795.6652895599418,
    "Location": "closed/NVIDIA/results/A100-PCIe-80GBx8_TRT_MaxQ/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "NVIDIA",
    "Platform": "A100-PCIe-80GBx8_TRT_MaxQ",
    "Result": 1845900,
    "Result_Power": 2319.945364238411,
    "Result_Power_Units": "Watts",
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G482-Z54 (8x A100-PCIe-80GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "7c1d7b02cd5043ff",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/A100-PCIe-80GBx8_TRT_MaxQ/dlrm-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 795.6652895599418,
    "Location": "closed/NVIDIA/results/A100-PCIe-80GBx8_TRT_MaxQ/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "NVIDIA",
    "Platform": "A100-PCIe-80GBx8_TRT_MaxQ",
    "Result": 1845900,
    "Result_Power": 2319.945364238411,
    "Result_Power_Units": "Watts",
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G482-Z54 (8x A100-PCIe-80GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "d9cedd6ee2b144ef",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/A100-PCIe-80GBx8_TRT_MaxQ/dlrm-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 797.5904306402903,
    "Location": "closed/NVIDIA/results/DGX-Station-A100_A100-SXM-80GBx4_TRT_MaxQ/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "NVIDIA",
    "Platform": "DGX-Station-A100_A100-SXM-80GBx4_TRT_MaxQ",
    "Result": 1001010,
    "Result_Power": 1255.0426403641884,
    "Result_Power_Units": "Watts",
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX Station A100 (4x A100-SXM-80GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "ccd1694a283b4c02",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/DGX-Station-A100_A100-SXM-80GBx4_TRT_MaxQ/dlrm-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 797.5904306402903,
    "Location": "closed/NVIDIA/results/DGX-Station-A100_A100-SXM-80GBx4_TRT_MaxQ/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "NVIDIA",
    "Platform": "DGX-Station-A100_A100-SXM-80GBx4_TRT_MaxQ",
    "Result": 1001010,
    "Result_Power": 1255.0426403641884,
    "Result_Power_Units": "Watts",
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX Station A100 (4x A100-SXM-80GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "ebd8778efb9d4296",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/DGX-Station-A100_A100-SXM-80GBx4_TRT_MaxQ/dlrm-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 646.2255623969089,
    "Location": "closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT_MaxQ/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "NVIDIA",
    "Platform": "DGX-A100_A100-SXM-80GBx8_TRT_MaxQ",
    "Result": 2140540,
    "Result_Power": 3312.3728378378346,
    "Result_Power_Units": "Watts",
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX A100 (8x A100-SXM-80GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "0987795cafa545ea",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT_MaxQ/dlrm-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 646.2255623969089,
    "Location": "closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT_MaxQ/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "NVIDIA",
    "Platform": "DGX-A100_A100-SXM-80GBx8_TRT_MaxQ",
    "Result": 2140540,
    "Result_Power": 3312.3728378378346,
    "Result_Power_Units": "Watts",
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX A100 (8x A100-SXM-80GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "a71cf2c10a0d4592",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT_MaxQ/dlrm-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 701.5322391941828,
    "Location": "closed/NVIDIA/results/A100-SXM-80GB_aarch64x8_TRT_MaxQ/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "NVIDIA",
    "Platform": "A100-SXM-80GB_aarch64x8_TRT_MaxQ",
    "Result": 1940830,
    "Result_Power": 2766.5585294117636,
    "Result_Power_Units": "Watts",
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G492-PD0 (8x A100-SXM-80GB_aarch64, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 80,
    "host_processor_model_name": "Ampere Altra Q80-30",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "164a7ee7c21a4b5e",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/A100-SXM-80GB_aarch64x8_TRT_MaxQ/dlrm-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 701.5322391941828,
    "Location": "closed/NVIDIA/results/A100-SXM-80GB_aarch64x8_TRT_MaxQ/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "NVIDIA",
    "Platform": "A100-SXM-80GB_aarch64x8_TRT_MaxQ",
    "Result": 1940830,
    "Result_Power": 2766.5585294117636,
    "Result_Power_Units": "Watts",
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G492-PD0 (8x A100-SXM-80GB_aarch64, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 80,
    "host_processor_model_name": "Ampere Altra Q80-30",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "e6d3e37072984b8f",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/A100-SXM-80GB_aarch64x8_TRT_MaxQ/dlrm-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 768.8090809620702,
    "Location": "closed/NVIDIA/results/A100-PCIe-80GB_aarch64x4_TRT_MaxQ/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "NVIDIA",
    "Platform": "A100-PCIe-80GB_aarch64x4_TRT_MaxQ",
    "Result": 953749,
    "Result_Power": 1240.5537650602412,
    "Result_Power_Units": "Watts",
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G242-P31 (4x A100-PCIe-80GB_aarch64, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 80,
    "host_processor_model_name": "Ampere Altra Q80-30",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "46d8ff71a18b4327",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/A100-PCIe-80GB_aarch64x4_TRT_MaxQ/dlrm-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 768.8090809620702,
    "Location": "closed/NVIDIA/results/A100-PCIe-80GB_aarch64x4_TRT_MaxQ/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "NVIDIA",
    "Platform": "A100-PCIe-80GB_aarch64x4_TRT_MaxQ",
    "Result": 953749,
    "Result_Power": 1240.5537650602412,
    "Result_Power_Units": "Watts",
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G242-P31 (4x A100-PCIe-80GB_aarch64, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 80,
    "host_processor_model_name": "Ampere Altra Q80-30",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "5fd095c930bc4d57",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/A100-PCIe-80GB_aarch64x4_TRT_MaxQ/dlrm-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 650.3565995845393,
    "Location": "closed/Fujitsu/results/GX2570M6_A100-SXM4-40GBx8_TRT_MaxQ/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "Fujitsu",
    "Platform": "GX2570M6_A100-SXM4-40GBx8_TRT_MaxQ",
    "Result": 2124460,
    "Result_Power": 3266.607890743551,
    "Result_Power_Units": "Watts",
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "PRIMERGY GX2570M6 (8x A100-SXM-40GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM4-40GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 144,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8352V CPU @ 2.10GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Maximum GPU power is limitted to 275W with nvidia-smi command",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.3",
    "uid": "9aa395003d464661",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Fujitsu/results/GX2570M6_A100-SXM4-40GBx8_TRT_MaxQ/dlrm-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 650.3565995845393,
    "Location": "closed/Fujitsu/results/GX2570M6_A100-SXM4-40GBx8_TRT_MaxQ/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "Fujitsu",
    "Platform": "GX2570M6_A100-SXM4-40GBx8_TRT_MaxQ",
    "Result": 2124460,
    "Result_Power": 3266.607890743551,
    "Result_Power_Units": "Watts",
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "PRIMERGY GX2570M6 (8x A100-SXM-40GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM4-40GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 144,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8352V CPU @ 2.10GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Maximum GPU power is limitted to 275W with nvidia-smi command",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.3",
    "uid": "5c2a4f5c00484f78",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Fujitsu/results/GX2570M6_A100-SXM4-40GBx8_TRT_MaxQ/dlrm-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 75.12854729462143,
    "Location": "closed/Dell/results/XR12_A2x1_TRT_MaxQ/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "Dell",
    "Platform": "XR12_A2x1_TRT_MaxQ",
    "Result": 22034.9,
    "Result_Power": 293.2959679572763,
    "Result_Power_Units": "Watts",
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XR12 (1x A2, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A2",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6312U CPU @ 2.40GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "CentOS 8.2",
    "uid": "f0513014b35c43ab",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Dell/results/XR12_A2x1_TRT_MaxQ/dlrm-99/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 75.12854729462143,
    "Location": "closed/Dell/results/XR12_A2x1_TRT_MaxQ/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "Dell",
    "Platform": "XR12_A2x1_TRT_MaxQ",
    "Result": 22034.9,
    "Result_Power": 293.2959679572763,
    "Result_Power_Units": "Watts",
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XR12 (1x A2, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A2",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": true,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6312U CPU @ 2.40GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "CentOS 8.2",
    "uid": "8469212e2e444396",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Dell/results/XR12_A2x1_TRT_MaxQ/dlrm-99.9/Offline",
    "version": "v2.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 641.7652063686284,
    "Location": "closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT_MaxQ/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "NVIDIA",
    "Platform": "DGX-A100_A100-SXM-80GBx8_TRT_MaxQ",
    "Result": 2128420,
    "Result_Power": 3316.5088709677425,
    "Result_Power_Units": "Watts",
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX A100 (8x A100-SXM-80GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": true,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "96cd0d9b64da464d",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT_MaxQ/dlrm-99/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 641.7652063686284,
    "Location": "closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT_MaxQ/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "NVIDIA",
    "Platform": "DGX-A100_A100-SXM-80GBx8_TRT_MaxQ",
    "Result": 2128420,
    "Result_Power": 3316.5088709677425,
    "Result_Power_Units": "Watts",
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX A100 (8x A100-SXM-80GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": true,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "ebbcccc63e0042a4",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT_MaxQ/dlrm-99.9/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 80.57947441381238,
    "Location": "closed/Dell/results/XR12_A2x1_TRT_MaxQ/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "Dell",
    "Platform": "XR12_A2x1_TRT_MaxQ",
    "Result": 22172.1,
    "Result_Power": 275.1581610738256,
    "Result_Power_Units": "Watts",
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XR12 (1x A2, MaxQ, TensorRT)",
    "SystemType": "datacenter,edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A2",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": true,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6312U CPU @ 2.40GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "CentOS 8.2",
    "uid": "50eea6f50b6f4694",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/Dell/results/XR12_A2x1_TRT_MaxQ/dlrm-99/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 80.57947441381238,
    "Location": "closed/Dell/results/XR12_A2x1_TRT_MaxQ/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "Dell",
    "Platform": "XR12_A2x1_TRT_MaxQ",
    "Result": 22172.1,
    "Result_Power": 275.1581610738256,
    "Result_Power_Units": "Watts",
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Dell PowerEdge XR12 (1x A2, MaxQ, TensorRT)",
    "SystemType": "datacenter,edge",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A2",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": true,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6312U CPU @ 2.40GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "CentOS 8.2",
    "uid": "96d0a4a8df2d4e7e",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/Dell/results/XR12_A2x1_TRT_MaxQ/dlrm-99.9/Offline",
    "version": "v2.1"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 742.615787341962,
    "Location": "closed/NVIDIA/results/A100-PCIe-80GBx8_TRT_MaxQ/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "NVIDIA",
    "Platform": "A100-PCIe-80GBx8_TRT_MaxQ",
    "Result": 1573310,
    "Result_Power": 2118.60564617315,
    "Result_Power_Units": "Watts",
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G482-Z54 (8x A100-PCIe-80GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": true,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "70d9c3bf0b364b60",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/NVIDIA/results/A100-PCIe-80GBx8_TRT_MaxQ/dlrm-99/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 742.615787341962,
    "Location": "closed/NVIDIA/results/A100-PCIe-80GBx8_TRT_MaxQ/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "NVIDIA",
    "Platform": "A100-PCIe-80GBx8_TRT_MaxQ",
    "Result": 1573310,
    "Result_Power": 2118.60564617315,
    "Result_Power_Units": "Watts",
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G482-Z54 (8x A100-PCIe-80GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": true,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "042bd3994a024d46",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/NVIDIA/results/A100-PCIe-80GBx8_TRT_MaxQ/dlrm-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 1111.3066828730807,
    "Location": "closed/NVIDIA/results/H100-PCIe-80GBx8_TRT_MaxQ/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "NVIDIA",
    "Platform": "H100-PCIe-80GBx8_TRT_MaxQ",
    "Result": 3046880,
    "Result_Power": 2741.709419152279,
    "Result_Power_Units": "Watts",
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G482-Z54 (8x H100-PCIe-80GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": true,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "c111baa4e1fc48c0",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/NVIDIA/results/H100-PCIe-80GBx8_TRT_MaxQ/dlrm-99/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 80.185,
    "Accuracy_div_100": 0.80185,
    "Availability": "available",
    "Division": "closed",
    "Inference_per_Joule": 1111.3066828730807,
    "Location": "closed/NVIDIA/results/H100-PCIe-80GBx8_TRT_MaxQ/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "NVIDIA",
    "Platform": "H100-PCIe-80GBx8_TRT_MaxQ",
    "Result": 3046880,
    "Result_Power": 2741.709419152279,
    "Result_Power_Units": "Watts",
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G482-Z54 (8x H100-PCIe-80GB, MaxQ, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": true,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "4a3f6a210ee84abf",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/NVIDIA/results/H100-PCIe-80GBx8_TRT_MaxQ/dlrm-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 80.186,
    "Accuracy_div_100": 0.80186,
    "Availability": "preview",
    "Division": "closed",
    "Inference_per_Joule": 1033.4132512287954,
    "Location": "closed/Neuchips/results/RecAccel-N3000-32GB-PCIEx8/dlrm-99/Offline",
    "MlperfModel": "dlrm-99",
    "Model": "dlrm-99",
    "Organization": "Neuchips",
    "Platform": "RecAccel-N3000-32GB-PCIEx8",
    "Result": 811664,
    "Result_Power": 785.4205459770125,
    "Result_Power_Units": "Watts",
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G482-Z54 (8x RecAccel-N3000-32GB-PCIE)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "RecAccel N3000",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": true,
    "host_processor_core_count": 32,
    "host_processor_model_name": "AMD EPYC 7452 32-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.1",
    "uid": "3b15b20e4b0c4bd7",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Neuchips/results/RecAccel-N3000-32GB-PCIEx8/dlrm-99/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 80.186,
    "Accuracy_div_100": 0.80186,
    "Availability": "preview",
    "Division": "closed",
    "Inference_per_Joule": 1033.4132512287954,
    "Location": "closed/Neuchips/results/RecAccel-N3000-32GB-PCIEx8/dlrm-99.9/Offline",
    "MlperfModel": "dlrm-99.9",
    "Model": "dlrm-99.9",
    "Organization": "Neuchips",
    "Platform": "RecAccel-N3000-32GB-PCIEx8",
    "Result": 811664,
    "Result_Power": 785.4205459770125,
    "Result_Power_Units": "Watts",
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Gigabyte G482-Z54 (8x RecAccel-N3000-32GB-PCIE)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "RecAccel N3000",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": true,
    "host_processor_core_count": 32,
    "host_processor_model_name": "AMD EPYC 7452 32-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.1",
    "uid": "b2b3fb9d48504d30",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Neuchips/results/RecAccel-N3000-32GB-PCIEx8/dlrm-99.9/Offline",
    "version": "v3.0"
  }
]
