[
  {
    "Accuracy": 90.8575190748761,
    "Accuracy_div_100": 0.90858,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Moffett/results/Moffett_S10_Inspur/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Moffett",
    "Platform": "Moffett_S10_Inspur",
    "Result": 2548.22,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Inspur NF5468M6-P (1x SparseOne S10, PCIe/FHFL, Moffett-SDK)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "MOFFETT S10-PCIe/FHFL-40GB",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Moffett SDK",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platium 8380",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.5 LTS",
    "uid": "589909f02e7d496b",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/Moffett/results/Moffett_S10_Inspur/bert-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.8575190748761,
    "Accuracy_div_100": 0.90858,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Moffett/results/Moffett_S30_Inspur/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Moffett",
    "Platform": "Moffett_S30_Inspur",
    "Result": 3840.74,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Inspur NF5468M6-P (1x SparseOne S30, PCIe/FHFL, Moffett-SDK)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "MOFFETT S30-PCIe/FHFL-60GB",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Moffett SDK",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platium 8380",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.5 LTS",
    "uid": "53ef56a3432740ac",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/Moffett/results/Moffett_S30_Inspur/bert-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.8575190748761,
    "Accuracy_div_100": 0.90858,
    "Availability": "preview",
    "Division": "open",
    "Location": "open/Moffett/results/Moffett_S40_Inspur/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Moffett",
    "Platform": "Moffett_S40_Inspur",
    "Result": 5068.94,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Inspur NF5468M6-P (1x SparseOne S40, PCIe/FHFL, Moffett-SDK)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "MOFFETT S40-PCIe/FHFL-80GB",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Moffett SDK",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platium 8380",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.5 LTS",
    "uid": "16436b3cc195493b",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/Moffett/results/Moffett_S40_Inspur/bert-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.38982811354983,
    "Accuracy_div_100": 0.9039,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Supermicro/results/A100X4_751GE_TRT/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Supermicro",
    "Platform": "A100X4_751GE_TRT",
    "Result": 12392.9,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "SYS-751GE-TNRT, TensorRT",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "INTEL XEON GOLD 6444Y 16-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.3",
    "uid": "4779f7f7e9fd4724",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/Supermicro/results/A100X4_751GE_TRT/bert-99/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.88273936857954,
    "Accuracy_div_100": 0.90883,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Supermicro/results/A100X4_751GE_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Supermicro",
    "Platform": "A100X4_751GE_TRT",
    "Result": 6476.1,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "SYS-751GE-TNRT, TensorRT",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "INTEL XEON GOLD 6444Y 16-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.3",
    "uid": "8a556437b3d3426b",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/Supermicro/results/A100X4_751GE_TRT/bert-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.38982811354983,
    "Accuracy_div_100": 0.9039,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Supermicro/results/A100X4_751GE_TRT_Triton/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Supermicro",
    "Platform": "A100X4_751GE_TRT_Triton",
    "Result": 12359.8,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "SYS-751GE-TNRT, TensorRT, Triton",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "INTEL XEON GOLD 6444Y 16-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.3",
    "uid": "27fa86c591374df8",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/Supermicro/results/A100X4_751GE_TRT_Triton/bert-99/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.88273936857954,
    "Accuracy_div_100": 0.90883,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Supermicro/results/A100X4_751GE_TRT_Triton/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Supermicro",
    "Platform": "A100X4_751GE_TRT_Triton",
    "Result": 6485.91,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "SYS-751GE-TNRT, TensorRT, Triton",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "INTEL XEON GOLD 6444Y 16-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.3",
    "uid": "6ca68b0678554204",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/Supermicro/results/A100X4_751GE_TRT_Triton/bert-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.41431155207196,
    "Accuracy_div_100": 0.90414,
    "Availability": "available",
    "Division": "open",
    "Location": "open/NeuralMagic/results/nm192ca_genoa_deepsparse/bert-99_obert-mobilebert/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99_obert-mobilebert",
    "Organization": "NeuralMagic",
    "Platform": "nm192ca_genoa_deepsparse",
    "Result": 5578.73,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NM192ca_genoa (2x AMD EPYC 9654, DeepSparse)",
    "SystemType": "datacenter,edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "DeepSparse 1.4.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9654 96-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "DeepSparse 1.4.0",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-5.15.0-58-generic-glibc2.35)",
    "uid": "23edd8ae06304a93",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/NeuralMagic/results/nm192ca_genoa_deepsparse/bert-99_obert-mobilebert/offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.79990624075134,
    "Accuracy_div_100": 0.908,
    "Availability": "available",
    "Division": "open",
    "Location": "open/NeuralMagic/results/nm192ca_genoa_deepsparse/bert-99.9_obert-mobilebert/offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9_obert-mobilebert",
    "Organization": "NeuralMagic",
    "Platform": "nm192ca_genoa_deepsparse",
    "Result": 3275.62,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NM192ca_genoa (2x AMD EPYC 9654, DeepSparse)",
    "SystemType": "datacenter,edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "DeepSparse 1.4.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9654 96-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "DeepSparse 1.4.0",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-5.15.0-58-generic-glibc2.35)",
    "uid": "d8569532eb3f410e",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/NeuralMagic/results/nm192ca_genoa_deepsparse/bert-99.9_obert-mobilebert/offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.0299132434367,
    "Accuracy_div_100": 0.9003,
    "Availability": "available",
    "Division": "open",
    "Location": "open/NeuralMagic/results/nm192ca_genoa_deepsparse/bert-99_obert-large/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99_obert-large",
    "Organization": "NeuralMagic",
    "Platform": "nm192ca_genoa_deepsparse",
    "Result": 1367.14,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NM192ca_genoa (2x AMD EPYC 9654, DeepSparse)",
    "SystemType": "datacenter,edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "DeepSparse 1.4.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9654 96-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "DeepSparse 1.4.0",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-5.15.0-58-generic-glibc2.35)",
    "uid": "a465524645084dd5",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/NeuralMagic/results/nm192ca_genoa_deepsparse/bert-99_obert-large/offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.87487229720105,
    "Accuracy_div_100": 0.90875,
    "Availability": "available",
    "Division": "open",
    "Location": "open/NeuralMagic/results/nm192ca_genoa_onnxruntime/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "NeuralMagic",
    "Platform": "nm192ca_genoa_onnxruntime",
    "Result": 4.59599,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NM192ca_genoa (2x AMD EPYC 9654, ONNXRuntime)",
    "SystemType": "datacenter,edge",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "onnxruntime v1.14.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9654 96-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "onnxruntime v1.14.0",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-5.15.0-58-generic-glibc2.35)",
    "uid": "de923e122d014363",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/NeuralMagic/results/nm192ca_genoa_onnxruntime/bert-99/offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 91.43001450212992,
    "Accuracy_div_100": 0.9143,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Deci/results/DGX-A100_A100-SXM-80GBx1_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Deci",
    "Platform": "DGX-A100_A100-SXM-80GBx1_TRT",
    "Result": 13377.2,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX A100 (1x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0.6, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7543",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.3",
    "uid": "5d8df7b79e48423a",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/Deci/results/DGX-A100_A100-SXM-80GBx1_TRT/bert-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 91.43001450212992,
    "Accuracy_div_100": 0.9143,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Deci/results/DGX-A100_A100-SXM-80GBx8_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Deci",
    "Platform": "DGX-A100_A100-SXM-80GBx8_TRT",
    "Result": 103053,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA DGX A100 (8x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0.6, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7543",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.3",
    "uid": "2a226f9267e64099",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/Deci/results/DGX-A100_A100-SXM-80GBx8_TRT/bert-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.91720943580663,
    "Accuracy_div_100": 0.90917,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Deci/results/Intel-SPR-112-cores/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Deci",
    "Platform": "Intel-SPR-112-cores",
    "Result": 1189.33,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "Intel Sapphire Rapids 112 Cores",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Intel Extension For Pytorch",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+ (Sapphire Rapids) CPU @ 2.00GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Intel IPEX with Deci AutoNAC",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 LTS",
    "uid": "cd6ef3b9193046c2",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/Deci/results/Intel-SPR-112-cores/bert-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 91.34622413544257,
    "Accuracy_div_100": 0.91346,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Deci/results/H100_PCIe-80GBx1_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Deci",
    "Platform": "H100_PCIe-80GBx1_TRT",
    "Result": 17584.2,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA H100 (1x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.5.3.1, CUDA 11.8",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6354",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5",
    "uid": "7bdee6e407c545b6",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/Deci/results/H100_PCIe-80GBx1_TRT/bert-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 91.28163424674494,
    "Accuracy_div_100": 0.91282,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Deci/results/A30x1_TRT/bert-99.9/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Deci",
    "Platform": "A30x1_TRT",
    "Result": 5885.46,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "NVIDIA A30 (A30x1, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0.6, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6354",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.3",
    "uid": "f968bb56f0f34256",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/Deci/results/A30x1_TRT/bert-99.9/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.91678269111374,
    "Accuracy_div_100": 0.90917,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Qualcomm/results/g292_z43_q18-qaic-v1.8.3.7-aic100/bert_pruned_83.2_mp/offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert_pruned_83.2_mp",
    "Organization": "Qualcomm",
    "Platform": "g292_z43_q18-qaic-v1.8.3.7-aic100",
    "Result": 31944.1,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "GIGABYTE G292-Z43 (18x QAIC100 Pro)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 18,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.8.3",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7713 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5 LTS (Linux kernel: 5.4.0-135-generic #152-Ubuntu SMP Wed Nov 23 20:19:22 UTC 2022)",
    "uid": "f424bd7429314241",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/Qualcomm/results/g292_z43_q18-qaic-v1.8.3.7-aic100/bert_pruned_83.2_mp/offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 86.13436789084363,
    "Accuracy_div_100": 0.86134,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Qualcomm/results/g292_z43_q18-qaic-v1.8.3.7-aic100/distilbert_mp/offline",
    "MlperfModel": "bert-99",
    "Model": "distilbert_mp",
    "Organization": "Qualcomm",
    "Platform": "g292_z43_q18-qaic-v1.8.3.7-aic100",
    "Result": 59177.5,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "GIGABYTE G292-Z43 (18x QAIC100 Pro)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 18,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.8.3",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7713 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5 LTS (Linux kernel: 5.4.0-135-generic #152-Ubuntu SMP Wed Nov 23 20:19:22 UTC 2022)",
    "uid": "b173a5335a904283",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/Qualcomm/results/g292_z43_q18-qaic-v1.8.3.7-aic100/distilbert_mp/offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.03424083183069,
    "Accuracy_div_100": 0.90034,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Qualcomm/results/g292_z43_q18-qaic-v1.8.3.7-aic100/bert_pruned_82.6_mp/offline",
    "MlperfModel": "bert-99",
    "Model": "bert_pruned_82.6_mp",
    "Organization": "Qualcomm",
    "Platform": "g292_z43_q18-qaic-v1.8.3.7-aic100",
    "Result": 39443.8,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "GIGABYTE G292-Z43 (18x QAIC100 Pro)",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "QUALCOMM Cloud AI 100 PCIe/HHHL Pro",
    "accelerators_per_node": 18,
    "compliance": 1,
    "errors": 0,
    "framework": "QUALCOMM Cloud AI SDK v1.8.3",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7713 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "With 75W Accelerator TDP constraints. Powered by Collective Knowledge v2.6.1",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5 LTS (Linux kernel: 5.4.0-135-generic #152-Ubuntu SMP Wed Nov 23 20:19:22 UTC 2022)",
    "uid": "4a6ca103b2a14cdf",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/Qualcomm/results/g292_z43_q18-qaic-v1.8.3.7-aic100/bert_pruned_82.6_mp/offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 91.07451933296576,
    "Accuracy_div_100": 0.91075,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Intel/results/1-node-2S-SPR-Neural_Engine-INT8/bert-99.9_MiniLM/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9_MiniLM",
    "Organization": "Intel",
    "Platform": "1-node-2S-SPR-Neural_Engine-INT8",
    "Result": 4260.95,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "1-node-2S-SPR-Neural_Engine-INT8",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "PyTorch",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54Q-2U",
    "number_of_nodes": 2,
    "operating_system": "CentOS Stream 8",
    "uid": "e7f32cc10d254b39",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/Intel/results/1-node-2S-SPR-Neural_Engine-INT8/bert-99.9_MiniLM/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.2931675957547,
    "Accuracy_div_100": 0.90293,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Intel/results/1-node-2S-SPR-OpenVINO-INT8/bert-99_jpqd-mobilebert/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99_jpqd-mobilebert",
    "Organization": "Intel",
    "Platform": "1-node-2S-SPR-OpenVINO-INT8",
    "Result": 1678.28,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "1-node-2S-SPR-OpenVINO-INT8",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "OpenVINO",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Intel Devlopment Platform (2U Server)",
    "number_of_nodes": 1,
    "operating_system": "CentOS Stream release 8",
    "uid": "a7abb577a1184522",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/Intel/results/1-node-2S-SPR-OpenVINO-INT8/bert-99_jpqd-mobilebert/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.94478332426705,
    "Accuracy_div_100": 0.90945,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Intel/results/1-node-2S-SPR-OpenVINO-INT8/bert-99.9_jpqd-large/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9_jpqd-large",
    "Organization": "Intel",
    "Platform": "1-node-2S-SPR-OpenVINO-INT8",
    "Result": 768.596,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "1-node-2S-SPR-OpenVINO-INT8",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "OpenVINO",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Intel Devlopment Platform (2U Server)",
    "number_of_nodes": 1,
    "operating_system": "CentOS Stream release 8",
    "uid": "612cb4173f72444e",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/Intel/results/1-node-2S-SPR-OpenVINO-INT8/bert-99.9_jpqd-large/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.15430667223764,
    "Accuracy_div_100": 0.90154,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Intel/results/1-node-2S-SPR-OpenVINO-INT8/bert-99_jpqd-large/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99_jpqd-large",
    "Organization": "Intel",
    "Platform": "1-node-2S-SPR-OpenVINO-INT8",
    "Result": 865.76,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "1-node-2S-SPR-OpenVINO-INT8",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "OpenVINO",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Intel Devlopment Platform (2U Server)",
    "number_of_nodes": 1,
    "operating_system": "CentOS Stream release 8",
    "uid": "1793bcfc56864eb6",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/Intel/results/1-node-2S-SPR-OpenVINO-INT8/bert-99_jpqd-large/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.14092926702556,
    "Accuracy_div_100": 0.90141,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Intel/results/1-node-2S-SPR-OpenVINO-INT8/bert-99_jpqd-base/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99_jpqd-base",
    "Organization": "Intel",
    "Platform": "1-node-2S-SPR-OpenVINO-INT8",
    "Result": 1105.24,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "1-node-2S-SPR-OpenVINO-INT8",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "OpenVINO",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Intel Devlopment Platform (2U Server)",
    "number_of_nodes": 1,
    "operating_system": "CentOS Stream release 8",
    "uid": "883ed8a0587a497e",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/Intel/results/1-node-2S-SPR-OpenVINO-INT8/bert-99_jpqd-base/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.24891234802074,
    "Accuracy_div_100": 0.90249,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Intel/results/1-node-2S-ICX-Neural_Engine-INT8/bert-99/Offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Intel",
    "Platform": "1-node-2S-ICX-Neural_Engine-INT8",
    "Result": 333.134,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "1-node-2S-ICX-Neural_Engine-INT8",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural_Engine",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8380",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54Q-2U",
    "number_of_nodes": 2,
    "operating_system": "Ubuntu 20.04.1 LTS",
    "uid": "d8d00cc6cc514fe7",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/Intel/results/1-node-2S-ICX-Neural_Engine-INT8/bert-99/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.92786470887266,
    "Accuracy_div_100": 0.90928,
    "Availability": "available",
    "Division": "open",
    "Location": "open/Intel/results/1-node-2S-ICX-Neural_Engine-INT8/bert-99.9_MiniLM/Offline",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9_MiniLM",
    "Organization": "Intel",
    "Platform": "1-node-2S-ICX-Neural_Engine-INT8",
    "Result": 2227.79,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "1-node-2S-ICX-Neural_Engine-INT8",
    "SystemType": "datacenter",
    "Units": "Samples/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Neural_Engine",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8380",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54Q-2U",
    "number_of_nodes": 2,
    "operating_system": "Ubuntu 20.04.1 LTS",
    "uid": "19013ac40eb74dd5",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/Intel/results/1-node-2S-ICX-Neural_Engine-INT8/bert-99.9_MiniLM/Offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.87487229720105,
    "Accuracy_div_100": 0.90875,
    "Availability": "available",
    "Division": "open",
    "Location": "open/cTuning/results/aws_g4dn.xlarge-reference-gpu-pytorch-v2.1.0.dev20230303-default_config/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "cTuning",
    "Platform": "aws_g4dn.xlarge-reference-gpu-pytorch-v2.1.0.dev20230303-default_config",
    "Result": 11.273,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance g4dn.xlarge",
    "SystemType": "datacenter,edge",
    "Units": "Samples/s",
    "accelerator_model_name": "Tesla T4",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Pytorch 2.1.0 Dev version",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 2,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8259CL CPU @ 2.50GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Powered by MLCommons Collective Mind framework (CK2). ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-5.15.0-1028-aws-glibc2.35)",
    "uid": "3c1edb1228154369",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/cTuning/results/aws_g4dn.xlarge-reference-gpu-pytorch-v2.1.0.dev20230303-default_config/bert-99/offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.87487229720105,
    "Accuracy_div_100": 0.90875,
    "Availability": "available",
    "Division": "open",
    "Location": "open/cTuning/results/aws_g4dn.xlarge.497G-reference-gpu-pytorch-v1.13.1-default_config/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "cTuning",
    "Platform": "aws_g4dn.xlarge.497G-reference-gpu-pytorch-v1.13.1-default_config",
    "Result": 10.4627,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance g4dn.xlarge",
    "SystemType": "datacenter,edge",
    "Units": "Samples/s",
    "accelerator_model_name": "Tesla T4",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Pytorch v1.13.1",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 2,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8259CL CPU @ 2.50GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Powered by MLCommons Collective Mind framework (CK2). ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-5.15.0-1028-aws-glibc2.35)",
    "uid": "4a238d5e3ff1476f",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/cTuning/results/aws_g4dn.xlarge.497G-reference-gpu-pytorch-v1.13.1-default_config/bert-99/offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.87487229720105,
    "Accuracy_div_100": 0.90875,
    "Availability": "available",
    "Division": "open",
    "Location": "open/cTuning/results/aws_g4dn.xlarge-reference-gpu-pytorch-v1.13.1-default_config/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "cTuning",
    "Platform": "aws_g4dn.xlarge-reference-gpu-pytorch-v1.13.1-default_config",
    "Result": 11.3458,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance g4dn.xlarge",
    "SystemType": "datacenter,edge",
    "Units": "Samples/s",
    "accelerator_model_name": "Tesla T4",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "Pytorch 1.13.1",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 2,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8259CL CPU @ 2.50GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Powered by MLCommons Collective Mind framework (CK2). ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-5.15.0-1028-aws-glibc2.35)",
    "uid": "cb426ced8d274a00",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/cTuning/results/aws_g4dn.xlarge-reference-gpu-pytorch-v1.13.1-default_config/bert-99/offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.87487229720105,
    "Accuracy_div_100": 0.90875,
    "Availability": "available",
    "Division": "open",
    "Location": "open/cTuning/results/aws_g4dn.xlarge.497G-reference-gpu-onnxruntime-v1.14.0-default_config/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "cTuning",
    "Platform": "aws_g4dn.xlarge.497G-reference-gpu-onnxruntime-v1.14.0-default_config",
    "Result": 12.3217,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance g4dn.xlarge",
    "SystemType": "datacenter,edge",
    "Units": "Samples/s",
    "accelerator_model_name": "Tesla T4",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Onnxruntime v1.14.0 with GPU support",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 2,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8259CL CPU @ 2.50GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Powered by MLCommons Collective Mind framework (CK2). ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-5.15.0-1028-aws-glibc2.35)",
    "uid": "771ad41bf8864121",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/cTuning/results/aws_g4dn.xlarge.497G-reference-gpu-onnxruntime-v1.14.0-default_config/bert-99/offline",
    "version": "v3.0"
  },
  {
    "Accuracy": 90.24821866958023,
    "Accuracy_div_100": 0.90248,
    "Availability": "available",
    "Division": "open",
    "Location": "open/cTuning/results/aws_g4dn.xlarge.497G-nvidia_original-gpu-tensorrt-v8.5.2.2-default_config/bert-99/offline",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "cTuning",
    "Platform": "aws_g4dn.xlarge.497G-nvidia_original-gpu-tensorrt-v8.5.2.2-default_config",
    "Result": 317.058,
    "Result_Units": "Samples/s",
    "Scenario": "Offline",
    "SystemName": "AWS cloud instance g4dn.xlarge",
    "SystemType": "datacenter,edge",
    "Units": "Samples/s",
    "accelerator_model_name": "Tesla T4",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.5.2.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 2,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8259CL CPU @ 2.50GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Powered by MLCommons Collective Mind framework (CK2). ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-5.15.0-1028-aws-glibc2.35)",
    "uid": "356d05294780412c",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/open/cTuning/results/aws_g4dn.xlarge.497G-nvidia_original-gpu-tensorrt-v8.5.2.2-default_config/bert-99/offline",
    "version": "v3.0"
  }
]
