[
  {
    "Accuracy": 92.55225596969493,
    "Accuracy_div_100": 0.92552,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/IEI/results/NF5468M6_A40x8_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "IEI",
    "Platform": "NF5468M6_A40x8_TRT",
    "Result": 37912.4,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "NF5468M6 (8x A40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A40",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8380",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5",
    "uid": "6c313f75f6534902",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/IEI/results/NF5468M6_A40x8_TRT/rnnt/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 92.56578502333763,
    "Accuracy_div_100": 0.92566,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS_521GE_TNRT_H100_PCIe_80GBX8_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Supermicro",
    "Platform": "SYS_521GE_TNRT_H100_PCIe_80GBX8_TRT",
    "Result": 100015,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "SYS-521GE-TNRT (8xH100-PCIe-80GB)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8462Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "uid": "fb10e52238fe48fd",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Supermicro/results/SYS_521GE_TNRT_H100_PCIe_80GBX8_TRT/rnnt/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 92.56578502333763,
    "Accuracy_div_100": 0.92566,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Supermicro",
    "Platform": "AS_8125GS_TNHR_H100_SXM_80GBx8_TRT",
    "Result": 172014,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "AS-8125GS-TNHR (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 9554",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2 LTS",
    "uid": "21670dd3d7934c65",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Supermicro/results/AS_8125GS_TNHR_H100_SXM_80GBx8_TRT/rnnt/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 92.5567656542425,
    "Accuracy_div_100": 0.92557,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H100-PCIe-80GBx1_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "NVIDIA",
    "Platform": "H100-PCIe-80GBx1_TRT",
    "Result": 15006.8,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Gigabyte G482-Z54 (1x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "f9db638adb344b00",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/NVIDIA/results/H100-PCIe-80GBx1_TRT/rnnt/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 92.55225596969493,
    "Accuracy_div_100": 0.92552,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/L4x1_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "NVIDIA",
    "Platform": "L4x1_TRT",
    "Result": 3754.56,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "ASROCKRACK 1U1G-MILAN (1x L4, TensorRT)",
    "SystemType": "datacenter,edge",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 7313P 16-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "b855d60b9c694796",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/NVIDIA/results/L4x1_TRT/rnnt/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 92.5680398656114,
    "Accuracy_div_100": 0.92568,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "NVIDIA",
    "Platform": "GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT",
    "Result": 24008,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "NVIDIA GH200-GraceHopper-Superchip (1x GH200-96GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA GH200-GraceHopper-Superchip",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 72,
    "host_processor_model_name": "NVIDIA Grace CPU",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "NVIDIA MGX Reference Platform",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2",
    "uid": "16c6a98ba1784355",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/NVIDIA/results/GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT/rnnt/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 92.56127533879005,
    "Accuracy_div_100": 0.92561,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H100-PCIe-80GBx8_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "NVIDIA",
    "Platform": "H100-PCIe-80GBx8_TRT",
    "Result": 100015,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Gigabyte G482-Z54 (8x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "8bd1f0fbd86941eb",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/NVIDIA/results/H100-PCIe-80GBx8_TRT/rnnt/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 92.56127533879005,
    "Accuracy_div_100": 0.92561,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "NVIDIA",
    "Platform": "DGX-H100_H100-SXM-80GBx8_TRT",
    "Result": 144022,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "NVIDIA DGX H100 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "34737ce2aba54559",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT/rnnt/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 92.5567656542425,
    "Accuracy_div_100": 0.92557,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx1_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "NVIDIA",
    "Platform": "DGX-H100_H100-SXM-80GBx1_TRT",
    "Result": 21510.7,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "NVIDIA DGX H100 (1x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "b2f5b6f7f30b4e32",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx1_TRT/rnnt/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 92.55000112742113,
    "Accuracy_div_100": 0.9255,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/CTuning/results/gcp_g2.standard.4-nvidia_original-gpu-tensorrt-vdefault-default_config/rnnt/server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "CTuning",
    "Platform": "gcp_g2.standard.4-nvidia_original-gpu-tensorrt-vdefault-default_config",
    "Result": 3654.74,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Google Cloud Platform (g2.standard.4)",
    "SystemType": "datacenter,edge",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Nvidia inference implementation with CM API, TensorRT v8.6.1.6",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 2,
    "host_processor_model_name": "Intel(R) Xeon(R) CPU @ 2.20GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Powered by MLCommons CM automation language and CK playground. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-5.19.0-1030-gcp-glibc2.35)",
    "uid": "120fba27af434361",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/CTuning/results/gcp_g2.standard.4-nvidia_original-gpu-tensorrt-vdefault-default_config/rnnt/server",
    "version": "v3.1"
  },
  {
    "Accuracy": 92.55225596969493,
    "Accuracy_div_100": 0.92552,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC4000A_E12_L4x8_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "ASUSTeK",
    "Platform": "ESC4000A_E12_L4x8_TRT",
    "Result": 30512.7,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "ESC4000A-E12 (8x L4, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9654 96-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "e69c018b432649dd",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/ASUSTeK/results/ESC4000A_E12_L4x8_TRT/rnnt/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 92.56127533879005,
    "Accuracy_div_100": 0.92561,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/H100_PCIe_80GBx8_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "ASUSTeK",
    "Platform": "H100_PCIe_80GBx8_TRT",
    "Result": 120017,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "ESC8000A-E12 (8xH100-PCIe-80GB, TensorRT",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9654 96-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "8d36ec99e6ce40dc",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/ASUSTeK/results/H100_PCIe_80GBx8_TRT/rnnt/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 92.55225596969493,
    "Accuracy_div_100": 0.92552,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Fujitsu/results/PRIMERGY_CDI_V1_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Fujitsu",
    "Platform": "PRIMERGY_CDI_V1_TRT",
    "Result": 48216.9,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "PRIMERGY_CDI_V1 (4x A100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-PCIE-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6430 CPU @ 2.10GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "GPUs are installed in an external PCIe box.",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "5f24ebd947364d9a",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Fujitsu/results/PRIMERGY_CDI_V1_TRT/rnnt/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 92.56127533879005,
    "Accuracy_div_100": 0.92561,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/Lenovo_H100_PCIe_80GBx8_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Lenovo",
    "Platform": "Lenovo_H100_PCIe_80GBx8_TRT",
    "Result": 129622,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Lenovo ThinkSystem SR675 V3 (8x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 9554 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2",
    "uid": "94ab1d38176b461d",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Lenovo/results/Lenovo_H100_PCIe_80GBx8_TRT/rnnt/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 92.55225596969493,
    "Accuracy_div_100": 0.92552,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R750xa_A100_PCIe_80GBx4_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Dell",
    "Platform": "R750xa_A100_PCIe_80GBx4_TRT",
    "Result": 49616.6,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge R750xa (4x A100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6338 CPU @ 2.00GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.1",
    "uid": "85c141d70d63438a",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Dell/results/R750xa_A100_PCIe_80GBx4_TRT/rnnt/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 92.56578502333763,
    "Accuracy_div_100": 0.92566,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R760xa_H100_PCIe_80GBx2_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Dell",
    "Platform": "R760xa_H100_PCIe_80GBx2_TRT",
    "Result": 34054.4,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge R760xa (2x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "579ae9f043ad40ad",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Dell/results/R760xa_H100_PCIe_80GBx2_TRT/rnnt/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 92.56127533879005,
    "Accuracy_div_100": 0.92561,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9640_H100_SXM_80GBx4_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Dell",
    "Platform": "XE9640_H100_SXM_80GBx4_TRT",
    "Result": 90021.9,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge XE9640 (4x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "00063c1884d945f0",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Dell/results/XE9640_H100_SXM_80GBx4_TRT/rnnt/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 92.55902049651627,
    "Accuracy_div_100": 0.92559,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R750xa_H100_PCIe_80GBx4_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Dell",
    "Platform": "R750xa_H100_PCIe_80GBx4_TRT",
    "Result": 64620.2,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge R750xa (4x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6338 CPU @ 2.00GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "NVIDIA H100-PCIe-80GB (TDP: 310W)",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.6",
    "uid": "ac47d61d2d8f4d6b",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Dell/results/R750xa_H100_PCIe_80GBx4_TRT/rnnt/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 92.56127533879005,
    "Accuracy_div_100": 0.92561,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R760xa_H100_PCIe_80GBx4_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Dell",
    "Platform": "R760xa_H100_PCIe_80GBx4_TRT",
    "Result": 68021.4,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge R760xa (4x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "6a93a245b2b94858",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Dell/results/R760xa_H100_PCIe_80GBx4_TRT/rnnt/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 92.56578502333763,
    "Accuracy_div_100": 0.92566,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9680_H100_SXM_80GBx8_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Dell",
    "Platform": "XE9680_H100_SXM_80GBx8_TRT",
    "Result": 178016,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge XE9680 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 52,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "d2a3de7d486d4cfd",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Dell/results/XE9680_H100_SXM_80GBx8_TRT/rnnt/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 92.18020699452073,
    "Accuracy_div_100": 0.9218,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/1-node-2S-SPR-PyTorch-MIX/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Dell",
    "Platform": "1-node-2S-SPR-PyTorch-MIX",
    "Result": 4204.8,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge Server R760 (1x Intel Xeon Platinum 8480+)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "PyTorch",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 112,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "CentOS Stream 8",
    "uid": "02af73be28c34f7a",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Dell/results/1-node-2S-SPR-PyTorch-MIX/rnnt/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 92.56127533879005,
    "Accuracy_div_100": 0.92561,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Dell",
    "Platform": "XE8640_H100_SXM_80GBx4_TRT",
    "Result": 96223.3,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge XE8640 (4x NVIDIA H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.1",
    "uid": "6ef6e4340e674a7e",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Dell/results/XE8640_H100_SXM_80GBx4_TRT/rnnt/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 92.54774628514735,
    "Accuracy_div_100": 0.92548,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/xFusion/results/G5500V7_A30x10_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "xFusion",
    "Platform": "G5500V7_A30x10_TRT",
    "Result": 58821.1,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "xFusion FusionServer G5500V7(10x NVIDIA A30, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 10,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6458Q @ 3.1 GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "7b5f83a09d2f46de",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/xFusion/results/G5500V7_A30x10_TRT/rnnt/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 92.55225596969493,
    "Accuracy_div_100": 0.92552,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/xFusion/results/G5500V7_L40x8_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "xFusion",
    "Platform": "G5500V7_L40x8_TRT",
    "Result": 75540.4,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "xFusion FusionServer G5500V7(8x NVIDIA L40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L40",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6458Q @ 3.1 GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "1704a0984e2f421e",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/xFusion/results/G5500V7_L40x8_TRT/rnnt/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 92.55225596969493,
    "Accuracy_div_100": 0.92552,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/xFusion/results/G5500V7_A30x8_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "xFusion",
    "Platform": "G5500V7_A30x8_TRT",
    "Result": 46517,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "xFusion FusionServer G5500V7(8x NVIDIA A30, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6458Q @ 3.1 GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "10ce4644d2ad499d",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/xFusion/results/G5500V7_A30x8_TRT/rnnt/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 92.55000112742113,
    "Accuracy_div_100": 0.9255,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/xFusion/results/L4x6_2288H_V7_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "xFusion",
    "Platform": "L4x6_2288H_V7_TRT",
    "Result": 14807.6,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "xFusion FusionServer 2288H V7(6x NVIDIA L4, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 6,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 44,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8458P CPU @ 2.7 GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "0372fed58a8f49fe",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/xFusion/results/L4x6_2288H_V7_TRT/rnnt/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 92.55225596969493,
    "Accuracy_div_100": 0.92552,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/xFusion/results/G5500V7_L40x10_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "xFusion",
    "Platform": "G5500V7_L40x10_TRT",
    "Result": 94219.3,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "xFusion FusionServer G5500V7(10x NVIDIA L40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L40",
    "accelerators_per_node": 10,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6458Q @ 3.1 GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "56afc0aa5b4b4ac4",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/xFusion/results/G5500V7_L40x10_TRT/rnnt/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 92.18020699452073,
    "Accuracy_div_100": 0.9218,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Intel/results/1-node-2S-SPR-PyTorch-MIX/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Intel",
    "Platform": "1-node-2S-SPR-PyTorch-MIX",
    "Result": 4204.8,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "1-node-2S-SPR-PyTorch-MIX",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "PyTorch",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54Q-2U",
    "number_of_nodes": 1,
    "operating_system": "CentOS Stream 8",
    "uid": "01b19623cb9e4183",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Intel/results/1-node-2S-SPR-PyTorch-MIX/rnnt/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 92.5567656542425,
    "Accuracy_div_100": 0.92557,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Oracle/results/OCI-A100_A100-SXM-80GBx8_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Oracle",
    "Platform": "OCI-A100_A100-SXM-80GBx8_TRT",
    "Result": 104012,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "BM.GPU.A100-v2.8",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7J13 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "7ea0ca32997446cb",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Oracle/results/OCI-A100_A100-SXM-80GBx8_TRT/rnnt/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 92.55000112742113,
    "Accuracy_div_100": 0.9255,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Oracle/results/A10x4_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Oracle",
    "Platform": "A10x4_TRT",
    "Result": 9202.52,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "BM.GPU.A10.4",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A10-PCI-24GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8358 CPU @ 2.60GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "e6730f78d8cd4ffd",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Oracle/results/A10x4_TRT/rnnt/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 92.56578502333763,
    "Accuracy_div_100": 0.92566,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/GigaComputing/results/GIGABYTE-G593-SD0_H100-SXM-80GBx8_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "GigaComputing",
    "Platform": "GIGABYTE-G593-SD0_H100-SXM-80GBx8_TRT",
    "Result": 180017,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "GIGABYTE G593-SD0",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "d00c1436c1e44249",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/GigaComputing/results/GIGABYTE-G593-SD0_H100-SXM-80GBx8_TRT/rnnt/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 92.55225596969493,
    "Accuracy_div_100": 0.92552,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/R5350G6_L40x8_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "H3C",
    "Platform": "R5350G6_L40x8_TRT",
    "Result": 80815.2,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "H3C UniServer R5350 G6 (8x L40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L40",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "AMD EPYC 9754 128-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5",
    "uid": "3fce68e63d4e42ff",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/H3C/results/R5350G6_L40x8_TRT/rnnt/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 92.55225596969493,
    "Accuracy_div_100": 0.92552,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/R5300G6_L40x8_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "H3C",
    "Platform": "R5300G6_L40x8_TRT",
    "Result": 81015.5,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "H3C UniServer R5300 G6 (8x L40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L40",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 44,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8458P",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5",
    "uid": "0eb8d90eb55e49cb",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/H3C/results/R5300G6_L40x8_TRT/rnnt/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 92.56127533879005,
    "Accuracy_div_100": 0.92561,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/D54Q_2U_H100_PCIe_80GBx2_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "D54Q_2U_H100_PCIe_80GBx2_TRT",
    "Result": 30013,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "D54Q_2U (2x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6430 32-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.0",
    "uid": "af2df3e3469b46df",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Quanta_Cloud_Technology/results/D54Q_2U_H100_PCIe_80GBx2_TRT/rnnt/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 92.56127533879005,
    "Accuracy_div_100": 0.92561,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/D54U_3U_H100_PCIe_80GBx4_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "D54U_3U_H100_PCIe_80GBx4_TRT",
    "Result": 60023.1,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "D54U-3U (4x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.0",
    "uid": "25999f2f962e4db4",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Quanta_Cloud_Technology/results/D54U_3U_H100_PCIe_80GBx4_TRT/rnnt/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 92.18020699452073,
    "Accuracy_div_100": 0.9218,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/1-node-2S-SPR-PyTorch-INT8/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "1-node-2S-SPR-PyTorch-INT8",
    "Result": 4104.84,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "1-node-2S-SPR-PyTorch-INT8",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": "N/A",
    "compliance": 1,
    "errors": 0,
    "framework": "PyTorch",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+ 56-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54Q-2U",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.1",
    "uid": "dfb702eda8aa4780",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Quanta_Cloud_Technology/results/1-node-2S-SPR-PyTorch-INT8/rnnt/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 92.55000112742113,
    "Accuracy_div_100": 0.9255,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/D54Q_2U_L4_PCIe_24GBx4_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "D54Q_2U_L4_PCIe_24GBx4_TRT",
    "Result": 15006.8,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "D54Q_2U (4x L4-PCIe-24GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L4-PCIe-24GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 9.0.0, CUDA 12.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6430 32-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Rocky Linux 9.0",
    "uid": "40461bcbe6aa45f5",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Quanta_Cloud_Technology/results/D54Q_2U_L4_PCIe_24GBx4_TRT/rnnt/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 92.18020699452073,
    "Accuracy_div_100": 0.9218,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/1-node-2S-SPR-PyTorch-MIX/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "HPE",
    "Platform": "1-node-2S-SPR-PyTorch-MIX",
    "Result": 4104.84,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "1-node-2S-SPR-PyTorch-MIX",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "PyTorch",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "HPE ProLiant DL380a Gen11. N/A",
    "number_of_nodes": 1,
    "operating_system": "Red Hat Enterprise Linux 8.8 (Ootpa)",
    "uid": "4e8bc8c3403f4c1a",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/HPE/results/1-node-2S-SPR-PyTorch-MIX/rnnt/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 92.5545108119687,
    "Accuracy_div_100": 0.92555,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A30x8_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "NVIDIA",
    "Platform": "A30x8_TRT",
    "Result": 36989.1,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Gigabyte G482-Z54 (8x A30, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "1af6b649c2714180",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/A30x8_TRT/rnnt/Server",
    "version": "v2.0"
  },
  {
    "Accuracy": 92.54549144287357,
    "Accuracy_div_100": 0.92545,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-A100_A100-SXM-80GB-MIG_1x1g.10gb_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "NVIDIA",
    "Platform": "DGX-A100_A100-SXM-80GB-MIG_1x1g.10gb_TRT",
    "Result": 1349.55,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "NVIDIA DGX A100 (1x A100-SXM-80GB-MIG-1x1g.10gb, TensorRT)",
    "SystemType": "datacenter,edge",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB (1x1g.10gb MIG)",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "32dedbbf76d940ea",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GB-MIG_1x1g.10gb_TRT/rnnt/Server",
    "version": "v2.0"
  },
  {
    "Accuracy": 92.53647207377844,
    "Accuracy_div_100": 0.92536,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A2x2_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "NVIDIA",
    "Platform": "A2x2_TRT",
    "Result": 1305.39,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Supermicro AS-1114S-WTRT (2x A2, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A2",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 8,
    "host_processor_model_name": "AMD EPYC 7232P 8-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "26580a6b2fe54302",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/A2x2_TRT/rnnt/Server",
    "version": "v2.0"
  },
  {
    "Accuracy": 92.55225596969493,
    "Accuracy_div_100": 0.92552,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "NVIDIA",
    "Platform": "DGX-A100_A100-SXM-80GBx8_TRT",
    "Result": 104000,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "NVIDIA DGX A100 (8x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "054289e579714690",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT/rnnt/Server",
    "version": "v2.0"
  },
  {
    "Accuracy": 92.55000112742113,
    "Accuracy_div_100": 0.9255,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A30-MIG_1x1g.6gb_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "NVIDIA",
    "Platform": "A30-MIG_1x1g.6gb_TRT",
    "Result": 1100.24,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Gigabyte G482-Z54 (1x A30-MIG-1x1g.6gb, TensorRT)",
    "SystemType": "datacenter,edge",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A30 (1x1g.6gb MIG)",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "f640ee8c4adf462f",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/A30-MIG_1x1g.6gb_TRT/rnnt/Server",
    "version": "v2.0"
  },
  {
    "Accuracy": 92.55000112742113,
    "Accuracy_div_100": 0.9255,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-A100_A100-SXM-80GB-MIG_1x1g.10gb_TRT_HeteroMultiUse/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "NVIDIA",
    "Platform": "DGX-A100_A100-SXM-80GB-MIG_1x1g.10gb_TRT_HeteroMultiUse",
    "Result": 1320.17,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "NVIDIA DGX A100 (1x A100-SXM-80GB-MIG-1x1g.10gb, TensorRT, HeteroMultiUse)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB (1x1g.10gb MIG)",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "f7cd8ce971c4485d",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GB-MIG_1x1g.10gb_TRT_HeteroMultiUse/rnnt/Server",
    "version": "v2.0"
  },
  {
    "Accuracy": 92.55000112742113,
    "Accuracy_div_100": 0.9255,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A30-MIG_1x1g.6gb_TRT_HeteroMultiUse/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "NVIDIA",
    "Platform": "A30-MIG_1x1g.6gb_TRT_HeteroMultiUse",
    "Result": 950.113,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Gigabyte G482-Z54 (1x A30-MIG-1x1g.6gb, TensorRT, HeteroMultiUse)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A30 (1x1g.6gb MIG)",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "9200529f18b14dfc",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/A30-MIG_1x1g.6gb_TRT_HeteroMultiUse/rnnt/Server",
    "version": "v2.0"
  },
  {
    "Accuracy": 92.5545108119687,
    "Accuracy_div_100": 0.92555,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A100-PCIe-80GBx8_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "NVIDIA",
    "Platform": "A100-PCIe-80GBx8_TRT",
    "Result": 89993.7,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Gigabyte G482-Z54 (8x A100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "8b7bee90c6bd4102",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/A100-PCIe-80GBx8_TRT/rnnt/Server",
    "version": "v2.0"
  },
  {
    "Accuracy": 92.5545108119687,
    "Accuracy_div_100": 0.92555,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A100-SXM-80GB_aarch64x8_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "NVIDIA",
    "Platform": "A100-SXM-80GB_aarch64x8_TRT",
    "Result": 104000,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Gigabyte G492-PD0 (8x A100-SXM-80GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 80,
    "host_processor_model_name": "Ampere Altra Q80-30",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "54bfb70a85204144",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/A100-SXM-80GB_aarch64x8_TRT/rnnt/Server",
    "version": "v2.0"
  },
  {
    "Accuracy": 92.55000112742113,
    "Accuracy_div_100": 0.9255,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-Station-A100_A100-SXM-80GBx4_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "NVIDIA",
    "Platform": "DGX-Station-A100_A100-SXM-80GBx4_TRT",
    "Result": 44989.2,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "NVIDIA DGX Station A100 (4x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "4cf6a66caf784825",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/DGX-Station-A100_A100-SXM-80GBx4_TRT/rnnt/Server",
    "version": "v2.0"
  },
  {
    "Accuracy": 92.55000112742113,
    "Accuracy_div_100": 0.9255,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A100-PCIe-80GB_aarch64x4_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "NVIDIA",
    "Platform": "A100-PCIe-80GB_aarch64x4_TRT",
    "Result": 42988.8,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Gigabyte G242-P31 (4x A100-PCIe-80GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 80,
    "host_processor_model_name": "Ampere Altra Q80-30",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "284dcf2be8214c8b",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/NVIDIA/results/A100-PCIe-80GB_aarch64x4_TRT/rnnt/Server",
    "version": "v2.0"
  },
  {
    "Accuracy": 92.55225596969493,
    "Accuracy_div_100": 0.92552,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Azure/results/NC48ads_A100_v4_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Azure",
    "Platform": "NC48ads_A100_v4_TRT",
    "Result": 22989,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "NC48ads_A100_v4 (2x A100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "AMD EPYC 7V13 64-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.6 LTS",
    "uid": "acbd7aeb44444da8",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Azure/results/NC48ads_A100_v4_TRT/rnnt/Server",
    "version": "v2.0"
  },
  {
    "Accuracy": 92.5545108119687,
    "Accuracy_div_100": 0.92555,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Azure/results/ND96amsr_A100_v4_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Azure",
    "Platform": "ND96amsr_A100_v4_TRT",
    "Result": 104999,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "ND96amsr_A100_v4 (8x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 7V12 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.6 LTS",
    "uid": "65149f06f0834aea",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Azure/results/ND96amsr_A100_v4_TRT/rnnt/Server",
    "version": "v2.0"
  },
  {
    "Accuracy": 92.5545108119687,
    "Accuracy_div_100": 0.92555,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Azure/results/ND96asr_v4_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Azure",
    "Platform": "ND96asr_v4_TRT",
    "Result": 102048,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "ND96asr_v4 (8x A100-SXM-40GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-SXM-40GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 7V12 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.6",
    "uid": "ab06900eb5964f2a",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Azure/results/ND96asr_v4_TRT/rnnt/Server",
    "version": "v2.0"
  },
  {
    "Accuracy": 92.5545108119687,
    "Accuracy_div_100": 0.92555,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Azure/results/NC96ads_A100_v4_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Azure",
    "Platform": "NC96ads_A100_v4_TRT",
    "Result": 46389.2,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "NC96ads_A100_v4 (4x A100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 7V13 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.6 LTS",
    "uid": "c239d657e92f46ff",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Azure/results/NC96ads_A100_v4_TRT/rnnt/Server",
    "version": "v2.0"
  },
  {
    "Accuracy": 92.55225596969493,
    "Accuracy_div_100": 0.92552,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Fujitsu/results/GX2460M1_A30x4_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Fujitsu",
    "Platform": "GX2460M1_A30x4_TRT",
    "Result": 17691,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "PRIMERGY GX2460M1 (4x A30, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7302",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.3 LTS",
    "uid": "e148427d86964307",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Fujitsu/results/GX2460M1_A30x4_TRT/rnnt/Server",
    "version": "v2.0"
  },
  {
    "Accuracy": 92.5545108119687,
    "Accuracy_div_100": 0.92555,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Fujitsu/results/GX2570M6_A100-SXM4-40GBx8_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Fujitsu",
    "Platform": "GX2570M6_A100-SXM4-40GBx8_TRT",
    "Result": 92496.2,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "PRIMERGY GX2570M6 (8x A100-SXM-40GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-SXM4-40GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 144,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8352V CPU @ 2.10GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.3",
    "uid": "b8e5aaae439b4bf3",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Fujitsu/results/GX2570M6_A100-SXM4-40GBx8_TRT/rnnt/Server",
    "version": "v2.0"
  },
  {
    "Accuracy": 92.56578502333763,
    "Accuracy_div_100": 0.92566,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE2420_T4x1_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Dell",
    "Platform": "XE2420_T4x1_TRT",
    "Result": 950.113,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge XE2420 (1x T4, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA T4",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 22,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6238 CPU @ 2.10GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "ECC on",
    "number_of_nodes": 1,
    "operating_system": "CentOS 8.2.2004",
    "uid": "94b2a6c722d54940",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Dell/results/XE2420_T4x1_TRT/rnnt/Server",
    "version": "v2.0"
  },
  {
    "Accuracy": 92.53421723150466,
    "Accuracy_div_100": 0.92534,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XR12_A2x1_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Dell",
    "Platform": "XR12_A2x1_TRT",
    "Result": 652.49,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge XR12 (1x A2, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A2",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6312U CPU @ 2.40GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "CentOS 8.2",
    "uid": "001a76d3b67a4886",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Dell/results/XR12_A2x1_TRT/rnnt/Server",
    "version": "v2.0"
  },
  {
    "Accuracy": 92.55000112742113,
    "Accuracy_div_100": 0.9255,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R750xa_A100_PCIE_80GBx4_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Dell",
    "Platform": "R750xa_A100_PCIE_80GBx4_TRT",
    "Result": 48485.1,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge R750xa (4x A100-PCIE-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6338 CPU @ 2.00GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "CentOS 8.2",
    "uid": "fc5994a1a7424f99",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Dell/results/R750xa_A100_PCIE_80GBx4_TRT/rnnt/Server",
    "version": "v2.0"
  },
  {
    "Accuracy": 92.55225596969493,
    "Accuracy_div_100": 0.92552,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE8545_A100_SXM_80GBx4_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Dell",
    "Platform": "XE8545_A100_SXM_80GBx4_TRT",
    "Result": 53486.2,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge XE8545 (4x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7763",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "500W A100-SXM-80GB",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.3",
    "uid": "7a3b18bab1dd42c2",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Dell/results/XE8545_A100_SXM_80GBx4_TRT/rnnt/Server",
    "version": "v2.0"
  },
  {
    "Accuracy": 92.5545108119687,
    "Accuracy_div_100": 0.92555,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/DSS8440_A100_PCIE_80GBx10_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Dell",
    "Platform": "DSS8440_A100_PCIE_80GBx10_TRT",
    "Result": 111002,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell DSS 8440 (10x NVIDIA A100-PCIE-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-PCIE-80GB",
    "accelerators_per_node": 10,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6248R CPU @ 3.00GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "CentOS 8.2",
    "uid": "658e7f648f7140b5",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Dell/results/DSS8440_A100_PCIE_80GBx10_TRT/rnnt/Server",
    "version": "v2.0"
  },
  {
    "Accuracy": 92.5545108119687,
    "Accuracy_div_100": 0.92555,
    "Availability": "rdi",
    "Division": "closed",
    "Location": "closed/Inspur/results/NF5468M6_A100-PCIe-80GBx12_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Inspur",
    "Platform": "NF5468M6_A100-PCIe-80GBx12_TRT",
    "Result": 136498,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "NF5468M6J (12x A100-PCIe, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 12,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8358",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "NF5468M6(8x A100-PCIe)+JBOG(4x A100-PCIe)",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "6b93502ded3345ac",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Inspur/results/NF5468M6_A100-PCIe-80GBx12_TRT/rnnt/Server",
    "version": "v2.0"
  },
  {
    "Accuracy": 92.5545108119687,
    "Accuracy_div_100": 0.92555,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Inspur/results/NF5688M6_A100-SXM-80GBx8_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Inspur",
    "Platform": "NF5688M6_A100-SXM-80GBx8_TRT",
    "Result": 109004,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "NF5688M6 (8x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8358",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "9e5eb2b832d442a7",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Inspur/results/NF5688M6_A100-SXM-80GBx8_TRT/rnnt/Server",
    "version": "v2.0"
  },
  {
    "Accuracy": 92.55000112742113,
    "Accuracy_div_100": 0.9255,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Inspur/results/NF5488A5_A100-SXM-80GBx8_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Inspur",
    "Platform": "NF5488A5_A100-SXM-80GBx8_TRT",
    "Result": 108001,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "NF5488A5 (8x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "725026b2604548e2",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/Inspur/results/NF5488A5_A100-SXM-80GBx8_TRT/rnnt/Server",
    "version": "v2.0"
  },
  {
    "Accuracy": 92.5545108119687,
    "Accuracy_div_100": 0.92555,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/A30_4_R4900G5_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "H3C",
    "Platform": "A30_4_R4900G5_TRT",
    "Result": 10494,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "H3C UniServer R4900 G5 (4x A30, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8380 CPU @ 2.30GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "3ef3309642394d58",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/H3C/results/A30_4_R4900G5_TRT/rnnt/Server",
    "version": "v2.0"
  },
  {
    "Accuracy": 92.5545108119687,
    "Accuracy_div_100": 0.92555,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/A100-PCIe-80GBx8_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "H3C",
    "Platform": "A100-PCIe-80GBx8_TRT",
    "Result": 95996.8,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "H3C UniServer R5300 G5 (8x A100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8380 CPU @ 2.30GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "ec7148f637d54684",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/H3C/results/A100-PCIe-80GBx8_TRT/rnnt/Server",
    "version": "v2.0"
  },
  {
    "Accuracy": 92.5545108119687,
    "Accuracy_div_100": 0.92555,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/R5500G5_A100-SXM-80GBx8_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "H3C",
    "Platform": "R5500G5_A100-SXM-80GBx8_TRT",
    "Result": 104499,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "H3C UniServer R5500 G5 (8x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8380 CPU @ 2.30GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "400W_A100-SXM-80GB",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "c6ac26c17ed74ee3",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/H3C/results/R5500G5_A100-SXM-80GBx8_TRT/rnnt/Server",
    "version": "v2.0"
  },
  {
    "Accuracy": 92.55000112742113,
    "Accuracy_div_100": 0.9255,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/A30x8_Custom_R5300G5_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "H3C",
    "Platform": "A30x8_Custom_R5300G5_TRT",
    "Result": 36487.7,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "H3C UniServer R5300 G5 (8x A30, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.0",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8380 CPU @ 2.30GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "d4eca6b19ab04126",
    "url": "https://github.com/mlcommons/inference_results_v2.0/tree/master/closed/H3C/results/A30x8_Custom_R5300G5_TRT/rnnt/Server",
    "version": "v2.0"
  },
  {
    "Accuracy": 92.5545108119687,
    "Accuracy_div_100": 0.92555,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/AS-4124GS-TNR_8_A100-PCIe-80GB_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Supermicro",
    "Platform": "AS-4124GS-TNR_8_A100-PCIe-80GB_TRT",
    "Result": 90004.9,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "AS-4124GS-TNR (8xA100-PCIe-80GB)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7713 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "8a0ac02a72c94d04",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/Supermicro/results/AS-4124GS-TNR_8_A100-PCIe-80GB_TRT/rnnt/Server",
    "version": "v2.1"
  },
  {
    "Accuracy": 92.55000112742113,
    "Accuracy_div_100": 0.9255,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-A100_A100-SXM-80GB-MIG_1x1g.10gb_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "NVIDIA",
    "Platform": "DGX-A100_A100-SXM-80GB-MIG_1x1g.10gb_TRT",
    "Result": 1347.28,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "NVIDIA DGX A100 (1x A100-SXM-80GB-MIG-1x1g.10gb, TensorRT)",
    "SystemType": "datacenter,edge",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB (1x1g.10gb MIG)",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "c96832d4a6c541b3",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GB-MIG_1x1g.10gb_TRT/rnnt/Server",
    "version": "v2.1"
  },
  {
    "Accuracy": 92.5545108119687,
    "Accuracy_div_100": 0.92555,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "NVIDIA",
    "Platform": "DGX-A100_A100-SXM-80GBx8_TRT",
    "Result": 104020,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "NVIDIA DGX A100 (8x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "4f5bc9f3908a4d7c",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT/rnnt/Server",
    "version": "v2.1"
  },
  {
    "Accuracy": 92.55902049651627,
    "Accuracy_div_100": 0.92559,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H100-SXM-80GBx1_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "NVIDIA",
    "Platform": "H100-SXM-80GBx1_TRT",
    "Result": 21487.9,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "NVIDIA H100 (1x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.5.0, CUDA 11.8",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 7252 8-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Private git branch used to produce all NVIDIA H100 results. The git hash of the private branch is 35fc4b9a7758edc6063bb3a4ba4bfa94ce7aa9e1",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "7dd059e3156c4ea4",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/NVIDIA/results/H100-SXM-80GBx1_TRT/rnnt/Server",
    "version": "v2.1"
  },
  {
    "Accuracy": 92.55000112742113,
    "Accuracy_div_100": 0.9255,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A100-PCIe-80GBx8_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "NVIDIA",
    "Platform": "A100-PCIe-80GBx8_TRT",
    "Result": 90004.9,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Gigabyte G482-Z54 (8x A100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "f82ea01306dc4712",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/NVIDIA/results/A100-PCIe-80GBx8_TRT/rnnt/Server",
    "version": "v2.1"
  },
  {
    "Accuracy": 92.54549144287357,
    "Accuracy_div_100": 0.92545,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC4000_A2x8_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "ASUSTeK",
    "Platform": "ESC4000_A2x8_TRT",
    "Result": 7394.06,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "ASUS ESC4000-E10S (8x A2, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A2",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 8,
    "host_processor_model_name": " Intel(R) Xeon(R) Platinum 8352M 32-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "cce24221c8714081",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/ASUSTeK/results/ESC4000_A2x8_TRT/rnnt/Server",
    "version": "v2.1"
  },
  {
    "Accuracy": 92.5545108119687,
    "Accuracy_div_100": 0.92555,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/A100-PCIe-80GBx8_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "ASUSTeK",
    "Platform": "A100-PCIe-80GBx8_TRT",
    "Result": 98511.9,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "ASUS ESC8000A-E11 (8x A100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7763 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "459ca4265568445d",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/ASUSTeK/results/A100-PCIe-80GBx8_TRT/rnnt/Server",
    "version": "v2.1"
  },
  {
    "Accuracy": 92.5545108119687,
    "Accuracy_div_100": 0.92555,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Azure/results/ND96amsr_A100_v4_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Azure",
    "Platform": "ND96amsr_A100_v4_TRT",
    "Result": 104020,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "ND96amsr_A100_v4 (8x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 7V12 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.6 LTS",
    "uid": "c50f79a3f53b40e5",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/Azure/results/ND96amsr_A100_v4_TRT/rnnt/Server",
    "version": "v2.1"
  },
  {
    "Accuracy": 92.54549144287357,
    "Accuracy_div_100": 0.92545,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Azure/results/NV72ads_A10_v5_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Azure",
    "Platform": "NV72ads_A10_v5_TRT",
    "Result": 6993.5,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "NV72ads_A10_v5 (2x NVIDIA A10-24Q, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A10-24Q",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2.3, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "AMD EPYC 74F3 24-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.6 LTS",
    "uid": "469b855920bc4b76",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/Azure/results/NV72ads_A10_v5_TRT/rnnt/Server",
    "version": "v2.1"
  },
  {
    "Accuracy": 92.5545108119687,
    "Accuracy_div_100": 0.92555,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Azure/results/NC96ads_A100_v4_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Azure",
    "Platform": "NC96ads_A100_v4_TRT",
    "Result": 46396.4,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "NC96ads_A100_v4 (4x A100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 7V13 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.6 LTS",
    "uid": "7640aca502fa40e8",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/Azure/results/NC96ads_A100_v4_TRT/rnnt/Server",
    "version": "v2.1"
  },
  {
    "Accuracy": 92.5545108119687,
    "Accuracy_div_100": 0.92555,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/A100-PCIe-80GBx8_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Lenovo",
    "Platform": "A100-PCIe-80GBx8_TRT",
    "Result": 90004.9,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Lenovo SR670v2 (8x A100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 36,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8360Y CPU @ 2.40GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "eedb1c2922594d25",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/Lenovo/results/A100-PCIe-80GBx8_TRT/rnnt/Server",
    "version": "v2.1"
  },
  {
    "Accuracy": 92.55000112742113,
    "Accuracy_div_100": 0.9255,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/A100_SXM_80GBx4_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Lenovo",
    "Platform": "A100_SXM_80GBx4_TRT",
    "Result": 51997.9,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Lenovo SR670v2 (4x A100-SXM-80GB_aarch64, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 36,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8360Y CPU @ 2.40GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "d7ccec3bc19545cd",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/Lenovo/results/A100_SXM_80GBx4_TRT/rnnt/Server",
    "version": "v2.1"
  },
  {
    "Accuracy": 92.5545108119687,
    "Accuracy_div_100": 0.92555,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R750xa_A100_PCIE_80GBx4_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Dell",
    "Platform": "R750xa_A100_PCIE_80GBx4_TRT",
    "Result": 49592.9,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge R750xa (4x A100-PCIE-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6338 CPU @ 2.00GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "CentOS 8.2",
    "uid": "0e723448cd8246aa",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/Dell/results/R750xa_A100_PCIE_80GBx4_TRT/rnnt/Server",
    "version": "v2.1"
  },
  {
    "Accuracy": 92.5545108119687,
    "Accuracy_div_100": 0.92555,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE8545_A100_SXM_80GBx4_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Dell",
    "Platform": "XE8545_A100_SXM_80GBx4_TRT",
    "Result": 55197.7,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge XE8545 (4x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB CTS",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7763",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "NVIDIA A100-SXM-80GB (TDP: 500W)",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "845e31879fcd49cf",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/Dell/results/XE8545_A100_SXM_80GBx4_TRT/rnnt/Server",
    "version": "v2.1"
  },
  {
    "Accuracy": 92.5545108119687,
    "Accuracy_div_100": 0.92555,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/GIGABYTE/results/G492-ID0_A100-SXM-80GBx8_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "GIGABYTE",
    "Platform": "G492-ID0_A100-SXM-80GBx8_TRT",
    "Result": 108514,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "G492-ID0 (8x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.7",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8380",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.3",
    "uid": "d3e611a295df4251",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/GIGABYTE/results/G492-ID0_A100-SXM-80GBx8_TRT/rnnt/Server",
    "version": "v2.1"
  },
  {
    "Accuracy": 92.55225596969493,
    "Accuracy_div_100": 0.92552,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Nettrix/results/A100_SXM4_80GBx8_Custom_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Nettrix",
    "Platform": "A100_SXM4_80GBx8_Custom_TRT",
    "Result": 109913,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "X660G45L (8x A100-SXM4-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-SXM4-80GB CTS",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 38,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8368Q",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "NVIDIA A100-SXM4-80GB (TDP:500W)",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "4b267d66f0c34804",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/Nettrix/results/A100_SXM4_80GBx8_Custom_TRT/rnnt/Server",
    "version": "v2.1"
  },
  {
    "Accuracy": 92.53872691605223,
    "Accuracy_div_100": 0.92539,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/A2x5_R4900G5_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "H3C",
    "Platform": "A2x5_R4900G5_TRT",
    "Result": 3996.74,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "H3C UniServer R4900 G5(5x A2, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A2",
    "accelerators_per_node": 5,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8380 CPU @ 2.30GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "dbe9d971b619485b",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/H3C/results/A2x5_R4900G5_TRT/rnnt/Server",
    "version": "v2.1"
  },
  {
    "Accuracy": 92.55225596969493,
    "Accuracy_div_100": 0.92552,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/R5300G5_A30x8_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "H3C",
    "Platform": "R5300G5_A30x8_TRT",
    "Result": 39396.2,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "H3C UniServer R5300 G5 (8x A30, TensorRT, Triton)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8362 CPU @ 2.80GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "814623ca3a154181",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/H3C/results/R5300G5_A30x8_TRT/rnnt/Server",
    "version": "v2.1"
  },
  {
    "Accuracy": 92.55225596969493,
    "Accuracy_div_100": 0.92552,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/A30x3_R4900G5_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "H3C",
    "Platform": "A30x3_R4900G5_TRT",
    "Result": 12994.7,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "H3C UniServer R4900 G5(3x A30, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 3,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8380 CPU @ 2.30GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "a55797982e2f4a22",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/H3C/results/A30x3_R4900G5_TRT/rnnt/Server",
    "version": "v2.1"
  },
  {
    "Accuracy": 92.55225596969493,
    "Accuracy_div_100": 0.92552,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/R5500G5_Intel_A100_A100-SXM-80GBx8_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "H3C",
    "Platform": "R5500G5_Intel_A100_A100-SXM-80GBx8_TRT",
    "Result": 107914,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "H3C UniServer R5500 G5 Intel (8x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8378A",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "eb8c8d2562df4e7f",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/H3C/results/R5500G5_Intel_A100_A100-SXM-80GBx8_TRT/rnnt/Server",
    "version": "v2.1"
  },
  {
    "Accuracy": 92.55225596969493,
    "Accuracy_div_100": 0.92552,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/A100-PCIe-80GBx3_R4900G5_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "H3C",
    "Platform": "A100-PCIe-80GBx3_R4900G5_TRT",
    "Result": 33289.3,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "H3C UniServer R4900 G5(3x A100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 3,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8380 CPU @ 2.30GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "24bc39fff6f448b7",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/H3C/results/A100-PCIe-80GBx3_R4900G5_TRT/rnnt/Server",
    "version": "v2.1"
  },
  {
    "Accuracy": 92.5545108119687,
    "Accuracy_div_100": 0.92555,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/R5500G5_AMD_A100_A100-SXM-80GBx8_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "H3C",
    "Platform": "R5500G5_AMD_A100_A100-SXM-80GBx8_TRT",
    "Result": 107515,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "H3C UniServer R5500 G5 AMD (8x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7773X",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "1a96abc15e1c4b9e",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/H3C/results/R5500G5_AMD_A100_A100-SXM-80GBx8_TRT/rnnt/Server",
    "version": "v2.1"
  },
  {
    "Accuracy": 92.5545108119687,
    "Accuracy_div_100": 0.92555,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/R5300G5_A100_SXM_80GBx4_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "H3C",
    "Platform": "R5300G5_A100_SXM_80GBx4_TRT",
    "Result": 44998.2,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "H3C UniServer R5300 G5(4x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8362 CPU @ 2.80GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "9810a135f47e4303",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/H3C/results/R5300G5_A100_SXM_80GBx4_TRT/rnnt/Server",
    "version": "v2.1"
  },
  {
    "Accuracy": 92.5567656542425,
    "Accuracy_div_100": 0.92557,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/R5300G5_A100_PCIE_80GBX4_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "H3C",
    "Platform": "R5300G5_A100_PCIE_80GBX4_TRT",
    "Result": 47797.4,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "H3C UniServer R5300 G5 (4x A100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.2, CUDA 11.5",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8362 CPU @ 2.80GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "2a13ca4d59474a2c",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/H3C/results/R5300G5_A100_PCIE_80GBX4_TRT/rnnt/Server",
    "version": "v2.1"
  },
  {
    "Accuracy": 92.55225596969493,
    "Accuracy_div_100": 0.92552,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/Apollo_6500_gen10_plus_A100-SXM-40GBx4_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "HPE",
    "Platform": "Apollo_6500_gen10_plus_A100-SXM-40GBx4_TRT",
    "Result": 47997.8,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "HPE Apollo 6500 Gen10+ (645d - 4x A100 SXM 40GB)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-SXM-40GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7702",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "RHEL 8.5",
    "uid": "f9879109e10c4114",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/HPE/results/Apollo_6500_gen10_plus_A100-SXM-40GBx4_TRT/rnnt/Server",
    "version": "v2.1"
  },
  {
    "Accuracy": 92.55000112742113,
    "Accuracy_div_100": 0.9255,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/Apollo_6500_gen10_plus_A100-SXM-80GB-MIG_1x1g.10gb_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "HPE",
    "Platform": "Apollo_6500_gen10_plus_A100-SXM-80GB-MIG_1x1g.10gb_TRT",
    "Result": 1347.28,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "HPE Apollo 6500 Gen10+ (675d - 8x A100-SXM-80GB-MIG-1x1g.10gb), TensorRT",
    "SystemType": "datacenter,edge",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB (1x1g.10gb MIG)",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.4.0, CUDA 11.6",
    "git_url": "https://github.com/mlcommons/inference_results_v2.1",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7763",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "RHEL 8.5",
    "uid": "b1cf659ac7c64c3b",
    "url": "https://github.com/mlcommons/inference_results_v2.1/tree/master/closed/HPE/results/Apollo_6500_gen10_plus_A100-SXM-80GB-MIG_1x1g.10gb_TRT/rnnt/Server",
    "version": "v2.1"
  },
  {
    "Accuracy": 92.56353018106384,
    "Accuracy_div_100": 0.92564,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS-741GE-TNRT_4_H100-PCIe-80GB_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Supermicro",
    "Platform": "SYS-741GE-TNRT_4_H100-PCIe-80GB_TRT",
    "Result": 65001.7,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "SYS-741GE-TNRT (4xH100-PCIe-80GB)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6448Y",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5",
    "uid": "f04aca04c1654933",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Supermicro/results/SYS-741GE-TNRT_4_H100-PCIe-80GB_TRT/rnnt/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 92.56353018106384,
    "Accuracy_div_100": 0.92564,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/SYS-221HE-FTNR-DATACENTER_2_H100-PCIe-80GB_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Supermicro",
    "Platform": "SYS-221HE-FTNR-DATACENTER_2_H100-PCIe-80GB_TRT",
    "Result": 30006.6,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "SYS-221HE-FTNR (2xH100-PCIe-80GB)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 48,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8468",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "71a742ed56b3459b",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Supermicro/results/SYS-221HE-FTNR-DATACENTER_2_H100-PCIe-80GB_TRT/rnnt/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 92.56578502333763,
    "Accuracy_div_100": 0.92566,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Supermicro/results/AS-4125GS-TNRT_8_H100-PCIe-80GB_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Supermicro",
    "Platform": "AS-4125GS-TNRT_8_H100-PCIe-80GB_TRT",
    "Result": 125004,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "AS-4125GS-TNRT (8xH100-PCIe-80GB)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 9174F 16-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2",
    "uid": "a0609531ec474d24",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Supermicro/results/AS-4125GS-TNRT_8_H100-PCIe-80GB_TRT/rnnt/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 92.56353018106384,
    "Accuracy_div_100": 0.92564,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H100-PCIe-80GBx1_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "NVIDIA",
    "Platform": "H100-PCIe-80GBx1_TRT",
    "Result": 14997.7,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Gigabyte G482-Z54 (1x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "5b8d6df5cbf34d8a",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/NVIDIA/results/H100-PCIe-80GBx1_TRT/rnnt/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 92.540981758326,
    "Accuracy_div_100": 0.92541,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/L4x1_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "NVIDIA",
    "Platform": "L4x1_TRT",
    "Result": 3800.6,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "NVIDIA L4 (1x L4, TensorRT)",
    "SystemType": "datacenter,edge",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "AMD EPYC 7313P 16-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "da4355a74e1148fe",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/NVIDIA/results/L4x1_TRT/rnnt/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 92.56578502333763,
    "Accuracy_div_100": 0.92566,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/H100-PCIe-80GBx8_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "NVIDIA",
    "Platform": "H100-PCIe-80GBx8_TRT",
    "Result": 100001,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Gigabyte G482-Z54 (8x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "b9a9c3b0aefc47f3",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/NVIDIA/results/H100-PCIe-80GBx8_TRT/rnnt/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 92.5545108119687,
    "Accuracy_div_100": 0.92555,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "NVIDIA",
    "Platform": "DGX-A100_A100-SXM-80GBx8_TRT",
    "Result": 104000,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "NVIDIA DGX A100 (8x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "efb85f4a8c02467b",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT/rnnt/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 92.56578502333763,
    "Accuracy_div_100": 0.92566,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "NVIDIA",
    "Platform": "DGX-H100_H100-SXM-80GBx8_TRT",
    "Result": 144006,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "NVIDIA DGX H100 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "08b4d6841c25459c",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx8_TRT/rnnt/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 92.56127533879005,
    "Accuracy_div_100": 0.92561,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx1_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "NVIDIA",
    "Platform": "DGX-H100_H100-SXM-80GBx1_TRT",
    "Result": 21506,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "NVIDIA DGX H100 (1x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480C",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "072a67914d304622",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/NVIDIA/results/DGX-H100_H100-SXM-80GBx1_TRT/rnnt/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 92.5545108119687,
    "Accuracy_div_100": 0.92555,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/NVIDIA/results/A100-PCIe-80GBx8_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "NVIDIA",
    "Platform": "A100-PCIe-80GBx8_TRT",
    "Result": 89999.2,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Gigabyte G482-Z54 (8x A100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7742 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "bf9af52420a24064",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/NVIDIA/results/A100-PCIe-80GBx8_TRT/rnnt/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 92.54323660059978,
    "Accuracy_div_100": 0.92543,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/ESC4000A_E12_L4x8_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "ASUSTeK",
    "Platform": "ESC4000A_E12_L4x8_TRT",
    "Result": 30110,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "ASUS ESC4000A-E12 (8x L4, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 9654 96-Core Processor",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "01f87f2c48b64003",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/ASUSTeK/results/ESC4000A_E12_L4x8_TRT/rnnt/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 92.56353018106384,
    "Accuracy_div_100": 0.92564,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/ASUSTeK/results/H100_PCIe_80GBx8_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "ASUSTeK",
    "Platform": "H100_PCIe_80GBx8_TRT",
    "Result": 102400,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "ESC8000-E12 (8xH100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8460Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "3f9e20e21ab246cd",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/ASUSTeK/results/H100_PCIe_80GBx8_TRT/rnnt/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 92.55225596969493,
    "Accuracy_div_100": 0.92552,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Azure/results/NC96ads_A100_v4_MIG_1g_10gb_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Azure",
    "Platform": "NC96ads_A100_v4_MIG_1g_10gb_TRT",
    "Result": 998.427,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "NC96ads_A100_v4 (4x A100-PCIe-80GB-MIG-1x1g.10gb, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB (1x1g.10gb MIG)",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 7V13 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5 LTS",
    "uid": "68c26938098849ca",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Azure/results/NC96ads_A100_v4_MIG_1g_10gb_TRT/rnnt/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 92.5545108119687,
    "Accuracy_div_100": 0.92555,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Azure/results/NC96ads_A100_v4_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Azure",
    "Platform": "NC96ads_A100_v4_TRT",
    "Result": 47801,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "NC96ads_A100_v4 (4x A100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 96,
    "host_processor_model_name": "AMD EPYC 7V13 64-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5 LTS",
    "uid": "896047368eac4821",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Azure/results/NC96ads_A100_v4_TRT/rnnt/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 92.55000112742113,
    "Accuracy_div_100": 0.9255,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Lenovo/results/A100-PCIe-80GBx8_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Lenovo",
    "Platform": "A100-PCIe-80GBx8_TRT",
    "Result": 98598.9,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Lenovo ThinkSystem SR670 V2 Server with 8x 80GB PCIe A100",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "NGC MLPerf v3.0.2",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 36,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8360Y CPU @ 2.40GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Air Cooling",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04.2 LTS",
    "uid": "e6a340c79af240ec",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Lenovo/results/A100-PCIe-80GBx8_TRT/rnnt/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 92.56578502333763,
    "Accuracy_div_100": 0.92566,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/vR750xa_H100_PCIe_80Cx2_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Dell",
    "Platform": "vR750xa_H100_PCIe_80Cx2_TRT",
    "Result": 31131.2,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge R750xa, VMware vSphere 8.0.1 (2x H100-80C, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-80C",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8358 CPU @ 2.60GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": " VM Specifications 16 vCPU out of 128 available, 128GB of memory out of available 256GB ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4 on VMware ESXi, 8.0.1",
    "uid": "debbbb914f724036",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Dell/results/vR750xa_H100_PCIe_80Cx2_TRT/rnnt/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 92.55225596969493,
    "Accuracy_div_100": 0.92552,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XR4520c_A30x1_TRT_DATACENTER/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Dell",
    "Platform": "XR4520c_A30x1_TRT_DATACENTER",
    "Result": 5101.18,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge XR4520c (1x A30, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 16,
    "host_processor_model_name": "Intel(R) Xeon(R) D-2776NT CPU @ 2.10GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "2b3ac7e06dc64268",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Dell/results/XR4520c_A30x1_TRT_DATACENTER/rnnt/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 92.56578502333763,
    "Accuracy_div_100": 0.92566,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R750xa_H100_PCIe_80GBx4_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Dell",
    "Platform": "R750xa_H100_PCIe_80GBx4_TRT",
    "Result": 64101,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge R750xa (4x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6338 CPU @ 2.00GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "NVIDIA H100-PCIe-80GB (TDP: 310W)",
    "number_of_nodes": 1,
    "operating_system": "CentOS 8.2",
    "uid": "9b58f56c33ad48bd",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Dell/results/R750xa_H100_PCIe_80GBx4_TRT/rnnt/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 92.55225596969493,
    "Accuracy_div_100": 0.92552,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/vXE8545_A100_SXM_80GBx4_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Dell",
    "Platform": "vXE8545_A100_SXM_80GBx4_TRT",
    "Result": 51001.8,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge XE8545, VMware vSphere 8.0.1 (4x A100-SXM-80C, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80C",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 128,
    "host_processor_model_name": "AMD EPYC 7543",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "VMware vSphere 8.0.1, Ubuntu 20.04.2",
    "uid": "d1f92945c1454f79",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Dell/results/vXE8545_A100_SXM_80GBx4_TRT/rnnt/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 92.56353018106384,
    "Accuracy_div_100": 0.92564,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R750xa_H100_PCIe_80GBx2_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Dell",
    "Platform": "R750xa_H100_PCIe_80GBx2_TRT",
    "Result": 32004.5,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge R750xa (2x H100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6338 CPU @ 2.00GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "NVIDIA H100-PCIe-80GB (TDP: 310W)",
    "number_of_nodes": 1,
    "operating_system": "CentOS 8.2",
    "uid": "93c37e99b7e4457a",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Dell/results/R750xa_H100_PCIe_80GBx2_TRT/rnnt/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 92.5545108119687,
    "Accuracy_div_100": 0.92555,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE8545_A100_SXM4_80GBx4_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Dell",
    "Platform": "XE8545_A100_SXM4_80GBx4_TRT",
    "Result": 54000.4,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge XE8545 (4x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB CTS",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "AMD EPYC 7763",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "NVIDIA A100-SXM4-80GB (TDP: 500W)",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "8bb1fc9751084eba",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Dell/results/XE8545_A100_SXM4_80GBx4_TRT/rnnt/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 92.56578502333763,
    "Accuracy_div_100": 0.92566,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9680_H100_SXM_80GBx8_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Dell",
    "Platform": "XE9680_H100_SXM_80GBx8_TRT",
    "Result": 180018,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge XE9680 (8x H100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-SXM-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 52,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "f148050d59894840",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Dell/results/XE9680_H100_SXM_80GBx8_TRT/rnnt/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 92.55225596969493,
    "Accuracy_div_100": 0.92552,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/R750xa_A100_PCIE_80GBx4_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Dell",
    "Platform": "R750xa_A100_PCIE_80GBx4_TRT",
    "Result": 48500.3,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge R750xa (4x A100-PCIe-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 64,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6338 CPU @ 2.00GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "CentOS 8.2",
    "uid": "d653b7a6f6444486",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Dell/results/R750xa_A100_PCIE_80GBx4_TRT/rnnt/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 92.55225596969493,
    "Accuracy_div_100": 0.92552,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/XE9680_A100_SXM4_80GBx8_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Dell",
    "Platform": "XE9680_A100_SXM4_80GBx8_TRT",
    "Result": 109005,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge XE9680 (8x A100-SXM-80GB, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB CTS",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 52,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8470",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "NVIDIA A100-SXM4-80GB (TDP: 500W)",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "51b2b16f32384aef",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Dell/results/XE9680_A100_SXM4_80GBx8_TRT/rnnt/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 92.18020699452073,
    "Accuracy_div_100": 0.9218,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Dell/results/1-node-2S-SPR-PyTorch-MIX/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Dell",
    "Platform": "1-node-2S-SPR-PyTorch-MIX",
    "Result": 4101.58,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "Dell PowerEdge Server R760 (1x Intel Xeon Platinum 8480+)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "PyTorch",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 224,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "CentOS Stream 8",
    "uid": "64e0316a1fdc4767",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Dell/results/1-node-2S-SPR-PyTorch-MIX/rnnt/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 92.5545108119687,
    "Accuracy_div_100": 0.92555,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/xFusion/results/G5500V7_A30x10_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "xFusion",
    "Platform": "G5500V7_A30x10_TRT",
    "Result": 44003.5,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "xFusion FusionServer G5500V7(10x NVIDIA A30, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 10,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 44,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8458P CPU @ 2.7 GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "928c6dbed65b4c16",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/xFusion/results/G5500V7_A30x10_TRT/rnnt/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 92.5545108119687,
    "Accuracy_div_100": 0.92555,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/xFusion/results/G5500V7_L40x8_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "xFusion",
    "Platform": "G5500V7_L40x8_TRT",
    "Result": 76501.8,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "xFusion FusionServer G5500V7(8x NVIDIA L40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L40",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 44,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8458P CPU @ 2.7 GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "6a450175e35f4771",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/xFusion/results/G5500V7_L40x8_TRT/rnnt/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 92.5545108119687,
    "Accuracy_div_100": 0.92555,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/xFusion/results/G5500V7_A30x8_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "xFusion",
    "Platform": "G5500V7_A30x8_TRT",
    "Result": 32104.3,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "xFusion FusionServer G5500V7(8x NVIDIA A30, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 44,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8458P CPU @ 2.7 GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "47b01ab288cc4427",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/xFusion/results/G5500V7_A30x8_TRT/rnnt/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 92.54323660059978,
    "Accuracy_div_100": 0.92543,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/xFusion/results/L4x6_2288H_V7_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "xFusion",
    "Platform": "L4x6_2288H_V7_TRT",
    "Result": 6001.92,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "xFusion FusionServer 2288H V7(6x NVIDIA L4, TensorRT)",
    "SystemType": "datacenter,edge",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 6,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 44,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8458P CPU @ 2.7 GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "cfe2b72c05434f77",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/xFusion/results/L4x6_2288H_V7_TRT/rnnt/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 92.5545108119687,
    "Accuracy_div_100": 0.92555,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/xFusion/results/G5500V7_L40x10_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "xFusion",
    "Platform": "G5500V7_L40x10_TRT",
    "Result": 95299.3,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "xFusion FusionServer G5500V7(10x NVIDIA L40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L40",
    "accelerators_per_node": 10,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 44,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8458P CPU @ 2.7 GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "22740d1b63d142c2",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/xFusion/results/G5500V7_L40x10_TRT/rnnt/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 92.56578502333763,
    "Accuracy_div_100": 0.92566,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/GIGABYTE/results/GIGABYTE-G493-SB0_H100-PCIe-80GBx8_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "GIGABYTE",
    "Platform": "GIGABYTE-G493-SB0_H100-PCIe-80GBx8_TRT",
    "Result": 120002,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "GIGABYTE G493-SB0",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA H100-PCIe-80GB",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.4",
    "uid": "e210974fc03442b7",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/GIGABYTE/results/GIGABYTE-G493-SB0_H100-PCIe-80GBx8_TRT/rnnt/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 92.18020699452073,
    "Accuracy_div_100": 0.9218,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Intel/results/1-node-2S-SPR-PyTorch-MIX/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Intel",
    "Platform": "1-node-2S-SPR-PyTorch-MIX",
    "Result": 4252.12,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "1-node-2S-SPR-PyTorch-INT8",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "PyTorch",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "QuantaGrid D54Q-2U",
    "number_of_nodes": 2,
    "operating_system": "CentOS Stream 8",
    "uid": "96da673f35ef4361",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Intel/results/1-node-2S-SPR-PyTorch-MIX/rnnt/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 92.5545108119687,
    "Accuracy_div_100": 0.92555,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Nettrix/results/L40x8_Custom_X640_G40_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Nettrix",
    "Platform": "L40x8_Custom_X640_G40_TRT",
    "Result": 72961.4,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "X640 G40 (8xL40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L40",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8380",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "009148da3fa949ec",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/L40x8_Custom_X640_G40_TRT/rnnt/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 92.55225596969493,
    "Accuracy_div_100": 0.92552,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Nettrix/results/A40X3_CUSTOM_X620_G50_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Nettrix",
    "Platform": "A40X3_CUSTOM_X620_G50_TRT",
    "Result": 6823.5,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "X620 G50 (3x A40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A40",
    "accelerators_per_node": 3,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "87353813adf14681",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/A40X3_CUSTOM_X620_G50_TRT/rnnt/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 92.5545108119687,
    "Accuracy_div_100": 0.92555,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/Nettrix/results/A30x8_Custom_X640_G50_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Nettrix",
    "Platform": "A30x8_Custom_X640_G50_TRT",
    "Result": 34305.2,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "X640 G50 (8x A30, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "4d9bab3b349a4758",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/A30x8_Custom_X640_G50_TRT/rnnt/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 92.53421723150466,
    "Accuracy_div_100": 0.92534,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/Nettrix/results/L4x8_Custom_X640_G40_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Nettrix",
    "Platform": "L4x8_Custom_X640_G40_TRT",
    "Result": 29705.9,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "X640 G40 (8x L4, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 38,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8368",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "9667b53c90884f35",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/L4x8_Custom_X640_G40_TRT/rnnt/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 92.5545108119687,
    "Accuracy_div_100": 0.92555,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Nettrix/results/L40x3_Custom_X620_G40_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Nettrix",
    "Platform": "L40x3_Custom_X620_G40_TRT",
    "Result": 27906.6,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "X620 G40 (3xL40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L40",
    "accelerators_per_node": 3,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 28,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6348",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "2f7b3679471c4b5e",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/L40x3_Custom_X620_G40_TRT/rnnt/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 92.54774628514735,
    "Accuracy_div_100": 0.92548,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Nettrix/results/L40x3_Custom_X620_G50_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Nettrix",
    "Platform": "L40x3_Custom_X620_G50_TRT",
    "Result": 28106.5,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "X620 G50 (3xL40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L40",
    "accelerators_per_node": 3,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6442Y",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "caa0afc677884810",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/L40x3_Custom_X620_G50_TRT/rnnt/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 92.5545108119687,
    "Accuracy_div_100": 0.92555,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Nettrix/results/A40X8_CUSTOM_X640_G40_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Nettrix",
    "Platform": "A40X8_CUSTOM_X640_G40_TRT",
    "Result": 28506.3,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "X640 G40 (8x A40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A40",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 38,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8368",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "2d66fec6602445dd",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/A40X8_CUSTOM_X640_G40_TRT/rnnt/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 92.55000112742113,
    "Accuracy_div_100": 0.9255,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Nettrix/results/A30x3_Custom_X620_G40_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Nettrix",
    "Platform": "A30x3_Custom_X620_G40_TRT",
    "Result": 7603.42,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "X620 G40 (3x A30, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 3,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 28,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6348 CPU @ 2.60GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "8601825b3f734b3c",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/A30x3_Custom_X620_G40_TRT/rnnt/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 92.54774628514735,
    "Accuracy_div_100": 0.92548,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/Nettrix/results/L4x4_Custom_X620_G40_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Nettrix",
    "Platform": "L4x4_Custom_X620_G40_TRT",
    "Result": 14947.4,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "X620 G40 (4x L4, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 28,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6348",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "21deb70e777e427e",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/L4x4_Custom_X620_G40_TRT/rnnt/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 92.54774628514735,
    "Accuracy_div_100": 0.92548,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Nettrix/results/A30x4_Custom_X620_G50_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Nettrix",
    "Platform": "A30x4_Custom_X620_G50_TRT",
    "Result": 11998.2,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "X620 G50 (4x A30, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 44,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8458P",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "12f63c62a6354e00",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/A30x4_Custom_X620_G50_TRT/rnnt/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 92.5545108119687,
    "Accuracy_div_100": 0.92555,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/Nettrix/results/L40x8_Custom_X640_G50_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Nettrix",
    "Platform": "L40x8_Custom_X640_G50_TRT",
    "Result": 74480.6,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "X640 G50 (8xL40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L40",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "30bfe27135de4ad0",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/L40x8_Custom_X640_G50_TRT/rnnt/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 92.5545108119687,
    "Accuracy_div_100": 0.92555,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/Nettrix/results/A40X8_CUSTOM_X640_G50_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Nettrix",
    "Platform": "A40X8_CUSTOM_X640_G50_TRT",
    "Result": 28016.3,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "X640 G50 (8x A40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A40",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "92c3e7fa76134aa8",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/A40X8_CUSTOM_X640_G50_TRT/rnnt/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 92.5545108119687,
    "Accuracy_div_100": 0.92555,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Nettrix/results/A30x8_Custom_X640_G40_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Nettrix",
    "Platform": "A30x8_Custom_X640_G40_TRT",
    "Result": 34505.1,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "X640 G40 (8x A30, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 18,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6354",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "b0c7d9d815c54b80",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/A30x8_Custom_X640_G40_TRT/rnnt/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 92.55000112742113,
    "Accuracy_div_100": 0.9255,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Nettrix/results/A40X3_CUSTOM_X620_G40_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Nettrix",
    "Platform": "A40X3_CUSTOM_X620_G40_TRT",
    "Result": 7512.98,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "X620 G40 (3x A40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A40",
    "accelerators_per_node": 3,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 28,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6348",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "0429da32227b4ff6",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/A40X3_CUSTOM_X620_G40_TRT/rnnt/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 92.55225596969493,
    "Accuracy_div_100": 0.92552,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/Nettrix/results/L4x8_Custom_X640_G50_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Nettrix",
    "Platform": "L4x8_Custom_X640_G50_TRT",
    "Result": 30305.5,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "X640 G50 (8x L4, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "839cecf1a46041c9",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/L4x8_Custom_X640_G50_TRT/rnnt/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 92.54774628514735,
    "Accuracy_div_100": 0.92548,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/Nettrix/results/L4x5_Custom_X620_G50_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Nettrix",
    "Platform": "L4x5_Custom_X620_G50_TRT",
    "Result": 18752.6,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "X620 G50 (5x L4, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 5,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 32,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 6458Q",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "192c65c2e86a4e9e",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Nettrix/results/L4x5_Custom_X620_G50_TRT/rnnt/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 92.5545108119687,
    "Accuracy_div_100": 0.92555,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Inspur/results/NF5468M6_A40x8_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Inspur",
    "Platform": "NF5468M6_A40x8_TRT",
    "Result": 37510,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "NF5468M6 (8x A40, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A40",
    "accelerators_per_node": 8,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8380",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5",
    "uid": "d640fa2f021940e1",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Inspur/results/NF5468M6_A40x8_TRT/rnnt/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 92.5545108119687,
    "Accuracy_div_100": 0.92555,
    "Availability": "preview",
    "Division": "closed",
    "Location": "closed/H3C/results/R4900G6_L4x2_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "H3C",
    "Platform": "R4900G6_L4x2_TRT",
    "Result": 7453.21,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "H3C UniServer R4900 G6(2xL4, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA L4",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 40,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8460Y+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "4bfe643530354e28",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/H3C/results/R4900G6_L4x2_TRT/rnnt/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 92.55000112742113,
    "Accuracy_div_100": 0.9255,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/R5300G6_A30x10_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "H3C",
    "Platform": "R5300G6_A30x10_TRT",
    "Result": 44003.5,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "H3C UniServer R5300 G6 (10x A30, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 10,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 44,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8458P",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5",
    "uid": "7cb78107bf5d462b",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/H3C/results/R5300G6_A30x10_TRT/rnnt/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 92.53872691605223,
    "Accuracy_div_100": 0.92539,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/A2x2_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "H3C",
    "Platform": "A2x2_TRT",
    "Result": 1998.74,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "H3C UniServer R4950 G6 (2x A2, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A2",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 384,
    "host_processor_model_name": "AMD EPYC 9654 96-Core Processor",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.2",
    "uid": "3b0d4c14269f4f1e",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/H3C/results/A2x2_TRT/rnnt/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 92.5545108119687,
    "Accuracy_div_100": 0.92555,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/H3C/results/R5300G6_A30x4_TRT/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "H3C",
    "Platform": "R5300G6_A30x4_TRT",
    "Result": 8503.38,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "H3C UniServer R5300 G6 (4x A30, TensorRT)",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A30",
    "accelerators_per_node": 4,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 11.7",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 44,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8458P",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04.5",
    "uid": "00dedcc970814b3c",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/H3C/results/R5300G6_A30x4_TRT/rnnt/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 92.18020699452073,
    "Accuracy_div_100": 0.9218,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Quanta_Cloud_Technology/results/1-node-2S-SPR-PyTorch-MIX/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "Quanta_Cloud_Technology",
    "Platform": "1-node-2S-SPR-PyTorch-MIX",
    "Result": 4101.58,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "1-node-2S-SPR-PyTorch-INT8",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "PyTorch",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 2,
    "operating_system": "Rocky Linux release 9.0 (Blue Onyx)",
    "uid": "f72d7b1658cc4a93",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/Quanta_Cloud_Technology/results/1-node-2S-SPR-PyTorch-MIX/rnnt/Server",
    "version": "v3.0"
  },
  {
    "Accuracy": 92.18020699452073,
    "Accuracy_div_100": 0.9218,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/HPE/results/1-node-2S-SPR-PyTorch-MIX/rnnt/Server",
    "MlperfModel": "rnnt",
    "Model": "rnnt",
    "Organization": "HPE",
    "Platform": "1-node-2S-SPR-PyTorch-MIX",
    "Result": 4101.58,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "1-node-2S-SPR-PyTorch-MIX",
    "SystemType": "datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "N/A",
    "accelerators_per_node": 0,
    "compliance": 1,
    "errors": 0,
    "framework": "PyTorch",
    "git_url": "https://github.com/mlcommons/inference_results_v3.0",
    "has_power": false,
    "host_processor_core_count": 56,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8480+",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "ProLiant DL380a Gen11",
    "number_of_nodes": 2,
    "operating_system": "Red Hat Enterprise Linux 8.7",
    "uid": "fa9118d9e63c4e3a",
    "url": "https://github.com/mlcommons/inference_results_v3.0/tree/master/closed/HPE/results/1-node-2S-SPR-PyTorch-MIX/rnnt/Server",
    "version": "v3.0"
  }
]
