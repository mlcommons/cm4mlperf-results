[
  {
    "Accuracy": 90.25897829249658,
    "Accuracy_div_100": 0.90259,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/CTuning/results/GATE_Overflow_Intel_Sapphire_Rapids-nvidia_original-gpu-tensorrt-vdefault-default_config/bert-99/server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "CTuning",
    "Platform": "GATE_Overflow_Intel_Sapphire_Rapids-nvidia_original-gpu-tensorrt-vdefault-default_config",
    "Result": 7693.92,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "GATE Overflow Intel Sapphire Rapids (2x RTX 4090)",
    "SystemType": "edge,datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA GeForce RTX 4090",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "Nvidia inference implementation with CM API, TensorRT v9.0.0",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.6.2. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04 (linux-6.2.0-39-generic-glibc2.31)",
    "uid": "05c88e199c5e4eba",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/CTuning/results/GATE_Overflow_Intel_Sapphire_Rapids-nvidia_original-gpu-tensorrt-vdefault-default_config/bert-99/server",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.89074704580993,
    "Accuracy_div_100": 0.90891,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/CTuning/results/GATE_Overflow_Intel_Sapphire_Rapids-nvidia_original-gpu-tensorrt-vdefault-default_config/bert-99.9/server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "CTuning",
    "Platform": "GATE_Overflow_Intel_Sapphire_Rapids-nvidia_original-gpu-tensorrt-vdefault-default_config",
    "Result": 2932.14,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "GATE Overflow Intel Sapphire Rapids (2x RTX 4090)",
    "SystemType": "edge,datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA GeForce RTX 4090",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "Nvidia inference implementation with CM API, TensorRT v9.0.0",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.6.2. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04 (linux-6.2.0-39-generic-glibc2.31)",
    "uid": "8c720a95118344b0",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/CTuning/results/GATE_Overflow_Intel_Sapphire_Rapids-nvidia_original-gpu-tensorrt-vdefault-default_config/bert-99.9/server",
    "version": "v4.0"
  },
  {
    "Accuracy": 43.0003,
    "Accuracy_div_100": 0.43,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/CTuning/results/GATE_Overflow_Intel_Sapphire_Rapids-nvidia_original-gpu-tensorrt-vdefault-default_config/gptj-99/server",
    "MlperfModel": "gptj-99",
    "Model": "gptj-99",
    "Organization": "CTuning",
    "Platform": "GATE_Overflow_Intel_Sapphire_Rapids-nvidia_original-gpu-tensorrt-vdefault-default_config",
    "Result": 7.69582,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "GATE Overflow Intel Sapphire Rapids (2x RTX 4090)",
    "SystemType": "edge,datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA GeForce RTX 4090",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "Nvidia inference implementation with CM API, TensorRT v9.0.0",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.6.2. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04 (linux-6.2.0-39-generic-glibc2.31)",
    "uid": "a5f43aedc8a5425d",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/CTuning/results/GATE_Overflow_Intel_Sapphire_Rapids-nvidia_original-gpu-tensorrt-vdefault-default_config/gptj-99/server",
    "version": "v4.0"
  },
  {
    "Accuracy": 43.0003,
    "Accuracy_div_100": 0.43,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/CTuning/results/GATE_Overflow_Intel_Sapphire_Rapids-nvidia_original-gpu-tensorrt-vdefault-default_config/gptj-99.9/server",
    "MlperfModel": "gptj-99.9",
    "Model": "gptj-99.9",
    "Organization": "CTuning",
    "Platform": "GATE_Overflow_Intel_Sapphire_Rapids-nvidia_original-gpu-tensorrt-vdefault-default_config",
    "Result": 7.69582,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "GATE Overflow Intel Sapphire Rapids (2x RTX 4090)",
    "SystemType": "edge,datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA GeForce RTX 4090",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "Nvidia inference implementation with CM API, TensorRT v9.0.0",
    "git_url": "https://github.com/mlcommons/inference_results_v4.0",
    "has_power": false,
    "host_processor_core_count": 24,
    "host_processor_model_name": "Intel(R) Xeon(R) w7-2495X",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Automated by MLCommons CM v1.6.2. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 20.04 (linux-6.2.0-39-generic-glibc2.31)",
    "uid": "36444beead924f6b",
    "url": "https://github.com/mlcommons/inference_results_v4.0/tree/master/closed/CTuning/results/GATE_Overflow_Intel_Sapphire_Rapids-nvidia_original-gpu-tensorrt-vdefault-default_config/gptj-99.9/server",
    "version": "v4.0"
  },
  {
    "Accuracy": 90.24547347185802,
    "Accuracy_div_100": 0.90245,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/TTA/results/KR580S1-nvidia_original-gpu-tensorrt-vdefault-default_config/bert-99/server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "TTA",
    "Platform": "KR580S1-nvidia_original-gpu-tensorrt-vdefault-default_config",
    "Result": 539.238,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "KR580S1",
    "SystemType": "edge,datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA T4",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "tensorrt 8.6.1, ",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 36,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6140 CPU @ 2.30GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Powered by MLCommons CM automation language and CK playground",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-4.18.0-448.el8.x86_64-glibc2.35)",
    "uid": "eca543c624bb48a5",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/TTA/results/KR580S1-nvidia_original-gpu-tensorrt-vdefault-default_config/bert-99/server",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.89234189792515,
    "Accuracy_div_100": 0.90892,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/TTA/results/KR580S1-nvidia_original-gpu-tensorrt-vdefault-default_config/bert-99.9/server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "TTA",
    "Platform": "KR580S1-nvidia_original-gpu-tensorrt-vdefault-default_config",
    "Result": 249.414,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "KR580S1",
    "SystemType": "edge,datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA T4",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "tensorrt 8.6.1, ",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 36,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6140 CPU @ 2.30GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "Powered by MLCommons CM automation language and CK playground",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-4.18.0-448.el8.x86_64-glibc2.35)",
    "uid": "ffa708c6c07f4e50",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/TTA/results/KR580S1-nvidia_original-gpu-tensorrt-vdefault-default_config/bert-99.9/server",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.2297091515729,
    "Accuracy_div_100": 0.9023,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/CTuning/results/aws_g4dn.xlarge-nvidia_original-gpu-tensorrt-vdefault-default_config/bert-99/server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "CTuning",
    "Platform": "aws_g4dn.xlarge-nvidia_original-gpu-tensorrt-vdefault-default_config",
    "Result": 289.681,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "AWS cloud instance g4dn.xlarge",
    "SystemType": "edge,datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA T4",
    "accelerators_per_node": 1,
    "compliance": 1,
    "errors": 0,
    "framework": "Nvidia inference implementation with CM API, TensorRT v8.6.1.6",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 2,
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8259CL CPU @ 2.50GHz",
    "host_processors_per_node": 1,
    "inferred": 0,
    "notes": "Powered by MLCommons CM automation language and CK playground. ",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04 (linux-5.19.0-1029-aws-glibc2.35)",
    "uid": "3f9a58d9a44144c5",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/CTuning/results/aws_g4dn.xlarge-nvidia_original-gpu-tensorrt-vdefault-default_config/bert-99/server",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.38590173403216,
    "Accuracy_div_100": 0.90386,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Nutanix/results/NX_3155G_G8_A100_PCIe_80GBx2_TRT/bert-99/Server",
    "MlperfModel": "bert-99",
    "Model": "bert-99",
    "Organization": "Nutanix",
    "Platform": "NX_3155G_G8_A100_PCIe_80GBx2_TRT",
    "Result": 5603.34,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "NX_3155G_G8_A100_PCIe_80GBx2",
    "SystemType": "edge,datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 18,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6354 CPU @ 3.00GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "8f1cff0f9c7248af",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Nutanix/results/NX_3155G_G8_A100_PCIe_80GBx2_TRT/bert-99/Server",
    "version": "v3.1"
  },
  {
    "Accuracy": 90.88723524062507,
    "Accuracy_div_100": 0.90887,
    "Availability": "available",
    "Division": "closed",
    "Location": "closed/Nutanix/results/NX_3155G_G8_A100_PCIe_80GBx2_TRT/bert-99.9/Server",
    "MlperfModel": "bert-99.9",
    "Model": "bert-99.9",
    "Organization": "Nutanix",
    "Platform": "NX_3155G_G8_A100_PCIe_80GBx2_TRT",
    "Result": 2803.89,
    "Result_Units": "Queries/s",
    "Scenario": "Server",
    "SystemName": "NX_3155G_G8_A100_PCIe_80GBx2",
    "SystemType": "edge,datacenter",
    "Units": "Queries/s",
    "accelerator_model_name": "NVIDIA A100-PCIe-80GB",
    "accelerators_per_node": 2,
    "compliance": 1,
    "errors": 0,
    "framework": "TensorRT 8.6.0, CUDA 12.0",
    "git_url": "https://github.com/mlcommons/inference_results_v3.1",
    "has_power": false,
    "host_processor_core_count": 18,
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6354 CPU @ 3.00GHz",
    "host_processors_per_node": 2,
    "inferred": 0,
    "notes": "",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 22.04",
    "uid": "8c77ea0f78db4734",
    "url": "https://github.com/mlcommons/inference_results_v3.1/tree/master/closed/Nutanix/results/NX_3155G_G8_A100_PCIe_80GBx2_TRT/bert-99.9/Server",
    "version": "v3.1"
  }
]
